{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "VdCNU0ZLCrrK",
        "QpZnQ-33Eqy3",
        "M9I3DWddEu8O",
        "xpyzuOx7F_XZ",
        "7CerADR6GeA2",
        "aF4JpACxJTZX",
        "Ln24p1NLJYa5",
        "vVDMfALiJhgb",
        "tiP6vNzqJ2fs"
      ],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Setup"
      ],
      "metadata": {
        "id": "-Tb57b8D-s8M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9t17i2U-d71",
        "outputId": "aba10ea3-1b26-4bab-b422-663f7550760f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'GKD'...\n",
            "remote: Enumerating objects: 48, done.\u001b[K\n",
            "remote: Counting objects: 100% (48/48), done.\u001b[K\n",
            "remote: Compressing objects: 100% (32/32), done.\u001b[K\n",
            "remote: Total 48 (delta 23), reused 39 (delta 14), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (48/48), 402.63 KiB | 1.68 MiB/s, done.\n",
            "Resolving deltas: 100% (23/23), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/chr26195/GKD.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd GKD && pip3 install -r requirements.txt\n",
        "\n",
        "import torch\n",
        "\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "!pip install torch-cluster -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "!pip install git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "!pip install ogb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iADYxBdO-g6B",
        "outputId": "6d9e6e9a-e236-465e-ec2c-5eabde1ddabe"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: googledrivedownloader==0.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (0.4)\n",
            "Collecting numpy==1.21.5 (from -r requirements.txt (line 2))\n",
            "  Downloading numpy-1.21.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m91.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ogb==1.3.3 (from -r requirements.txt (line 3))\n",
            "  Downloading ogb-1.3.3-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.2/78.2 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit_learn==1.1.3 (from -r requirements.txt (line 4))\n",
            "  Downloading scikit_learn-1.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.5/30.5 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy==1.7.3 (from -r requirements.txt (line 5))\n",
            "  Downloading scipy-1.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Ignored the following versions that require a different python version: 1.6.2 Requires-Python >=3.7,<3.10; 1.6.3 Requires-Python >=3.7,<3.10; 1.7.0 Requires-Python >=3.7,<3.10; 1.7.1 Requires-Python >=3.7,<3.10\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.9.0 (from versions: 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 2.0.0, 2.0.1, 2.1.0, 2.1.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.9.0\u001b[0m\u001b[31m\n",
            "\u001b[0mLooking in links: https://data.pyg.org/whl/torch-2.1.0+cu118.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu118/torch_scatter-2.1.2%2Bpt21cu118-cp310-cp310-linux_x86_64.whl (10.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.2+pt21cu118\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.1.0+cu118.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu118/torch_sparse-0.6.18%2Bpt21cu118-cp310-cp310-linux_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.23.5)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.18+pt21cu118\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.1.0+cu118.html\n",
            "Collecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu118/torch_cluster-1.6.3%2Bpt21cu118-cp310-cp310-linux_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-cluster) (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-cluster) (1.23.5)\n",
            "Installing collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.6.3+pt21cu118\n",
            "Collecting git+https://github.com/pyg-team/pytorch_geometric.git\n",
            "  Cloning https://github.com/pyg-team/pytorch_geometric.git to /tmp/pip-req-build-7qf0unxa\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/pyg-team/pytorch_geometric.git /tmp/pip-req-build-7qf0unxa\n",
            "  Resolved https://github.com/pyg-team/pytorch_geometric.git to commit 699120e2584077b0113eb9519e58c5e3dbcc1ec6\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (1.11.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (2023.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (3.1.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (3.9.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0) (5.9.5)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric==2.4.0) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric==2.4.0) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric==2.4.0) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric==2.4.0) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric==2.4.0) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric==2.4.0) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric==2.4.0) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.4.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.4.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.4.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.4.0) (2023.11.17)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric==2.4.0) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric==2.4.0) (3.2.0)\n",
            "Building wheels for collected packages: torch_geometric\n",
            "  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch_geometric: filename=torch_geometric-2.4.0-py3-none-any.whl size=1065432 sha256=cf85b35c191a7e2fbea06ea26af1debbe7e751f9a7be1a77749be97b25501170\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-gs7owmpi/wheels/d3/78/eb/9e26525b948d19533f1688fb6c209cec8a0ba793d39b49ae8f\n",
            "Successfully built torch_geometric\n",
            "Installing collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.4.0\n",
            "Collecting ogb\n",
            "  Downloading ogb-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (2.1.0+cu118)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.23.5)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (4.66.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.2.2)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.5.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (2.0.7)\n",
            "Collecting outdated>=0.2.0 (from ogb)\n",
            "  Downloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb) (67.7.2)\n",
            "Collecting littleutils (from outdated>=0.2.0->ogb)\n",
            "  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb) (2.31.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb) (2023.3.post1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->ogb) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->ogb) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->ogb) (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->ogb) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->ogb) (1.3.0)\n",
            "Building wheels for collected packages: littleutils\n",
            "  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7026 sha256=24df9c501489c09239e2f6a5032216bd5cadc2210a293d07d637d3a6b1066138\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/fe/b0/27a9892da57472e538c7452a721a9cf463cc03cf7379889266\n",
            "Successfully built littleutils\n",
            "Installing collected packages: littleutils, outdated, ogb\n",
            "Successfully installed littleutils-0.2.2 ogb-1.3.6 outdated-0.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/CUAI/Non-Homophily-Large-Scale.git && cp -r Non-Homophily-Large-Scale/data/facebook100 datafacebook100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9iw4i9Ec8g3",
        "outputId": "1f7d9b0f-a10a-49ce-973c-5b67804b1685"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Non-Homophily-Large-Scale'...\n",
            "remote: Enumerating objects: 157, done.\u001b[K\n",
            "remote: Counting objects: 100% (157/157), done.\u001b[K\n",
            "remote: Compressing objects: 100% (116/116), done.\u001b[K\n",
            "remote: Total 157 (delta 57), reused 133 (delta 39), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (157/157), 34.60 MiB | 10.57 MiB/s, done.\n",
            "Resolving deltas: 100% (57/57), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd datafacebook100 && ls"
      ],
      "metadata": {
        "id": "Bwlof_CvsqVk"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir saved_models"
      ],
      "metadata": {
        "id": "zfFYOqoh-j6S"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir logs"
      ],
      "metadata": {
        "id": "2sZalwm3-m0Y"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Results"
      ],
      "metadata": {
        "id": "LEBbfgfTCTaC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PubMed"
      ],
      "metadata": {
        "id": "VdCNU0ZLCrrK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Pre-train Data"
      ],
      "metadata": {
        "id": "r3yXHR2z-21A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 GKD/main.py --dataset pubmed --rand_split --use_bn --base_model gcn --mode pretrain --dist_mode no --save_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmC_XGlG-oic",
        "outputId": "f52ef67d-a294-45d8-c080-4b01576676a4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(data_dir='data', dataset='pubmed', sub_dataset='', cpu=False, seed=42, train_prop=0.5, valid_prop=0.25, protocol='semi', rand_split=True, metric='acc', runs=5, epochs=200, hidden_channels=32, num_layers=3, gat_heads=8, out_heads=1, hops=1, lp_alpha=0.1, gpr_alpha=0.1, jk_type='max', directed=False, num_mlp_layers=1, display_step=5, cached=False, print_prop=False, priv_type='edge', priv_ratio=0.5, save_model=True, save_name='gcn', log_name='none', base_model='gcn', not_load_teacher=False, mode='pretrain', dist_mode='no', weight_decay=0.05, dropout=0.0, lr=0.01, use_bn=True, use_batch=False, batch_size=2048, oracle=False, device=0, alpha=0.5, delta=0.1, use_kd=False, beta=0.0, tau=1.0, kernel='sigmoid', t=1.0, include_last=False, s=2, m=1, lr2=0.001, sim='l2', ker_norm=False)\n",
            "cuda:0\n",
            "pubmed\n",
            "Num nodes: 19717\n",
            "torch.Size([19717, 1])\n",
            "num nodes 19717 | num classes 3 | num node feats 500\n",
            "MODEL: GeoDist(\n",
            "  (k): Kernel(\n",
            "    (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  )\n",
            "  (teacher_gnn): ModuleList(\n",
            "    (0): Linear(in_features=500, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (student_gnn): ModuleList(\n",
            "    (0): Linear(in_features=500, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  (bns2d): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            ")\n",
            "Epoch: 00, Loss: 1.6011, Train: 67.54%, Valid: 66.95%, Test: 64.60%\n",
            "Epoch: 05, Loss: 0.5158, Train: 83.47%, Valid: 82.00%, Test: 81.60%\n",
            "Epoch: 10, Loss: 0.4209, Train: 85.41%, Valid: 83.79%, Test: 83.63%\n",
            "Epoch: 15, Loss: 0.3833, Train: 86.47%, Valid: 84.34%, Test: 84.32%\n",
            "Epoch: 20, Loss: 0.3598, Train: 87.56%, Valid: 85.07%, Test: 84.77%\n",
            "Epoch: 25, Loss: 0.3334, Train: 88.73%, Valid: 85.82%, Test: 84.54%\n",
            "Epoch: 30, Loss: 0.3052, Train: 89.81%, Valid: 85.84%, Test: 84.81%\n",
            "Epoch: 35, Loss: 0.3290, Train: 88.27%, Valid: 86.02%, Test: 84.52%\n",
            "Epoch: 40, Loss: 0.3126, Train: 89.18%, Valid: 86.00%, Test: 84.79%\n",
            "Epoch: 45, Loss: 0.2865, Train: 90.77%, Valid: 86.39%, Test: 84.77%\n",
            "Epoch: 50, Loss: 0.2718, Train: 91.24%, Valid: 86.04%, Test: 84.36%\n",
            "Epoch: 55, Loss: 0.3347, Train: 88.59%, Valid: 85.64%, Test: 84.79%\n",
            "Epoch: 60, Loss: 0.3097, Train: 89.80%, Valid: 85.76%, Test: 85.25%\n",
            "Epoch: 65, Loss: 0.2822, Train: 90.78%, Valid: 86.43%, Test: 84.38%\n",
            "Epoch: 70, Loss: 0.2600, Train: 91.84%, Valid: 86.24%, Test: 83.77%\n",
            "Epoch: 75, Loss: 0.4261, Train: 87.34%, Valid: 84.58%, Test: 83.63%\n",
            "Epoch: 80, Loss: 0.3486, Train: 88.04%, Valid: 85.90%, Test: 85.23%\n",
            "Epoch: 85, Loss: 0.3288, Train: 88.71%, Valid: 86.14%, Test: 84.87%\n",
            "Epoch: 90, Loss: 0.3094, Train: 89.69%, Valid: 86.61%, Test: 85.40%\n",
            "Epoch: 95, Loss: 0.2872, Train: 90.63%, Valid: 86.33%, Test: 83.98%\n",
            "Epoch: 100, Loss: 0.2631, Train: 90.67%, Valid: 85.76%, Test: 82.35%\n",
            "Epoch: 105, Loss: 0.3058, Train: 89.74%, Valid: 85.84%, Test: 85.46%\n",
            "Epoch: 110, Loss: 0.2785, Train: 90.63%, Valid: 86.53%, Test: 84.58%\n",
            "Epoch: 115, Loss: 0.2572, Train: 91.55%, Valid: 86.33%, Test: 83.98%\n",
            "Epoch: 120, Loss: 0.4413, Train: 88.23%, Valid: 85.11%, Test: 84.65%\n",
            "Epoch: 125, Loss: 0.3156, Train: 89.30%, Valid: 86.26%, Test: 85.58%\n",
            "Epoch: 130, Loss: 0.2921, Train: 90.46%, Valid: 86.35%, Test: 84.75%\n",
            "Epoch: 135, Loss: 0.2684, Train: 91.42%, Valid: 86.73%, Test: 84.02%\n",
            "Epoch: 140, Loss: 0.2588, Train: 92.21%, Valid: 86.51%, Test: 84.12%\n",
            "Epoch: 145, Loss: 0.2402, Train: 91.45%, Valid: 85.07%, Test: 81.36%\n",
            "Epoch: 150, Loss: 0.3427, Train: 88.25%, Valid: 85.60%, Test: 85.38%\n",
            "Epoch: 155, Loss: 0.3117, Train: 89.83%, Valid: 86.49%, Test: 85.38%\n",
            "Epoch: 160, Loss: 0.2832, Train: 90.96%, Valid: 86.77%, Test: 84.48%\n",
            "Epoch: 165, Loss: 0.2743, Train: 91.71%, Valid: 86.59%, Test: 84.30%\n",
            "Epoch: 170, Loss: 0.2460, Train: 92.06%, Valid: 86.69%, Test: 83.83%\n",
            "Epoch: 175, Loss: 0.3708, Train: 86.89%, Valid: 84.58%, Test: 83.59%\n",
            "Epoch: 180, Loss: 0.3531, Train: 88.48%, Valid: 85.58%, Test: 85.19%\n",
            "Epoch: 185, Loss: 0.3159, Train: 89.93%, Valid: 86.47%, Test: 85.52%\n",
            "Epoch: 190, Loss: 0.2904, Train: 90.82%, Valid: 86.79%, Test: 85.15%\n",
            "Epoch: 195, Loss: 0.2676, Train: 91.84%, Valid: 86.65%, Test: 84.00%\n",
            "Run 01:\n",
            "Highest Train: 93.14\n",
            "Highest Valid: 87.08\n",
            "Highest Test: 85.84\n",
            "Chosen epoch: 190\n",
            "Final Train: 90.30\n",
            "Final Test: 85.15\n",
            "Epoch: 00, Loss: 1.4893, Train: 74.56%, Valid: 72.98%, Test: 72.37%\n",
            "Epoch: 05, Loss: 0.4671, Train: 84.57%, Valid: 82.96%, Test: 82.88%\n",
            "Epoch: 10, Loss: 0.4017, Train: 86.18%, Valid: 84.50%, Test: 84.44%\n",
            "Epoch: 15, Loss: 0.3691, Train: 87.52%, Valid: 85.60%, Test: 85.11%\n",
            "Epoch: 20, Loss: 0.3427, Train: 88.15%, Valid: 85.58%, Test: 85.74%\n",
            "Epoch: 25, Loss: 0.3167, Train: 89.61%, Valid: 86.04%, Test: 85.72%\n",
            "Epoch: 30, Loss: 0.3149, Train: 87.74%, Valid: 85.17%, Test: 84.40%\n",
            "Epoch: 35, Loss: 0.3034, Train: 89.58%, Valid: 86.31%, Test: 84.75%\n",
            "Epoch: 40, Loss: 0.2837, Train: 90.64%, Valid: 86.18%, Test: 84.46%\n",
            "Epoch: 45, Loss: 0.2669, Train: 91.15%, Valid: 85.90%, Test: 84.95%\n",
            "Epoch: 50, Loss: 0.5875, Train: 82.96%, Valid: 81.33%, Test: 81.40%\n",
            "Epoch: 55, Loss: 0.3665, Train: 87.55%, Valid: 85.15%, Test: 85.27%\n",
            "Epoch: 60, Loss: 0.3460, Train: 88.40%, Valid: 86.04%, Test: 85.58%\n",
            "Epoch: 65, Loss: 0.3216, Train: 89.50%, Valid: 86.29%, Test: 85.90%\n",
            "Epoch: 70, Loss: 0.3014, Train: 89.84%, Valid: 86.16%, Test: 85.64%\n",
            "Epoch: 75, Loss: 0.2800, Train: 90.58%, Valid: 85.64%, Test: 85.23%\n",
            "Epoch: 80, Loss: 0.2887, Train: 90.85%, Valid: 86.65%, Test: 85.98%\n",
            "Epoch: 85, Loss: 0.2669, Train: 91.43%, Valid: 86.00%, Test: 84.42%\n",
            "Epoch: 90, Loss: 0.3085, Train: 89.75%, Valid: 85.86%, Test: 84.75%\n",
            "Epoch: 95, Loss: 0.2889, Train: 90.71%, Valid: 86.29%, Test: 85.64%\n",
            "Epoch: 100, Loss: 0.2669, Train: 91.50%, Valid: 86.65%, Test: 85.15%\n",
            "Epoch: 105, Loss: 0.2542, Train: 91.14%, Valid: 85.62%, Test: 83.75%\n",
            "Epoch: 110, Loss: 0.2799, Train: 90.22%, Valid: 86.20%, Test: 85.25%\n",
            "Epoch: 115, Loss: 0.2713, Train: 91.94%, Valid: 86.73%, Test: 84.87%\n",
            "Epoch: 120, Loss: 0.2599, Train: 92.04%, Valid: 85.55%, Test: 83.89%\n",
            "Epoch: 125, Loss: 0.2378, Train: 91.87%, Valid: 86.00%, Test: 83.63%\n",
            "Epoch: 130, Loss: 0.3001, Train: 90.20%, Valid: 85.80%, Test: 84.40%\n",
            "Epoch: 135, Loss: 0.2819, Train: 91.55%, Valid: 86.65%, Test: 85.66%\n",
            "Epoch: 140, Loss: 0.2497, Train: 92.10%, Valid: 86.39%, Test: 84.60%\n",
            "Epoch: 145, Loss: 0.2297, Train: 92.36%, Valid: 85.64%, Test: 84.44%\n",
            "Epoch: 150, Loss: 0.3221, Train: 90.26%, Valid: 86.20%, Test: 85.72%\n",
            "Epoch: 155, Loss: 0.2889, Train: 91.09%, Valid: 86.73%, Test: 86.33%\n",
            "Epoch: 160, Loss: 0.2602, Train: 92.14%, Valid: 86.53%, Test: 85.42%\n",
            "Epoch: 165, Loss: 0.2354, Train: 92.71%, Valid: 86.16%, Test: 84.14%\n",
            "Epoch: 170, Loss: 0.2798, Train: 90.90%, Valid: 85.45%, Test: 84.24%\n",
            "Epoch: 175, Loss: 0.2434, Train: 91.78%, Valid: 85.76%, Test: 84.81%\n",
            "Epoch: 180, Loss: 0.2463, Train: 92.64%, Valid: 86.06%, Test: 84.46%\n",
            "Epoch: 185, Loss: 0.2294, Train: 92.35%, Valid: 85.74%, Test: 83.65%\n",
            "Epoch: 190, Loss: 0.3364, Train: 90.23%, Valid: 85.37%, Test: 84.91%\n",
            "Epoch: 195, Loss: 0.2909, Train: 91.08%, Valid: 86.47%, Test: 85.76%\n",
            "Run 02:\n",
            "Highest Train: 93.23\n",
            "Highest Valid: 87.08\n",
            "Highest Test: 86.51\n",
            "Chosen epoch: 195\n",
            "Final Train: 90.97\n",
            "Final Test: 85.80\n",
            "Epoch: 00, Loss: 1.2459, Train: 70.06%, Valid: 69.87%, Test: 67.73%\n",
            "Epoch: 05, Loss: 0.4830, Train: 84.40%, Valid: 82.73%, Test: 82.29%\n",
            "Epoch: 10, Loss: 0.4219, Train: 85.67%, Valid: 83.75%, Test: 83.87%\n",
            "Epoch: 15, Loss: 0.3899, Train: 86.80%, Valid: 84.62%, Test: 85.07%\n",
            "Epoch: 20, Loss: 0.3625, Train: 87.84%, Valid: 85.07%, Test: 85.15%\n",
            "Epoch: 25, Loss: 0.3321, Train: 88.89%, Valid: 85.62%, Test: 85.11%\n",
            "Epoch: 30, Loss: 0.3052, Train: 86.38%, Valid: 83.22%, Test: 82.07%\n",
            "Epoch: 35, Loss: 0.3249, Train: 88.64%, Valid: 86.00%, Test: 85.21%\n",
            "Epoch: 40, Loss: 0.2950, Train: 90.05%, Valid: 86.43%, Test: 85.07%\n",
            "Epoch: 45, Loss: 0.2718, Train: 91.02%, Valid: 86.45%, Test: 84.02%\n",
            "Epoch: 50, Loss: 0.2967, Train: 88.52%, Valid: 85.29%, Test: 83.29%\n",
            "Epoch: 55, Loss: 0.2960, Train: 90.46%, Valid: 86.79%, Test: 85.54%\n",
            "Epoch: 60, Loss: 0.2732, Train: 90.92%, Valid: 86.53%, Test: 85.70%\n",
            "Epoch: 65, Loss: 0.2770, Train: 90.65%, Valid: 85.78%, Test: 84.06%\n",
            "Epoch: 70, Loss: 0.2685, Train: 91.58%, Valid: 86.47%, Test: 84.83%\n",
            "Epoch: 75, Loss: 0.2610, Train: 90.64%, Valid: 85.53%, Test: 82.94%\n",
            "Epoch: 80, Loss: 0.3155, Train: 89.97%, Valid: 86.16%, Test: 86.21%\n",
            "Epoch: 85, Loss: 0.2935, Train: 90.62%, Valid: 86.47%, Test: 85.03%\n",
            "Epoch: 90, Loss: 0.2674, Train: 91.94%, Valid: 86.61%, Test: 84.89%\n",
            "Epoch: 95, Loss: 0.2452, Train: 92.21%, Valid: 86.20%, Test: 84.16%\n",
            "Epoch: 100, Loss: 0.3436, Train: 88.22%, Valid: 85.05%, Test: 84.50%\n",
            "Epoch: 105, Loss: 0.3116, Train: 89.70%, Valid: 86.29%, Test: 84.56%\n",
            "Epoch: 110, Loss: 0.2883, Train: 91.05%, Valid: 86.79%, Test: 85.07%\n",
            "Epoch: 115, Loss: 0.2617, Train: 91.97%, Valid: 86.61%, Test: 84.18%\n",
            "Epoch: 120, Loss: 0.2973, Train: 89.10%, Valid: 85.51%, Test: 84.62%\n",
            "Epoch: 125, Loss: 0.2989, Train: 90.63%, Valid: 86.12%, Test: 84.36%\n",
            "Epoch: 130, Loss: 0.2671, Train: 91.62%, Valid: 86.14%, Test: 83.94%\n",
            "Epoch: 135, Loss: 0.2418, Train: 92.56%, Valid: 86.71%, Test: 83.61%\n",
            "Epoch: 140, Loss: 0.3446, Train: 88.07%, Valid: 84.78%, Test: 83.29%\n",
            "Epoch: 145, Loss: 0.3105, Train: 90.06%, Valid: 85.86%, Test: 84.28%\n",
            "Epoch: 150, Loss: 0.2807, Train: 90.75%, Valid: 86.24%, Test: 83.85%\n",
            "Epoch: 155, Loss: 0.2566, Train: 91.85%, Valid: 86.10%, Test: 83.08%\n",
            "Epoch: 160, Loss: 0.3799, Train: 88.26%, Valid: 84.97%, Test: 84.24%\n",
            "Epoch: 165, Loss: 0.3320, Train: 89.13%, Valid: 85.84%, Test: 85.52%\n",
            "Epoch: 170, Loss: 0.2964, Train: 90.38%, Valid: 86.18%, Test: 84.71%\n",
            "Epoch: 175, Loss: 0.2697, Train: 91.37%, Valid: 86.87%, Test: 84.60%\n",
            "Epoch: 180, Loss: 0.2454, Train: 92.04%, Valid: 85.98%, Test: 84.08%\n",
            "Epoch: 185, Loss: 0.2952, Train: 90.22%, Valid: 86.41%, Test: 85.44%\n",
            "Epoch: 190, Loss: 0.2753, Train: 91.72%, Valid: 86.53%, Test: 83.94%\n",
            "Epoch: 195, Loss: 0.2486, Train: 92.66%, Valid: 86.29%, Test: 83.43%\n",
            "Run 03:\n",
            "Highest Train: 92.66\n",
            "Highest Valid: 86.87\n",
            "Highest Test: 86.21\n",
            "Chosen epoch: 176\n",
            "Final Train: 91.37\n",
            "Final Test: 84.60\n",
            "Epoch: 00, Loss: 1.4781, Train: 65.28%, Valid: 64.07%, Test: 63.35%\n",
            "Epoch: 05, Loss: 0.4638, Train: 84.18%, Valid: 82.88%, Test: 82.88%\n",
            "Epoch: 10, Loss: 0.4134, Train: 85.64%, Valid: 83.95%, Test: 84.75%\n",
            "Epoch: 15, Loss: 0.3879, Train: 86.66%, Valid: 84.60%, Test: 85.58%\n",
            "Epoch: 20, Loss: 0.3661, Train: 87.61%, Valid: 85.29%, Test: 85.54%\n",
            "Epoch: 25, Loss: 0.3452, Train: 88.52%, Valid: 85.66%, Test: 85.44%\n",
            "Epoch: 30, Loss: 0.3190, Train: 89.60%, Valid: 86.12%, Test: 85.15%\n",
            "Epoch: 35, Loss: 0.3685, Train: 87.69%, Valid: 84.46%, Test: 84.28%\n",
            "Epoch: 40, Loss: 0.3200, Train: 89.26%, Valid: 85.98%, Test: 85.72%\n",
            "Epoch: 45, Loss: 0.3015, Train: 90.20%, Valid: 86.61%, Test: 85.33%\n",
            "Epoch: 50, Loss: 0.2848, Train: 90.69%, Valid: 86.29%, Test: 84.77%\n",
            "Epoch: 55, Loss: 0.2638, Train: 90.22%, Valid: 85.45%, Test: 84.26%\n",
            "Epoch: 60, Loss: 0.3540, Train: 88.06%, Valid: 85.86%, Test: 85.03%\n",
            "Epoch: 65, Loss: 0.3186, Train: 89.82%, Valid: 86.08%, Test: 85.54%\n",
            "Epoch: 70, Loss: 0.2926, Train: 90.18%, Valid: 86.69%, Test: 85.70%\n",
            "Epoch: 75, Loss: 0.2763, Train: 90.85%, Valid: 86.35%, Test: 85.03%\n",
            "Epoch: 80, Loss: 0.2773, Train: 91.49%, Valid: 86.33%, Test: 85.01%\n",
            "Epoch: 85, Loss: 0.3148, Train: 90.32%, Valid: 86.04%, Test: 84.00%\n",
            "Epoch: 90, Loss: 0.2567, Train: 91.47%, Valid: 86.18%, Test: 84.08%\n",
            "Epoch: 95, Loss: 0.2467, Train: 90.92%, Valid: 85.23%, Test: 84.06%\n",
            "Epoch: 100, Loss: 0.3457, Train: 87.90%, Valid: 84.99%, Test: 85.38%\n",
            "Epoch: 105, Loss: 0.3124, Train: 89.60%, Valid: 86.26%, Test: 85.66%\n",
            "Epoch: 110, Loss: 0.2853, Train: 90.72%, Valid: 86.26%, Test: 84.91%\n",
            "Epoch: 115, Loss: 0.2672, Train: 91.50%, Valid: 86.29%, Test: 84.56%\n",
            "Epoch: 120, Loss: 0.2655, Train: 89.01%, Valid: 84.18%, Test: 83.08%\n",
            "Epoch: 125, Loss: 0.2634, Train: 91.51%, Valid: 86.29%, Test: 83.69%\n",
            "Epoch: 130, Loss: 0.2594, Train: 91.47%, Valid: 85.66%, Test: 84.26%\n",
            "Epoch: 135, Loss: 0.2792, Train: 91.53%, Valid: 86.43%, Test: 84.87%\n",
            "Epoch: 140, Loss: 0.2491, Train: 91.88%, Valid: 85.72%, Test: 83.83%\n",
            "Epoch: 145, Loss: 0.2412, Train: 92.26%, Valid: 85.92%, Test: 84.04%\n",
            "Epoch: 150, Loss: 0.2428, Train: 92.49%, Valid: 86.39%, Test: 84.18%\n",
            "Epoch: 155, Loss: 0.2616, Train: 90.44%, Valid: 85.33%, Test: 84.46%\n",
            "Epoch: 160, Loss: 0.2575, Train: 92.03%, Valid: 86.49%, Test: 84.69%\n",
            "Epoch: 165, Loss: 0.2613, Train: 91.06%, Valid: 85.13%, Test: 83.96%\n",
            "Epoch: 170, Loss: 0.2369, Train: 92.39%, Valid: 85.70%, Test: 83.69%\n",
            "Epoch: 175, Loss: 0.2363, Train: 92.97%, Valid: 86.20%, Test: 83.98%\n",
            "Epoch: 180, Loss: 0.2573, Train: 84.46%, Valid: 79.16%, Test: 76.19%\n",
            "Epoch: 185, Loss: 0.3532, Train: 88.85%, Valid: 85.98%, Test: 86.13%\n",
            "Epoch: 190, Loss: 0.3135, Train: 89.75%, Valid: 86.26%, Test: 85.35%\n",
            "Epoch: 195, Loss: 0.2986, Train: 90.25%, Valid: 86.63%, Test: 86.02%\n",
            "Run 04:\n",
            "Highest Train: 93.45\n",
            "Highest Valid: 86.91\n",
            "Highest Test: 86.15\n",
            "Chosen epoch: 90\n",
            "Final Train: 91.79\n",
            "Final Test: 84.69\n",
            "Epoch: 00, Loss: 1.2116, Train: 75.49%, Valid: 75.15%, Test: 73.53%\n",
            "Epoch: 05, Loss: 0.4395, Train: 84.73%, Valid: 82.80%, Test: 83.16%\n",
            "Epoch: 10, Loss: 0.3954, Train: 86.23%, Valid: 84.46%, Test: 84.58%\n",
            "Epoch: 15, Loss: 0.3690, Train: 87.55%, Valid: 85.01%, Test: 85.38%\n",
            "Epoch: 20, Loss: 0.3448, Train: 88.18%, Valid: 85.78%, Test: 86.25%\n",
            "Epoch: 25, Loss: 0.3388, Train: 88.75%, Valid: 85.64%, Test: 86.39%\n",
            "Epoch: 30, Loss: 0.3068, Train: 90.08%, Valid: 85.92%, Test: 85.58%\n",
            "Epoch: 35, Loss: 0.3240, Train: 90.13%, Valid: 86.04%, Test: 86.45%\n",
            "Epoch: 40, Loss: 0.2737, Train: 90.32%, Valid: 86.43%, Test: 84.18%\n",
            "Epoch: 45, Loss: 0.2702, Train: 91.27%, Valid: 86.35%, Test: 86.25%\n",
            "Epoch: 50, Loss: 0.2926, Train: 90.55%, Valid: 86.20%, Test: 85.44%\n",
            "Epoch: 55, Loss: 0.2663, Train: 92.01%, Valid: 86.35%, Test: 85.50%\n",
            "Epoch: 60, Loss: 0.2593, Train: 91.46%, Valid: 85.94%, Test: 85.35%\n",
            "Epoch: 65, Loss: 0.2699, Train: 91.65%, Valid: 86.10%, Test: 85.11%\n",
            "Epoch: 70, Loss: 0.2761, Train: 92.21%, Valid: 86.26%, Test: 85.33%\n",
            "Epoch: 75, Loss: 0.2645, Train: 91.58%, Valid: 86.04%, Test: 85.13%\n",
            "Epoch: 80, Loss: 0.2627, Train: 92.25%, Valid: 85.84%, Test: 83.87%\n",
            "Epoch: 85, Loss: 0.2567, Train: 91.33%, Valid: 85.90%, Test: 84.58%\n",
            "Epoch: 90, Loss: 0.2432, Train: 92.14%, Valid: 86.12%, Test: 84.81%\n",
            "Epoch: 95, Loss: 0.2405, Train: 89.68%, Valid: 84.09%, Test: 83.85%\n",
            "Epoch: 100, Loss: 0.2734, Train: 91.18%, Valid: 86.16%, Test: 84.24%\n",
            "Epoch: 105, Loss: 0.2491, Train: 92.37%, Valid: 86.61%, Test: 84.58%\n",
            "Epoch: 110, Loss: 0.3063, Train: 84.34%, Valid: 80.34%, Test: 79.82%\n",
            "Epoch: 115, Loss: 0.3317, Train: 88.83%, Valid: 85.74%, Test: 85.80%\n",
            "Epoch: 120, Loss: 0.2989, Train: 90.31%, Valid: 85.76%, Test: 85.31%\n",
            "Epoch: 125, Loss: 0.2746, Train: 91.39%, Valid: 86.51%, Test: 85.35%\n",
            "Epoch: 130, Loss: 0.2756, Train: 86.91%, Valid: 82.25%, Test: 79.23%\n",
            "Epoch: 135, Loss: 0.2995, Train: 89.92%, Valid: 85.78%, Test: 84.52%\n",
            "Epoch: 140, Loss: 0.2751, Train: 91.18%, Valid: 86.55%, Test: 85.48%\n",
            "Epoch: 145, Loss: 0.2501, Train: 92.04%, Valid: 86.33%, Test: 84.44%\n",
            "Epoch: 150, Loss: 0.2824, Train: 90.55%, Valid: 86.02%, Test: 84.93%\n",
            "Epoch: 155, Loss: 0.2673, Train: 91.63%, Valid: 86.26%, Test: 85.35%\n",
            "Epoch: 160, Loss: 0.2444, Train: 92.15%, Valid: 86.20%, Test: 84.60%\n",
            "Epoch: 165, Loss: 0.2297, Train: 93.01%, Valid: 86.04%, Test: 83.61%\n",
            "Epoch: 170, Loss: 0.2495, Train: 89.39%, Valid: 83.61%, Test: 81.64%\n",
            "Epoch: 175, Loss: 0.2947, Train: 90.35%, Valid: 85.96%, Test: 85.19%\n",
            "Epoch: 180, Loss: 0.2650, Train: 91.79%, Valid: 86.55%, Test: 84.95%\n",
            "Epoch: 185, Loss: 0.2415, Train: 92.28%, Valid: 86.10%, Test: 84.20%\n",
            "Epoch: 190, Loss: 0.3144, Train: 90.03%, Valid: 85.78%, Test: 85.40%\n",
            "Epoch: 195, Loss: 0.2727, Train: 91.38%, Valid: 86.35%, Test: 85.42%\n",
            "Run 05:\n",
            "Highest Train: 93.32\n",
            "Highest Valid: 86.89\n",
            "Highest Test: 86.57\n",
            "Chosen epoch: 142\n",
            "Final Train: 91.66\n",
            "Final Test: 85.31\n",
            "All runs:\n",
            "Highest Train: 93.16 ± 0.30\n",
            "Highest Test: 86.26 ± 0.30\n",
            "Highest Valid: 86.97 ± 0.10\n",
            "  Final Train: 91.22 ± 0.60\n",
            "   Final Test: 85.11 ± 0.49\n",
            "Saving results to logs/pubmed_edge.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Edge Aware Setting\n"
      ],
      "metadata": {
        "id": "kuu1GlEdCGTD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 GKD/main.py --dataset pubmed --rand_split --use_bn --base_model gcn --mode train --priv_type edge --dist_mode gkd --kernel sigmoid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yK1cu8zj-z32",
        "outputId": "003fa41b-202d-4e41-c28f-bf30aaf03251"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(data_dir='data', dataset='pubmed', sub_dataset='', cpu=False, seed=42, train_prop=0.5, valid_prop=0.25, protocol='semi', rand_split=True, metric='acc', runs=5, epochs=200, hidden_channels=32, num_layers=3, gat_heads=8, out_heads=1, hops=1, lp_alpha=0.1, gpr_alpha=0.1, jk_type='max', directed=False, num_mlp_layers=1, display_step=5, cached=False, print_prop=False, priv_type='edge', priv_ratio=0.5, save_model=False, save_name='gcn', log_name='none', base_model='gcn', not_load_teacher=False, mode='train', dist_mode='gkd', weight_decay=0.05, dropout=0.0, lr=0.01, use_bn=True, use_batch=False, batch_size=2048, oracle=False, device=0, alpha=0.5, delta=0.1, use_kd=False, beta=0.0, tau=1.0, kernel='sigmoid', t=1.0, include_last=False, s=2, m=1, lr2=0.001, sim='l2', ker_norm=False)\n",
            "cuda:0\n",
            "pubmed\n",
            "Num nodes: 19717\n",
            "torch.Size([19717, 1])\n",
            "num nodes 19717 | num classes 3 | num node feats 500\n",
            "MODEL: GeoDist(\n",
            "  (k): Kernel(\n",
            "    (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  )\n",
            "  (teacher_gnn): ModuleList(\n",
            "    (0): Linear(in_features=500, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (student_gnn): ModuleList(\n",
            "    (0): Linear(in_features=500, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  (bns2d): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            ")\n",
            "Epoch: 00, Loss: 30492376.0000, Train: 46.48%, Valid: 46.62%, Test: 46.29%\n",
            "Epoch: 05, Loss: 13358913.0000, Train: 67.37%, Valid: 67.11%, Test: 67.04%\n",
            "Epoch: 10, Loss: 10831945.0000, Train: 83.04%, Valid: 81.09%, Test: 82.13%\n",
            "Epoch: 15, Loss: 9545926.0000, Train: 85.30%, Valid: 82.86%, Test: 83.53%\n",
            "Epoch: 20, Loss: 8710532.0000, Train: 85.77%, Valid: 83.22%, Test: 84.28%\n",
            "Epoch: 25, Loss: 8053471.0000, Train: 86.65%, Valid: 83.83%, Test: 85.13%\n",
            "Epoch: 30, Loss: 7536694.5000, Train: 87.55%, Valid: 84.24%, Test: 85.15%\n",
            "Epoch: 35, Loss: 7110733.5000, Train: 88.04%, Valid: 84.95%, Test: 85.58%\n",
            "Epoch: 40, Loss: 6768037.5000, Train: 88.36%, Valid: 85.53%, Test: 85.82%\n",
            "Epoch: 45, Loss: 6493394.0000, Train: 88.80%, Valid: 85.58%, Test: 86.19%\n",
            "Epoch: 50, Loss: 6261611.0000, Train: 88.97%, Valid: 85.47%, Test: 86.04%\n",
            "Epoch: 55, Loss: 6077120.5000, Train: 89.28%, Valid: 85.84%, Test: 86.15%\n",
            "Epoch: 60, Loss: 5918932.0000, Train: 89.44%, Valid: 85.90%, Test: 86.13%\n",
            "Epoch: 65, Loss: 5784859.0000, Train: 89.69%, Valid: 86.00%, Test: 86.25%\n",
            "Epoch: 70, Loss: 5669408.5000, Train: 89.78%, Valid: 86.10%, Test: 86.47%\n",
            "Epoch: 75, Loss: 5569563.0000, Train: 89.84%, Valid: 86.04%, Test: 86.51%\n",
            "Epoch: 80, Loss: 5480048.0000, Train: 90.07%, Valid: 86.00%, Test: 86.51%\n",
            "Epoch: 85, Loss: 5401013.0000, Train: 90.22%, Valid: 86.16%, Test: 86.67%\n",
            "Epoch: 90, Loss: 5329289.0000, Train: 90.22%, Valid: 86.31%, Test: 86.65%\n",
            "Epoch: 95, Loss: 5263473.0000, Train: 90.29%, Valid: 86.37%, Test: 86.57%\n",
            "Epoch: 100, Loss: 5226847.0000, Train: 90.25%, Valid: 86.31%, Test: 86.57%\n",
            "Epoch: 105, Loss: 5182023.5000, Train: 90.41%, Valid: 86.37%, Test: 86.65%\n",
            "Epoch: 110, Loss: 5131908.0000, Train: 90.56%, Valid: 86.47%, Test: 86.65%\n",
            "Epoch: 115, Loss: 5063186.0000, Train: 90.56%, Valid: 86.55%, Test: 86.63%\n",
            "Epoch: 120, Loss: 5019547.5000, Train: 90.60%, Valid: 86.47%, Test: 86.65%\n",
            "Epoch: 125, Loss: 4991894.0000, Train: 90.59%, Valid: 86.37%, Test: 86.59%\n",
            "Epoch: 130, Loss: 4954885.5000, Train: 90.66%, Valid: 86.45%, Test: 86.49%\n",
            "Epoch: 135, Loss: 4918975.0000, Train: 90.62%, Valid: 86.29%, Test: 86.45%\n",
            "Epoch: 140, Loss: 4922248.0000, Train: 90.59%, Valid: 86.45%, Test: 86.53%\n",
            "Epoch: 145, Loss: 4915181.0000, Train: 90.65%, Valid: 86.41%, Test: 86.51%\n",
            "Epoch: 150, Loss: 4850555.0000, Train: 90.74%, Valid: 86.12%, Test: 86.37%\n",
            "Epoch: 155, Loss: 4816534.5000, Train: 90.73%, Valid: 86.18%, Test: 86.29%\n",
            "Epoch: 160, Loss: 4810555.0000, Train: 90.68%, Valid: 85.94%, Test: 86.29%\n",
            "Epoch: 165, Loss: 4787710.0000, Train: 90.75%, Valid: 85.98%, Test: 86.29%\n",
            "Epoch: 170, Loss: 4797960.0000, Train: 90.76%, Valid: 86.08%, Test: 86.39%\n",
            "Epoch: 175, Loss: 4783636.0000, Train: 90.71%, Valid: 86.16%, Test: 86.43%\n",
            "Epoch: 180, Loss: 4726843.0000, Train: 90.70%, Valid: 86.20%, Test: 86.45%\n",
            "Epoch: 185, Loss: 4724472.0000, Train: 90.81%, Valid: 86.14%, Test: 86.25%\n",
            "Epoch: 190, Loss: 4783632.0000, Train: 90.79%, Valid: 86.14%, Test: 86.51%\n",
            "Epoch: 195, Loss: 4708884.0000, Train: 90.77%, Valid: 86.20%, Test: 86.51%\n",
            "Run 01:\n",
            "Highest Train: 90.87\n",
            "Highest Valid: 86.55\n",
            "Highest Test: 86.77\n",
            "Chosen epoch: 108\n",
            "Final Train: 90.44\n",
            "Final Test: 86.59\n",
            "Epoch: 00, Loss: 31617328.0000, Train: 46.78%, Valid: 46.52%, Test: 46.65%\n",
            "Epoch: 05, Loss: 15105087.0000, Train: 69.00%, Valid: 69.12%, Test: 69.21%\n",
            "Epoch: 10, Loss: 12370526.0000, Train: 80.92%, Valid: 79.87%, Test: 79.61%\n",
            "Epoch: 15, Loss: 11104894.0000, Train: 84.30%, Valid: 82.33%, Test: 82.35%\n",
            "Epoch: 20, Loss: 10241489.0000, Train: 86.18%, Valid: 83.51%, Test: 84.08%\n",
            "Epoch: 25, Loss: 9640014.0000, Train: 87.25%, Valid: 84.50%, Test: 84.36%\n",
            "Epoch: 30, Loss: 9189688.0000, Train: 87.77%, Valid: 84.97%, Test: 85.05%\n",
            "Epoch: 35, Loss: 8824419.0000, Train: 88.18%, Valid: 85.33%, Test: 85.64%\n",
            "Epoch: 40, Loss: 8539282.0000, Train: 88.54%, Valid: 85.76%, Test: 86.02%\n",
            "Epoch: 45, Loss: 8301319.0000, Train: 88.88%, Valid: 85.82%, Test: 85.96%\n",
            "Epoch: 50, Loss: 8104325.0000, Train: 89.07%, Valid: 86.10%, Test: 85.84%\n",
            "Epoch: 55, Loss: 7939417.5000, Train: 89.22%, Valid: 86.16%, Test: 85.98%\n",
            "Epoch: 60, Loss: 7798660.0000, Train: 89.43%, Valid: 86.08%, Test: 86.04%\n",
            "Epoch: 65, Loss: 7673517.0000, Train: 89.57%, Valid: 86.08%, Test: 86.21%\n",
            "Epoch: 70, Loss: 7566016.5000, Train: 89.69%, Valid: 86.18%, Test: 86.27%\n",
            "Epoch: 75, Loss: 7471414.5000, Train: 89.77%, Valid: 86.14%, Test: 86.11%\n",
            "Epoch: 80, Loss: 7386432.5000, Train: 89.89%, Valid: 86.20%, Test: 86.13%\n",
            "Epoch: 85, Loss: 7309984.5000, Train: 89.86%, Valid: 86.10%, Test: 86.17%\n",
            "Epoch: 90, Loss: 7240703.0000, Train: 90.02%, Valid: 86.33%, Test: 86.06%\n",
            "Epoch: 95, Loss: 7178040.0000, Train: 90.02%, Valid: 86.41%, Test: 86.04%\n",
            "Epoch: 100, Loss: 7120831.0000, Train: 90.05%, Valid: 86.53%, Test: 86.21%\n",
            "Epoch: 105, Loss: 7066690.0000, Train: 90.16%, Valid: 86.49%, Test: 86.25%\n",
            "Epoch: 110, Loss: 7017634.5000, Train: 90.28%, Valid: 86.53%, Test: 86.23%\n",
            "Epoch: 115, Loss: 6972171.0000, Train: 90.26%, Valid: 86.51%, Test: 86.23%\n",
            "Epoch: 120, Loss: 6930340.0000, Train: 90.21%, Valid: 86.67%, Test: 86.13%\n",
            "Epoch: 125, Loss: 6890685.0000, Train: 90.26%, Valid: 86.55%, Test: 86.15%\n",
            "Epoch: 130, Loss: 6860189.0000, Train: 90.33%, Valid: 86.53%, Test: 86.13%\n",
            "Epoch: 135, Loss: 6824983.0000, Train: 90.40%, Valid: 86.43%, Test: 86.19%\n",
            "Epoch: 140, Loss: 6805200.5000, Train: 90.42%, Valid: 86.53%, Test: 86.29%\n",
            "Epoch: 145, Loss: 6786281.5000, Train: 90.40%, Valid: 86.55%, Test: 86.27%\n",
            "Epoch: 150, Loss: 6738783.0000, Train: 90.45%, Valid: 86.61%, Test: 86.37%\n",
            "Epoch: 155, Loss: 6731873.5000, Train: 90.55%, Valid: 86.55%, Test: 86.41%\n",
            "Epoch: 160, Loss: 6730454.0000, Train: 90.53%, Valid: 86.39%, Test: 86.29%\n",
            "Epoch: 165, Loss: 6676775.0000, Train: 90.56%, Valid: 86.35%, Test: 86.31%\n",
            "Epoch: 170, Loss: 6671835.0000, Train: 90.52%, Valid: 86.63%, Test: 86.47%\n",
            "Epoch: 175, Loss: 6672491.0000, Train: 90.40%, Valid: 86.71%, Test: 86.37%\n",
            "Epoch: 180, Loss: 6621980.5000, Train: 90.44%, Valid: 86.73%, Test: 86.37%\n",
            "Epoch: 185, Loss: 6621651.0000, Train: 90.50%, Valid: 86.45%, Test: 86.47%\n",
            "Epoch: 190, Loss: 6619693.5000, Train: 90.56%, Valid: 86.45%, Test: 86.59%\n",
            "Epoch: 195, Loss: 6597567.0000, Train: 90.51%, Valid: 86.65%, Test: 86.67%\n",
            "Run 02:\n",
            "Highest Train: 90.56\n",
            "Highest Valid: 86.73\n",
            "Highest Test: 86.67\n",
            "Chosen epoch: 178\n",
            "Final Train: 90.48\n",
            "Final Test: 86.35\n",
            "Epoch: 00, Loss: 31013162.0000, Train: 52.42%, Valid: 53.32%, Test: 52.43%\n",
            "Epoch: 05, Loss: 12696504.0000, Train: 77.69%, Valid: 76.97%, Test: 77.20%\n",
            "Epoch: 10, Loss: 10528904.0000, Train: 81.64%, Valid: 80.10%, Test: 79.96%\n",
            "Epoch: 15, Loss: 9489162.0000, Train: 83.85%, Valid: 81.76%, Test: 81.81%\n",
            "Epoch: 20, Loss: 8808852.0000, Train: 85.75%, Valid: 83.65%, Test: 84.12%\n",
            "Epoch: 25, Loss: 8326531.5000, Train: 86.59%, Valid: 84.93%, Test: 84.65%\n",
            "Epoch: 30, Loss: 7935254.0000, Train: 87.31%, Valid: 84.91%, Test: 85.15%\n",
            "Epoch: 35, Loss: 7636390.5000, Train: 87.69%, Valid: 84.99%, Test: 85.46%\n",
            "Epoch: 40, Loss: 7384643.5000, Train: 88.03%, Valid: 85.49%, Test: 85.35%\n",
            "Epoch: 45, Loss: 7177123.5000, Train: 88.27%, Valid: 85.68%, Test: 85.70%\n",
            "Epoch: 50, Loss: 7002964.0000, Train: 88.62%, Valid: 85.86%, Test: 86.19%\n",
            "Epoch: 55, Loss: 6863202.5000, Train: 88.86%, Valid: 85.80%, Test: 86.47%\n",
            "Epoch: 60, Loss: 6744044.5000, Train: 89.15%, Valid: 85.78%, Test: 86.43%\n",
            "Epoch: 65, Loss: 6640677.0000, Train: 89.25%, Valid: 85.80%, Test: 86.51%\n",
            "Epoch: 70, Loss: 6552230.5000, Train: 89.41%, Valid: 86.10%, Test: 86.61%\n",
            "Epoch: 75, Loss: 6474198.0000, Train: 89.50%, Valid: 86.18%, Test: 86.71%\n",
            "Epoch: 80, Loss: 6404910.0000, Train: 89.50%, Valid: 86.31%, Test: 86.75%\n",
            "Epoch: 85, Loss: 6342299.0000, Train: 89.62%, Valid: 86.41%, Test: 86.71%\n",
            "Epoch: 90, Loss: 6284760.0000, Train: 89.65%, Valid: 86.45%, Test: 86.75%\n",
            "Epoch: 95, Loss: 6234118.5000, Train: 89.75%, Valid: 86.45%, Test: 86.80%\n",
            "Epoch: 100, Loss: 6188080.0000, Train: 89.75%, Valid: 86.57%, Test: 86.92%\n",
            "Epoch: 105, Loss: 6145863.0000, Train: 89.72%, Valid: 86.55%, Test: 86.90%\n",
            "Epoch: 110, Loss: 6107136.5000, Train: 89.82%, Valid: 86.61%, Test: 86.98%\n",
            "Epoch: 115, Loss: 6071183.0000, Train: 89.84%, Valid: 86.77%, Test: 86.86%\n",
            "Epoch: 120, Loss: 6114979.5000, Train: 89.71%, Valid: 86.75%, Test: 86.75%\n",
            "Epoch: 125, Loss: 6032543.0000, Train: 89.91%, Valid: 86.73%, Test: 86.92%\n",
            "Epoch: 130, Loss: 5995877.0000, Train: 89.86%, Valid: 86.73%, Test: 87.02%\n",
            "Epoch: 135, Loss: 5974528.0000, Train: 89.85%, Valid: 86.67%, Test: 87.06%\n",
            "Epoch: 140, Loss: 5941427.0000, Train: 89.85%, Valid: 86.71%, Test: 86.92%\n",
            "Epoch: 145, Loss: 5924131.0000, Train: 89.94%, Valid: 86.61%, Test: 87.04%\n",
            "Epoch: 150, Loss: 5927688.0000, Train: 89.93%, Valid: 86.43%, Test: 87.02%\n",
            "Epoch: 155, Loss: 5895508.0000, Train: 89.91%, Valid: 86.57%, Test: 86.92%\n",
            "Epoch: 160, Loss: 5873298.5000, Train: 90.00%, Valid: 86.65%, Test: 86.96%\n",
            "Epoch: 165, Loss: 5902396.5000, Train: 89.87%, Valid: 86.63%, Test: 86.88%\n",
            "Epoch: 170, Loss: 5856784.5000, Train: 89.92%, Valid: 86.57%, Test: 86.94%\n",
            "Epoch: 175, Loss: 5818133.0000, Train: 90.05%, Valid: 86.59%, Test: 87.00%\n",
            "Epoch: 180, Loss: 5805965.5000, Train: 90.13%, Valid: 86.61%, Test: 87.10%\n",
            "Epoch: 185, Loss: 5775591.5000, Train: 90.10%, Valid: 86.73%, Test: 86.92%\n",
            "Epoch: 190, Loss: 5781818.0000, Train: 90.14%, Valid: 86.81%, Test: 87.04%\n",
            "Epoch: 195, Loss: 5760955.0000, Train: 90.20%, Valid: 86.57%, Test: 86.98%\n",
            "Run 03:\n",
            "Highest Train: 90.31\n",
            "Highest Valid: 86.81\n",
            "Highest Test: 87.10\n",
            "Chosen epoch: 117\n",
            "Final Train: 89.81\n",
            "Final Test: 86.71\n",
            "Epoch: 00, Loss: 30524538.0000, Train: 40.15%, Valid: 38.73%, Test: 39.49%\n",
            "Epoch: 05, Loss: 14157582.0000, Train: 67.70%, Valid: 66.36%, Test: 68.03%\n",
            "Epoch: 10, Loss: 11709441.0000, Train: 80.52%, Valid: 78.76%, Test: 78.70%\n",
            "Epoch: 15, Loss: 10501252.0000, Train: 83.97%, Valid: 81.64%, Test: 82.15%\n",
            "Epoch: 20, Loss: 9736450.0000, Train: 85.32%, Valid: 83.04%, Test: 83.55%\n",
            "Epoch: 25, Loss: 9197147.0000, Train: 86.28%, Valid: 83.71%, Test: 83.87%\n",
            "Epoch: 30, Loss: 8768206.0000, Train: 86.85%, Valid: 84.09%, Test: 84.28%\n",
            "Epoch: 35, Loss: 8431704.0000, Train: 87.33%, Valid: 84.40%, Test: 84.79%\n",
            "Epoch: 40, Loss: 8166310.5000, Train: 87.78%, Valid: 84.78%, Test: 85.25%\n",
            "Epoch: 45, Loss: 7940536.5000, Train: 88.30%, Valid: 84.82%, Test: 85.80%\n",
            "Epoch: 50, Loss: 7758051.5000, Train: 88.49%, Valid: 84.99%, Test: 85.98%\n",
            "Epoch: 55, Loss: 7605114.5000, Train: 88.98%, Valid: 85.21%, Test: 86.17%\n",
            "Epoch: 60, Loss: 7473325.0000, Train: 89.20%, Valid: 85.62%, Test: 86.27%\n",
            "Epoch: 65, Loss: 7359259.0000, Train: 89.33%, Valid: 85.68%, Test: 86.33%\n",
            "Epoch: 70, Loss: 7259848.0000, Train: 89.35%, Valid: 85.72%, Test: 86.51%\n",
            "Epoch: 75, Loss: 7173705.5000, Train: 89.57%, Valid: 85.84%, Test: 86.55%\n",
            "Epoch: 80, Loss: 7096868.5000, Train: 89.70%, Valid: 85.88%, Test: 86.63%\n",
            "Epoch: 85, Loss: 7026008.0000, Train: 89.67%, Valid: 85.92%, Test: 86.69%\n",
            "Epoch: 90, Loss: 6964696.5000, Train: 89.76%, Valid: 85.96%, Test: 86.77%\n",
            "Epoch: 95, Loss: 6908893.0000, Train: 89.70%, Valid: 85.98%, Test: 86.71%\n",
            "Epoch: 100, Loss: 6857394.5000, Train: 89.76%, Valid: 85.94%, Test: 86.71%\n",
            "Epoch: 105, Loss: 6809667.0000, Train: 89.94%, Valid: 85.90%, Test: 86.77%\n",
            "Epoch: 110, Loss: 6765051.0000, Train: 89.99%, Valid: 85.96%, Test: 86.75%\n",
            "Epoch: 115, Loss: 6723696.5000, Train: 90.06%, Valid: 86.00%, Test: 86.90%\n",
            "Epoch: 120, Loss: 6684769.0000, Train: 90.02%, Valid: 85.96%, Test: 86.90%\n",
            "Epoch: 125, Loss: 6648051.0000, Train: 90.07%, Valid: 85.94%, Test: 86.82%\n",
            "Epoch: 130, Loss: 6613568.5000, Train: 90.11%, Valid: 85.90%, Test: 86.82%\n",
            "Epoch: 135, Loss: 6607733.5000, Train: 90.21%, Valid: 85.86%, Test: 86.69%\n",
            "Epoch: 140, Loss: 6579337.5000, Train: 90.23%, Valid: 85.88%, Test: 86.73%\n",
            "Epoch: 145, Loss: 6546707.0000, Train: 90.22%, Valid: 85.94%, Test: 86.71%\n",
            "Epoch: 150, Loss: 6517759.5000, Train: 90.19%, Valid: 85.92%, Test: 86.71%\n",
            "Epoch: 155, Loss: 6513242.5000, Train: 90.32%, Valid: 86.04%, Test: 86.88%\n",
            "Epoch: 160, Loss: 6493144.5000, Train: 90.24%, Valid: 85.90%, Test: 86.88%\n",
            "Epoch: 165, Loss: 6458565.0000, Train: 90.25%, Valid: 85.92%, Test: 86.88%\n",
            "Epoch: 170, Loss: 6427522.0000, Train: 90.25%, Valid: 86.04%, Test: 86.88%\n",
            "Epoch: 175, Loss: 6434928.5000, Train: 90.12%, Valid: 86.04%, Test: 86.86%\n",
            "Epoch: 180, Loss: 6422977.0000, Train: 90.25%, Valid: 85.98%, Test: 86.96%\n",
            "Epoch: 185, Loss: 6377390.0000, Train: 90.25%, Valid: 85.94%, Test: 86.98%\n",
            "Epoch: 190, Loss: 6348793.0000, Train: 90.21%, Valid: 85.90%, Test: 86.94%\n",
            "Epoch: 195, Loss: 6354186.0000, Train: 90.25%, Valid: 86.18%, Test: 86.92%\n",
            "Run 04:\n",
            "Highest Train: 90.32\n",
            "Highest Valid: 86.18\n",
            "Highest Test: 87.06\n",
            "Chosen epoch: 196\n",
            "Final Train: 90.25\n",
            "Final Test: 86.92\n",
            "Epoch: 00, Loss: 30673972.0000, Train: 19.78%, Valid: 20.25%, Test: 19.07%\n",
            "Epoch: 05, Loss: 14287828.0000, Train: 42.59%, Valid: 43.52%, Test: 42.82%\n",
            "Epoch: 10, Loss: 12058509.0000, Train: 66.54%, Valid: 66.04%, Test: 65.03%\n",
            "Epoch: 15, Loss: 10852642.0000, Train: 78.51%, Valid: 76.38%, Test: 76.80%\n",
            "Epoch: 20, Loss: 10016182.0000, Train: 82.65%, Valid: 79.91%, Test: 81.38%\n",
            "Epoch: 25, Loss: 9393772.0000, Train: 85.26%, Valid: 82.71%, Test: 83.94%\n",
            "Epoch: 30, Loss: 8886186.0000, Train: 86.89%, Valid: 84.22%, Test: 85.15%\n",
            "Epoch: 35, Loss: 8492666.0000, Train: 87.84%, Valid: 84.87%, Test: 85.64%\n",
            "Epoch: 40, Loss: 8190468.0000, Train: 88.41%, Valid: 85.13%, Test: 85.88%\n",
            "Epoch: 45, Loss: 7940788.5000, Train: 88.80%, Valid: 85.37%, Test: 86.00%\n",
            "Epoch: 50, Loss: 7730113.5000, Train: 89.04%, Valid: 85.51%, Test: 86.04%\n",
            "Epoch: 55, Loss: 7550738.0000, Train: 89.25%, Valid: 85.88%, Test: 86.29%\n",
            "Epoch: 60, Loss: 7395603.0000, Train: 89.44%, Valid: 85.98%, Test: 86.41%\n",
            "Epoch: 65, Loss: 7262642.5000, Train: 89.54%, Valid: 85.92%, Test: 86.51%\n",
            "Epoch: 70, Loss: 7145845.0000, Train: 89.72%, Valid: 85.84%, Test: 86.57%\n",
            "Epoch: 75, Loss: 7044564.5000, Train: 89.84%, Valid: 85.94%, Test: 86.82%\n",
            "Epoch: 80, Loss: 6953930.5000, Train: 89.93%, Valid: 85.88%, Test: 86.98%\n",
            "Epoch: 85, Loss: 6872245.0000, Train: 89.99%, Valid: 85.94%, Test: 86.98%\n",
            "Epoch: 90, Loss: 6798192.0000, Train: 90.06%, Valid: 86.00%, Test: 86.82%\n",
            "Epoch: 95, Loss: 6728822.0000, Train: 90.12%, Valid: 86.00%, Test: 86.71%\n",
            "Epoch: 100, Loss: 6665055.0000, Train: 90.27%, Valid: 85.92%, Test: 86.84%\n",
            "Epoch: 105, Loss: 6605282.0000, Train: 90.35%, Valid: 85.98%, Test: 86.80%\n",
            "Epoch: 110, Loss: 6549228.0000, Train: 90.29%, Valid: 86.18%, Test: 86.75%\n",
            "Epoch: 115, Loss: 6498023.5000, Train: 90.35%, Valid: 86.10%, Test: 86.65%\n",
            "Epoch: 120, Loss: 6452767.0000, Train: 90.42%, Valid: 86.20%, Test: 86.75%\n",
            "Epoch: 125, Loss: 6456349.0000, Train: 90.39%, Valid: 86.10%, Test: 86.77%\n",
            "Epoch: 130, Loss: 6383375.5000, Train: 90.51%, Valid: 86.14%, Test: 86.86%\n",
            "Epoch: 135, Loss: 6344374.5000, Train: 90.64%, Valid: 86.10%, Test: 86.90%\n",
            "Epoch: 140, Loss: 6323268.5000, Train: 90.66%, Valid: 86.24%, Test: 86.90%\n",
            "Epoch: 145, Loss: 6305082.0000, Train: 90.76%, Valid: 86.20%, Test: 86.88%\n",
            "Epoch: 150, Loss: 6258872.0000, Train: 90.79%, Valid: 86.16%, Test: 87.00%\n",
            "Epoch: 155, Loss: 6233846.5000, Train: 90.75%, Valid: 86.45%, Test: 87.00%\n",
            "Epoch: 160, Loss: 6229921.5000, Train: 90.84%, Valid: 86.35%, Test: 87.18%\n",
            "Epoch: 165, Loss: 6232897.0000, Train: 90.93%, Valid: 86.51%, Test: 87.08%\n",
            "Epoch: 170, Loss: 6160672.0000, Train: 90.85%, Valid: 86.14%, Test: 87.06%\n",
            "Epoch: 175, Loss: 6140055.5000, Train: 90.85%, Valid: 86.20%, Test: 87.02%\n",
            "Epoch: 180, Loss: 6126707.5000, Train: 90.90%, Valid: 85.86%, Test: 86.77%\n",
            "Epoch: 185, Loss: 6110252.0000, Train: 90.93%, Valid: 86.06%, Test: 87.06%\n",
            "Epoch: 190, Loss: 6111598.5000, Train: 90.86%, Valid: 85.90%, Test: 86.67%\n",
            "Epoch: 195, Loss: 6084004.0000, Train: 90.95%, Valid: 86.00%, Test: 86.90%\n",
            "Run 05:\n",
            "Highest Train: 91.06\n",
            "Highest Valid: 86.51\n",
            "Highest Test: 87.20\n",
            "Chosen epoch: 166\n",
            "Final Train: 90.93\n",
            "Final Test: 87.08\n",
            "All runs:\n",
            "Highest Train: 90.62 ± 0.33\n",
            "Highest Test: 86.96 ± 0.23\n",
            "Highest Valid: 86.56 ± 0.24\n",
            "  Final Train: 90.38 ± 0.41\n",
            "   Final Test: 86.73 ± 0.28\n",
            "Saving results to logs/pubmed_edge.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 GKD/main.py --dataset pubmed --rand_split --use_bn --base_model gcn --mode train --priv_type edge --dist_mode gkd --kernel gaussian"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTIZlkYA_Ycn",
        "outputId": "73d77eb9-38ee-49f6-9430-9276d38f2bf0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(data_dir='data', dataset='pubmed', sub_dataset='', cpu=False, seed=42, train_prop=0.5, valid_prop=0.25, protocol='semi', rand_split=True, metric='acc', runs=5, epochs=200, hidden_channels=32, num_layers=3, gat_heads=8, out_heads=1, hops=1, lp_alpha=0.1, gpr_alpha=0.1, jk_type='max', directed=False, num_mlp_layers=1, display_step=5, cached=False, print_prop=False, priv_type='edge', priv_ratio=0.5, save_model=False, save_name='gcn', log_name='none', base_model='gcn', not_load_teacher=False, mode='train', dist_mode='gkd', weight_decay=0.05, dropout=0.0, lr=0.01, use_bn=True, use_batch=False, batch_size=2048, oracle=False, device=0, alpha=0.5, delta=0.1, use_kd=False, beta=0.0, tau=1.0, kernel='gaussian', t=1.0, include_last=False, s=2, m=1, lr2=0.001, sim='l2', ker_norm=False)\n",
            "cuda:0\n",
            "pubmed\n",
            "Num nodes: 19717\n",
            "torch.Size([19717, 1])\n",
            "num nodes 19717 | num classes 3 | num node feats 500\n",
            "MODEL: GeoDist(\n",
            "  (k): Kernel(\n",
            "    (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  )\n",
            "  (teacher_gnn): ModuleList(\n",
            "    (0): Linear(in_features=500, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (student_gnn): ModuleList(\n",
            "    (0): Linear(in_features=500, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  (bns2d): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            ")\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/GKD/main.py\", line 180, in <module>\n",
            "    outputs = model(dataset, dataset_mask, mode='train', dist_mode=args.dist_mode, t=args.t)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/GKD/models.py\", line 68, in forward\n",
            "    return self.forward_student(data_full, data, dist_mode, t)\n",
            "  File \"/content/GKD/models.py\", line 97, in forward_student\n",
            "    return self.gkd(xs, xt, edge_index, edge_index_full, train_idx, share_node_idx)\n",
            "  File \"/content/GKD/models.py\", line 154, in gkd\n",
            "    loss_list.append(self.k.dist_loss(mt, ms, A))\n",
            "  File \"/content/GKD/kernels.py\", line 63, in dist_loss\n",
            "    return (nn.MSELoss(reduction='none')(mt, ms) * (A + (1-A) * self.args.delta)).sum()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\", line 40, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\", line 909, in __rsub__\n",
            "    return _C._VariableFunctions.rsub(self, other)\n",
            "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacty of 15.77 GiB of which 146.12 MiB is free. Process 40792 has 15.63 GiB memory in use. Of the allocated memory 13.17 GiB is allocated by PyTorch, and 1.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 GKD/main.py --dataset pubmed --rand_split --use_bn --base_model gcn --mode train --priv_type edge --dist_mode gkd --use_kd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aB2S2LJp_fiM",
        "outputId": "95be2861-f960-43cd-ffdd-fc183a0fc421"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(data_dir='data', dataset='pubmed', sub_dataset='', cpu=False, seed=42, train_prop=0.5, valid_prop=0.25, protocol='semi', rand_split=True, metric='acc', runs=5, epochs=200, hidden_channels=32, num_layers=3, gat_heads=8, out_heads=1, hops=1, lp_alpha=0.1, gpr_alpha=0.1, jk_type='max', directed=False, num_mlp_layers=1, display_step=5, cached=False, print_prop=False, priv_type='edge', priv_ratio=0.5, save_model=False, save_name='gcn', log_name='none', base_model='gcn', not_load_teacher=False, mode='train', dist_mode='gkd', weight_decay=0.05, dropout=0.0, lr=0.01, use_bn=True, use_batch=False, batch_size=2048, oracle=False, device=0, alpha=0.5, delta=0.1, use_kd=True, beta=0.0, tau=1.0, kernel='sigmoid', t=1.0, include_last=False, s=2, m=1, lr2=0.001, sim='l2', ker_norm=False)\n",
            "cuda:0\n",
            "pubmed\n",
            "Num nodes: 19717\n",
            "torch.Size([19717, 1])\n",
            "num nodes 19717 | num classes 3 | num node feats 500\n",
            "MODEL: GeoDist(\n",
            "  (k): Kernel(\n",
            "    (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  )\n",
            "  (teacher_gnn): ModuleList(\n",
            "    (0): Linear(in_features=500, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (student_gnn): ModuleList(\n",
            "    (0): Linear(in_features=500, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  (bns2d): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            ")\n",
            "Epoch: 00, Loss: 30492376.0000, Train: 46.48%, Valid: 46.62%, Test: 46.29%\n",
            "Epoch: 05, Loss: 13358913.0000, Train: 67.37%, Valid: 67.11%, Test: 67.04%\n",
            "Epoch: 10, Loss: 10831945.0000, Train: 83.04%, Valid: 81.09%, Test: 82.13%\n",
            "Epoch: 15, Loss: 9545926.0000, Train: 85.30%, Valid: 82.86%, Test: 83.53%\n",
            "Epoch: 20, Loss: 8710531.0000, Train: 85.77%, Valid: 83.22%, Test: 84.28%\n",
            "Epoch: 25, Loss: 8053471.0000, Train: 86.65%, Valid: 83.83%, Test: 85.13%\n",
            "Epoch: 30, Loss: 7536694.5000, Train: 87.55%, Valid: 84.24%, Test: 85.15%\n",
            "Epoch: 35, Loss: 7110734.0000, Train: 88.04%, Valid: 84.95%, Test: 85.58%\n",
            "Epoch: 40, Loss: 6768038.0000, Train: 88.36%, Valid: 85.53%, Test: 85.82%\n",
            "Epoch: 45, Loss: 6493394.0000, Train: 88.80%, Valid: 85.58%, Test: 86.19%\n",
            "Epoch: 50, Loss: 6261611.0000, Train: 88.97%, Valid: 85.47%, Test: 86.04%\n",
            "Epoch: 55, Loss: 6077120.5000, Train: 89.28%, Valid: 85.84%, Test: 86.15%\n",
            "Epoch: 60, Loss: 5918932.0000, Train: 89.44%, Valid: 85.90%, Test: 86.13%\n",
            "Epoch: 65, Loss: 5784858.5000, Train: 89.69%, Valid: 86.00%, Test: 86.25%\n",
            "Epoch: 70, Loss: 5669408.5000, Train: 89.78%, Valid: 86.10%, Test: 86.47%\n",
            "Epoch: 75, Loss: 5569563.0000, Train: 89.84%, Valid: 86.04%, Test: 86.51%\n",
            "Epoch: 80, Loss: 5480048.0000, Train: 90.07%, Valid: 86.00%, Test: 86.51%\n",
            "Epoch: 85, Loss: 5401013.0000, Train: 90.22%, Valid: 86.16%, Test: 86.67%\n",
            "Epoch: 90, Loss: 5329289.0000, Train: 90.22%, Valid: 86.31%, Test: 86.65%\n",
            "Epoch: 95, Loss: 5263473.0000, Train: 90.29%, Valid: 86.37%, Test: 86.57%\n",
            "Epoch: 100, Loss: 5226850.0000, Train: 90.25%, Valid: 86.31%, Test: 86.57%\n",
            "Epoch: 105, Loss: 5182026.5000, Train: 90.41%, Valid: 86.37%, Test: 86.65%\n",
            "Epoch: 110, Loss: 5131905.0000, Train: 90.56%, Valid: 86.47%, Test: 86.65%\n",
            "Epoch: 115, Loss: 5063187.0000, Train: 90.56%, Valid: 86.55%, Test: 86.63%\n",
            "Epoch: 120, Loss: 5019543.0000, Train: 90.60%, Valid: 86.47%, Test: 86.65%\n",
            "Epoch: 125, Loss: 4991911.0000, Train: 90.59%, Valid: 86.37%, Test: 86.59%\n",
            "Epoch: 130, Loss: 4954816.0000, Train: 90.65%, Valid: 86.45%, Test: 86.49%\n",
            "Epoch: 135, Loss: 4918614.5000, Train: 90.63%, Valid: 86.29%, Test: 86.43%\n",
            "Epoch: 140, Loss: 4925851.5000, Train: 90.58%, Valid: 86.47%, Test: 86.55%\n",
            "Epoch: 145, Loss: 4916328.0000, Train: 90.64%, Valid: 86.41%, Test: 86.51%\n",
            "Epoch: 150, Loss: 4849494.0000, Train: 90.75%, Valid: 86.14%, Test: 86.39%\n",
            "Epoch: 155, Loss: 4812208.5000, Train: 90.76%, Valid: 86.14%, Test: 86.31%\n",
            "Epoch: 160, Loss: 4828168.5000, Train: 90.71%, Valid: 85.96%, Test: 86.17%\n",
            "Epoch: 165, Loss: 4809647.0000, Train: 90.77%, Valid: 85.94%, Test: 86.19%\n",
            "Epoch: 170, Loss: 4780633.0000, Train: 90.72%, Valid: 86.00%, Test: 86.37%\n",
            "Epoch: 175, Loss: 4764536.5000, Train: 90.74%, Valid: 86.20%, Test: 86.37%\n",
            "Epoch: 180, Loss: 4722545.0000, Train: 90.72%, Valid: 86.18%, Test: 86.41%\n",
            "Epoch: 185, Loss: 4688744.0000, Train: 90.76%, Valid: 86.20%, Test: 86.51%\n",
            "Epoch: 190, Loss: 4772565.0000, Train: 90.83%, Valid: 86.22%, Test: 86.37%\n",
            "Epoch: 195, Loss: 4728944.0000, Train: 90.83%, Valid: 86.33%, Test: 86.41%\n",
            "Run 01:\n",
            "Highest Train: 90.89\n",
            "Highest Valid: 86.55\n",
            "Highest Test: 86.77\n",
            "Chosen epoch: 108\n",
            "Final Train: 90.44\n",
            "Final Test: 86.59\n",
            "Epoch: 00, Loss: 31617328.0000, Train: 46.78%, Valid: 46.52%, Test: 46.65%\n",
            "Epoch: 05, Loss: 15105087.0000, Train: 69.00%, Valid: 69.12%, Test: 69.21%\n",
            "Epoch: 10, Loss: 12370526.0000, Train: 80.92%, Valid: 79.87%, Test: 79.61%\n",
            "Epoch: 15, Loss: 11104894.0000, Train: 84.30%, Valid: 82.33%, Test: 82.35%\n",
            "Epoch: 20, Loss: 10241489.0000, Train: 86.18%, Valid: 83.51%, Test: 84.08%\n",
            "Epoch: 25, Loss: 9640014.0000, Train: 87.25%, Valid: 84.50%, Test: 84.36%\n",
            "Epoch: 30, Loss: 9189688.0000, Train: 87.77%, Valid: 84.97%, Test: 85.05%\n",
            "Epoch: 35, Loss: 8824416.0000, Train: 88.18%, Valid: 85.33%, Test: 85.64%\n",
            "Epoch: 40, Loss: 8539282.0000, Train: 88.54%, Valid: 85.76%, Test: 86.02%\n",
            "Epoch: 45, Loss: 8301321.5000, Train: 88.88%, Valid: 85.82%, Test: 85.96%\n",
            "Epoch: 50, Loss: 8104328.0000, Train: 89.07%, Valid: 86.10%, Test: 85.84%\n",
            "Epoch: 55, Loss: 7939409.5000, Train: 89.22%, Valid: 86.16%, Test: 85.98%\n",
            "Epoch: 60, Loss: 7798666.0000, Train: 89.43%, Valid: 86.10%, Test: 86.06%\n",
            "Epoch: 65, Loss: 7673521.5000, Train: 89.57%, Valid: 86.08%, Test: 86.23%\n",
            "Epoch: 70, Loss: 7566035.0000, Train: 89.68%, Valid: 86.18%, Test: 86.27%\n",
            "Epoch: 75, Loss: 7471438.0000, Train: 89.77%, Valid: 86.12%, Test: 86.11%\n",
            "Epoch: 80, Loss: 7386514.5000, Train: 89.90%, Valid: 86.20%, Test: 86.11%\n",
            "Epoch: 85, Loss: 7310076.5000, Train: 89.89%, Valid: 86.10%, Test: 86.19%\n",
            "Epoch: 90, Loss: 7240793.5000, Train: 90.01%, Valid: 86.33%, Test: 86.02%\n",
            "Epoch: 95, Loss: 7178013.0000, Train: 90.02%, Valid: 86.41%, Test: 86.06%\n",
            "Epoch: 100, Loss: 7120698.0000, Train: 90.00%, Valid: 86.51%, Test: 86.23%\n",
            "Epoch: 105, Loss: 7066555.0000, Train: 90.18%, Valid: 86.49%, Test: 86.23%\n",
            "Epoch: 110, Loss: 7017448.5000, Train: 90.30%, Valid: 86.57%, Test: 86.27%\n",
            "Epoch: 115, Loss: 6972039.0000, Train: 90.22%, Valid: 86.47%, Test: 86.23%\n",
            "Epoch: 120, Loss: 6930313.0000, Train: 90.19%, Valid: 86.65%, Test: 86.13%\n",
            "Epoch: 125, Loss: 6890813.5000, Train: 90.24%, Valid: 86.55%, Test: 86.15%\n",
            "Epoch: 130, Loss: 6865850.5000, Train: 90.25%, Valid: 86.47%, Test: 86.15%\n",
            "Epoch: 135, Loss: 6820457.0000, Train: 90.26%, Valid: 86.47%, Test: 86.21%\n",
            "Epoch: 140, Loss: 6811661.0000, Train: 90.40%, Valid: 86.41%, Test: 86.29%\n",
            "Epoch: 145, Loss: 6779682.0000, Train: 90.51%, Valid: 86.26%, Test: 86.31%\n",
            "Epoch: 150, Loss: 6733578.0000, Train: 90.55%, Valid: 86.49%, Test: 86.29%\n",
            "Epoch: 155, Loss: 6720038.0000, Train: 90.41%, Valid: 86.59%, Test: 86.51%\n",
            "Epoch: 160, Loss: 6724319.5000, Train: 90.44%, Valid: 86.55%, Test: 86.49%\n",
            "Epoch: 165, Loss: 6684154.0000, Train: 90.42%, Valid: 86.61%, Test: 86.45%\n",
            "Epoch: 170, Loss: 6677374.0000, Train: 90.32%, Valid: 86.51%, Test: 86.43%\n",
            "Epoch: 175, Loss: 6688174.0000, Train: 90.41%, Valid: 86.39%, Test: 86.31%\n",
            "Epoch: 180, Loss: 6654034.0000, Train: 90.41%, Valid: 86.31%, Test: 86.29%\n",
            "Epoch: 185, Loss: 6637929.0000, Train: 90.39%, Valid: 86.45%, Test: 86.35%\n",
            "Epoch: 190, Loss: 6599493.5000, Train: 90.46%, Valid: 86.51%, Test: 86.39%\n",
            "Epoch: 195, Loss: 6652173.0000, Train: 90.61%, Valid: 86.18%, Test: 86.57%\n",
            "Run 02:\n",
            "Highest Train: 90.61\n",
            "Highest Valid: 86.77\n",
            "Highest Test: 86.57\n",
            "Chosen epoch: 180\n",
            "Final Train: 90.48\n",
            "Final Test: 86.55\n",
            "Epoch: 00, Loss: 31013162.0000, Train: 52.42%, Valid: 53.32%, Test: 52.43%\n",
            "Epoch: 05, Loss: 12696504.0000, Train: 77.69%, Valid: 76.97%, Test: 77.20%\n",
            "Epoch: 10, Loss: 10528904.0000, Train: 81.64%, Valid: 80.10%, Test: 79.96%\n",
            "Epoch: 15, Loss: 9489162.0000, Train: 83.85%, Valid: 81.76%, Test: 81.81%\n",
            "Epoch: 20, Loss: 8808852.0000, Train: 85.75%, Valid: 83.65%, Test: 84.12%\n",
            "Epoch: 25, Loss: 8326531.5000, Train: 86.59%, Valid: 84.93%, Test: 84.65%\n",
            "Epoch: 30, Loss: 7935253.0000, Train: 87.31%, Valid: 84.91%, Test: 85.15%\n",
            "Epoch: 35, Loss: 7636387.5000, Train: 87.69%, Valid: 84.99%, Test: 85.46%\n",
            "Epoch: 40, Loss: 7384646.0000, Train: 88.03%, Valid: 85.49%, Test: 85.35%\n",
            "Epoch: 45, Loss: 7177125.0000, Train: 88.27%, Valid: 85.68%, Test: 85.70%\n",
            "Epoch: 50, Loss: 7002979.0000, Train: 88.62%, Valid: 85.86%, Test: 86.21%\n",
            "Epoch: 55, Loss: 6863217.5000, Train: 88.86%, Valid: 85.80%, Test: 86.47%\n",
            "Epoch: 60, Loss: 6744111.5000, Train: 89.15%, Valid: 85.78%, Test: 86.43%\n",
            "Epoch: 65, Loss: 6640777.0000, Train: 89.24%, Valid: 85.80%, Test: 86.51%\n",
            "Epoch: 70, Loss: 6552262.5000, Train: 89.40%, Valid: 86.12%, Test: 86.59%\n",
            "Epoch: 75, Loss: 6474138.5000, Train: 89.51%, Valid: 86.22%, Test: 86.71%\n",
            "Epoch: 80, Loss: 6404799.0000, Train: 89.51%, Valid: 86.35%, Test: 86.75%\n",
            "Epoch: 85, Loss: 6342012.0000, Train: 89.62%, Valid: 86.43%, Test: 86.69%\n",
            "Epoch: 90, Loss: 6284687.0000, Train: 89.66%, Valid: 86.43%, Test: 86.75%\n",
            "Epoch: 95, Loss: 6234046.0000, Train: 89.77%, Valid: 86.45%, Test: 86.80%\n",
            "Epoch: 100, Loss: 6188125.5000, Train: 89.74%, Valid: 86.59%, Test: 86.90%\n",
            "Epoch: 105, Loss: 6145916.0000, Train: 89.72%, Valid: 86.49%, Test: 86.94%\n",
            "Epoch: 110, Loss: 6107153.0000, Train: 89.78%, Valid: 86.61%, Test: 86.94%\n",
            "Epoch: 115, Loss: 6076011.5000, Train: 89.88%, Valid: 86.77%, Test: 86.84%\n",
            "Epoch: 120, Loss: 6041294.0000, Train: 89.88%, Valid: 86.67%, Test: 86.92%\n",
            "Epoch: 125, Loss: 6019794.0000, Train: 89.90%, Valid: 86.67%, Test: 86.98%\n",
            "Epoch: 130, Loss: 5996338.5000, Train: 89.89%, Valid: 86.59%, Test: 86.92%\n",
            "Epoch: 135, Loss: 5966008.0000, Train: 89.90%, Valid: 86.69%, Test: 87.02%\n",
            "Epoch: 140, Loss: 5931901.5000, Train: 89.94%, Valid: 86.61%, Test: 86.98%\n",
            "Epoch: 145, Loss: 5930469.0000, Train: 89.82%, Valid: 86.69%, Test: 86.90%\n",
            "Epoch: 150, Loss: 5919843.0000, Train: 89.93%, Valid: 86.55%, Test: 87.02%\n",
            "Epoch: 155, Loss: 5903647.0000, Train: 89.83%, Valid: 86.59%, Test: 87.06%\n",
            "Epoch: 160, Loss: 5892723.5000, Train: 90.03%, Valid: 86.71%, Test: 86.96%\n",
            "Epoch: 165, Loss: 5864739.0000, Train: 90.09%, Valid: 86.45%, Test: 87.04%\n",
            "Epoch: 170, Loss: 5814671.0000, Train: 90.04%, Valid: 86.47%, Test: 86.94%\n",
            "Epoch: 175, Loss: 5829053.5000, Train: 89.98%, Valid: 86.47%, Test: 86.92%\n",
            "Epoch: 180, Loss: 5789237.0000, Train: 90.05%, Valid: 86.47%, Test: 86.96%\n",
            "Epoch: 185, Loss: 5792675.5000, Train: 90.13%, Valid: 86.67%, Test: 86.86%\n",
            "Epoch: 190, Loss: 5756103.5000, Train: 90.14%, Valid: 86.57%, Test: 87.00%\n",
            "Epoch: 195, Loss: 5792857.0000, Train: 90.14%, Valid: 86.57%, Test: 86.86%\n",
            "Run 03:\n",
            "Highest Train: 90.24\n",
            "Highest Valid: 86.81\n",
            "Highest Test: 87.10\n",
            "Chosen epoch: 127\n",
            "Final Train: 89.76\n",
            "Final Test: 86.82\n",
            "Epoch: 00, Loss: 30524538.0000, Train: 40.15%, Valid: 38.73%, Test: 39.49%\n",
            "Epoch: 05, Loss: 14157582.0000, Train: 67.70%, Valid: 66.36%, Test: 68.03%\n",
            "Epoch: 10, Loss: 11709441.0000, Train: 80.52%, Valid: 78.76%, Test: 78.70%\n",
            "Epoch: 15, Loss: 10501252.0000, Train: 83.97%, Valid: 81.64%, Test: 82.15%\n",
            "Epoch: 20, Loss: 9736450.0000, Train: 85.32%, Valid: 83.04%, Test: 83.55%\n",
            "Epoch: 25, Loss: 9197147.0000, Train: 86.28%, Valid: 83.71%, Test: 83.87%\n",
            "Epoch: 30, Loss: 8768206.0000, Train: 86.85%, Valid: 84.09%, Test: 84.28%\n",
            "Epoch: 35, Loss: 8431704.0000, Train: 87.33%, Valid: 84.40%, Test: 84.79%\n",
            "Epoch: 40, Loss: 8166310.5000, Train: 87.78%, Valid: 84.78%, Test: 85.25%\n",
            "Epoch: 45, Loss: 7940536.5000, Train: 88.30%, Valid: 84.82%, Test: 85.80%\n",
            "Epoch: 50, Loss: 7758052.0000, Train: 88.49%, Valid: 84.99%, Test: 85.98%\n",
            "Epoch: 55, Loss: 7605115.0000, Train: 88.98%, Valid: 85.21%, Test: 86.17%\n",
            "Epoch: 60, Loss: 7473325.0000, Train: 89.20%, Valid: 85.62%, Test: 86.27%\n",
            "Epoch: 65, Loss: 7359259.0000, Train: 89.33%, Valid: 85.68%, Test: 86.33%\n",
            "Epoch: 70, Loss: 7259848.0000, Train: 89.35%, Valid: 85.72%, Test: 86.51%\n",
            "Epoch: 75, Loss: 7173705.5000, Train: 89.57%, Valid: 85.84%, Test: 86.55%\n",
            "Epoch: 80, Loss: 7096868.0000, Train: 89.70%, Valid: 85.88%, Test: 86.63%\n",
            "Epoch: 85, Loss: 7026008.0000, Train: 89.67%, Valid: 85.92%, Test: 86.69%\n",
            "Epoch: 90, Loss: 6964696.5000, Train: 89.76%, Valid: 85.96%, Test: 86.77%\n",
            "Epoch: 95, Loss: 6908892.5000, Train: 89.70%, Valid: 85.98%, Test: 86.71%\n",
            "Epoch: 100, Loss: 6857392.5000, Train: 89.76%, Valid: 85.94%, Test: 86.73%\n",
            "Epoch: 105, Loss: 6809664.0000, Train: 89.94%, Valid: 85.88%, Test: 86.77%\n",
            "Epoch: 110, Loss: 6765051.0000, Train: 89.99%, Valid: 85.96%, Test: 86.73%\n",
            "Epoch: 115, Loss: 6723707.0000, Train: 90.05%, Valid: 86.00%, Test: 86.92%\n",
            "Epoch: 120, Loss: 6684785.0000, Train: 90.03%, Valid: 85.94%, Test: 86.90%\n",
            "Epoch: 125, Loss: 6648087.0000, Train: 90.08%, Valid: 85.94%, Test: 86.77%\n",
            "Epoch: 130, Loss: 6614220.0000, Train: 90.10%, Valid: 85.92%, Test: 86.82%\n",
            "Epoch: 135, Loss: 6601715.0000, Train: 90.19%, Valid: 85.90%, Test: 86.77%\n",
            "Epoch: 140, Loss: 6572090.0000, Train: 90.22%, Valid: 85.92%, Test: 86.75%\n",
            "Epoch: 145, Loss: 6544858.0000, Train: 90.24%, Valid: 85.98%, Test: 86.75%\n",
            "Epoch: 150, Loss: 6516799.5000, Train: 90.20%, Valid: 85.84%, Test: 86.80%\n",
            "Epoch: 155, Loss: 6511491.0000, Train: 90.26%, Valid: 85.90%, Test: 86.86%\n",
            "Epoch: 160, Loss: 6484586.5000, Train: 90.23%, Valid: 85.90%, Test: 86.84%\n",
            "Epoch: 165, Loss: 6462883.0000, Train: 90.22%, Valid: 85.86%, Test: 86.86%\n",
            "Epoch: 170, Loss: 6459133.5000, Train: 90.22%, Valid: 86.06%, Test: 87.02%\n",
            "Epoch: 175, Loss: 6432254.0000, Train: 90.24%, Valid: 86.00%, Test: 86.94%\n",
            "Epoch: 180, Loss: 6405042.0000, Train: 90.19%, Valid: 85.94%, Test: 86.92%\n",
            "Epoch: 185, Loss: 6394800.5000, Train: 90.30%, Valid: 86.00%, Test: 86.94%\n",
            "Epoch: 190, Loss: 6367945.0000, Train: 90.27%, Valid: 85.96%, Test: 86.86%\n",
            "Epoch: 195, Loss: 6346577.5000, Train: 90.28%, Valid: 86.04%, Test: 86.82%\n",
            "Run 04:\n",
            "Highest Train: 90.34\n",
            "Highest Valid: 86.24\n",
            "Highest Test: 87.10\n",
            "Chosen epoch: 184\n",
            "Final Train: 90.25\n",
            "Final Test: 87.00\n",
            "Epoch: 00, Loss: 30673972.0000, Train: 19.78%, Valid: 20.25%, Test: 19.07%\n",
            "Epoch: 05, Loss: 14287828.0000, Train: 42.59%, Valid: 43.52%, Test: 42.82%\n",
            "Epoch: 10, Loss: 12058509.0000, Train: 66.54%, Valid: 66.04%, Test: 65.03%\n",
            "Epoch: 15, Loss: 10852642.0000, Train: 78.51%, Valid: 76.38%, Test: 76.80%\n",
            "Epoch: 20, Loss: 10016181.0000, Train: 82.65%, Valid: 79.91%, Test: 81.38%\n",
            "Epoch: 25, Loss: 9393773.0000, Train: 85.26%, Valid: 82.71%, Test: 83.94%\n",
            "Epoch: 30, Loss: 8886191.0000, Train: 86.89%, Valid: 84.22%, Test: 85.15%\n",
            "Epoch: 35, Loss: 8492674.0000, Train: 87.84%, Valid: 84.87%, Test: 85.64%\n",
            "Epoch: 40, Loss: 8190488.0000, Train: 88.41%, Valid: 85.13%, Test: 85.88%\n",
            "Epoch: 45, Loss: 7940780.5000, Train: 88.80%, Valid: 85.37%, Test: 86.00%\n",
            "Epoch: 50, Loss: 7730112.5000, Train: 89.04%, Valid: 85.51%, Test: 86.04%\n",
            "Epoch: 55, Loss: 7550785.0000, Train: 89.25%, Valid: 85.88%, Test: 86.31%\n",
            "Epoch: 60, Loss: 7395720.0000, Train: 89.44%, Valid: 85.96%, Test: 86.37%\n",
            "Epoch: 65, Loss: 7262754.0000, Train: 89.56%, Valid: 85.90%, Test: 86.49%\n",
            "Epoch: 70, Loss: 7145970.0000, Train: 89.72%, Valid: 85.84%, Test: 86.57%\n",
            "Epoch: 75, Loss: 7044648.5000, Train: 89.82%, Valid: 85.94%, Test: 86.80%\n",
            "Epoch: 80, Loss: 6954026.0000, Train: 89.93%, Valid: 85.86%, Test: 86.96%\n",
            "Epoch: 85, Loss: 6872301.0000, Train: 89.97%, Valid: 85.92%, Test: 87.00%\n",
            "Epoch: 90, Loss: 6798216.5000, Train: 90.04%, Valid: 86.00%, Test: 86.80%\n",
            "Epoch: 95, Loss: 6728835.5000, Train: 90.10%, Valid: 85.96%, Test: 86.73%\n",
            "Epoch: 100, Loss: 6665236.0000, Train: 90.26%, Valid: 85.92%, Test: 86.80%\n",
            "Epoch: 105, Loss: 6605577.0000, Train: 90.32%, Valid: 86.04%, Test: 86.73%\n",
            "Epoch: 110, Loss: 6549715.0000, Train: 90.26%, Valid: 86.12%, Test: 86.73%\n",
            "Epoch: 115, Loss: 6498560.0000, Train: 90.34%, Valid: 86.14%, Test: 86.67%\n",
            "Epoch: 120, Loss: 6452381.0000, Train: 90.42%, Valid: 86.18%, Test: 86.71%\n",
            "Epoch: 125, Loss: 6473968.5000, Train: 90.43%, Valid: 86.10%, Test: 86.80%\n",
            "Epoch: 130, Loss: 6387518.5000, Train: 90.42%, Valid: 86.20%, Test: 86.88%\n",
            "Epoch: 135, Loss: 6347776.0000, Train: 90.60%, Valid: 86.16%, Test: 86.96%\n",
            "Epoch: 140, Loss: 6324702.5000, Train: 90.63%, Valid: 86.37%, Test: 86.86%\n",
            "Epoch: 145, Loss: 6319915.5000, Train: 90.58%, Valid: 86.02%, Test: 86.86%\n",
            "Epoch: 150, Loss: 6281094.5000, Train: 90.78%, Valid: 86.29%, Test: 86.96%\n",
            "Epoch: 155, Loss: 6255978.0000, Train: 90.78%, Valid: 86.41%, Test: 87.04%\n",
            "Epoch: 160, Loss: 6232143.0000, Train: 90.86%, Valid: 86.26%, Test: 86.96%\n",
            "Epoch: 165, Loss: 6180394.5000, Train: 90.84%, Valid: 86.29%, Test: 86.88%\n",
            "Epoch: 170, Loss: 6194002.5000, Train: 90.80%, Valid: 86.10%, Test: 86.88%\n",
            "Epoch: 175, Loss: 6166379.5000, Train: 90.86%, Valid: 85.96%, Test: 86.86%\n",
            "Epoch: 180, Loss: 6142115.0000, Train: 90.94%, Valid: 86.18%, Test: 87.04%\n",
            "Epoch: 185, Loss: 6249274.5000, Train: 90.85%, Valid: 85.82%, Test: 87.04%\n",
            "Epoch: 190, Loss: 6112231.5000, Train: 90.97%, Valid: 86.24%, Test: 87.04%\n",
            "Epoch: 195, Loss: 6114229.0000, Train: 91.03%, Valid: 86.18%, Test: 86.90%\n",
            "Run 05:\n",
            "Highest Train: 91.09\n",
            "Highest Valid: 86.53\n",
            "Highest Test: 87.20\n",
            "Chosen epoch: 158\n",
            "Final Train: 90.77\n",
            "Final Test: 87.02\n",
            "All runs:\n",
            "Highest Train: 90.64 ± 0.36\n",
            "Highest Test: 86.95 ± 0.27\n",
            "Highest Valid: 86.58 ± 0.23\n",
            "  Final Train: 90.34 ± 0.37\n",
            "   Final Test: 86.80 ± 0.22\n",
            "Saving results to logs/pubmed_edge.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 GKD/main.py --dataset pubmed --rand_split --use_bn --base_model gcn --mode train --priv_type edge --dist_mode gkd --use_kd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQEGy7m0_kGn",
        "outputId": "5dee523f-500d-4b34-d0f3-82986da2e7aa"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(data_dir='data', dataset='pubmed', sub_dataset='', cpu=False, seed=42, train_prop=0.5, valid_prop=0.25, protocol='semi', rand_split=True, metric='acc', runs=5, epochs=200, hidden_channels=32, num_layers=3, gat_heads=8, out_heads=1, hops=1, lp_alpha=0.1, gpr_alpha=0.1, jk_type='max', directed=False, num_mlp_layers=1, display_step=5, cached=False, print_prop=False, priv_type='edge', priv_ratio=0.5, save_model=False, save_name='gcn', log_name='none', base_model='gcn', not_load_teacher=False, mode='train', dist_mode='gkd', weight_decay=0.05, dropout=0.0, lr=0.01, use_bn=True, use_batch=False, batch_size=2048, oracle=False, device=0, alpha=0.5, delta=0.1, use_kd=True, beta=0.0, tau=1.0, kernel='sigmoid', t=1.0, include_last=False, s=2, m=1, lr2=0.001, sim='l2', ker_norm=False)\n",
            "cuda:0\n",
            "pubmed\n",
            "Num nodes: 19717\n",
            "torch.Size([19717, 1])\n",
            "num nodes 19717 | num classes 3 | num node feats 500\n",
            "MODEL: GeoDist(\n",
            "  (k): Kernel(\n",
            "    (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  )\n",
            "  (teacher_gnn): ModuleList(\n",
            "    (0): Linear(in_features=500, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (student_gnn): ModuleList(\n",
            "    (0): Linear(in_features=500, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  (bns2d): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            ")\n",
            "Epoch: 00, Loss: 30492376.0000, Train: 46.48%, Valid: 46.62%, Test: 46.29%\n",
            "Epoch: 05, Loss: 13358913.0000, Train: 67.37%, Valid: 67.11%, Test: 67.04%\n",
            "Epoch: 10, Loss: 10831945.0000, Train: 83.04%, Valid: 81.09%, Test: 82.13%\n",
            "Epoch: 15, Loss: 9545926.0000, Train: 85.30%, Valid: 82.86%, Test: 83.53%\n",
            "Epoch: 20, Loss: 8710531.0000, Train: 85.77%, Valid: 83.22%, Test: 84.28%\n",
            "Epoch: 25, Loss: 8053471.0000, Train: 86.65%, Valid: 83.83%, Test: 85.13%\n",
            "Epoch: 30, Loss: 7536695.0000, Train: 87.55%, Valid: 84.24%, Test: 85.15%\n",
            "Epoch: 35, Loss: 7110734.0000, Train: 88.04%, Valid: 84.95%, Test: 85.58%\n",
            "Epoch: 40, Loss: 6768038.0000, Train: 88.36%, Valid: 85.53%, Test: 85.82%\n",
            "Epoch: 45, Loss: 6493394.0000, Train: 88.80%, Valid: 85.58%, Test: 86.19%\n",
            "Epoch: 50, Loss: 6261611.0000, Train: 88.97%, Valid: 85.47%, Test: 86.04%\n",
            "Epoch: 55, Loss: 6077120.5000, Train: 89.28%, Valid: 85.84%, Test: 86.15%\n",
            "Epoch: 60, Loss: 5918932.0000, Train: 89.44%, Valid: 85.90%, Test: 86.13%\n",
            "Epoch: 65, Loss: 5784858.5000, Train: 89.69%, Valid: 86.00%, Test: 86.25%\n",
            "Epoch: 70, Loss: 5669408.5000, Train: 89.78%, Valid: 86.10%, Test: 86.47%\n",
            "Epoch: 75, Loss: 5569563.0000, Train: 89.84%, Valid: 86.04%, Test: 86.51%\n",
            "Epoch: 80, Loss: 5480048.0000, Train: 90.07%, Valid: 86.00%, Test: 86.51%\n",
            "Epoch: 85, Loss: 5401013.0000, Train: 90.22%, Valid: 86.16%, Test: 86.67%\n",
            "Epoch: 90, Loss: 5329289.0000, Train: 90.22%, Valid: 86.31%, Test: 86.65%\n",
            "Epoch: 95, Loss: 5263473.5000, Train: 90.29%, Valid: 86.37%, Test: 86.57%\n",
            "Epoch: 100, Loss: 5226855.0000, Train: 90.25%, Valid: 86.31%, Test: 86.57%\n",
            "Epoch: 105, Loss: 5182036.0000, Train: 90.41%, Valid: 86.37%, Test: 86.65%\n",
            "Epoch: 110, Loss: 5131909.0000, Train: 90.56%, Valid: 86.47%, Test: 86.65%\n",
            "Epoch: 115, Loss: 5063201.0000, Train: 90.56%, Valid: 86.53%, Test: 86.63%\n",
            "Epoch: 120, Loss: 5019532.0000, Train: 90.60%, Valid: 86.47%, Test: 86.67%\n",
            "Epoch: 125, Loss: 4991762.0000, Train: 90.59%, Valid: 86.35%, Test: 86.63%\n",
            "Epoch: 130, Loss: 4956291.0000, Train: 90.66%, Valid: 86.45%, Test: 86.47%\n",
            "Epoch: 135, Loss: 4922407.5000, Train: 90.65%, Valid: 86.26%, Test: 86.45%\n",
            "Epoch: 140, Loss: 4910605.5000, Train: 90.65%, Valid: 86.47%, Test: 86.55%\n",
            "Epoch: 145, Loss: 4918010.0000, Train: 90.74%, Valid: 86.35%, Test: 86.53%\n",
            "Epoch: 150, Loss: 4849953.0000, Train: 90.73%, Valid: 86.18%, Test: 86.45%\n",
            "Epoch: 155, Loss: 4851864.5000, Train: 90.73%, Valid: 86.20%, Test: 86.37%\n",
            "Epoch: 160, Loss: 4815296.0000, Train: 90.73%, Valid: 86.02%, Test: 86.25%\n",
            "Epoch: 165, Loss: 4782470.0000, Train: 90.72%, Valid: 86.08%, Test: 86.31%\n",
            "Epoch: 170, Loss: 4803147.0000, Train: 90.71%, Valid: 86.06%, Test: 86.23%\n",
            "Epoch: 175, Loss: 4760702.0000, Train: 90.71%, Valid: 86.04%, Test: 86.33%\n",
            "Epoch: 180, Loss: 4808523.5000, Train: 90.77%, Valid: 86.10%, Test: 86.37%\n",
            "Epoch: 185, Loss: 4718048.0000, Train: 90.79%, Valid: 86.14%, Test: 86.61%\n",
            "Epoch: 190, Loss: 4709189.0000, Train: 90.86%, Valid: 86.33%, Test: 86.43%\n",
            "Epoch: 195, Loss: 4693183.5000, Train: 90.77%, Valid: 86.04%, Test: 86.25%\n",
            "Run 01:\n",
            "Highest Train: 90.89\n",
            "Highest Valid: 86.55\n",
            "Highest Test: 86.75\n",
            "Chosen epoch: 108\n",
            "Final Train: 90.44\n",
            "Final Test: 86.59\n",
            "Epoch: 00, Loss: 31617328.0000, Train: 46.78%, Valid: 46.52%, Test: 46.65%\n",
            "Epoch: 05, Loss: 15105088.0000, Train: 69.00%, Valid: 69.12%, Test: 69.21%\n",
            "Epoch: 10, Loss: 12370526.0000, Train: 80.92%, Valid: 79.87%, Test: 79.61%\n",
            "Epoch: 15, Loss: 11104894.0000, Train: 84.30%, Valid: 82.33%, Test: 82.35%\n",
            "Epoch: 20, Loss: 10241489.0000, Train: 86.18%, Valid: 83.51%, Test: 84.08%\n",
            "Epoch: 25, Loss: 9640014.0000, Train: 87.25%, Valid: 84.50%, Test: 84.36%\n",
            "Epoch: 30, Loss: 9189688.0000, Train: 87.77%, Valid: 84.97%, Test: 85.05%\n",
            "Epoch: 35, Loss: 8824416.0000, Train: 88.18%, Valid: 85.33%, Test: 85.64%\n",
            "Epoch: 40, Loss: 8539282.0000, Train: 88.54%, Valid: 85.76%, Test: 86.02%\n",
            "Epoch: 45, Loss: 8301321.5000, Train: 88.88%, Valid: 85.82%, Test: 85.96%\n",
            "Epoch: 50, Loss: 8104327.5000, Train: 89.07%, Valid: 86.10%, Test: 85.84%\n",
            "Epoch: 55, Loss: 7939408.0000, Train: 89.22%, Valid: 86.16%, Test: 85.98%\n",
            "Epoch: 60, Loss: 7798662.5000, Train: 89.43%, Valid: 86.10%, Test: 86.06%\n",
            "Epoch: 65, Loss: 7673518.0000, Train: 89.57%, Valid: 86.08%, Test: 86.23%\n",
            "Epoch: 70, Loss: 7566020.5000, Train: 89.68%, Valid: 86.18%, Test: 86.27%\n",
            "Epoch: 75, Loss: 7471424.0000, Train: 89.77%, Valid: 86.12%, Test: 86.11%\n",
            "Epoch: 80, Loss: 7386484.0000, Train: 89.89%, Valid: 86.20%, Test: 86.11%\n",
            "Epoch: 85, Loss: 7310041.0000, Train: 89.88%, Valid: 86.12%, Test: 86.21%\n",
            "Epoch: 90, Loss: 7240796.5000, Train: 90.01%, Valid: 86.33%, Test: 86.02%\n",
            "Epoch: 95, Loss: 7178021.5000, Train: 90.03%, Valid: 86.41%, Test: 86.06%\n",
            "Epoch: 100, Loss: 7120784.0000, Train: 90.01%, Valid: 86.49%, Test: 86.21%\n",
            "Epoch: 105, Loss: 7066650.0000, Train: 90.17%, Valid: 86.47%, Test: 86.21%\n",
            "Epoch: 110, Loss: 7017523.0000, Train: 90.26%, Valid: 86.57%, Test: 86.29%\n",
            "Epoch: 115, Loss: 6972185.0000, Train: 90.21%, Valid: 86.55%, Test: 86.25%\n",
            "Epoch: 120, Loss: 6930383.5000, Train: 90.21%, Valid: 86.61%, Test: 86.17%\n",
            "Epoch: 125, Loss: 6890604.0000, Train: 90.25%, Valid: 86.49%, Test: 86.15%\n",
            "Epoch: 130, Loss: 6856958.0000, Train: 90.36%, Valid: 86.49%, Test: 86.21%\n",
            "Epoch: 135, Loss: 6837327.0000, Train: 90.35%, Valid: 86.47%, Test: 86.27%\n",
            "Epoch: 140, Loss: 6809052.0000, Train: 90.36%, Valid: 86.55%, Test: 86.33%\n",
            "Epoch: 145, Loss: 6788907.0000, Train: 90.38%, Valid: 86.45%, Test: 86.31%\n",
            "Epoch: 150, Loss: 6744457.0000, Train: 90.42%, Valid: 86.51%, Test: 86.49%\n",
            "Epoch: 155, Loss: 6718507.0000, Train: 90.53%, Valid: 86.59%, Test: 86.39%\n",
            "Epoch: 160, Loss: 6734548.0000, Train: 90.50%, Valid: 86.39%, Test: 86.35%\n",
            "Epoch: 165, Loss: 6686690.5000, Train: 90.53%, Valid: 86.37%, Test: 86.41%\n",
            "Epoch: 170, Loss: 6670822.0000, Train: 90.56%, Valid: 86.47%, Test: 86.43%\n",
            "Epoch: 175, Loss: 6685294.0000, Train: 90.43%, Valid: 86.71%, Test: 86.49%\n",
            "Epoch: 180, Loss: 6648877.5000, Train: 90.47%, Valid: 86.71%, Test: 86.47%\n",
            "Epoch: 185, Loss: 6642502.0000, Train: 90.53%, Valid: 86.67%, Test: 86.53%\n",
            "Epoch: 190, Loss: 6621765.0000, Train: 90.40%, Valid: 86.59%, Test: 86.31%\n",
            "Epoch: 195, Loss: 6598475.5000, Train: 90.43%, Valid: 86.57%, Test: 86.47%\n",
            "Run 02:\n",
            "Highest Train: 90.60\n",
            "Highest Valid: 86.71\n",
            "Highest Test: 86.63\n",
            "Chosen epoch: 174\n",
            "Final Train: 90.44\n",
            "Final Test: 86.43\n",
            "Epoch: 00, Loss: 31013162.0000, Train: 52.42%, Valid: 53.32%, Test: 52.43%\n",
            "Epoch: 05, Loss: 12696504.0000, Train: 77.69%, Valid: 76.97%, Test: 77.20%\n",
            "Epoch: 10, Loss: 10528904.0000, Train: 81.64%, Valid: 80.10%, Test: 79.96%\n",
            "Epoch: 15, Loss: 9489162.0000, Train: 83.85%, Valid: 81.76%, Test: 81.81%\n",
            "Epoch: 20, Loss: 8808852.0000, Train: 85.75%, Valid: 83.65%, Test: 84.12%\n",
            "Epoch: 25, Loss: 8326531.5000, Train: 86.59%, Valid: 84.93%, Test: 84.65%\n",
            "Epoch: 30, Loss: 7935254.0000, Train: 87.31%, Valid: 84.91%, Test: 85.15%\n",
            "Epoch: 35, Loss: 7636390.5000, Train: 87.69%, Valid: 84.99%, Test: 85.46%\n",
            "Epoch: 40, Loss: 7384643.5000, Train: 88.03%, Valid: 85.49%, Test: 85.35%\n",
            "Epoch: 45, Loss: 7177123.5000, Train: 88.27%, Valid: 85.68%, Test: 85.70%\n",
            "Epoch: 50, Loss: 7002964.0000, Train: 88.62%, Valid: 85.86%, Test: 86.19%\n",
            "Epoch: 55, Loss: 6863202.5000, Train: 88.86%, Valid: 85.80%, Test: 86.47%\n",
            "Epoch: 60, Loss: 6744044.5000, Train: 89.15%, Valid: 85.78%, Test: 86.43%\n",
            "Epoch: 65, Loss: 6640677.0000, Train: 89.25%, Valid: 85.80%, Test: 86.51%\n",
            "Epoch: 70, Loss: 6552230.5000, Train: 89.41%, Valid: 86.10%, Test: 86.61%\n",
            "Epoch: 75, Loss: 6474198.0000, Train: 89.50%, Valid: 86.18%, Test: 86.71%\n",
            "Epoch: 80, Loss: 6404910.0000, Train: 89.50%, Valid: 86.31%, Test: 86.75%\n",
            "Epoch: 85, Loss: 6342299.0000, Train: 89.62%, Valid: 86.41%, Test: 86.71%\n",
            "Epoch: 90, Loss: 6284760.0000, Train: 89.65%, Valid: 86.45%, Test: 86.75%\n",
            "Epoch: 95, Loss: 6234118.5000, Train: 89.75%, Valid: 86.45%, Test: 86.80%\n",
            "Epoch: 100, Loss: 6188081.0000, Train: 89.75%, Valid: 86.57%, Test: 86.92%\n",
            "Epoch: 105, Loss: 6145863.0000, Train: 89.72%, Valid: 86.55%, Test: 86.90%\n",
            "Epoch: 110, Loss: 6107137.0000, Train: 89.82%, Valid: 86.61%, Test: 86.98%\n",
            "Epoch: 115, Loss: 6071212.0000, Train: 89.84%, Valid: 86.75%, Test: 86.86%\n",
            "Epoch: 120, Loss: 6119329.5000, Train: 89.74%, Valid: 86.79%, Test: 86.77%\n",
            "Epoch: 125, Loss: 6023804.0000, Train: 89.87%, Valid: 86.75%, Test: 86.94%\n",
            "Epoch: 130, Loss: 5995314.5000, Train: 89.86%, Valid: 86.75%, Test: 87.02%\n",
            "Epoch: 135, Loss: 5974487.5000, Train: 89.85%, Valid: 86.63%, Test: 87.06%\n",
            "Epoch: 140, Loss: 5945234.0000, Train: 89.84%, Valid: 86.65%, Test: 86.98%\n",
            "Epoch: 145, Loss: 5921671.5000, Train: 90.01%, Valid: 86.63%, Test: 87.04%\n",
            "Epoch: 150, Loss: 5915029.5000, Train: 89.95%, Valid: 86.47%, Test: 86.98%\n",
            "Epoch: 155, Loss: 5891372.0000, Train: 89.92%, Valid: 86.57%, Test: 86.96%\n",
            "Epoch: 160, Loss: 5880396.0000, Train: 89.92%, Valid: 86.63%, Test: 86.92%\n",
            "Epoch: 165, Loss: 5853320.0000, Train: 89.95%, Valid: 86.59%, Test: 86.98%\n",
            "Epoch: 170, Loss: 5832704.5000, Train: 90.07%, Valid: 86.55%, Test: 86.94%\n",
            "Epoch: 175, Loss: 5859112.0000, Train: 90.03%, Valid: 86.59%, Test: 86.90%\n",
            "Epoch: 180, Loss: 5833852.0000, Train: 90.01%, Valid: 86.47%, Test: 86.94%\n",
            "Epoch: 185, Loss: 5805497.5000, Train: 90.11%, Valid: 86.57%, Test: 86.96%\n",
            "Epoch: 190, Loss: 5782797.0000, Train: 90.11%, Valid: 86.63%, Test: 86.92%\n",
            "Epoch: 195, Loss: 5765099.5000, Train: 90.19%, Valid: 86.37%, Test: 86.92%\n",
            "Run 03:\n",
            "Highest Train: 90.23\n",
            "Highest Valid: 86.87\n",
            "Highest Test: 87.10\n",
            "Chosen epoch: 122\n",
            "Final Train: 89.84\n",
            "Final Test: 86.90\n",
            "Epoch: 00, Loss: 30524538.0000, Train: 40.15%, Valid: 38.73%, Test: 39.49%\n",
            "Epoch: 05, Loss: 14157582.0000, Train: 67.70%, Valid: 66.36%, Test: 68.03%\n",
            "Epoch: 10, Loss: 11709441.0000, Train: 80.52%, Valid: 78.76%, Test: 78.70%\n",
            "Epoch: 15, Loss: 10501252.0000, Train: 83.97%, Valid: 81.64%, Test: 82.15%\n",
            "Epoch: 20, Loss: 9736450.0000, Train: 85.32%, Valid: 83.04%, Test: 83.55%\n",
            "Epoch: 25, Loss: 9197147.0000, Train: 86.28%, Valid: 83.71%, Test: 83.87%\n",
            "Epoch: 30, Loss: 8768206.0000, Train: 86.85%, Valid: 84.09%, Test: 84.28%\n",
            "Epoch: 35, Loss: 8431704.0000, Train: 87.33%, Valid: 84.40%, Test: 84.79%\n",
            "Epoch: 40, Loss: 8166310.5000, Train: 87.78%, Valid: 84.78%, Test: 85.25%\n",
            "Epoch: 45, Loss: 7940536.5000, Train: 88.30%, Valid: 84.82%, Test: 85.80%\n",
            "Epoch: 50, Loss: 7758052.0000, Train: 88.49%, Valid: 84.99%, Test: 85.98%\n",
            "Epoch: 55, Loss: 7605115.0000, Train: 88.98%, Valid: 85.21%, Test: 86.17%\n",
            "Epoch: 60, Loss: 7473325.0000, Train: 89.20%, Valid: 85.62%, Test: 86.27%\n",
            "Epoch: 65, Loss: 7359259.0000, Train: 89.33%, Valid: 85.68%, Test: 86.33%\n",
            "Epoch: 70, Loss: 7259848.0000, Train: 89.35%, Valid: 85.72%, Test: 86.51%\n",
            "Epoch: 75, Loss: 7173705.5000, Train: 89.57%, Valid: 85.84%, Test: 86.55%\n",
            "Epoch: 80, Loss: 7096868.0000, Train: 89.70%, Valid: 85.88%, Test: 86.63%\n",
            "Epoch: 85, Loss: 7026008.0000, Train: 89.67%, Valid: 85.92%, Test: 86.69%\n",
            "Epoch: 90, Loss: 6964696.5000, Train: 89.76%, Valid: 85.96%, Test: 86.77%\n",
            "Epoch: 95, Loss: 6908893.0000, Train: 89.70%, Valid: 85.98%, Test: 86.71%\n",
            "Epoch: 100, Loss: 6857394.5000, Train: 89.76%, Valid: 85.94%, Test: 86.71%\n",
            "Epoch: 105, Loss: 6809667.0000, Train: 89.94%, Valid: 85.90%, Test: 86.77%\n",
            "Epoch: 110, Loss: 6765051.0000, Train: 89.99%, Valid: 85.96%, Test: 86.75%\n",
            "Epoch: 115, Loss: 6723696.5000, Train: 90.06%, Valid: 86.00%, Test: 86.90%\n",
            "Epoch: 120, Loss: 6684769.0000, Train: 90.02%, Valid: 85.96%, Test: 86.90%\n",
            "Epoch: 125, Loss: 6648052.0000, Train: 90.07%, Valid: 85.94%, Test: 86.82%\n",
            "Epoch: 130, Loss: 6613569.0000, Train: 90.11%, Valid: 85.90%, Test: 86.82%\n",
            "Epoch: 135, Loss: 6607733.0000, Train: 90.21%, Valid: 85.86%, Test: 86.69%\n",
            "Epoch: 140, Loss: 6579343.0000, Train: 90.23%, Valid: 85.88%, Test: 86.73%\n",
            "Epoch: 145, Loss: 6546736.0000, Train: 90.22%, Valid: 85.94%, Test: 86.71%\n",
            "Epoch: 150, Loss: 6517747.0000, Train: 90.19%, Valid: 85.92%, Test: 86.71%\n",
            "Epoch: 155, Loss: 6513320.0000, Train: 90.32%, Valid: 86.04%, Test: 86.88%\n",
            "Epoch: 160, Loss: 6493041.0000, Train: 90.23%, Valid: 85.90%, Test: 86.88%\n",
            "Epoch: 165, Loss: 6458331.0000, Train: 90.22%, Valid: 85.90%, Test: 86.88%\n",
            "Epoch: 170, Loss: 6427854.0000, Train: 90.26%, Valid: 86.04%, Test: 86.90%\n",
            "Epoch: 175, Loss: 6433776.0000, Train: 90.15%, Valid: 86.08%, Test: 86.88%\n",
            "Epoch: 180, Loss: 6430794.0000, Train: 90.28%, Valid: 86.00%, Test: 86.90%\n",
            "Epoch: 185, Loss: 6378080.5000, Train: 90.21%, Valid: 85.94%, Test: 87.00%\n",
            "Epoch: 190, Loss: 6349864.0000, Train: 90.21%, Valid: 85.96%, Test: 86.92%\n",
            "Epoch: 195, Loss: 6351747.0000, Train: 90.22%, Valid: 86.16%, Test: 86.96%\n",
            "Run 04:\n",
            "Highest Train: 90.32\n",
            "Highest Valid: 86.20\n",
            "Highest Test: 87.06\n",
            "Chosen epoch: 198\n",
            "Final Train: 90.22\n",
            "Final Test: 86.98\n",
            "Epoch: 00, Loss: 30673972.0000, Train: 19.78%, Valid: 20.25%, Test: 19.07%\n",
            "Epoch: 05, Loss: 14287828.0000, Train: 42.59%, Valid: 43.52%, Test: 42.82%\n",
            "Epoch: 10, Loss: 12058509.0000, Train: 66.54%, Valid: 66.04%, Test: 65.03%\n",
            "Epoch: 15, Loss: 10852642.0000, Train: 78.51%, Valid: 76.38%, Test: 76.80%\n",
            "Epoch: 20, Loss: 10016181.0000, Train: 82.65%, Valid: 79.91%, Test: 81.38%\n",
            "Epoch: 25, Loss: 9393773.0000, Train: 85.26%, Valid: 82.71%, Test: 83.94%\n",
            "Epoch: 30, Loss: 8886191.0000, Train: 86.89%, Valid: 84.22%, Test: 85.15%\n",
            "Epoch: 35, Loss: 8492674.0000, Train: 87.84%, Valid: 84.87%, Test: 85.64%\n",
            "Epoch: 40, Loss: 8190488.0000, Train: 88.41%, Valid: 85.13%, Test: 85.88%\n",
            "Epoch: 45, Loss: 7940782.5000, Train: 88.80%, Valid: 85.37%, Test: 86.00%\n",
            "Epoch: 50, Loss: 7730116.5000, Train: 89.04%, Valid: 85.51%, Test: 86.04%\n",
            "Epoch: 55, Loss: 7550781.5000, Train: 89.25%, Valid: 85.88%, Test: 86.31%\n",
            "Epoch: 60, Loss: 7395712.0000, Train: 89.44%, Valid: 85.96%, Test: 86.39%\n",
            "Epoch: 65, Loss: 7262753.0000, Train: 89.56%, Valid: 85.90%, Test: 86.47%\n",
            "Epoch: 70, Loss: 7145981.5000, Train: 89.73%, Valid: 85.84%, Test: 86.57%\n",
            "Epoch: 75, Loss: 7044672.0000, Train: 89.82%, Valid: 85.94%, Test: 86.80%\n",
            "Epoch: 80, Loss: 6954046.0000, Train: 89.92%, Valid: 85.88%, Test: 86.96%\n",
            "Epoch: 85, Loss: 6872308.0000, Train: 89.95%, Valid: 85.86%, Test: 86.96%\n",
            "Epoch: 90, Loss: 6798296.5000, Train: 90.05%, Valid: 86.00%, Test: 86.82%\n",
            "Epoch: 95, Loss: 6728898.5000, Train: 90.11%, Valid: 85.96%, Test: 86.75%\n",
            "Epoch: 100, Loss: 6665285.0000, Train: 90.27%, Valid: 85.92%, Test: 86.84%\n",
            "Epoch: 105, Loss: 6605680.0000, Train: 90.30%, Valid: 86.04%, Test: 86.75%\n",
            "Epoch: 110, Loss: 6549668.5000, Train: 90.27%, Valid: 86.16%, Test: 86.73%\n",
            "Epoch: 115, Loss: 6498460.5000, Train: 90.38%, Valid: 86.14%, Test: 86.63%\n",
            "Epoch: 120, Loss: 6451221.0000, Train: 90.43%, Valid: 86.14%, Test: 86.69%\n",
            "Epoch: 125, Loss: 6489493.0000, Train: 90.36%, Valid: 85.78%, Test: 86.80%\n",
            "Epoch: 130, Loss: 6408516.0000, Train: 90.45%, Valid: 86.24%, Test: 86.86%\n",
            "Epoch: 135, Loss: 6345094.5000, Train: 90.61%, Valid: 86.12%, Test: 86.94%\n",
            "Epoch: 140, Loss: 6325791.5000, Train: 90.69%, Valid: 86.20%, Test: 86.88%\n",
            "Epoch: 145, Loss: 6291781.0000, Train: 90.70%, Valid: 86.18%, Test: 86.92%\n",
            "Epoch: 150, Loss: 6365840.0000, Train: 90.82%, Valid: 86.55%, Test: 86.96%\n",
            "Epoch: 155, Loss: 6287202.5000, Train: 90.83%, Valid: 86.33%, Test: 87.06%\n",
            "Epoch: 160, Loss: 6206573.0000, Train: 90.76%, Valid: 86.06%, Test: 86.94%\n",
            "Epoch: 165, Loss: 6181022.5000, Train: 90.84%, Valid: 86.04%, Test: 86.96%\n",
            "Epoch: 170, Loss: 6149365.5000, Train: 90.87%, Valid: 86.02%, Test: 86.90%\n",
            "Epoch: 175, Loss: 6178543.5000, Train: 91.00%, Valid: 86.22%, Test: 87.14%\n",
            "Epoch: 180, Loss: 6152375.0000, Train: 91.01%, Valid: 86.04%, Test: 87.16%\n",
            "Epoch: 185, Loss: 6105194.0000, Train: 90.99%, Valid: 86.16%, Test: 87.08%\n",
            "Epoch: 190, Loss: 6083452.0000, Train: 90.95%, Valid: 86.00%, Test: 87.02%\n",
            "Epoch: 195, Loss: 6072083.0000, Train: 91.03%, Valid: 86.10%, Test: 87.08%\n",
            "Run 05:\n",
            "Highest Train: 91.04\n",
            "Highest Valid: 86.55\n",
            "Highest Test: 87.18\n",
            "Chosen epoch: 151\n",
            "Final Train: 90.82\n",
            "Final Test: 86.96\n",
            "All runs:\n",
            "Highest Train: 90.62 ± 0.35\n",
            "Highest Test: 86.95 ± 0.24\n",
            "Highest Valid: 86.58 ± 0.25\n",
            "  Final Train: 90.35 ± 0.36\n",
            "   Final Test: 86.77 ± 0.25\n",
            "Saving results to logs/pubmed_edge.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 GKD/main.py --dataset pubmed --rand_split --use_bn --base_model gcn --mode train --priv_type edge --dist_mode pgkd --use_kd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rqm0jSwk_oNZ",
        "outputId": "b11d6190-9abb-4d81-e703-04f3702fe28e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(data_dir='data', dataset='pubmed', sub_dataset='', cpu=False, seed=42, train_prop=0.5, valid_prop=0.25, protocol='semi', rand_split=True, metric='acc', runs=5, epochs=200, hidden_channels=32, num_layers=3, gat_heads=8, out_heads=1, hops=1, lp_alpha=0.1, gpr_alpha=0.1, jk_type='max', directed=False, num_mlp_layers=1, display_step=5, cached=False, print_prop=False, priv_type='edge', priv_ratio=0.5, save_model=False, save_name='gcn', log_name='none', base_model='gcn', not_load_teacher=False, mode='train', dist_mode='pgkd', weight_decay=0.05, dropout=0.0, lr=0.01, use_bn=True, use_batch=False, batch_size=2048, oracle=False, device=0, alpha=0.5, delta=0.1, use_kd=True, beta=0.0, tau=1.0, kernel='sigmoid', t=1.0, include_last=False, s=2, m=1, lr2=0.001, sim='l2', ker_norm=False)\n",
            "cuda:0\n",
            "pubmed\n",
            "Num nodes: 19717\n",
            "torch.Size([19717, 1])\n",
            "num nodes 19717 | num classes 3 | num node feats 500\n",
            "MODEL: GeoDist(\n",
            "  (k): Kernel(\n",
            "    (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  )\n",
            "  (teacher_gnn): ModuleList(\n",
            "    (0): Linear(in_features=500, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (student_gnn): ModuleList(\n",
            "    (0): Linear(in_features=500, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  (bns2d): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            ")\n",
            "Epoch: 00, Loss: 6341668864.0000, Train: 43.60%, Valid: 44.57%, Test: 43.91%\n",
            "Epoch: 05, Loss: 2130430976.0000, Train: 73.25%, Valid: 73.04%, Test: 72.35%\n",
            "Epoch: 10, Loss: 1683976320.0000, Train: 84.06%, Valid: 82.35%, Test: 82.72%\n",
            "Epoch: 15, Loss: 1460921600.0000, Train: 86.42%, Valid: 84.60%, Test: 84.99%\n",
            "Epoch: 20, Loss: 1310125696.0000, Train: 87.03%, Valid: 85.49%, Test: 85.38%\n",
            "Epoch: 25, Loss: 1197878016.0000, Train: 87.61%, Valid: 86.08%, Test: 85.88%\n",
            "Epoch: 30, Loss: 1106704128.0000, Train: 88.14%, Valid: 86.51%, Test: 86.13%\n",
            "Epoch: 35, Loss: 1033196608.0000, Train: 88.54%, Valid: 86.91%, Test: 86.43%\n",
            "Epoch: 40, Loss: 971373824.0000, Train: 88.96%, Valid: 87.16%, Test: 86.69%\n",
            "Epoch: 45, Loss: 918176384.0000, Train: 89.18%, Valid: 87.22%, Test: 86.75%\n",
            "Epoch: 50, Loss: 871220992.0000, Train: 89.47%, Valid: 87.32%, Test: 87.26%\n",
            "Epoch: 55, Loss: 828964672.0000, Train: 89.57%, Valid: 87.26%, Test: 87.40%\n",
            "Epoch: 60, Loss: 791807872.0000, Train: 89.78%, Valid: 87.28%, Test: 87.67%\n",
            "Epoch: 65, Loss: 758093696.0000, Train: 89.91%, Valid: 87.40%, Test: 87.71%\n",
            "Epoch: 70, Loss: 726919424.0000, Train: 89.94%, Valid: 87.60%, Test: 87.83%\n",
            "Epoch: 75, Loss: 698494464.0000, Train: 90.00%, Valid: 87.66%, Test: 87.75%\n",
            "Epoch: 80, Loss: 672249728.0000, Train: 90.08%, Valid: 87.48%, Test: 87.81%\n",
            "Epoch: 85, Loss: 648305024.0000, Train: 90.20%, Valid: 87.50%, Test: 87.81%\n",
            "Epoch: 90, Loss: 625711936.0000, Train: 90.26%, Valid: 87.42%, Test: 87.81%\n",
            "Epoch: 95, Loss: 603517504.0000, Train: 90.29%, Valid: 87.42%, Test: 87.91%\n",
            "Epoch: 100, Loss: 581597120.0000, Train: 90.30%, Valid: 87.22%, Test: 88.03%\n",
            "Epoch: 105, Loss: 560821888.0000, Train: 90.38%, Valid: 87.26%, Test: 87.93%\n",
            "Epoch: 110, Loss: 542676928.0000, Train: 90.42%, Valid: 87.22%, Test: 87.87%\n",
            "Epoch: 115, Loss: 526875264.0000, Train: 90.44%, Valid: 87.28%, Test: 87.81%\n",
            "Epoch: 120, Loss: 513236224.0000, Train: 90.43%, Valid: 87.24%, Test: 87.85%\n",
            "Epoch: 125, Loss: 506055360.0000, Train: 90.48%, Valid: 87.34%, Test: 87.91%\n",
            "Epoch: 130, Loss: 493359232.0000, Train: 90.54%, Valid: 87.34%, Test: 87.99%\n",
            "Epoch: 135, Loss: 494297536.0000, Train: 90.59%, Valid: 87.22%, Test: 87.93%\n",
            "Epoch: 140, Loss: 473304992.0000, Train: 90.60%, Valid: 87.28%, Test: 87.75%\n",
            "Epoch: 145, Loss: 459398688.0000, Train: 90.58%, Valid: 87.18%, Test: 87.89%\n",
            "Epoch: 150, Loss: 449557632.0000, Train: 90.62%, Valid: 87.26%, Test: 87.75%\n",
            "Epoch: 155, Loss: 436159232.0000, Train: 90.61%, Valid: 87.34%, Test: 87.85%\n",
            "Epoch: 160, Loss: 424506688.0000, Train: 90.58%, Valid: 87.30%, Test: 87.81%\n",
            "Epoch: 165, Loss: 412247456.0000, Train: 90.48%, Valid: 87.16%, Test: 87.75%\n",
            "Epoch: 170, Loss: 401488416.0000, Train: 90.57%, Valid: 87.08%, Test: 87.73%\n",
            "Epoch: 175, Loss: 392576864.0000, Train: 90.48%, Valid: 87.00%, Test: 87.63%\n",
            "Epoch: 180, Loss: 384486528.0000, Train: 90.52%, Valid: 86.98%, Test: 87.63%\n",
            "Epoch: 185, Loss: 380766496.0000, Train: 90.38%, Valid: 87.00%, Test: 87.69%\n",
            "Epoch: 190, Loss: 383976256.0000, Train: 90.50%, Valid: 86.98%, Test: 87.55%\n",
            "Epoch: 195, Loss: 380392320.0000, Train: 90.50%, Valid: 87.10%, Test: 87.63%\n",
            "Run 01:\n",
            "Highest Train: 90.65\n",
            "Highest Valid: 87.73\n",
            "Highest Test: 88.03\n",
            "Chosen epoch: 74\n",
            "Final Train: 89.99\n",
            "Final Test: 87.79\n",
            "Epoch: 00, Loss: 7274234368.0000, Train: 49.36%, Valid: 50.15%, Test: 50.12%\n",
            "Epoch: 05, Loss: 2465123328.0000, Train: 65.48%, Valid: 64.48%, Test: 64.87%\n",
            "Epoch: 10, Loss: 1794357248.0000, Train: 78.91%, Valid: 77.70%, Test: 78.07%\n",
            "Epoch: 15, Loss: 1543337984.0000, Train: 85.38%, Valid: 84.13%, Test: 84.10%\n",
            "Epoch: 20, Loss: 1386616704.0000, Train: 86.71%, Valid: 84.99%, Test: 85.07%\n",
            "Epoch: 25, Loss: 1274738176.0000, Train: 87.24%, Valid: 85.31%, Test: 85.78%\n",
            "Epoch: 30, Loss: 1187534592.0000, Train: 87.59%, Valid: 85.47%, Test: 86.06%\n",
            "Epoch: 35, Loss: 1111828992.0000, Train: 87.90%, Valid: 85.62%, Test: 86.53%\n",
            "Epoch: 40, Loss: 1047281216.0000, Train: 88.02%, Valid: 85.66%, Test: 86.77%\n",
            "Epoch: 45, Loss: 992321856.0000, Train: 88.42%, Valid: 85.92%, Test: 86.92%\n",
            "Epoch: 50, Loss: 943602688.0000, Train: 88.82%, Valid: 86.16%, Test: 87.12%\n",
            "Epoch: 55, Loss: 899568512.0000, Train: 89.18%, Valid: 86.37%, Test: 87.38%\n",
            "Epoch: 60, Loss: 859874688.0000, Train: 89.35%, Valid: 86.57%, Test: 87.57%\n",
            "Epoch: 65, Loss: 823144064.0000, Train: 89.42%, Valid: 86.57%, Test: 87.53%\n",
            "Epoch: 70, Loss: 787988032.0000, Train: 89.51%, Valid: 86.55%, Test: 87.63%\n",
            "Epoch: 75, Loss: 754585600.0000, Train: 89.67%, Valid: 86.73%, Test: 87.69%\n",
            "Epoch: 80, Loss: 724720576.0000, Train: 89.78%, Valid: 86.81%, Test: 87.69%\n",
            "Epoch: 85, Loss: 697200704.0000, Train: 89.91%, Valid: 86.83%, Test: 87.67%\n",
            "Epoch: 90, Loss: 671435136.0000, Train: 89.91%, Valid: 86.83%, Test: 87.63%\n",
            "Epoch: 95, Loss: 648408704.0000, Train: 89.95%, Valid: 86.85%, Test: 87.65%\n",
            "Epoch: 100, Loss: 627290816.0000, Train: 90.02%, Valid: 86.91%, Test: 87.46%\n",
            "Epoch: 105, Loss: 608343552.0000, Train: 90.00%, Valid: 86.98%, Test: 87.42%\n",
            "Epoch: 110, Loss: 590874624.0000, Train: 90.06%, Valid: 86.98%, Test: 87.53%\n",
            "Epoch: 115, Loss: 575252608.0000, Train: 90.08%, Valid: 86.95%, Test: 87.59%\n",
            "Epoch: 120, Loss: 574343360.0000, Train: 90.20%, Valid: 87.00%, Test: 87.55%\n",
            "Epoch: 125, Loss: 557473024.0000, Train: 90.24%, Valid: 87.00%, Test: 87.51%\n",
            "Epoch: 130, Loss: 542074624.0000, Train: 90.22%, Valid: 86.93%, Test: 87.53%\n",
            "Epoch: 135, Loss: 530664160.0000, Train: 90.22%, Valid: 86.95%, Test: 87.57%\n",
            "Epoch: 140, Loss: 521314400.0000, Train: 90.27%, Valid: 87.04%, Test: 87.57%\n",
            "Epoch: 145, Loss: 510490112.0000, Train: 90.28%, Valid: 86.93%, Test: 87.67%\n",
            "Epoch: 150, Loss: 506411392.0000, Train: 90.26%, Valid: 87.06%, Test: 87.48%\n",
            "Epoch: 155, Loss: 492526336.0000, Train: 90.29%, Valid: 87.06%, Test: 87.59%\n",
            "Epoch: 160, Loss: 484632448.0000, Train: 90.33%, Valid: 87.06%, Test: 87.65%\n",
            "Epoch: 165, Loss: 492069408.0000, Train: 90.19%, Valid: 87.10%, Test: 87.48%\n",
            "Epoch: 170, Loss: 472673440.0000, Train: 90.16%, Valid: 87.14%, Test: 87.59%\n",
            "Epoch: 175, Loss: 456010752.0000, Train: 90.26%, Valid: 87.06%, Test: 87.69%\n",
            "Epoch: 180, Loss: 452097664.0000, Train: 90.25%, Valid: 87.02%, Test: 87.77%\n",
            "Epoch: 185, Loss: 440072704.0000, Train: 90.21%, Valid: 86.98%, Test: 87.79%\n",
            "Epoch: 190, Loss: 435346752.0000, Train: 90.23%, Valid: 86.91%, Test: 87.87%\n",
            "Epoch: 195, Loss: 436330752.0000, Train: 90.20%, Valid: 86.93%, Test: 87.65%\n",
            "Run 02:\n",
            "Highest Train: 90.33\n",
            "Highest Valid: 87.14\n",
            "Highest Test: 87.87\n",
            "Chosen epoch: 171\n",
            "Final Train: 90.16\n",
            "Final Test: 87.59\n",
            "Epoch: 00, Loss: 5109819904.0000, Train: 50.80%, Valid: 50.88%, Test: 51.08%\n",
            "Epoch: 05, Loss: 1724495232.0000, Train: 70.76%, Valid: 69.87%, Test: 70.79%\n",
            "Epoch: 10, Loss: 1280666112.0000, Train: 82.17%, Valid: 80.89%, Test: 81.16%\n",
            "Epoch: 15, Loss: 1084165376.0000, Train: 84.34%, Valid: 82.96%, Test: 83.33%\n",
            "Epoch: 20, Loss: 967585408.0000, Train: 85.25%, Valid: 84.16%, Test: 84.30%\n",
            "Epoch: 25, Loss: 886157056.0000, Train: 86.11%, Valid: 84.58%, Test: 85.05%\n",
            "Epoch: 30, Loss: 826356224.0000, Train: 86.56%, Valid: 84.80%, Test: 85.38%\n",
            "Epoch: 35, Loss: 779568192.0000, Train: 86.70%, Valid: 85.07%, Test: 85.44%\n",
            "Epoch: 40, Loss: 738327488.0000, Train: 87.19%, Valid: 85.39%, Test: 85.66%\n",
            "Epoch: 45, Loss: 700195968.0000, Train: 87.50%, Valid: 85.49%, Test: 85.98%\n",
            "Epoch: 50, Loss: 665845696.0000, Train: 87.86%, Valid: 85.94%, Test: 86.19%\n",
            "Epoch: 55, Loss: 636017536.0000, Train: 88.10%, Valid: 86.10%, Test: 86.43%\n",
            "Epoch: 60, Loss: 610560128.0000, Train: 88.27%, Valid: 86.10%, Test: 86.53%\n",
            "Epoch: 65, Loss: 588324288.0000, Train: 88.42%, Valid: 86.16%, Test: 86.61%\n",
            "Epoch: 70, Loss: 569237824.0000, Train: 88.54%, Valid: 86.24%, Test: 86.71%\n",
            "Epoch: 75, Loss: 552465280.0000, Train: 88.63%, Valid: 86.45%, Test: 86.88%\n",
            "Epoch: 80, Loss: 537712000.0000, Train: 88.68%, Valid: 86.43%, Test: 86.86%\n",
            "Epoch: 85, Loss: 524650400.0000, Train: 88.71%, Valid: 86.43%, Test: 86.88%\n",
            "Epoch: 90, Loss: 512404864.0000, Train: 88.83%, Valid: 86.47%, Test: 86.98%\n",
            "Epoch: 95, Loss: 501331136.0000, Train: 88.93%, Valid: 86.47%, Test: 87.08%\n",
            "Epoch: 100, Loss: 491164032.0000, Train: 88.96%, Valid: 86.43%, Test: 87.18%\n",
            "Epoch: 105, Loss: 481447168.0000, Train: 89.01%, Valid: 86.45%, Test: 87.14%\n",
            "Epoch: 110, Loss: 472076416.0000, Train: 89.01%, Valid: 86.35%, Test: 87.16%\n",
            "Epoch: 115, Loss: 462843328.0000, Train: 89.03%, Valid: 86.43%, Test: 87.08%\n",
            "Epoch: 120, Loss: 453996672.0000, Train: 89.03%, Valid: 86.51%, Test: 87.12%\n",
            "Epoch: 125, Loss: 445363776.0000, Train: 89.05%, Valid: 86.45%, Test: 87.12%\n",
            "Epoch: 130, Loss: 436757664.0000, Train: 88.98%, Valid: 86.43%, Test: 87.14%\n",
            "Epoch: 135, Loss: 428334848.0000, Train: 89.13%, Valid: 86.45%, Test: 87.16%\n",
            "Epoch: 140, Loss: 420036288.0000, Train: 89.13%, Valid: 86.37%, Test: 87.24%\n",
            "Epoch: 145, Loss: 412132288.0000, Train: 89.26%, Valid: 86.51%, Test: 87.12%\n",
            "Epoch: 150, Loss: 404501824.0000, Train: 89.25%, Valid: 86.57%, Test: 87.06%\n",
            "Epoch: 155, Loss: 397257920.0000, Train: 89.27%, Valid: 86.57%, Test: 87.14%\n",
            "Epoch: 160, Loss: 390063424.0000, Train: 89.40%, Valid: 86.65%, Test: 87.16%\n",
            "Epoch: 165, Loss: 382617152.0000, Train: 89.48%, Valid: 86.77%, Test: 87.16%\n",
            "Epoch: 170, Loss: 375288768.0000, Train: 89.50%, Valid: 86.69%, Test: 87.04%\n",
            "Epoch: 175, Loss: 368639072.0000, Train: 89.59%, Valid: 86.71%, Test: 87.00%\n",
            "Epoch: 180, Loss: 363378560.0000, Train: 89.65%, Valid: 86.83%, Test: 87.00%\n",
            "Epoch: 185, Loss: 359378560.0000, Train: 89.69%, Valid: 86.75%, Test: 86.92%\n",
            "Epoch: 190, Loss: 356130560.0000, Train: 89.70%, Valid: 86.77%, Test: 86.98%\n",
            "Epoch: 195, Loss: 352785408.0000, Train: 89.75%, Valid: 86.73%, Test: 86.94%\n",
            "Run 03:\n",
            "Highest Train: 89.83\n",
            "Highest Valid: 86.83\n",
            "Highest Test: 87.24\n",
            "Chosen epoch: 181\n",
            "Final Train: 89.65\n",
            "Final Test: 87.00\n",
            "Epoch: 00, Loss: 6593083904.0000, Train: 35.15%, Valid: 33.68%, Test: 34.48%\n",
            "Epoch: 05, Loss: 2013894912.0000, Train: 46.82%, Valid: 46.87%, Test: 47.16%\n",
            "Epoch: 10, Loss: 1511347200.0000, Train: 62.02%, Valid: 61.76%, Test: 61.36%\n",
            "Epoch: 15, Loss: 1305638144.0000, Train: 80.93%, Valid: 79.77%, Test: 79.37%\n",
            "Epoch: 20, Loss: 1167524992.0000, Train: 85.97%, Valid: 84.46%, Test: 84.34%\n",
            "Epoch: 25, Loss: 1070399744.0000, Train: 87.05%, Valid: 85.39%, Test: 85.60%\n",
            "Epoch: 30, Loss: 995317760.0000, Train: 87.81%, Valid: 85.70%, Test: 86.11%\n",
            "Epoch: 35, Loss: 932681792.0000, Train: 88.06%, Valid: 86.22%, Test: 86.53%\n",
            "Epoch: 40, Loss: 879481728.0000, Train: 88.29%, Valid: 86.59%, Test: 86.80%\n",
            "Epoch: 45, Loss: 834173504.0000, Train: 88.64%, Valid: 86.61%, Test: 86.57%\n",
            "Epoch: 50, Loss: 794998080.0000, Train: 88.84%, Valid: 86.67%, Test: 86.90%\n",
            "Epoch: 55, Loss: 759948416.0000, Train: 88.92%, Valid: 86.75%, Test: 86.90%\n",
            "Epoch: 60, Loss: 728823680.0000, Train: 89.02%, Valid: 86.83%, Test: 87.16%\n",
            "Epoch: 65, Loss: 701678208.0000, Train: 89.10%, Valid: 87.04%, Test: 87.08%\n",
            "Epoch: 70, Loss: 677435520.0000, Train: 89.09%, Valid: 87.10%, Test: 87.02%\n",
            "Epoch: 75, Loss: 655520128.0000, Train: 89.15%, Valid: 87.00%, Test: 87.22%\n",
            "Epoch: 80, Loss: 635842944.0000, Train: 89.11%, Valid: 87.02%, Test: 87.14%\n",
            "Epoch: 85, Loss: 618146944.0000, Train: 89.09%, Valid: 86.93%, Test: 87.10%\n",
            "Epoch: 90, Loss: 602145984.0000, Train: 89.17%, Valid: 86.93%, Test: 86.98%\n",
            "Epoch: 95, Loss: 588493312.0000, Train: 89.15%, Valid: 86.85%, Test: 86.96%\n",
            "Epoch: 100, Loss: 577006208.0000, Train: 89.23%, Valid: 86.81%, Test: 87.02%\n",
            "Epoch: 105, Loss: 567358720.0000, Train: 89.26%, Valid: 86.67%, Test: 87.04%\n",
            "Epoch: 110, Loss: 559213632.0000, Train: 89.24%, Valid: 86.59%, Test: 86.90%\n",
            "Epoch: 115, Loss: 552364800.0000, Train: 89.13%, Valid: 86.61%, Test: 86.82%\n",
            "Epoch: 120, Loss: 546205824.0000, Train: 89.15%, Valid: 86.49%, Test: 86.71%\n",
            "Epoch: 125, Loss: 539513856.0000, Train: 89.13%, Valid: 86.53%, Test: 86.82%\n",
            "Epoch: 130, Loss: 532483776.0000, Train: 89.12%, Valid: 86.53%, Test: 86.75%\n",
            "Epoch: 135, Loss: 524921088.0000, Train: 89.09%, Valid: 86.55%, Test: 86.75%\n",
            "Epoch: 140, Loss: 516197056.0000, Train: 89.10%, Valid: 86.61%, Test: 86.86%\n",
            "Epoch: 145, Loss: 503894656.0000, Train: 89.19%, Valid: 86.53%, Test: 86.92%\n",
            "Epoch: 150, Loss: 488670464.0000, Train: 89.25%, Valid: 86.49%, Test: 87.00%\n",
            "Epoch: 155, Loss: 473143392.0000, Train: 89.28%, Valid: 86.53%, Test: 87.06%\n",
            "Epoch: 160, Loss: 457970624.0000, Train: 89.25%, Valid: 86.55%, Test: 87.14%\n",
            "Epoch: 165, Loss: 443253856.0000, Train: 89.37%, Valid: 86.53%, Test: 87.26%\n",
            "Epoch: 170, Loss: 429562592.0000, Train: 89.39%, Valid: 86.55%, Test: 87.32%\n",
            "Epoch: 175, Loss: 416966912.0000, Train: 89.31%, Valid: 86.57%, Test: 87.24%\n",
            "Epoch: 180, Loss: 405787392.0000, Train: 89.33%, Valid: 86.55%, Test: 87.30%\n",
            "Epoch: 185, Loss: 395630400.0000, Train: 89.34%, Valid: 86.53%, Test: 87.24%\n",
            "Epoch: 190, Loss: 386504128.0000, Train: 89.44%, Valid: 86.67%, Test: 87.26%\n",
            "Epoch: 195, Loss: 378135616.0000, Train: 89.35%, Valid: 86.73%, Test: 87.16%\n",
            "Run 04:\n",
            "Highest Train: 89.44\n",
            "Highest Valid: 87.14\n",
            "Highest Test: 87.32\n",
            "Chosen epoch: 70\n",
            "Final Train: 89.10\n",
            "Final Test: 87.02\n",
            "Epoch: 00, Loss: 5866298880.0000, Train: 33.31%, Valid: 33.84%, Test: 33.37%\n",
            "Epoch: 05, Loss: 1926680320.0000, Train: 29.71%, Valid: 30.03%, Test: 28.92%\n",
            "Epoch: 10, Loss: 1364510720.0000, Train: 40.76%, Valid: 41.41%, Test: 41.10%\n",
            "Epoch: 15, Loss: 1135550208.0000, Train: 66.77%, Valid: 67.46%, Test: 66.63%\n",
            "Epoch: 20, Loss: 995797696.0000, Train: 81.07%, Valid: 80.89%, Test: 80.55%\n",
            "Epoch: 25, Loss: 902716288.0000, Train: 84.81%, Valid: 83.71%, Test: 84.42%\n",
            "Epoch: 30, Loss: 834452800.0000, Train: 85.93%, Valid: 84.64%, Test: 85.46%\n",
            "Epoch: 35, Loss: 782211456.0000, Train: 86.58%, Valid: 85.27%, Test: 85.66%\n",
            "Epoch: 40, Loss: 738721792.0000, Train: 87.16%, Valid: 85.58%, Test: 86.00%\n",
            "Epoch: 45, Loss: 702981248.0000, Train: 87.59%, Valid: 85.78%, Test: 86.09%\n",
            "Epoch: 50, Loss: 672963328.0000, Train: 87.92%, Valid: 85.98%, Test: 86.47%\n",
            "Epoch: 55, Loss: 648876608.0000, Train: 88.14%, Valid: 86.20%, Test: 86.86%\n",
            "Epoch: 60, Loss: 628655104.0000, Train: 88.26%, Valid: 86.37%, Test: 87.14%\n",
            "Epoch: 65, Loss: 611007104.0000, Train: 88.37%, Valid: 86.49%, Test: 87.18%\n",
            "Epoch: 70, Loss: 595708224.0000, Train: 88.47%, Valid: 86.53%, Test: 87.26%\n",
            "Epoch: 75, Loss: 582304512.0000, Train: 88.52%, Valid: 86.67%, Test: 87.57%\n",
            "Epoch: 80, Loss: 570659840.0000, Train: 88.67%, Valid: 86.59%, Test: 87.63%\n",
            "Epoch: 85, Loss: 560024000.0000, Train: 88.87%, Valid: 86.51%, Test: 87.73%\n",
            "Epoch: 90, Loss: 550686464.0000, Train: 88.89%, Valid: 86.45%, Test: 87.71%\n",
            "Epoch: 95, Loss: 542674816.0000, Train: 89.01%, Valid: 86.69%, Test: 87.91%\n",
            "Epoch: 100, Loss: 535795776.0000, Train: 89.20%, Valid: 86.77%, Test: 88.03%\n",
            "Epoch: 105, Loss: 530122240.0000, Train: 89.24%, Valid: 86.89%, Test: 87.93%\n",
            "Epoch: 110, Loss: 525075072.0000, Train: 89.35%, Valid: 87.04%, Test: 88.01%\n",
            "Epoch: 115, Loss: 520043584.0000, Train: 89.46%, Valid: 87.12%, Test: 88.03%\n",
            "Epoch: 120, Loss: 515476544.0000, Train: 89.62%, Valid: 87.18%, Test: 88.15%\n",
            "Epoch: 125, Loss: 510892032.0000, Train: 89.64%, Valid: 87.18%, Test: 88.09%\n",
            "Epoch: 130, Loss: 506021920.0000, Train: 89.71%, Valid: 87.08%, Test: 88.15%\n",
            "Epoch: 135, Loss: 501452672.0000, Train: 89.78%, Valid: 87.00%, Test: 88.17%\n",
            "Epoch: 140, Loss: 496829440.0000, Train: 89.80%, Valid: 87.10%, Test: 88.15%\n",
            "Epoch: 145, Loss: 492138560.0000, Train: 89.86%, Valid: 86.98%, Test: 88.15%\n",
            "Epoch: 150, Loss: 487019520.0000, Train: 89.94%, Valid: 86.95%, Test: 88.17%\n",
            "Epoch: 155, Loss: 481567680.0000, Train: 90.06%, Valid: 87.00%, Test: 88.19%\n",
            "Epoch: 160, Loss: 475836064.0000, Train: 90.05%, Valid: 87.00%, Test: 88.26%\n",
            "Epoch: 165, Loss: 469140352.0000, Train: 90.13%, Valid: 86.95%, Test: 88.22%\n",
            "Epoch: 170, Loss: 461393984.0000, Train: 90.12%, Valid: 87.02%, Test: 88.15%\n",
            "Epoch: 175, Loss: 452814816.0000, Train: 90.20%, Valid: 86.98%, Test: 88.05%\n",
            "Epoch: 180, Loss: 443755840.0000, Train: 90.27%, Valid: 87.04%, Test: 87.91%\n",
            "Epoch: 185, Loss: 434970016.0000, Train: 90.28%, Valid: 87.06%, Test: 87.83%\n",
            "Epoch: 190, Loss: 426463296.0000, Train: 90.22%, Valid: 86.98%, Test: 87.73%\n",
            "Epoch: 195, Loss: 418498112.0000, Train: 90.26%, Valid: 87.02%, Test: 87.67%\n",
            "Run 05:\n",
            "Highest Train: 90.28\n",
            "Highest Valid: 87.22\n",
            "Highest Test: 88.26\n",
            "Chosen epoch: 119\n",
            "Final Train: 89.56\n",
            "Final Test: 88.09\n",
            "All runs:\n",
            "Highest Train: 90.11 ± 0.47\n",
            "Highest Test: 87.74 ± 0.44\n",
            "Highest Valid: 87.21 ± 0.32\n",
            "  Final Train: 89.69 ± 0.41\n",
            "   Final Test: 87.50 ± 0.48\n",
            "Saving results to logs/pubmed_edge.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Node Aware Setting"
      ],
      "metadata": {
        "id": "8feO7X-OAL7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 GKD/main.py --dataset pubmed --rand_split --use_bn --base_model gcn --mode train --dist_mode no --save_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_3m4x76-rGs",
        "outputId": "c379d48f-86b2-4276-9755-ba5ec589c1fb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(data_dir='data', dataset='pubmed', sub_dataset='', cpu=False, seed=42, train_prop=0.5, valid_prop=0.25, protocol='semi', rand_split=True, metric='acc', runs=5, epochs=200, hidden_channels=32, num_layers=3, gat_heads=8, out_heads=1, hops=1, lp_alpha=0.1, gpr_alpha=0.1, jk_type='max', directed=False, num_mlp_layers=1, display_step=5, cached=False, print_prop=False, priv_type='edge', priv_ratio=0.5, save_model=True, save_name='gcn', log_name='none', base_model='gcn', not_load_teacher=False, mode='train', dist_mode='no', weight_decay=0.05, dropout=0.0, lr=0.01, use_bn=True, use_batch=False, batch_size=2048, oracle=False, device=0, alpha=0.5, delta=0.1, use_kd=False, beta=0.0, tau=1.0, kernel='sigmoid', t=1.0, include_last=False, s=2, m=1, lr2=0.001, sim='l2', ker_norm=False)\n",
            "cuda:0\n",
            "pubmed\n",
            "Num nodes: 19717\n",
            "torch.Size([19717, 1])\n",
            "num nodes 19717 | num classes 3 | num node feats 500\n",
            "MODEL: GeoDist(\n",
            "  (k): Kernel(\n",
            "    (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  )\n",
            "  (teacher_gnn): ModuleList(\n",
            "    (0): Linear(in_features=500, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (student_gnn): ModuleList(\n",
            "    (0): Linear(in_features=500, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  (bns2d): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            ")\n",
            "Epoch: 00, Loss: 1.4255, Train: 73.01%, Valid: 70.95%, Test: 72.11%\n",
            "Epoch: 05, Loss: 0.4298, Train: 85.11%, Valid: 82.59%, Test: 83.04%\n",
            "Epoch: 10, Loss: 0.3662, Train: 87.13%, Valid: 83.77%, Test: 84.24%\n",
            "Epoch: 15, Loss: 0.3331, Train: 88.74%, Valid: 84.78%, Test: 84.93%\n",
            "Epoch: 20, Loss: 0.3079, Train: 89.91%, Valid: 85.05%, Test: 85.56%\n",
            "Epoch: 25, Loss: 0.2805, Train: 91.13%, Valid: 85.82%, Test: 85.92%\n",
            "Epoch: 30, Loss: 0.3082, Train: 89.76%, Valid: 85.03%, Test: 84.50%\n",
            "Epoch: 35, Loss: 0.2569, Train: 91.81%, Valid: 85.43%, Test: 85.74%\n",
            "Epoch: 40, Loss: 0.2306, Train: 92.96%, Valid: 85.53%, Test: 85.58%\n",
            "Epoch: 45, Loss: 0.2806, Train: 88.60%, Valid: 82.43%, Test: 82.41%\n",
            "Epoch: 50, Loss: 0.2774, Train: 90.87%, Valid: 84.44%, Test: 85.11%\n",
            "Epoch: 55, Loss: 0.2346, Train: 92.60%, Valid: 85.53%, Test: 85.25%\n",
            "Epoch: 60, Loss: 0.2184, Train: 93.82%, Valid: 85.43%, Test: 85.52%\n",
            "Epoch: 65, Loss: 0.1950, Train: 94.60%, Valid: 85.31%, Test: 85.40%\n",
            "Epoch: 70, Loss: 0.4806, Train: 86.63%, Valid: 82.25%, Test: 82.54%\n",
            "Epoch: 75, Loss: 0.3147, Train: 90.04%, Valid: 84.91%, Test: 85.29%\n",
            "Epoch: 80, Loss: 0.2807, Train: 91.33%, Valid: 85.35%, Test: 86.04%\n",
            "Epoch: 85, Loss: 0.2506, Train: 92.50%, Valid: 85.33%, Test: 86.47%\n",
            "Epoch: 90, Loss: 0.2282, Train: 93.55%, Valid: 85.64%, Test: 85.84%\n",
            "Epoch: 95, Loss: 0.2056, Train: 93.62%, Valid: 85.03%, Test: 84.91%\n",
            "Epoch: 100, Loss: 0.2839, Train: 90.75%, Valid: 84.80%, Test: 85.76%\n",
            "Epoch: 105, Loss: 0.2392, Train: 92.81%, Valid: 85.39%, Test: 85.68%\n",
            "Epoch: 110, Loss: 0.2077, Train: 93.94%, Valid: 85.11%, Test: 85.64%\n",
            "Epoch: 115, Loss: 0.1828, Train: 94.83%, Valid: 84.82%, Test: 85.01%\n",
            "Epoch: 120, Loss: 0.4463, Train: 85.66%, Valid: 80.42%, Test: 80.67%\n",
            "Epoch: 125, Loss: 0.3065, Train: 89.40%, Valid: 84.44%, Test: 85.07%\n",
            "Epoch: 130, Loss: 0.2826, Train: 91.35%, Valid: 85.27%, Test: 85.58%\n",
            "Epoch: 135, Loss: 0.2536, Train: 92.65%, Valid: 85.60%, Test: 85.92%\n",
            "Epoch: 140, Loss: 0.2276, Train: 93.72%, Valid: 85.41%, Test: 85.64%\n",
            "Epoch: 145, Loss: 0.2013, Train: 92.62%, Valid: 83.99%, Test: 83.35%\n",
            "Epoch: 150, Loss: 0.2691, Train: 91.61%, Valid: 84.95%, Test: 85.48%\n",
            "Epoch: 155, Loss: 0.2324, Train: 93.45%, Valid: 84.84%, Test: 85.80%\n",
            "Epoch: 160, Loss: 0.2011, Train: 94.10%, Valid: 84.93%, Test: 85.05%\n",
            "Epoch: 165, Loss: 0.1869, Train: 93.65%, Valid: 83.26%, Test: 83.39%\n",
            "Epoch: 170, Loss: 0.2394, Train: 92.08%, Valid: 84.46%, Test: 84.73%\n",
            "Epoch: 175, Loss: 0.2148, Train: 93.95%, Valid: 85.37%, Test: 85.21%\n",
            "Epoch: 180, Loss: 0.1885, Train: 94.92%, Valid: 84.68%, Test: 84.77%\n",
            "Epoch: 185, Loss: 0.1946, Train: 94.18%, Valid: 84.38%, Test: 83.96%\n",
            "Epoch: 190, Loss: 0.1799, Train: 95.37%, Valid: 84.56%, Test: 84.22%\n",
            "Epoch: 195, Loss: 0.1695, Train: 94.12%, Valid: 83.42%, Test: 82.84%\n",
            "Run 01:\n",
            "Highest Train: 95.37\n",
            "Highest Valid: 86.04\n",
            "Highest Test: 86.47\n",
            "Chosen epoch: 28\n",
            "Final Train: 91.59\n",
            "Final Test: 85.88\n",
            "Epoch: 00, Loss: 1.3942, Train: 72.54%, Valid: 71.74%, Test: 71.85%\n",
            "Epoch: 05, Loss: 0.4273, Train: 85.33%, Valid: 83.49%, Test: 83.51%\n",
            "Epoch: 10, Loss: 0.3576, Train: 87.65%, Valid: 84.60%, Test: 84.95%\n",
            "Epoch: 15, Loss: 0.3248, Train: 89.01%, Valid: 85.55%, Test: 85.82%\n",
            "Epoch: 20, Loss: 0.3001, Train: 90.31%, Valid: 85.84%, Test: 85.72%\n",
            "Epoch: 25, Loss: 0.2745, Train: 91.29%, Valid: 85.98%, Test: 86.47%\n",
            "Epoch: 30, Loss: 0.2913, Train: 91.09%, Valid: 85.80%, Test: 86.43%\n",
            "Epoch: 35, Loss: 0.2496, Train: 92.14%, Valid: 86.14%, Test: 86.09%\n",
            "Epoch: 40, Loss: 0.2254, Train: 92.87%, Valid: 85.39%, Test: 85.84%\n",
            "Epoch: 45, Loss: 0.2563, Train: 89.21%, Valid: 84.60%, Test: 84.40%\n",
            "Epoch: 50, Loss: 0.2662, Train: 91.53%, Valid: 86.14%, Test: 86.61%\n",
            "Epoch: 55, Loss: 0.2321, Train: 92.94%, Valid: 86.31%, Test: 86.67%\n",
            "Epoch: 60, Loss: 0.2274, Train: 92.88%, Valid: 85.72%, Test: 85.48%\n",
            "Epoch: 65, Loss: 0.2059, Train: 94.08%, Valid: 85.70%, Test: 85.96%\n",
            "Epoch: 70, Loss: 0.3243, Train: 89.61%, Valid: 84.58%, Test: 84.87%\n",
            "Epoch: 75, Loss: 0.2720, Train: 91.76%, Valid: 85.68%, Test: 86.29%\n",
            "Epoch: 80, Loss: 0.2404, Train: 92.92%, Valid: 86.45%, Test: 86.13%\n",
            "Epoch: 85, Loss: 0.2104, Train: 93.65%, Valid: 85.94%, Test: 85.80%\n",
            "Epoch: 90, Loss: 0.3016, Train: 87.08%, Valid: 80.50%, Test: 81.56%\n",
            "Epoch: 95, Loss: 0.2837, Train: 90.76%, Valid: 85.31%, Test: 85.80%\n",
            "Epoch: 100, Loss: 0.2562, Train: 92.55%, Valid: 86.04%, Test: 85.96%\n",
            "Epoch: 105, Loss: 0.2283, Train: 93.43%, Valid: 85.53%, Test: 86.35%\n",
            "Epoch: 110, Loss: 0.3516, Train: 88.07%, Valid: 82.57%, Test: 82.25%\n",
            "Epoch: 115, Loss: 0.2782, Train: 91.08%, Valid: 85.09%, Test: 85.84%\n",
            "Epoch: 120, Loss: 0.2428, Train: 92.70%, Valid: 85.88%, Test: 85.60%\n",
            "Epoch: 125, Loss: 0.2141, Train: 93.70%, Valid: 85.76%, Test: 85.58%\n",
            "Epoch: 130, Loss: 0.1914, Train: 94.33%, Valid: 84.84%, Test: 84.65%\n",
            "Epoch: 135, Loss: 0.2647, Train: 92.17%, Valid: 86.10%, Test: 86.21%\n",
            "Epoch: 140, Loss: 0.2319, Train: 93.34%, Valid: 85.53%, Test: 85.42%\n",
            "Epoch: 145, Loss: 0.2009, Train: 94.58%, Valid: 85.25%, Test: 84.58%\n",
            "Epoch: 150, Loss: 0.2210, Train: 89.58%, Valid: 83.16%, Test: 83.39%\n",
            "Epoch: 155, Loss: 0.2408, Train: 92.78%, Valid: 85.47%, Test: 85.84%\n",
            "Epoch: 160, Loss: 0.2087, Train: 93.88%, Valid: 85.35%, Test: 85.35%\n",
            "Epoch: 165, Loss: 0.1832, Train: 94.52%, Valid: 84.84%, Test: 84.83%\n",
            "Epoch: 170, Loss: 0.2144, Train: 90.27%, Valid: 82.02%, Test: 83.00%\n",
            "Epoch: 175, Loss: 0.3015, Train: 90.40%, Valid: 85.41%, Test: 85.38%\n",
            "Epoch: 180, Loss: 0.2666, Train: 92.01%, Valid: 86.04%, Test: 86.25%\n",
            "Epoch: 185, Loss: 0.2375, Train: 92.86%, Valid: 85.49%, Test: 85.84%\n",
            "Epoch: 190, Loss: 0.2123, Train: 93.71%, Valid: 85.17%, Test: 85.52%\n",
            "Epoch: 195, Loss: 0.2314, Train: 92.99%, Valid: 85.35%, Test: 85.68%\n",
            "Run 02:\n",
            "Highest Train: 94.98\n",
            "Highest Valid: 86.45\n",
            "Highest Test: 86.84\n",
            "Chosen epoch: 81\n",
            "Final Train: 92.92\n",
            "Final Test: 86.13\n",
            "Epoch: 00, Loss: 1.3894, Train: 73.72%, Valid: 72.49%, Test: 73.00%\n",
            "Epoch: 05, Loss: 0.4266, Train: 84.92%, Valid: 82.69%, Test: 83.57%\n",
            "Epoch: 10, Loss: 0.3687, Train: 86.91%, Valid: 83.91%, Test: 85.11%\n",
            "Epoch: 15, Loss: 0.3351, Train: 88.21%, Valid: 85.15%, Test: 85.96%\n",
            "Epoch: 20, Loss: 0.3106, Train: 89.39%, Valid: 85.47%, Test: 86.23%\n",
            "Epoch: 25, Loss: 0.2856, Train: 90.60%, Valid: 85.82%, Test: 86.35%\n",
            "Epoch: 30, Loss: 0.2902, Train: 90.66%, Valid: 85.82%, Test: 85.94%\n",
            "Epoch: 35, Loss: 0.2529, Train: 91.38%, Valid: 85.84%, Test: 85.82%\n",
            "Epoch: 40, Loss: 0.2370, Train: 91.97%, Valid: 84.93%, Test: 85.66%\n",
            "Epoch: 45, Loss: 0.2595, Train: 90.60%, Valid: 84.09%, Test: 84.12%\n",
            "Epoch: 50, Loss: 0.2376, Train: 92.34%, Valid: 85.62%, Test: 86.59%\n",
            "Epoch: 55, Loss: 0.2082, Train: 93.80%, Valid: 85.03%, Test: 85.98%\n",
            "Epoch: 60, Loss: 0.4780, Train: 84.04%, Valid: 80.28%, Test: 81.16%\n",
            "Epoch: 65, Loss: 0.3599, Train: 87.78%, Valid: 84.74%, Test: 85.56%\n",
            "Epoch: 70, Loss: 0.3172, Train: 89.38%, Valid: 85.58%, Test: 86.41%\n",
            "Epoch: 75, Loss: 0.2899, Train: 90.38%, Valid: 86.18%, Test: 86.84%\n",
            "Epoch: 80, Loss: 0.2655, Train: 91.71%, Valid: 86.12%, Test: 86.65%\n",
            "Epoch: 85, Loss: 0.2361, Train: 92.83%, Valid: 85.53%, Test: 86.69%\n",
            "Epoch: 90, Loss: 0.2226, Train: 90.50%, Valid: 82.19%, Test: 82.66%\n",
            "Epoch: 95, Loss: 0.3080, Train: 89.64%, Valid: 84.95%, Test: 85.40%\n",
            "Epoch: 100, Loss: 0.2688, Train: 91.28%, Valid: 85.90%, Test: 86.69%\n",
            "Epoch: 105, Loss: 0.2395, Train: 92.73%, Valid: 85.39%, Test: 86.09%\n",
            "Epoch: 110, Loss: 0.2161, Train: 93.52%, Valid: 84.89%, Test: 85.54%\n",
            "Epoch: 115, Loss: 0.2800, Train: 88.35%, Valid: 83.10%, Test: 83.79%\n",
            "Epoch: 120, Loss: 0.2903, Train: 90.33%, Valid: 85.76%, Test: 86.77%\n",
            "Epoch: 125, Loss: 0.2613, Train: 91.71%, Valid: 85.92%, Test: 86.88%\n",
            "Epoch: 130, Loss: 0.2300, Train: 92.94%, Valid: 85.86%, Test: 86.69%\n",
            "Epoch: 135, Loss: 0.2001, Train: 94.11%, Valid: 85.05%, Test: 85.64%\n",
            "Epoch: 140, Loss: 0.4225, Train: 89.46%, Valid: 85.11%, Test: 85.72%\n",
            "Epoch: 145, Loss: 0.3011, Train: 89.61%, Valid: 85.68%, Test: 85.98%\n",
            "Epoch: 150, Loss: 0.2753, Train: 91.41%, Valid: 85.58%, Test: 86.51%\n",
            "Epoch: 155, Loss: 0.2416, Train: 92.91%, Valid: 85.84%, Test: 86.17%\n",
            "Epoch: 160, Loss: 0.2113, Train: 93.66%, Valid: 84.62%, Test: 85.74%\n",
            "Epoch: 165, Loss: 0.3252, Train: 91.61%, Valid: 84.70%, Test: 85.48%\n",
            "Epoch: 170, Loss: 0.2495, Train: 92.70%, Valid: 86.00%, Test: 85.84%\n",
            "Epoch: 175, Loss: 0.2133, Train: 93.48%, Valid: 85.23%, Test: 85.17%\n",
            "Epoch: 180, Loss: 0.1956, Train: 94.19%, Valid: 83.95%, Test: 85.03%\n",
            "Epoch: 185, Loss: 0.2881, Train: 88.95%, Valid: 81.74%, Test: 82.47%\n",
            "Epoch: 190, Loss: 0.2659, Train: 91.26%, Valid: 85.78%, Test: 85.29%\n",
            "Epoch: 195, Loss: 0.2373, Train: 92.43%, Valid: 86.16%, Test: 86.84%\n",
            "Run 03:\n",
            "Highest Train: 94.78\n",
            "Highest Valid: 86.43\n",
            "Highest Test: 87.26\n",
            "Chosen epoch: 193\n",
            "Final Train: 92.06\n",
            "Final Test: 86.49\n",
            "Epoch: 00, Loss: 1.2910, Train: 72.25%, Valid: 71.33%, Test: 71.81%\n",
            "Epoch: 05, Loss: 0.4306, Train: 85.15%, Valid: 82.94%, Test: 83.71%\n",
            "Epoch: 10, Loss: 0.3664, Train: 87.20%, Valid: 83.55%, Test: 85.48%\n",
            "Epoch: 15, Loss: 0.3336, Train: 88.58%, Valid: 84.87%, Test: 86.21%\n",
            "Epoch: 20, Loss: 0.3047, Train: 90.16%, Valid: 85.55%, Test: 86.33%\n",
            "Epoch: 25, Loss: 0.2761, Train: 91.46%, Valid: 85.37%, Test: 86.51%\n",
            "Epoch: 30, Loss: 0.2582, Train: 91.80%, Valid: 85.64%, Test: 86.37%\n",
            "Epoch: 35, Loss: 0.2482, Train: 92.56%, Valid: 85.31%, Test: 86.02%\n",
            "Epoch: 40, Loss: 0.2449, Train: 92.56%, Valid: 85.21%, Test: 85.96%\n",
            "Epoch: 45, Loss: 0.2651, Train: 91.84%, Valid: 84.24%, Test: 84.16%\n",
            "Epoch: 50, Loss: 0.2273, Train: 93.20%, Valid: 84.72%, Test: 84.91%\n",
            "Epoch: 55, Loss: 0.2077, Train: 93.05%, Valid: 84.18%, Test: 84.16%\n",
            "Epoch: 60, Loss: 0.2315, Train: 92.92%, Valid: 85.23%, Test: 85.70%\n",
            "Epoch: 65, Loss: 0.2093, Train: 93.24%, Valid: 84.07%, Test: 84.77%\n",
            "Epoch: 70, Loss: 0.2215, Train: 93.47%, Valid: 85.15%, Test: 85.50%\n",
            "Epoch: 75, Loss: 0.1942, Train: 93.60%, Valid: 84.16%, Test: 84.87%\n",
            "Epoch: 80, Loss: 0.1922, Train: 93.74%, Valid: 84.58%, Test: 84.73%\n",
            "Epoch: 85, Loss: 0.3172, Train: 91.05%, Valid: 85.23%, Test: 86.47%\n",
            "Epoch: 90, Loss: 0.2570, Train: 92.20%, Valid: 85.70%, Test: 85.38%\n",
            "Epoch: 95, Loss: 0.2304, Train: 93.28%, Valid: 85.47%, Test: 85.72%\n",
            "Epoch: 100, Loss: 0.1975, Train: 94.20%, Valid: 84.64%, Test: 85.23%\n",
            "Epoch: 105, Loss: 0.2760, Train: 92.70%, Valid: 84.36%, Test: 85.17%\n",
            "Epoch: 110, Loss: 0.2192, Train: 93.48%, Valid: 84.42%, Test: 85.03%\n",
            "Epoch: 115, Loss: 0.1964, Train: 93.86%, Valid: 84.32%, Test: 84.71%\n",
            "Epoch: 120, Loss: 0.2555, Train: 93.17%, Valid: 84.91%, Test: 85.72%\n",
            "Epoch: 125, Loss: 0.2082, Train: 94.20%, Valid: 84.84%, Test: 85.15%\n",
            "Epoch: 130, Loss: 0.1849, Train: 94.87%, Valid: 84.40%, Test: 84.79%\n",
            "Epoch: 135, Loss: 0.2380, Train: 90.87%, Valid: 81.66%, Test: 82.92%\n",
            "Epoch: 140, Loss: 0.2811, Train: 91.27%, Valid: 84.66%, Test: 85.44%\n",
            "Epoch: 145, Loss: 0.2416, Train: 92.74%, Valid: 84.56%, Test: 85.29%\n",
            "Epoch: 150, Loss: 0.2201, Train: 93.82%, Valid: 84.68%, Test: 85.21%\n",
            "Epoch: 155, Loss: 0.2442, Train: 90.55%, Valid: 82.76%, Test: 82.70%\n",
            "Epoch: 160, Loss: 0.2725, Train: 92.62%, Valid: 85.31%, Test: 85.68%\n",
            "Epoch: 165, Loss: 0.2202, Train: 93.30%, Valid: 84.56%, Test: 85.21%\n",
            "Epoch: 170, Loss: 0.1981, Train: 94.22%, Valid: 84.52%, Test: 85.11%\n",
            "Epoch: 175, Loss: 0.1899, Train: 92.34%, Valid: 82.86%, Test: 83.79%\n",
            "Epoch: 180, Loss: 0.3205, Train: 91.82%, Valid: 85.15%, Test: 84.79%\n",
            "Epoch: 185, Loss: 0.2416, Train: 93.44%, Valid: 84.93%, Test: 85.66%\n",
            "Epoch: 190, Loss: 0.2095, Train: 94.08%, Valid: 85.09%, Test: 84.89%\n",
            "Epoch: 195, Loss: 0.1804, Train: 94.52%, Valid: 84.46%, Test: 84.83%\n",
            "Run 04:\n",
            "Highest Train: 94.97\n",
            "Highest Valid: 85.98\n",
            "Highest Test: 86.53\n",
            "Chosen epoch: 89\n",
            "Final Train: 91.84\n",
            "Final Test: 85.35\n",
            "Epoch: 00, Loss: 1.7697, Train: 54.67%, Valid: 55.14%, Test: 54.69%\n",
            "Epoch: 05, Loss: 0.5451, Train: 83.17%, Valid: 80.34%, Test: 82.17%\n",
            "Epoch: 10, Loss: 0.4142, Train: 86.42%, Valid: 83.36%, Test: 85.07%\n",
            "Epoch: 15, Loss: 0.3603, Train: 88.15%, Valid: 84.50%, Test: 85.92%\n",
            "Epoch: 20, Loss: 0.3285, Train: 89.22%, Valid: 85.11%, Test: 86.31%\n",
            "Epoch: 25, Loss: 0.2995, Train: 90.53%, Valid: 85.51%, Test: 86.80%\n",
            "Epoch: 30, Loss: 0.2723, Train: 90.75%, Valid: 85.13%, Test: 86.75%\n",
            "Epoch: 35, Loss: 0.2649, Train: 92.16%, Valid: 86.24%, Test: 86.51%\n",
            "Epoch: 40, Loss: 0.2413, Train: 93.20%, Valid: 85.94%, Test: 86.67%\n",
            "Epoch: 45, Loss: 0.3052, Train: 90.99%, Valid: 85.39%, Test: 85.68%\n",
            "Epoch: 50, Loss: 0.2422, Train: 92.57%, Valid: 85.92%, Test: 86.23%\n",
            "Epoch: 55, Loss: 0.2170, Train: 93.41%, Valid: 85.82%, Test: 85.96%\n",
            "Epoch: 60, Loss: 0.2158, Train: 92.71%, Valid: 85.41%, Test: 85.90%\n",
            "Epoch: 65, Loss: 0.2071, Train: 94.00%, Valid: 85.80%, Test: 85.40%\n",
            "Epoch: 70, Loss: 0.2292, Train: 93.49%, Valid: 85.53%, Test: 86.13%\n",
            "Epoch: 75, Loss: 0.1984, Train: 93.45%, Valid: 84.52%, Test: 85.42%\n",
            "Epoch: 80, Loss: 0.1851, Train: 93.96%, Valid: 85.23%, Test: 85.92%\n",
            "Epoch: 85, Loss: 0.2064, Train: 90.18%, Valid: 82.29%, Test: 81.93%\n",
            "Epoch: 90, Loss: 0.3183, Train: 89.88%, Valid: 85.05%, Test: 86.43%\n",
            "Epoch: 95, Loss: 0.2609, Train: 92.09%, Valid: 86.02%, Test: 86.63%\n",
            "Epoch: 100, Loss: 0.2375, Train: 92.88%, Valid: 85.98%, Test: 86.37%\n",
            "Epoch: 105, Loss: 0.2086, Train: 94.08%, Valid: 86.16%, Test: 85.78%\n",
            "Epoch: 110, Loss: 0.1887, Train: 92.24%, Valid: 83.53%, Test: 82.98%\n",
            "Epoch: 115, Loss: 0.3257, Train: 89.53%, Valid: 85.35%, Test: 85.74%\n",
            "Epoch: 120, Loss: 0.2864, Train: 91.29%, Valid: 85.45%, Test: 86.11%\n",
            "Epoch: 125, Loss: 0.2587, Train: 92.25%, Valid: 85.86%, Test: 86.45%\n",
            "Epoch: 130, Loss: 0.2327, Train: 93.18%, Valid: 86.02%, Test: 86.67%\n",
            "Epoch: 135, Loss: 0.2068, Train: 94.07%, Valid: 85.23%, Test: 86.15%\n",
            "Epoch: 140, Loss: 0.2828, Train: 89.09%, Valid: 84.44%, Test: 85.25%\n",
            "Epoch: 145, Loss: 0.3007, Train: 90.47%, Valid: 85.27%, Test: 86.15%\n",
            "Epoch: 150, Loss: 0.2615, Train: 92.02%, Valid: 86.31%, Test: 86.61%\n",
            "Epoch: 155, Loss: 0.2368, Train: 93.16%, Valid: 86.04%, Test: 86.31%\n",
            "Epoch: 160, Loss: 0.2040, Train: 93.85%, Valid: 86.00%, Test: 85.72%\n",
            "Epoch: 165, Loss: 0.2195, Train: 91.84%, Valid: 83.77%, Test: 84.08%\n",
            "Epoch: 170, Loss: 0.2126, Train: 93.57%, Valid: 85.86%, Test: 85.92%\n",
            "Epoch: 175, Loss: 0.2146, Train: 93.16%, Valid: 85.72%, Test: 86.15%\n",
            "Epoch: 180, Loss: 0.1891, Train: 94.20%, Valid: 85.29%, Test: 85.80%\n",
            "Epoch: 185, Loss: 0.1771, Train: 92.16%, Valid: 83.30%, Test: 83.71%\n",
            "Epoch: 190, Loss: 0.3169, Train: 88.45%, Valid: 84.72%, Test: 85.19%\n",
            "Epoch: 195, Loss: 0.2908, Train: 90.88%, Valid: 85.33%, Test: 86.39%\n",
            "Run 05:\n",
            "Highest Train: 94.87\n",
            "Highest Valid: 86.47\n",
            "Highest Test: 86.86\n",
            "Chosen epoch: 99\n",
            "Final Train: 92.70\n",
            "Final Test: 86.69\n",
            "All runs:\n",
            "Highest Train: 94.99 ± 0.23\n",
            "Highest Test: 86.79 ± 0.32\n",
            "Highest Valid: 86.27 ± 0.24\n",
            "  Final Train: 92.22 ± 0.57\n",
            "   Final Test: 86.11 ± 0.53\n",
            "Saving results to logs/pubmed_edge.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 GKD/main.py --dataset pubmed --rand_split --use_bn --base_model gcn --mode train  --dist_mode gkd --kernel sigmoid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsG5jcYgAOGl",
        "outputId": "1ece42b3-e9c4-4d0d-e984-f1bcd0fcc1a3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(data_dir='data', dataset='pubmed', sub_dataset='', cpu=False, seed=42, train_prop=0.5, valid_prop=0.25, protocol='semi', rand_split=True, metric='acc', runs=5, epochs=200, hidden_channels=32, num_layers=3, gat_heads=8, out_heads=1, hops=1, lp_alpha=0.1, gpr_alpha=0.1, jk_type='max', directed=False, num_mlp_layers=1, display_step=5, cached=False, print_prop=False, priv_type='edge', priv_ratio=0.5, save_model=False, save_name='gcn', log_name='none', base_model='gcn', not_load_teacher=False, mode='train', dist_mode='gkd', weight_decay=0.05, dropout=0.0, lr=0.01, use_bn=True, use_batch=False, batch_size=2048, oracle=False, device=0, alpha=0.5, delta=0.1, use_kd=False, beta=0.0, tau=1.0, kernel='sigmoid', t=1.0, include_last=False, s=2, m=1, lr2=0.001, sim='l2', ker_norm=False)\n",
            "cuda:0\n",
            "pubmed\n",
            "Num nodes: 19717\n",
            "torch.Size([19717, 1])\n",
            "num nodes 19717 | num classes 3 | num node feats 500\n",
            "MODEL: GeoDist(\n",
            "  (k): Kernel(\n",
            "    (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  )\n",
            "  (teacher_gnn): ModuleList(\n",
            "    (0): Linear(in_features=500, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (student_gnn): ModuleList(\n",
            "    (0): Linear(in_features=500, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  (bns2d): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            ")\n",
            "Epoch: 00, Loss: 30492376.0000, Train: 46.48%, Valid: 46.62%, Test: 46.29%\n",
            "Epoch: 05, Loss: 13358913.0000, Train: 67.37%, Valid: 67.11%, Test: 67.04%\n",
            "Epoch: 10, Loss: 10831944.0000, Train: 83.04%, Valid: 81.09%, Test: 82.13%\n",
            "Epoch: 15, Loss: 9545926.0000, Train: 85.30%, Valid: 82.86%, Test: 83.53%\n",
            "Epoch: 20, Loss: 8710532.0000, Train: 85.77%, Valid: 83.22%, Test: 84.28%\n",
            "Epoch: 25, Loss: 8053471.0000, Train: 86.65%, Valid: 83.83%, Test: 85.13%\n",
            "Epoch: 30, Loss: 7536694.5000, Train: 87.55%, Valid: 84.24%, Test: 85.15%\n",
            "Epoch: 35, Loss: 7110734.0000, Train: 88.04%, Valid: 84.95%, Test: 85.58%\n",
            "Epoch: 40, Loss: 6768037.5000, Train: 88.36%, Valid: 85.53%, Test: 85.82%\n",
            "Epoch: 45, Loss: 6493394.0000, Train: 88.80%, Valid: 85.58%, Test: 86.19%\n",
            "Epoch: 50, Loss: 6261611.0000, Train: 88.97%, Valid: 85.47%, Test: 86.04%\n",
            "Epoch: 55, Loss: 6077120.5000, Train: 89.28%, Valid: 85.84%, Test: 86.15%\n",
            "Epoch: 60, Loss: 5918932.0000, Train: 89.44%, Valid: 85.90%, Test: 86.13%\n",
            "Epoch: 65, Loss: 5784858.5000, Train: 89.69%, Valid: 86.00%, Test: 86.25%\n",
            "Epoch: 70, Loss: 5669409.0000, Train: 89.78%, Valid: 86.10%, Test: 86.47%\n",
            "Epoch: 75, Loss: 5569560.5000, Train: 89.84%, Valid: 86.04%, Test: 86.51%\n",
            "Epoch: 80, Loss: 5480053.0000, Train: 90.07%, Valid: 86.00%, Test: 86.51%\n",
            "Epoch: 85, Loss: 5401013.0000, Train: 90.22%, Valid: 86.16%, Test: 86.67%\n",
            "Epoch: 90, Loss: 5329262.0000, Train: 90.22%, Valid: 86.31%, Test: 86.61%\n",
            "Epoch: 95, Loss: 5264256.0000, Train: 90.32%, Valid: 86.39%, Test: 86.59%\n",
            "Epoch: 100, Loss: 5244582.0000, Train: 90.22%, Valid: 86.26%, Test: 86.49%\n",
            "Epoch: 105, Loss: 5190306.5000, Train: 90.38%, Valid: 86.35%, Test: 86.63%\n",
            "Epoch: 110, Loss: 5123681.5000, Train: 90.59%, Valid: 86.59%, Test: 86.67%\n",
            "Epoch: 115, Loss: 5074670.0000, Train: 90.59%, Valid: 86.53%, Test: 86.77%\n",
            "Epoch: 120, Loss: 5046635.0000, Train: 90.53%, Valid: 86.49%, Test: 86.73%\n",
            "Epoch: 125, Loss: 5012001.0000, Train: 90.58%, Valid: 86.51%, Test: 86.67%\n",
            "Epoch: 130, Loss: 5035751.5000, Train: 90.63%, Valid: 86.47%, Test: 86.59%\n",
            "Epoch: 135, Loss: 4948361.0000, Train: 90.65%, Valid: 86.37%, Test: 86.47%\n",
            "Epoch: 140, Loss: 4884119.5000, Train: 90.66%, Valid: 86.26%, Test: 86.29%\n",
            "Epoch: 145, Loss: 4863112.0000, Train: 90.71%, Valid: 86.31%, Test: 86.31%\n",
            "Epoch: 150, Loss: 4883326.0000, Train: 90.68%, Valid: 86.04%, Test: 86.57%\n",
            "Epoch: 155, Loss: 4940349.0000, Train: 90.74%, Valid: 86.29%, Test: 86.49%\n",
            "Epoch: 160, Loss: 4811618.0000, Train: 90.77%, Valid: 86.33%, Test: 86.35%\n",
            "Epoch: 165, Loss: 4810383.0000, Train: 90.75%, Valid: 86.20%, Test: 86.49%\n",
            "Epoch: 170, Loss: 4757305.5000, Train: 90.69%, Valid: 86.31%, Test: 86.41%\n",
            "Epoch: 175, Loss: 4747949.5000, Train: 90.75%, Valid: 86.10%, Test: 86.17%\n",
            "Epoch: 180, Loss: 4784330.5000, Train: 90.66%, Valid: 86.26%, Test: 86.51%\n",
            "Epoch: 185, Loss: 4710162.5000, Train: 90.66%, Valid: 86.24%, Test: 86.33%\n",
            "Epoch: 190, Loss: 4699297.0000, Train: 90.75%, Valid: 86.26%, Test: 86.31%\n",
            "Epoch: 195, Loss: 4720028.5000, Train: 90.81%, Valid: 86.18%, Test: 86.41%\n",
            "Run 01:\n",
            "Highest Train: 90.83\n",
            "Highest Valid: 86.59\n",
            "Highest Test: 86.82\n",
            "Chosen epoch: 111\n",
            "Final Train: 90.59\n",
            "Final Test: 86.67\n",
            "Epoch: 00, Loss: 31617328.0000, Train: 46.78%, Valid: 46.52%, Test: 46.65%\n",
            "Epoch: 05, Loss: 15105087.0000, Train: 69.00%, Valid: 69.12%, Test: 69.21%\n",
            "Epoch: 10, Loss: 12370526.0000, Train: 80.92%, Valid: 79.87%, Test: 79.61%\n",
            "Epoch: 15, Loss: 11104894.0000, Train: 84.30%, Valid: 82.33%, Test: 82.35%\n",
            "Epoch: 20, Loss: 10241489.0000, Train: 86.18%, Valid: 83.51%, Test: 84.08%\n",
            "Epoch: 25, Loss: 9640014.0000, Train: 87.25%, Valid: 84.50%, Test: 84.36%\n",
            "Epoch: 30, Loss: 9189688.0000, Train: 87.77%, Valid: 84.97%, Test: 85.05%\n",
            "Epoch: 35, Loss: 8824419.0000, Train: 88.18%, Valid: 85.33%, Test: 85.64%\n",
            "Epoch: 40, Loss: 8539282.0000, Train: 88.54%, Valid: 85.76%, Test: 86.02%\n",
            "Epoch: 45, Loss: 8301319.0000, Train: 88.88%, Valid: 85.82%, Test: 85.96%\n",
            "Epoch: 50, Loss: 8104325.0000, Train: 89.07%, Valid: 86.10%, Test: 85.84%\n",
            "Epoch: 55, Loss: 7939417.5000, Train: 89.22%, Valid: 86.16%, Test: 85.98%\n",
            "Epoch: 60, Loss: 7798660.5000, Train: 89.43%, Valid: 86.08%, Test: 86.04%\n",
            "Epoch: 65, Loss: 7673517.0000, Train: 89.57%, Valid: 86.08%, Test: 86.21%\n",
            "Epoch: 70, Loss: 7566015.5000, Train: 89.69%, Valid: 86.18%, Test: 86.27%\n",
            "Epoch: 75, Loss: 7471416.0000, Train: 89.77%, Valid: 86.12%, Test: 86.11%\n",
            "Epoch: 80, Loss: 7386439.5000, Train: 89.89%, Valid: 86.18%, Test: 86.11%\n",
            "Epoch: 85, Loss: 7309993.5000, Train: 89.87%, Valid: 86.12%, Test: 86.17%\n",
            "Epoch: 90, Loss: 7240696.0000, Train: 90.02%, Valid: 86.35%, Test: 86.04%\n",
            "Epoch: 95, Loss: 7177992.0000, Train: 90.02%, Valid: 86.41%, Test: 86.06%\n",
            "Epoch: 100, Loss: 7120804.5000, Train: 90.02%, Valid: 86.51%, Test: 86.23%\n",
            "Epoch: 105, Loss: 7066657.0000, Train: 90.16%, Valid: 86.53%, Test: 86.23%\n",
            "Epoch: 110, Loss: 7017631.0000, Train: 90.29%, Valid: 86.57%, Test: 86.19%\n",
            "Epoch: 115, Loss: 6972178.0000, Train: 90.24%, Valid: 86.55%, Test: 86.23%\n",
            "Epoch: 120, Loss: 6930291.0000, Train: 90.22%, Valid: 86.61%, Test: 86.19%\n",
            "Epoch: 125, Loss: 6890448.0000, Train: 90.21%, Valid: 86.55%, Test: 86.17%\n",
            "Epoch: 130, Loss: 6862273.0000, Train: 90.32%, Valid: 86.53%, Test: 86.09%\n",
            "Epoch: 135, Loss: 6821602.0000, Train: 90.38%, Valid: 86.45%, Test: 86.19%\n",
            "Epoch: 140, Loss: 6800002.0000, Train: 90.39%, Valid: 86.43%, Test: 86.31%\n",
            "Epoch: 145, Loss: 6787279.0000, Train: 90.42%, Valid: 86.55%, Test: 86.29%\n",
            "Epoch: 150, Loss: 6741881.0000, Train: 90.44%, Valid: 86.61%, Test: 86.41%\n",
            "Epoch: 155, Loss: 6720737.5000, Train: 90.47%, Valid: 86.63%, Test: 86.43%\n",
            "Epoch: 160, Loss: 6734452.0000, Train: 90.52%, Valid: 86.39%, Test: 86.35%\n",
            "Epoch: 165, Loss: 6683487.0000, Train: 90.57%, Valid: 86.29%, Test: 86.19%\n",
            "Epoch: 170, Loss: 6646820.0000, Train: 90.45%, Valid: 86.47%, Test: 86.27%\n",
            "Epoch: 175, Loss: 6643854.0000, Train: 90.43%, Valid: 86.61%, Test: 86.45%\n",
            "Epoch: 180, Loss: 6655664.0000, Train: 90.40%, Valid: 86.69%, Test: 86.47%\n",
            "Epoch: 185, Loss: 6638491.0000, Train: 90.44%, Valid: 86.63%, Test: 86.55%\n",
            "Epoch: 190, Loss: 6605142.5000, Train: 90.45%, Valid: 86.59%, Test: 86.59%\n",
            "Epoch: 195, Loss: 6568601.0000, Train: 90.48%, Valid: 86.71%, Test: 86.61%\n",
            "Run 02:\n",
            "Highest Train: 90.57\n",
            "Highest Valid: 86.71\n",
            "Highest Test: 86.65\n",
            "Chosen epoch: 193\n",
            "Final Train: 90.57\n",
            "Final Test: 86.47\n",
            "Epoch: 00, Loss: 31013162.0000, Train: 52.42%, Valid: 53.32%, Test: 52.43%\n",
            "Epoch: 05, Loss: 12696504.0000, Train: 77.69%, Valid: 76.97%, Test: 77.20%\n",
            "Epoch: 10, Loss: 10528904.0000, Train: 81.64%, Valid: 80.10%, Test: 79.96%\n",
            "Epoch: 15, Loss: 9489162.0000, Train: 83.85%, Valid: 81.76%, Test: 81.81%\n",
            "Epoch: 20, Loss: 8808852.0000, Train: 85.75%, Valid: 83.65%, Test: 84.12%\n",
            "Epoch: 25, Loss: 8326531.5000, Train: 86.59%, Valid: 84.93%, Test: 84.65%\n",
            "Epoch: 30, Loss: 7935254.0000, Train: 87.31%, Valid: 84.91%, Test: 85.15%\n",
            "Epoch: 35, Loss: 7636390.5000, Train: 87.69%, Valid: 84.99%, Test: 85.46%\n",
            "Epoch: 40, Loss: 7384643.5000, Train: 88.03%, Valid: 85.49%, Test: 85.35%\n",
            "Epoch: 45, Loss: 7177123.5000, Train: 88.27%, Valid: 85.68%, Test: 85.70%\n",
            "Epoch: 50, Loss: 7002964.0000, Train: 88.62%, Valid: 85.86%, Test: 86.19%\n",
            "Epoch: 55, Loss: 6863202.5000, Train: 88.86%, Valid: 85.80%, Test: 86.47%\n",
            "Epoch: 60, Loss: 6744044.5000, Train: 89.15%, Valid: 85.78%, Test: 86.43%\n",
            "Epoch: 65, Loss: 6640677.0000, Train: 89.25%, Valid: 85.80%, Test: 86.51%\n",
            "Epoch: 70, Loss: 6552230.5000, Train: 89.41%, Valid: 86.10%, Test: 86.61%\n",
            "Epoch: 75, Loss: 6474198.0000, Train: 89.50%, Valid: 86.18%, Test: 86.71%\n",
            "Epoch: 80, Loss: 6404910.0000, Train: 89.50%, Valid: 86.31%, Test: 86.75%\n",
            "Epoch: 85, Loss: 6342299.0000, Train: 89.62%, Valid: 86.41%, Test: 86.71%\n",
            "Epoch: 90, Loss: 6284760.0000, Train: 89.65%, Valid: 86.45%, Test: 86.75%\n",
            "Epoch: 95, Loss: 6234118.5000, Train: 89.75%, Valid: 86.45%, Test: 86.80%\n",
            "Epoch: 100, Loss: 6188081.0000, Train: 89.75%, Valid: 86.57%, Test: 86.92%\n",
            "Epoch: 105, Loss: 6145863.0000, Train: 89.72%, Valid: 86.55%, Test: 86.90%\n",
            "Epoch: 110, Loss: 6107137.0000, Train: 89.82%, Valid: 86.61%, Test: 86.98%\n",
            "Epoch: 115, Loss: 6071212.5000, Train: 89.84%, Valid: 86.75%, Test: 86.86%\n",
            "Epoch: 120, Loss: 6119352.0000, Train: 89.74%, Valid: 86.79%, Test: 86.77%\n",
            "Epoch: 125, Loss: 6023716.5000, Train: 89.87%, Valid: 86.75%, Test: 86.94%\n",
            "Epoch: 130, Loss: 5995284.5000, Train: 89.86%, Valid: 86.75%, Test: 87.02%\n",
            "Epoch: 135, Loss: 5974479.5000, Train: 89.85%, Valid: 86.65%, Test: 87.06%\n",
            "Epoch: 140, Loss: 5945333.5000, Train: 89.84%, Valid: 86.65%, Test: 87.00%\n",
            "Epoch: 145, Loss: 5922083.0000, Train: 90.00%, Valid: 86.61%, Test: 87.06%\n",
            "Epoch: 150, Loss: 5915260.0000, Train: 89.94%, Valid: 86.49%, Test: 87.04%\n",
            "Epoch: 155, Loss: 5889477.0000, Train: 89.95%, Valid: 86.59%, Test: 86.90%\n",
            "Epoch: 160, Loss: 5878812.0000, Train: 89.89%, Valid: 86.61%, Test: 86.88%\n",
            "Epoch: 165, Loss: 5849214.0000, Train: 89.94%, Valid: 86.59%, Test: 87.00%\n",
            "Epoch: 170, Loss: 5848771.0000, Train: 90.05%, Valid: 86.57%, Test: 86.90%\n",
            "Epoch: 175, Loss: 5820349.0000, Train: 90.05%, Valid: 86.55%, Test: 86.92%\n",
            "Epoch: 180, Loss: 5818507.5000, Train: 90.01%, Valid: 86.51%, Test: 86.88%\n",
            "Epoch: 185, Loss: 5811600.5000, Train: 90.13%, Valid: 86.61%, Test: 86.90%\n",
            "Epoch: 190, Loss: 5791484.0000, Train: 90.22%, Valid: 86.61%, Test: 86.98%\n",
            "Epoch: 195, Loss: 5761123.0000, Train: 90.29%, Valid: 86.51%, Test: 86.92%\n",
            "Run 03:\n",
            "Highest Train: 90.29\n",
            "Highest Valid: 86.87\n",
            "Highest Test: 87.12\n",
            "Chosen epoch: 122\n",
            "Final Train: 89.83\n",
            "Final Test: 86.90\n",
            "Epoch: 00, Loss: 30524538.0000, Train: 40.15%, Valid: 38.73%, Test: 39.49%\n",
            "Epoch: 05, Loss: 14157582.0000, Train: 67.70%, Valid: 66.36%, Test: 68.03%\n",
            "Epoch: 10, Loss: 11709442.0000, Train: 80.52%, Valid: 78.76%, Test: 78.70%\n",
            "Epoch: 15, Loss: 10501255.0000, Train: 83.97%, Valid: 81.64%, Test: 82.15%\n",
            "Epoch: 20, Loss: 9736450.0000, Train: 85.32%, Valid: 83.04%, Test: 83.55%\n",
            "Epoch: 25, Loss: 9197140.0000, Train: 86.28%, Valid: 83.71%, Test: 83.87%\n",
            "Epoch: 30, Loss: 8768189.0000, Train: 86.85%, Valid: 84.09%, Test: 84.28%\n",
            "Epoch: 35, Loss: 8431711.0000, Train: 87.33%, Valid: 84.40%, Test: 84.79%\n",
            "Epoch: 40, Loss: 8166284.0000, Train: 87.79%, Valid: 84.78%, Test: 85.25%\n",
            "Epoch: 45, Loss: 7940498.0000, Train: 88.30%, Valid: 84.82%, Test: 85.78%\n",
            "Epoch: 50, Loss: 7758006.0000, Train: 88.49%, Valid: 84.97%, Test: 85.98%\n",
            "Epoch: 55, Loss: 7605102.0000, Train: 89.00%, Valid: 85.21%, Test: 86.15%\n",
            "Epoch: 60, Loss: 7473385.5000, Train: 89.18%, Valid: 85.62%, Test: 86.29%\n",
            "Epoch: 65, Loss: 7359352.0000, Train: 89.35%, Valid: 85.62%, Test: 86.31%\n",
            "Epoch: 70, Loss: 7259989.0000, Train: 89.34%, Valid: 85.72%, Test: 86.51%\n",
            "Epoch: 75, Loss: 7173717.5000, Train: 89.60%, Valid: 85.82%, Test: 86.57%\n",
            "Epoch: 80, Loss: 7096915.5000, Train: 89.66%, Valid: 85.90%, Test: 86.67%\n",
            "Epoch: 85, Loss: 7025911.0000, Train: 89.68%, Valid: 85.94%, Test: 86.65%\n",
            "Epoch: 90, Loss: 6964625.0000, Train: 89.77%, Valid: 86.04%, Test: 86.77%\n",
            "Epoch: 95, Loss: 6908908.0000, Train: 89.70%, Valid: 85.96%, Test: 86.71%\n",
            "Epoch: 100, Loss: 6857518.5000, Train: 89.75%, Valid: 85.94%, Test: 86.69%\n",
            "Epoch: 105, Loss: 6809884.0000, Train: 89.89%, Valid: 85.88%, Test: 86.75%\n",
            "Epoch: 110, Loss: 6765633.0000, Train: 89.97%, Valid: 85.92%, Test: 86.65%\n",
            "Epoch: 115, Loss: 6724398.5000, Train: 90.04%, Valid: 86.02%, Test: 86.84%\n",
            "Epoch: 120, Loss: 6685737.5000, Train: 89.95%, Valid: 85.94%, Test: 86.80%\n",
            "Epoch: 125, Loss: 6649163.0000, Train: 90.07%, Valid: 85.88%, Test: 86.75%\n",
            "Epoch: 130, Loss: 6614462.0000, Train: 90.14%, Valid: 85.84%, Test: 86.77%\n",
            "Epoch: 135, Loss: 6597779.5000, Train: 90.18%, Valid: 85.86%, Test: 86.63%\n",
            "Epoch: 140, Loss: 6569641.0000, Train: 90.21%, Valid: 85.86%, Test: 86.71%\n",
            "Epoch: 145, Loss: 6548647.0000, Train: 90.21%, Valid: 85.92%, Test: 86.65%\n",
            "Epoch: 150, Loss: 6520918.0000, Train: 90.19%, Valid: 85.88%, Test: 86.71%\n",
            "Epoch: 155, Loss: 6499704.0000, Train: 90.20%, Valid: 85.96%, Test: 86.88%\n",
            "Epoch: 160, Loss: 6512122.0000, Train: 90.15%, Valid: 85.80%, Test: 86.82%\n",
            "Epoch: 165, Loss: 6458829.0000, Train: 90.21%, Valid: 86.00%, Test: 86.88%\n",
            "Epoch: 170, Loss: 6420532.5000, Train: 90.09%, Valid: 85.82%, Test: 87.04%\n",
            "Epoch: 175, Loss: 6396761.0000, Train: 90.16%, Valid: 85.90%, Test: 86.94%\n",
            "Epoch: 180, Loss: 6381959.0000, Train: 90.16%, Valid: 85.96%, Test: 86.94%\n",
            "Epoch: 185, Loss: 6429014.0000, Train: 90.13%, Valid: 86.00%, Test: 86.86%\n",
            "Epoch: 190, Loss: 6360814.0000, Train: 90.24%, Valid: 85.84%, Test: 86.82%\n",
            "Epoch: 195, Loss: 6339295.5000, Train: 90.22%, Valid: 85.84%, Test: 86.94%\n",
            "Run 04:\n",
            "Highest Train: 90.36\n",
            "Highest Valid: 86.22\n",
            "Highest Test: 87.06\n",
            "Chosen epoch: 185\n",
            "Final Train: 90.30\n",
            "Final Test: 86.94\n",
            "Epoch: 00, Loss: 30673972.0000, Train: 19.78%, Valid: 20.25%, Test: 19.07%\n",
            "Epoch: 05, Loss: 14287828.0000, Train: 42.59%, Valid: 43.52%, Test: 42.82%\n",
            "Epoch: 10, Loss: 12058510.0000, Train: 66.54%, Valid: 66.04%, Test: 65.03%\n",
            "Epoch: 15, Loss: 10852642.0000, Train: 78.51%, Valid: 76.38%, Test: 76.80%\n",
            "Epoch: 20, Loss: 10016181.0000, Train: 82.65%, Valid: 79.91%, Test: 81.38%\n",
            "Epoch: 25, Loss: 9393772.0000, Train: 85.26%, Valid: 82.71%, Test: 83.94%\n",
            "Epoch: 30, Loss: 8886191.0000, Train: 86.89%, Valid: 84.22%, Test: 85.15%\n",
            "Epoch: 35, Loss: 8492674.0000, Train: 87.84%, Valid: 84.87%, Test: 85.64%\n",
            "Epoch: 40, Loss: 8190488.0000, Train: 88.41%, Valid: 85.13%, Test: 85.88%\n",
            "Epoch: 45, Loss: 7940780.5000, Train: 88.80%, Valid: 85.37%, Test: 86.00%\n",
            "Epoch: 50, Loss: 7730112.5000, Train: 89.04%, Valid: 85.51%, Test: 86.04%\n",
            "Epoch: 55, Loss: 7550785.0000, Train: 89.25%, Valid: 85.88%, Test: 86.31%\n",
            "Epoch: 60, Loss: 7395720.0000, Train: 89.44%, Valid: 85.96%, Test: 86.37%\n",
            "Epoch: 65, Loss: 7262754.0000, Train: 89.56%, Valid: 85.90%, Test: 86.49%\n",
            "Epoch: 70, Loss: 7145970.5000, Train: 89.73%, Valid: 85.84%, Test: 86.57%\n",
            "Epoch: 75, Loss: 7044641.0000, Train: 89.82%, Valid: 85.94%, Test: 86.80%\n",
            "Epoch: 80, Loss: 6954018.5000, Train: 89.93%, Valid: 85.86%, Test: 86.98%\n",
            "Epoch: 85, Loss: 6872295.0000, Train: 89.95%, Valid: 85.94%, Test: 87.04%\n",
            "Epoch: 90, Loss: 6798184.5000, Train: 90.04%, Valid: 86.00%, Test: 86.80%\n",
            "Epoch: 95, Loss: 6728738.0000, Train: 90.13%, Valid: 85.96%, Test: 86.73%\n",
            "Epoch: 100, Loss: 6665087.0000, Train: 90.28%, Valid: 85.92%, Test: 86.77%\n",
            "Epoch: 105, Loss: 6605500.5000, Train: 90.31%, Valid: 86.02%, Test: 86.75%\n",
            "Epoch: 110, Loss: 6549563.0000, Train: 90.29%, Valid: 86.10%, Test: 86.73%\n",
            "Epoch: 115, Loss: 6498567.0000, Train: 90.37%, Valid: 86.16%, Test: 86.69%\n",
            "Epoch: 120, Loss: 6457564.0000, Train: 90.42%, Valid: 86.29%, Test: 86.73%\n",
            "Epoch: 125, Loss: 6423376.0000, Train: 90.44%, Valid: 86.12%, Test: 86.86%\n",
            "Epoch: 130, Loss: 6377131.5000, Train: 90.43%, Valid: 86.18%, Test: 86.90%\n",
            "Epoch: 135, Loss: 6336178.5000, Train: 90.55%, Valid: 86.10%, Test: 86.86%\n",
            "Epoch: 140, Loss: 6303332.0000, Train: 90.65%, Valid: 86.08%, Test: 86.90%\n",
            "Epoch: 145, Loss: 6337485.5000, Train: 90.74%, Valid: 86.31%, Test: 86.98%\n",
            "Epoch: 150, Loss: 6262552.0000, Train: 90.69%, Valid: 86.31%, Test: 87.04%\n",
            "Epoch: 155, Loss: 6230272.0000, Train: 90.74%, Valid: 86.31%, Test: 86.92%\n",
            "Epoch: 160, Loss: 6228304.0000, Train: 90.78%, Valid: 86.10%, Test: 86.88%\n",
            "Epoch: 165, Loss: 6220025.5000, Train: 90.92%, Valid: 86.29%, Test: 87.00%\n",
            "Epoch: 170, Loss: 6198879.0000, Train: 90.86%, Valid: 86.10%, Test: 86.88%\n",
            "Epoch: 175, Loss: 6166578.0000, Train: 90.88%, Valid: 86.00%, Test: 86.80%\n",
            "Epoch: 180, Loss: 6230005.0000, Train: 90.89%, Valid: 86.29%, Test: 87.10%\n",
            "Epoch: 185, Loss: 6162784.5000, Train: 90.95%, Valid: 86.20%, Test: 87.16%\n",
            "Epoch: 190, Loss: 6097644.0000, Train: 91.00%, Valid: 86.08%, Test: 87.08%\n",
            "Epoch: 195, Loss: 6081806.0000, Train: 91.06%, Valid: 86.26%, Test: 87.02%\n",
            "Run 05:\n",
            "Highest Train: 91.06\n",
            "Highest Valid: 86.41\n",
            "Highest Test: 87.16\n",
            "Chosen epoch: 164\n",
            "Final Train: 90.86\n",
            "Final Test: 86.82\n",
            "All runs:\n",
            "Highest Train: 90.62 ± 0.32\n",
            "Highest Test: 86.96 ± 0.22\n",
            "Highest Valid: 86.56 ± 0.25\n",
            "  Final Train: 90.43 ± 0.39\n",
            "   Final Test: 86.76 ± 0.19\n",
            "Saving results to logs/pubmed_edge.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 GKD/main.py --dataset pubmed --rand_split --use_bn --base_model gcn --mode train --priv_type edge --dist_mode gkd --use_kd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jy4OI4U4C3rA",
        "outputId": "9195a1fb-d660-4727-9105-109d1d85e178"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(data_dir='data', dataset='pubmed', sub_dataset='', cpu=False, seed=42, train_prop=0.5, valid_prop=0.25, protocol='semi', rand_split=True, metric='acc', runs=5, epochs=200, hidden_channels=32, num_layers=3, gat_heads=8, out_heads=1, hops=1, lp_alpha=0.1, gpr_alpha=0.1, jk_type='max', directed=False, num_mlp_layers=1, display_step=5, cached=False, print_prop=False, priv_type='edge', priv_ratio=0.5, save_model=False, save_name='gcn', log_name='none', base_model='gcn', not_load_teacher=False, mode='train', dist_mode='gkd', weight_decay=0.05, dropout=0.0, lr=0.01, use_bn=True, use_batch=False, batch_size=2048, oracle=False, device=0, alpha=0.5, delta=0.1, use_kd=True, beta=0.0, tau=1.0, kernel='sigmoid', t=1.0, include_last=False, s=2, m=1, lr2=0.001, sim='l2', ker_norm=False)\n",
            "cuda:0\n",
            "pubmed\n",
            "Num nodes: 19717\n",
            "torch.Size([19717, 1])\n",
            "num nodes 19717 | num classes 3 | num node feats 500\n",
            "MODEL: GeoDist(\n",
            "  (k): Kernel(\n",
            "    (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  )\n",
            "  (teacher_gnn): ModuleList(\n",
            "    (0): Linear(in_features=500, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (student_gnn): ModuleList(\n",
            "    (0): Linear(in_features=500, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  (bns2d): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            ")\n",
            "Epoch: 00, Loss: 30492376.0000, Train: 46.48%, Valid: 46.62%, Test: 46.29%\n",
            "Epoch: 05, Loss: 13358913.0000, Train: 67.37%, Valid: 67.11%, Test: 67.04%\n",
            "Epoch: 10, Loss: 10831945.0000, Train: 83.04%, Valid: 81.09%, Test: 82.13%\n",
            "Epoch: 15, Loss: 9545926.0000, Train: 85.30%, Valid: 82.86%, Test: 83.53%\n",
            "Epoch: 20, Loss: 8710531.0000, Train: 85.77%, Valid: 83.22%, Test: 84.28%\n",
            "Epoch: 25, Loss: 8053471.0000, Train: 86.65%, Valid: 83.83%, Test: 85.13%\n",
            "Epoch: 30, Loss: 7536694.5000, Train: 87.55%, Valid: 84.24%, Test: 85.15%\n",
            "Epoch: 35, Loss: 7110734.0000, Train: 88.04%, Valid: 84.95%, Test: 85.58%\n",
            "Epoch: 40, Loss: 6768038.0000, Train: 88.36%, Valid: 85.53%, Test: 85.82%\n",
            "Epoch: 45, Loss: 6493394.5000, Train: 88.80%, Valid: 85.58%, Test: 86.19%\n",
            "Epoch: 50, Loss: 6261610.5000, Train: 88.97%, Valid: 85.47%, Test: 86.04%\n",
            "Epoch: 55, Loss: 6077120.5000, Train: 89.28%, Valid: 85.84%, Test: 86.15%\n",
            "Epoch: 60, Loss: 5918933.0000, Train: 89.44%, Valid: 85.90%, Test: 86.13%\n",
            "Epoch: 65, Loss: 5784859.5000, Train: 89.69%, Valid: 86.00%, Test: 86.25%\n",
            "Epoch: 70, Loss: 5669412.5000, Train: 89.78%, Valid: 86.10%, Test: 86.47%\n",
            "Epoch: 75, Loss: 5569549.0000, Train: 89.83%, Valid: 86.04%, Test: 86.51%\n",
            "Epoch: 80, Loss: 5480038.5000, Train: 90.09%, Valid: 86.02%, Test: 86.51%\n",
            "Epoch: 85, Loss: 5401001.0000, Train: 90.22%, Valid: 86.14%, Test: 86.67%\n",
            "Epoch: 90, Loss: 5329192.0000, Train: 90.21%, Valid: 86.35%, Test: 86.61%\n",
            "Epoch: 95, Loss: 5263460.0000, Train: 90.33%, Valid: 86.39%, Test: 86.51%\n",
            "Epoch: 100, Loss: 5218094.5000, Train: 90.25%, Valid: 86.16%, Test: 86.41%\n",
            "Epoch: 105, Loss: 5163898.5000, Train: 90.41%, Valid: 86.35%, Test: 86.59%\n",
            "Epoch: 110, Loss: 5111641.0000, Train: 90.45%, Valid: 86.37%, Test: 86.61%\n",
            "Epoch: 115, Loss: 5073341.5000, Train: 90.47%, Valid: 86.39%, Test: 86.63%\n",
            "Epoch: 120, Loss: 5024018.0000, Train: 90.54%, Valid: 86.41%, Test: 86.53%\n",
            "Epoch: 125, Loss: 4983576.0000, Train: 90.58%, Valid: 86.43%, Test: 86.61%\n",
            "Epoch: 130, Loss: 4954060.0000, Train: 90.69%, Valid: 86.47%, Test: 86.59%\n",
            "Epoch: 135, Loss: 4962882.5000, Train: 90.69%, Valid: 86.39%, Test: 86.43%\n",
            "Epoch: 140, Loss: 4948500.0000, Train: 90.66%, Valid: 86.29%, Test: 86.53%\n",
            "Epoch: 145, Loss: 4915183.0000, Train: 90.67%, Valid: 86.33%, Test: 86.45%\n",
            "Epoch: 150, Loss: 4842429.5000, Train: 90.68%, Valid: 86.18%, Test: 86.49%\n",
            "Epoch: 155, Loss: 4813296.0000, Train: 90.75%, Valid: 86.14%, Test: 86.65%\n",
            "Epoch: 160, Loss: 4853558.5000, Train: 90.67%, Valid: 86.35%, Test: 86.55%\n",
            "Epoch: 165, Loss: 4832628.0000, Train: 90.73%, Valid: 86.41%, Test: 86.39%\n",
            "Epoch: 170, Loss: 4777452.5000, Train: 90.76%, Valid: 86.12%, Test: 86.45%\n",
            "Epoch: 175, Loss: 4741278.0000, Train: 90.77%, Valid: 86.26%, Test: 86.43%\n",
            "Epoch: 180, Loss: 4779855.0000, Train: 90.88%, Valid: 86.14%, Test: 86.59%\n",
            "Epoch: 185, Loss: 4718802.5000, Train: 90.73%, Valid: 86.10%, Test: 86.31%\n",
            "Epoch: 190, Loss: 4679023.5000, Train: 90.74%, Valid: 86.29%, Test: 86.31%\n",
            "Epoch: 195, Loss: 4688598.5000, Train: 90.81%, Valid: 86.26%, Test: 86.25%\n",
            "Run 01:\n",
            "Highest Train: 90.91\n",
            "Highest Valid: 86.59\n",
            "Highest Test: 86.73\n",
            "Chosen epoch: 114\n",
            "Final Train: 90.60\n",
            "Final Test: 86.73\n",
            "Epoch: 00, Loss: 31617328.0000, Train: 46.78%, Valid: 46.52%, Test: 46.65%\n",
            "Epoch: 05, Loss: 15105087.0000, Train: 69.00%, Valid: 69.12%, Test: 69.21%\n",
            "Epoch: 10, Loss: 12370526.0000, Train: 80.92%, Valid: 79.87%, Test: 79.61%\n",
            "Epoch: 15, Loss: 11104894.0000, Train: 84.30%, Valid: 82.33%, Test: 82.35%\n",
            "Epoch: 20, Loss: 10241489.0000, Train: 86.18%, Valid: 83.51%, Test: 84.08%\n",
            "Epoch: 25, Loss: 9640014.0000, Train: 87.25%, Valid: 84.50%, Test: 84.36%\n",
            "Epoch: 30, Loss: 9189688.0000, Train: 87.77%, Valid: 84.97%, Test: 85.05%\n",
            "Epoch: 35, Loss: 8824416.0000, Train: 88.18%, Valid: 85.33%, Test: 85.64%\n",
            "Epoch: 40, Loss: 8539282.0000, Train: 88.54%, Valid: 85.76%, Test: 86.02%\n",
            "Epoch: 45, Loss: 8301321.5000, Train: 88.88%, Valid: 85.82%, Test: 85.96%\n",
            "Epoch: 50, Loss: 8104328.0000, Train: 89.07%, Valid: 86.10%, Test: 85.84%\n",
            "Epoch: 55, Loss: 7939409.5000, Train: 89.22%, Valid: 86.16%, Test: 85.98%\n",
            "Epoch: 60, Loss: 7798666.0000, Train: 89.43%, Valid: 86.10%, Test: 86.06%\n",
            "Epoch: 65, Loss: 7673521.5000, Train: 89.57%, Valid: 86.08%, Test: 86.23%\n",
            "Epoch: 70, Loss: 7566035.0000, Train: 89.68%, Valid: 86.18%, Test: 86.27%\n",
            "Epoch: 75, Loss: 7471438.5000, Train: 89.77%, Valid: 86.12%, Test: 86.11%\n",
            "Epoch: 80, Loss: 7386514.5000, Train: 89.90%, Valid: 86.20%, Test: 86.11%\n",
            "Epoch: 85, Loss: 7310077.0000, Train: 89.89%, Valid: 86.10%, Test: 86.19%\n",
            "Epoch: 90, Loss: 7240794.0000, Train: 90.01%, Valid: 86.33%, Test: 86.02%\n",
            "Epoch: 95, Loss: 7178014.0000, Train: 90.02%, Valid: 86.41%, Test: 86.06%\n",
            "Epoch: 100, Loss: 7120698.0000, Train: 90.00%, Valid: 86.51%, Test: 86.23%\n",
            "Epoch: 105, Loss: 7066556.0000, Train: 90.17%, Valid: 86.49%, Test: 86.21%\n",
            "Epoch: 110, Loss: 7017448.5000, Train: 90.30%, Valid: 86.57%, Test: 86.27%\n",
            "Epoch: 115, Loss: 6972040.0000, Train: 90.22%, Valid: 86.51%, Test: 86.23%\n",
            "Epoch: 120, Loss: 6930287.0000, Train: 90.19%, Valid: 86.63%, Test: 86.15%\n",
            "Epoch: 125, Loss: 6890647.5000, Train: 90.25%, Valid: 86.55%, Test: 86.13%\n",
            "Epoch: 130, Loss: 6863854.5000, Train: 90.24%, Valid: 86.47%, Test: 86.17%\n",
            "Epoch: 135, Loss: 6821284.0000, Train: 90.26%, Valid: 86.47%, Test: 86.23%\n",
            "Epoch: 140, Loss: 6808484.0000, Train: 90.40%, Valid: 86.45%, Test: 86.27%\n",
            "Epoch: 145, Loss: 6784039.0000, Train: 90.51%, Valid: 86.22%, Test: 86.29%\n",
            "Epoch: 150, Loss: 6735193.0000, Train: 90.48%, Valid: 86.47%, Test: 86.31%\n",
            "Epoch: 155, Loss: 6720238.0000, Train: 90.41%, Valid: 86.61%, Test: 86.47%\n",
            "Epoch: 160, Loss: 6726666.0000, Train: 90.46%, Valid: 86.61%, Test: 86.51%\n",
            "Epoch: 165, Loss: 6681450.5000, Train: 90.39%, Valid: 86.61%, Test: 86.47%\n",
            "Epoch: 170, Loss: 6677747.0000, Train: 90.36%, Valid: 86.45%, Test: 86.43%\n",
            "Epoch: 175, Loss: 6688388.0000, Train: 90.45%, Valid: 86.35%, Test: 86.35%\n",
            "Epoch: 180, Loss: 6654450.0000, Train: 90.50%, Valid: 86.33%, Test: 86.25%\n",
            "Epoch: 185, Loss: 6631555.0000, Train: 90.47%, Valid: 86.51%, Test: 86.35%\n",
            "Epoch: 190, Loss: 6617952.5000, Train: 90.39%, Valid: 86.45%, Test: 86.43%\n",
            "Epoch: 195, Loss: 6619507.0000, Train: 90.55%, Valid: 86.39%, Test: 86.53%\n",
            "Run 02:\n",
            "Highest Train: 90.59\n",
            "Highest Valid: 86.77\n",
            "Highest Test: 86.55\n",
            "Chosen epoch: 193\n",
            "Final Train: 90.41\n",
            "Final Test: 86.47\n",
            "Epoch: 00, Loss: 31013162.0000, Train: 52.42%, Valid: 53.32%, Test: 52.43%\n",
            "Epoch: 05, Loss: 12696504.0000, Train: 77.69%, Valid: 76.97%, Test: 77.20%\n",
            "Epoch: 10, Loss: 10528904.0000, Train: 81.64%, Valid: 80.10%, Test: 79.96%\n",
            "Epoch: 15, Loss: 9489162.0000, Train: 83.85%, Valid: 81.76%, Test: 81.81%\n",
            "Epoch: 20, Loss: 8808852.0000, Train: 85.75%, Valid: 83.65%, Test: 84.12%\n",
            "Epoch: 25, Loss: 8326531.5000, Train: 86.59%, Valid: 84.93%, Test: 84.65%\n",
            "Epoch: 30, Loss: 7935254.0000, Train: 87.31%, Valid: 84.91%, Test: 85.15%\n",
            "Epoch: 35, Loss: 7636392.0000, Train: 87.69%, Valid: 84.99%, Test: 85.46%\n",
            "Epoch: 40, Loss: 7384643.0000, Train: 88.03%, Valid: 85.49%, Test: 85.35%\n",
            "Epoch: 45, Loss: 7177124.0000, Train: 88.27%, Valid: 85.68%, Test: 85.70%\n",
            "Epoch: 50, Loss: 7002961.5000, Train: 88.62%, Valid: 85.86%, Test: 86.19%\n",
            "Epoch: 55, Loss: 6863212.0000, Train: 88.86%, Valid: 85.80%, Test: 86.47%\n",
            "Epoch: 60, Loss: 6744053.5000, Train: 89.15%, Valid: 85.78%, Test: 86.43%\n",
            "Epoch: 65, Loss: 6640704.5000, Train: 89.25%, Valid: 85.80%, Test: 86.51%\n",
            "Epoch: 70, Loss: 6552237.0000, Train: 89.40%, Valid: 86.10%, Test: 86.59%\n",
            "Epoch: 75, Loss: 6474175.0000, Train: 89.52%, Valid: 86.18%, Test: 86.71%\n",
            "Epoch: 80, Loss: 6404891.5000, Train: 89.49%, Valid: 86.33%, Test: 86.75%\n",
            "Epoch: 85, Loss: 6342246.5000, Train: 89.61%, Valid: 86.41%, Test: 86.71%\n",
            "Epoch: 90, Loss: 6284770.5000, Train: 89.65%, Valid: 86.45%, Test: 86.77%\n",
            "Epoch: 95, Loss: 6234166.0000, Train: 89.75%, Valid: 86.47%, Test: 86.80%\n",
            "Epoch: 100, Loss: 6188159.0000, Train: 89.75%, Valid: 86.57%, Test: 86.96%\n",
            "Epoch: 105, Loss: 6146004.0000, Train: 89.73%, Valid: 86.55%, Test: 86.90%\n",
            "Epoch: 110, Loss: 6107336.0000, Train: 89.85%, Valid: 86.61%, Test: 86.94%\n",
            "Epoch: 115, Loss: 6074206.0000, Train: 89.84%, Valid: 86.81%, Test: 86.73%\n",
            "Epoch: 120, Loss: 6046310.0000, Train: 89.76%, Valid: 86.75%, Test: 86.73%\n",
            "Epoch: 125, Loss: 6027003.0000, Train: 89.71%, Valid: 86.73%, Test: 86.77%\n",
            "Epoch: 130, Loss: 6002457.0000, Train: 89.80%, Valid: 86.67%, Test: 86.86%\n",
            "Epoch: 135, Loss: 5971256.0000, Train: 89.88%, Valid: 86.69%, Test: 86.84%\n",
            "Epoch: 140, Loss: 5946614.5000, Train: 89.81%, Valid: 86.63%, Test: 86.88%\n",
            "Epoch: 145, Loss: 5907291.5000, Train: 89.82%, Valid: 86.63%, Test: 86.94%\n",
            "Epoch: 150, Loss: 5921652.5000, Train: 89.94%, Valid: 86.61%, Test: 87.04%\n",
            "Epoch: 155, Loss: 5905944.0000, Train: 90.05%, Valid: 86.59%, Test: 87.16%\n",
            "Epoch: 160, Loss: 5928258.0000, Train: 90.02%, Valid: 86.55%, Test: 87.00%\n",
            "Epoch: 165, Loss: 5850493.0000, Train: 89.98%, Valid: 86.67%, Test: 86.98%\n",
            "Epoch: 170, Loss: 5816191.0000, Train: 90.04%, Valid: 86.53%, Test: 86.92%\n",
            "Epoch: 175, Loss: 5815219.5000, Train: 89.91%, Valid: 86.63%, Test: 87.00%\n",
            "Epoch: 180, Loss: 5820419.0000, Train: 90.01%, Valid: 86.61%, Test: 86.92%\n",
            "Epoch: 185, Loss: 5807758.0000, Train: 90.08%, Valid: 86.69%, Test: 87.02%\n",
            "Epoch: 190, Loss: 5795605.0000, Train: 90.11%, Valid: 86.55%, Test: 87.04%\n",
            "Epoch: 195, Loss: 5766271.5000, Train: 90.17%, Valid: 86.59%, Test: 86.94%\n",
            "Run 03:\n",
            "Highest Train: 90.20\n",
            "Highest Valid: 86.83\n",
            "Highest Test: 87.16\n",
            "Chosen epoch: 120\n",
            "Final Train: 89.84\n",
            "Final Test: 86.77\n",
            "Epoch: 00, Loss: 30524538.0000, Train: 40.15%, Valid: 38.73%, Test: 39.49%\n",
            "Epoch: 05, Loss: 14157582.0000, Train: 67.70%, Valid: 66.36%, Test: 68.03%\n",
            "Epoch: 10, Loss: 11709441.0000, Train: 80.52%, Valid: 78.76%, Test: 78.70%\n",
            "Epoch: 15, Loss: 10501252.0000, Train: 83.97%, Valid: 81.64%, Test: 82.15%\n",
            "Epoch: 20, Loss: 9736450.0000, Train: 85.32%, Valid: 83.04%, Test: 83.55%\n",
            "Epoch: 25, Loss: 9197147.0000, Train: 86.28%, Valid: 83.71%, Test: 83.87%\n",
            "Epoch: 30, Loss: 8768205.0000, Train: 86.85%, Valid: 84.09%, Test: 84.28%\n",
            "Epoch: 35, Loss: 8431704.0000, Train: 87.33%, Valid: 84.40%, Test: 84.79%\n",
            "Epoch: 40, Loss: 8166310.5000, Train: 87.78%, Valid: 84.78%, Test: 85.25%\n",
            "Epoch: 45, Loss: 7940536.5000, Train: 88.30%, Valid: 84.82%, Test: 85.80%\n",
            "Epoch: 50, Loss: 7758052.0000, Train: 88.49%, Valid: 84.99%, Test: 85.98%\n",
            "Epoch: 55, Loss: 7605115.0000, Train: 88.98%, Valid: 85.21%, Test: 86.17%\n",
            "Epoch: 60, Loss: 7473325.0000, Train: 89.20%, Valid: 85.62%, Test: 86.27%\n",
            "Epoch: 65, Loss: 7359259.0000, Train: 89.33%, Valid: 85.68%, Test: 86.33%\n",
            "Epoch: 70, Loss: 7259848.0000, Train: 89.35%, Valid: 85.72%, Test: 86.51%\n",
            "Epoch: 75, Loss: 7173705.5000, Train: 89.57%, Valid: 85.84%, Test: 86.55%\n",
            "Epoch: 80, Loss: 7096868.0000, Train: 89.70%, Valid: 85.88%, Test: 86.63%\n",
            "Epoch: 85, Loss: 7026008.0000, Train: 89.67%, Valid: 85.92%, Test: 86.69%\n",
            "Epoch: 90, Loss: 6964696.5000, Train: 89.76%, Valid: 85.96%, Test: 86.77%\n",
            "Epoch: 95, Loss: 6908893.0000, Train: 89.70%, Valid: 85.98%, Test: 86.71%\n",
            "Epoch: 100, Loss: 6857394.5000, Train: 89.76%, Valid: 85.94%, Test: 86.71%\n",
            "Epoch: 105, Loss: 6809667.0000, Train: 89.94%, Valid: 85.90%, Test: 86.77%\n",
            "Epoch: 110, Loss: 6765051.0000, Train: 89.99%, Valid: 85.96%, Test: 86.75%\n",
            "Epoch: 115, Loss: 6723696.5000, Train: 90.06%, Valid: 86.00%, Test: 86.90%\n",
            "Epoch: 120, Loss: 6684767.5000, Train: 90.01%, Valid: 85.94%, Test: 86.88%\n",
            "Epoch: 125, Loss: 6648111.0000, Train: 90.06%, Valid: 85.98%, Test: 86.77%\n",
            "Epoch: 130, Loss: 6616238.0000, Train: 90.13%, Valid: 85.94%, Test: 86.88%\n",
            "Epoch: 135, Loss: 6586346.5000, Train: 90.17%, Valid: 85.84%, Test: 86.94%\n",
            "Epoch: 140, Loss: 6568975.0000, Train: 90.21%, Valid: 85.94%, Test: 86.75%\n",
            "Epoch: 145, Loss: 6544701.5000, Train: 90.24%, Valid: 85.96%, Test: 86.80%\n",
            "Epoch: 150, Loss: 6509207.0000, Train: 90.24%, Valid: 85.90%, Test: 86.84%\n",
            "Epoch: 155, Loss: 6498594.5000, Train: 90.26%, Valid: 86.02%, Test: 86.90%\n",
            "Epoch: 160, Loss: 6469692.5000, Train: 90.28%, Valid: 85.96%, Test: 86.82%\n",
            "Epoch: 165, Loss: 6450581.0000, Train: 90.27%, Valid: 85.98%, Test: 86.84%\n",
            "Epoch: 170, Loss: 6457376.0000, Train: 90.26%, Valid: 86.12%, Test: 86.90%\n",
            "Epoch: 175, Loss: 6432403.5000, Train: 90.18%, Valid: 86.08%, Test: 86.94%\n",
            "Epoch: 180, Loss: 6412113.5000, Train: 90.18%, Valid: 86.02%, Test: 86.90%\n",
            "Epoch: 185, Loss: 6405949.5000, Train: 90.25%, Valid: 86.10%, Test: 86.96%\n",
            "Epoch: 190, Loss: 6372455.0000, Train: 90.25%, Valid: 85.98%, Test: 86.86%\n",
            "Epoch: 195, Loss: 6383846.0000, Train: 90.36%, Valid: 86.14%, Test: 87.04%\n",
            "Run 04:\n",
            "Highest Train: 90.36\n",
            "Highest Valid: 86.22\n",
            "Highest Test: 87.10\n",
            "Chosen epoch: 194\n",
            "Final Train: 90.25\n",
            "Final Test: 86.90\n",
            "Epoch: 00, Loss: 30673972.0000, Train: 19.78%, Valid: 20.25%, Test: 19.07%\n",
            "Epoch: 05, Loss: 14287828.0000, Train: 42.59%, Valid: 43.52%, Test: 42.82%\n",
            "Epoch: 10, Loss: 12058509.0000, Train: 66.54%, Valid: 66.04%, Test: 65.03%\n",
            "Epoch: 15, Loss: 10852642.0000, Train: 78.51%, Valid: 76.38%, Test: 76.80%\n",
            "Epoch: 20, Loss: 10016181.0000, Train: 82.65%, Valid: 79.91%, Test: 81.38%\n",
            "Epoch: 25, Loss: 9393773.0000, Train: 85.26%, Valid: 82.71%, Test: 83.94%\n",
            "Epoch: 30, Loss: 8886191.0000, Train: 86.89%, Valid: 84.22%, Test: 85.15%\n",
            "Epoch: 35, Loss: 8492674.0000, Train: 87.84%, Valid: 84.87%, Test: 85.64%\n",
            "Epoch: 40, Loss: 8190488.0000, Train: 88.41%, Valid: 85.13%, Test: 85.88%\n",
            "Epoch: 45, Loss: 7940780.0000, Train: 88.80%, Valid: 85.37%, Test: 86.00%\n",
            "Epoch: 50, Loss: 7730112.5000, Train: 89.04%, Valid: 85.51%, Test: 86.04%\n",
            "Epoch: 55, Loss: 7550785.0000, Train: 89.25%, Valid: 85.88%, Test: 86.31%\n",
            "Epoch: 60, Loss: 7395720.0000, Train: 89.44%, Valid: 85.96%, Test: 86.37%\n",
            "Epoch: 65, Loss: 7262754.0000, Train: 89.56%, Valid: 85.90%, Test: 86.49%\n",
            "Epoch: 70, Loss: 7145971.0000, Train: 89.73%, Valid: 85.84%, Test: 86.57%\n",
            "Epoch: 75, Loss: 7044641.0000, Train: 89.82%, Valid: 85.94%, Test: 86.80%\n",
            "Epoch: 80, Loss: 6954018.5000, Train: 89.93%, Valid: 85.86%, Test: 86.98%\n",
            "Epoch: 85, Loss: 6872295.0000, Train: 89.95%, Valid: 85.94%, Test: 87.04%\n",
            "Epoch: 90, Loss: 6798185.5000, Train: 90.04%, Valid: 86.00%, Test: 86.80%\n",
            "Epoch: 95, Loss: 6728738.0000, Train: 90.13%, Valid: 85.96%, Test: 86.73%\n",
            "Epoch: 100, Loss: 6665087.0000, Train: 90.28%, Valid: 85.92%, Test: 86.77%\n",
            "Epoch: 105, Loss: 6605499.5000, Train: 90.31%, Valid: 86.02%, Test: 86.75%\n",
            "Epoch: 110, Loss: 6549557.0000, Train: 90.29%, Valid: 86.10%, Test: 86.73%\n",
            "Epoch: 115, Loss: 6498546.0000, Train: 90.36%, Valid: 86.12%, Test: 86.69%\n",
            "Epoch: 120, Loss: 6458555.5000, Train: 90.39%, Valid: 86.29%, Test: 86.75%\n",
            "Epoch: 125, Loss: 6419062.0000, Train: 90.48%, Valid: 86.18%, Test: 86.86%\n",
            "Epoch: 130, Loss: 6376426.0000, Train: 90.42%, Valid: 86.16%, Test: 86.90%\n",
            "Epoch: 135, Loss: 6336425.5000, Train: 90.56%, Valid: 86.12%, Test: 86.75%\n",
            "Epoch: 140, Loss: 6319426.5000, Train: 90.63%, Valid: 86.08%, Test: 87.02%\n",
            "Epoch: 145, Loss: 6282727.0000, Train: 90.73%, Valid: 86.14%, Test: 86.90%\n",
            "Epoch: 150, Loss: 6248869.0000, Train: 90.69%, Valid: 86.35%, Test: 87.00%\n",
            "Epoch: 155, Loss: 6232208.0000, Train: 90.70%, Valid: 86.02%, Test: 86.77%\n",
            "Epoch: 160, Loss: 6219789.5000, Train: 90.79%, Valid: 86.20%, Test: 86.92%\n",
            "Epoch: 165, Loss: 6209548.5000, Train: 90.80%, Valid: 86.29%, Test: 86.88%\n",
            "Epoch: 170, Loss: 6201758.0000, Train: 90.88%, Valid: 86.02%, Test: 86.84%\n",
            "Epoch: 175, Loss: 6160936.0000, Train: 90.98%, Valid: 86.00%, Test: 86.92%\n",
            "Epoch: 180, Loss: 6137736.0000, Train: 90.92%, Valid: 85.86%, Test: 86.69%\n",
            "Epoch: 185, Loss: 6342487.0000, Train: 91.03%, Valid: 86.37%, Test: 87.20%\n",
            "Epoch: 190, Loss: 6127595.0000, Train: 90.89%, Valid: 86.16%, Test: 87.00%\n",
            "Epoch: 195, Loss: 6110413.5000, Train: 90.98%, Valid: 86.20%, Test: 86.84%\n",
            "Run 05:\n",
            "Highest Train: 91.03\n",
            "Highest Valid: 86.47\n",
            "Highest Test: 87.20\n",
            "Chosen epoch: 159\n",
            "Final Train: 90.81\n",
            "Final Test: 87.10\n",
            "All runs:\n",
            "Highest Train: 90.62 ± 0.35\n",
            "Highest Test: 86.95 ± 0.29\n",
            "Highest Valid: 86.58 ± 0.24\n",
            "  Final Train: 90.38 ± 0.37\n",
            "   Final Test: 86.80 ± 0.23\n",
            "Saving results to logs/pubmed_edge.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 GKD/main.py --dataset pubmed --rand_split --use_bn --base_model gcn --mode train  --dist_mode gkd --use_kd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvOU48MxC4kO",
        "outputId": "7fa1f57f-7299-490e-cc2d-53beb8036467"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(data_dir='data', dataset='pubmed', sub_dataset='', cpu=False, seed=42, train_prop=0.5, valid_prop=0.25, protocol='semi', rand_split=True, metric='acc', runs=5, epochs=200, hidden_channels=32, num_layers=3, gat_heads=8, out_heads=1, hops=1, lp_alpha=0.1, gpr_alpha=0.1, jk_type='max', directed=False, num_mlp_layers=1, display_step=5, cached=False, print_prop=False, priv_type='edge', priv_ratio=0.5, save_model=False, save_name='gcn', log_name='none', base_model='gcn', not_load_teacher=False, mode='train', dist_mode='gkd', weight_decay=0.05, dropout=0.0, lr=0.01, use_bn=True, use_batch=False, batch_size=2048, oracle=False, device=0, alpha=0.5, delta=0.1, use_kd=True, beta=0.0, tau=1.0, kernel='sigmoid', t=1.0, include_last=False, s=2, m=1, lr2=0.001, sim='l2', ker_norm=False)\n",
            "cuda:0\n",
            "pubmed\n",
            "Num nodes: 19717\n",
            "torch.Size([19717, 1])\n",
            "num nodes 19717 | num classes 3 | num node feats 500\n",
            "MODEL: GeoDist(\n",
            "  (k): Kernel(\n",
            "    (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  )\n",
            "  (teacher_gnn): ModuleList(\n",
            "    (0): Linear(in_features=500, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (student_gnn): ModuleList(\n",
            "    (0): Linear(in_features=500, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  (bns2d): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            ")\n",
            "Epoch: 00, Loss: 30492376.0000, Train: 46.48%, Valid: 46.62%, Test: 46.29%\n",
            "Epoch: 05, Loss: 13358913.0000, Train: 67.37%, Valid: 67.11%, Test: 67.04%\n",
            "Epoch: 10, Loss: 10831945.0000, Train: 83.04%, Valid: 81.09%, Test: 82.13%\n",
            "Epoch: 15, Loss: 9545926.0000, Train: 85.30%, Valid: 82.86%, Test: 83.53%\n",
            "Epoch: 20, Loss: 8710531.0000, Train: 85.77%, Valid: 83.22%, Test: 84.28%\n",
            "Epoch: 25, Loss: 8053471.0000, Train: 86.65%, Valid: 83.83%, Test: 85.13%\n",
            "Epoch: 30, Loss: 7536694.5000, Train: 87.55%, Valid: 84.24%, Test: 85.15%\n",
            "Epoch: 35, Loss: 7110734.0000, Train: 88.04%, Valid: 84.95%, Test: 85.58%\n",
            "Epoch: 40, Loss: 6768038.0000, Train: 88.36%, Valid: 85.53%, Test: 85.82%\n",
            "Epoch: 45, Loss: 6493394.0000, Train: 88.80%, Valid: 85.58%, Test: 86.19%\n",
            "Epoch: 50, Loss: 6261611.0000, Train: 88.97%, Valid: 85.47%, Test: 86.04%\n",
            "Epoch: 55, Loss: 6077120.5000, Train: 89.28%, Valid: 85.84%, Test: 86.15%\n",
            "Epoch: 60, Loss: 5918932.0000, Train: 89.44%, Valid: 85.90%, Test: 86.13%\n",
            "Epoch: 65, Loss: 5784858.5000, Train: 89.69%, Valid: 86.00%, Test: 86.25%\n",
            "Epoch: 70, Loss: 5669408.5000, Train: 89.78%, Valid: 86.10%, Test: 86.47%\n",
            "Epoch: 75, Loss: 5569563.0000, Train: 89.84%, Valid: 86.04%, Test: 86.51%\n",
            "Epoch: 80, Loss: 5480048.0000, Train: 90.07%, Valid: 86.00%, Test: 86.51%\n",
            "Epoch: 85, Loss: 5401013.0000, Train: 90.22%, Valid: 86.16%, Test: 86.67%\n",
            "Epoch: 90, Loss: 5329289.0000, Train: 90.22%, Valid: 86.31%, Test: 86.65%\n",
            "Epoch: 95, Loss: 5263473.5000, Train: 90.29%, Valid: 86.37%, Test: 86.57%\n",
            "Epoch: 100, Loss: 5226854.0000, Train: 90.25%, Valid: 86.31%, Test: 86.57%\n",
            "Epoch: 105, Loss: 5182035.5000, Train: 90.41%, Valid: 86.37%, Test: 86.65%\n",
            "Epoch: 110, Loss: 5131905.5000, Train: 90.56%, Valid: 86.47%, Test: 86.65%\n",
            "Epoch: 115, Loss: 5063164.0000, Train: 90.56%, Valid: 86.53%, Test: 86.63%\n",
            "Epoch: 120, Loss: 5019549.5000, Train: 90.60%, Valid: 86.47%, Test: 86.67%\n",
            "Epoch: 125, Loss: 4991317.0000, Train: 90.59%, Valid: 86.39%, Test: 86.61%\n",
            "Epoch: 130, Loss: 4956843.0000, Train: 90.68%, Valid: 86.49%, Test: 86.47%\n",
            "Epoch: 135, Loss: 4918121.0000, Train: 90.65%, Valid: 86.31%, Test: 86.45%\n",
            "Epoch: 140, Loss: 4927998.0000, Train: 90.60%, Valid: 86.37%, Test: 86.47%\n",
            "Epoch: 145, Loss: 4917095.0000, Train: 90.66%, Valid: 86.37%, Test: 86.49%\n",
            "Epoch: 150, Loss: 4856018.0000, Train: 90.77%, Valid: 86.16%, Test: 86.45%\n",
            "Epoch: 155, Loss: 4810837.0000, Train: 90.76%, Valid: 86.18%, Test: 86.33%\n",
            "Epoch: 160, Loss: 4806851.5000, Train: 90.67%, Valid: 86.04%, Test: 86.29%\n",
            "Epoch: 165, Loss: 4783156.0000, Train: 90.68%, Valid: 85.96%, Test: 86.29%\n",
            "Epoch: 170, Loss: 4787799.5000, Train: 90.79%, Valid: 86.06%, Test: 86.33%\n",
            "Epoch: 175, Loss: 4763989.0000, Train: 90.67%, Valid: 86.20%, Test: 86.45%\n",
            "Epoch: 180, Loss: 4720664.0000, Train: 90.70%, Valid: 86.22%, Test: 86.39%\n",
            "Epoch: 185, Loss: 4691686.0000, Train: 90.80%, Valid: 86.14%, Test: 86.35%\n",
            "Epoch: 190, Loss: 4722156.0000, Train: 90.83%, Valid: 86.29%, Test: 86.37%\n",
            "Epoch: 195, Loss: 4709098.0000, Train: 90.81%, Valid: 86.14%, Test: 86.29%\n",
            "Run 01:\n",
            "Highest Train: 90.91\n",
            "Highest Valid: 86.55\n",
            "Highest Test: 86.75\n",
            "Chosen epoch: 108\n",
            "Final Train: 90.44\n",
            "Final Test: 86.59\n",
            "Epoch: 00, Loss: 31617328.0000, Train: 46.78%, Valid: 46.52%, Test: 46.65%\n",
            "Epoch: 05, Loss: 15105087.0000, Train: 69.00%, Valid: 69.12%, Test: 69.21%\n",
            "Epoch: 10, Loss: 12370526.0000, Train: 80.92%, Valid: 79.87%, Test: 79.61%\n",
            "Epoch: 15, Loss: 11104894.0000, Train: 84.30%, Valid: 82.33%, Test: 82.35%\n",
            "Epoch: 20, Loss: 10241489.0000, Train: 86.18%, Valid: 83.51%, Test: 84.08%\n",
            "Epoch: 25, Loss: 9640014.0000, Train: 87.25%, Valid: 84.50%, Test: 84.36%\n",
            "Epoch: 30, Loss: 9189691.0000, Train: 87.77%, Valid: 84.97%, Test: 85.05%\n",
            "Epoch: 35, Loss: 8824416.0000, Train: 88.18%, Valid: 85.33%, Test: 85.64%\n",
            "Epoch: 40, Loss: 8539285.0000, Train: 88.54%, Valid: 85.76%, Test: 86.02%\n",
            "Epoch: 45, Loss: 8301320.5000, Train: 88.88%, Valid: 85.82%, Test: 85.96%\n",
            "Epoch: 50, Loss: 8104346.5000, Train: 89.06%, Valid: 86.10%, Test: 85.84%\n",
            "Epoch: 55, Loss: 7939372.5000, Train: 89.23%, Valid: 86.16%, Test: 85.96%\n",
            "Epoch: 60, Loss: 7798715.0000, Train: 89.43%, Valid: 86.12%, Test: 86.04%\n",
            "Epoch: 65, Loss: 7673588.5000, Train: 89.58%, Valid: 86.08%, Test: 86.23%\n",
            "Epoch: 70, Loss: 7565931.5000, Train: 89.69%, Valid: 86.16%, Test: 86.27%\n",
            "Epoch: 75, Loss: 7471411.5000, Train: 89.76%, Valid: 86.14%, Test: 86.11%\n",
            "Epoch: 80, Loss: 7386423.0000, Train: 89.91%, Valid: 86.18%, Test: 86.13%\n",
            "Epoch: 85, Loss: 7309785.0000, Train: 89.87%, Valid: 86.14%, Test: 86.15%\n",
            "Epoch: 90, Loss: 7240633.0000, Train: 90.02%, Valid: 86.35%, Test: 86.02%\n",
            "Epoch: 95, Loss: 7177900.0000, Train: 90.03%, Valid: 86.43%, Test: 86.11%\n",
            "Epoch: 100, Loss: 7120461.5000, Train: 90.03%, Valid: 86.51%, Test: 86.17%\n",
            "Epoch: 105, Loss: 7066272.5000, Train: 90.13%, Valid: 86.57%, Test: 86.25%\n",
            "Epoch: 110, Loss: 7017118.5000, Train: 90.29%, Valid: 86.55%, Test: 86.29%\n",
            "Epoch: 115, Loss: 6971667.5000, Train: 90.23%, Valid: 86.51%, Test: 86.19%\n",
            "Epoch: 120, Loss: 6929942.0000, Train: 90.21%, Valid: 86.63%, Test: 86.11%\n",
            "Epoch: 125, Loss: 6890224.0000, Train: 90.25%, Valid: 86.53%, Test: 86.17%\n",
            "Epoch: 130, Loss: 6864748.0000, Train: 90.32%, Valid: 86.55%, Test: 86.09%\n",
            "Epoch: 135, Loss: 6820856.0000, Train: 90.35%, Valid: 86.47%, Test: 86.25%\n",
            "Epoch: 140, Loss: 6805250.0000, Train: 90.37%, Valid: 86.45%, Test: 86.23%\n",
            "Epoch: 145, Loss: 6787652.0000, Train: 90.41%, Valid: 86.53%, Test: 86.33%\n",
            "Epoch: 150, Loss: 6737624.0000, Train: 90.48%, Valid: 86.53%, Test: 86.33%\n",
            "Epoch: 155, Loss: 6719677.0000, Train: 90.41%, Valid: 86.61%, Test: 86.51%\n",
            "Epoch: 160, Loss: 6734876.0000, Train: 90.51%, Valid: 86.47%, Test: 86.31%\n",
            "Epoch: 165, Loss: 6691041.0000, Train: 90.46%, Valid: 86.39%, Test: 86.37%\n",
            "Epoch: 170, Loss: 6660712.0000, Train: 90.54%, Valid: 86.61%, Test: 86.43%\n",
            "Epoch: 175, Loss: 6677033.0000, Train: 90.41%, Valid: 86.71%, Test: 86.43%\n",
            "Epoch: 180, Loss: 6667333.5000, Train: 90.45%, Valid: 86.63%, Test: 86.45%\n",
            "Epoch: 185, Loss: 6628111.0000, Train: 90.46%, Valid: 86.53%, Test: 86.41%\n",
            "Epoch: 190, Loss: 6613836.0000, Train: 90.47%, Valid: 86.47%, Test: 86.35%\n",
            "Epoch: 195, Loss: 6587482.0000, Train: 90.44%, Valid: 86.61%, Test: 86.41%\n",
            "Run 02:\n",
            "Highest Train: 90.61\n",
            "Highest Valid: 86.73\n",
            "Highest Test: 86.65\n",
            "Chosen epoch: 197\n",
            "Final Train: 90.54\n",
            "Final Test: 86.47\n",
            "Epoch: 00, Loss: 31013162.0000, Train: 52.42%, Valid: 53.32%, Test: 52.43%\n",
            "Epoch: 05, Loss: 12696504.0000, Train: 77.69%, Valid: 76.97%, Test: 77.20%\n",
            "Epoch: 10, Loss: 10528904.0000, Train: 81.64%, Valid: 80.10%, Test: 79.96%\n",
            "Epoch: 15, Loss: 9489162.0000, Train: 83.85%, Valid: 81.76%, Test: 81.81%\n",
            "Epoch: 20, Loss: 8808852.0000, Train: 85.75%, Valid: 83.65%, Test: 84.12%\n",
            "Epoch: 25, Loss: 8326531.5000, Train: 86.59%, Valid: 84.93%, Test: 84.65%\n",
            "Epoch: 30, Loss: 7935254.0000, Train: 87.31%, Valid: 84.91%, Test: 85.15%\n",
            "Epoch: 35, Loss: 7636390.5000, Train: 87.69%, Valid: 84.99%, Test: 85.46%\n",
            "Epoch: 40, Loss: 7384643.5000, Train: 88.03%, Valid: 85.49%, Test: 85.35%\n",
            "Epoch: 45, Loss: 7177123.5000, Train: 88.27%, Valid: 85.68%, Test: 85.70%\n",
            "Epoch: 50, Loss: 7002964.0000, Train: 88.62%, Valid: 85.86%, Test: 86.19%\n",
            "Epoch: 55, Loss: 6863202.5000, Train: 88.86%, Valid: 85.80%, Test: 86.47%\n",
            "Epoch: 60, Loss: 6744044.5000, Train: 89.15%, Valid: 85.78%, Test: 86.43%\n",
            "Epoch: 65, Loss: 6640677.0000, Train: 89.25%, Valid: 85.80%, Test: 86.51%\n",
            "Epoch: 70, Loss: 6552230.5000, Train: 89.41%, Valid: 86.10%, Test: 86.61%\n",
            "Epoch: 75, Loss: 6474198.0000, Train: 89.50%, Valid: 86.18%, Test: 86.71%\n",
            "Epoch: 80, Loss: 6404910.0000, Train: 89.50%, Valid: 86.31%, Test: 86.75%\n",
            "Epoch: 85, Loss: 6342299.0000, Train: 89.62%, Valid: 86.41%, Test: 86.71%\n",
            "Epoch: 90, Loss: 6284760.0000, Train: 89.65%, Valid: 86.45%, Test: 86.75%\n",
            "Epoch: 95, Loss: 6234118.5000, Train: 89.75%, Valid: 86.45%, Test: 86.80%\n",
            "Epoch: 100, Loss: 6188080.0000, Train: 89.75%, Valid: 86.57%, Test: 86.92%\n",
            "Epoch: 105, Loss: 6145863.0000, Train: 89.72%, Valid: 86.55%, Test: 86.90%\n",
            "Epoch: 110, Loss: 6107137.0000, Train: 89.82%, Valid: 86.61%, Test: 86.98%\n",
            "Epoch: 115, Loss: 6071178.0000, Train: 89.84%, Valid: 86.77%, Test: 86.86%\n",
            "Epoch: 120, Loss: 6113423.0000, Train: 89.71%, Valid: 86.77%, Test: 86.73%\n",
            "Epoch: 125, Loss: 6035041.5000, Train: 89.90%, Valid: 86.71%, Test: 86.92%\n",
            "Epoch: 130, Loss: 5995818.0000, Train: 89.87%, Valid: 86.73%, Test: 87.00%\n",
            "Epoch: 135, Loss: 5974493.5000, Train: 89.85%, Valid: 86.67%, Test: 87.02%\n",
            "Epoch: 140, Loss: 5940393.0000, Train: 89.85%, Valid: 86.73%, Test: 86.88%\n",
            "Epoch: 145, Loss: 5923179.0000, Train: 89.89%, Valid: 86.65%, Test: 87.08%\n",
            "Epoch: 150, Loss: 5931481.5000, Train: 89.95%, Valid: 86.45%, Test: 87.00%\n",
            "Epoch: 155, Loss: 5895523.5000, Train: 89.91%, Valid: 86.63%, Test: 86.96%\n",
            "Epoch: 160, Loss: 5863549.0000, Train: 89.97%, Valid: 86.69%, Test: 86.92%\n",
            "Epoch: 165, Loss: 5857485.5000, Train: 89.87%, Valid: 86.61%, Test: 86.86%\n",
            "Epoch: 170, Loss: 5844349.5000, Train: 90.00%, Valid: 86.57%, Test: 86.90%\n",
            "Epoch: 175, Loss: 5851543.5000, Train: 89.98%, Valid: 86.53%, Test: 86.96%\n",
            "Epoch: 180, Loss: 5798071.0000, Train: 90.06%, Valid: 86.55%, Test: 87.10%\n",
            "Epoch: 185, Loss: 5776444.0000, Train: 90.11%, Valid: 86.67%, Test: 86.98%\n",
            "Epoch: 190, Loss: 5830089.5000, Train: 90.15%, Valid: 86.37%, Test: 86.98%\n",
            "Epoch: 195, Loss: 5770194.0000, Train: 90.17%, Valid: 86.51%, Test: 86.86%\n",
            "Run 03:\n",
            "Highest Train: 90.23\n",
            "Highest Valid: 86.81\n",
            "Highest Test: 87.10\n",
            "Chosen epoch: 117\n",
            "Final Train: 89.81\n",
            "Final Test: 86.75\n",
            "Epoch: 00, Loss: 30524538.0000, Train: 40.15%, Valid: 38.73%, Test: 39.49%\n",
            "Epoch: 05, Loss: 14157582.0000, Train: 67.70%, Valid: 66.36%, Test: 68.03%\n",
            "Epoch: 10, Loss: 11709442.0000, Train: 80.52%, Valid: 78.76%, Test: 78.70%\n",
            "Epoch: 15, Loss: 10501255.0000, Train: 83.97%, Valid: 81.64%, Test: 82.15%\n",
            "Epoch: 20, Loss: 9736450.0000, Train: 85.32%, Valid: 83.04%, Test: 83.55%\n",
            "Epoch: 25, Loss: 9197140.0000, Train: 86.28%, Valid: 83.71%, Test: 83.87%\n",
            "Epoch: 30, Loss: 8768189.0000, Train: 86.85%, Valid: 84.09%, Test: 84.28%\n",
            "Epoch: 35, Loss: 8431714.0000, Train: 87.33%, Valid: 84.40%, Test: 84.79%\n",
            "Epoch: 40, Loss: 8166297.0000, Train: 87.79%, Valid: 84.78%, Test: 85.25%\n",
            "Epoch: 45, Loss: 7940500.5000, Train: 88.30%, Valid: 84.82%, Test: 85.76%\n",
            "Epoch: 50, Loss: 7758011.5000, Train: 88.48%, Valid: 84.99%, Test: 85.98%\n",
            "Epoch: 55, Loss: 7605106.0000, Train: 88.99%, Valid: 85.21%, Test: 86.15%\n",
            "Epoch: 60, Loss: 7473378.0000, Train: 89.17%, Valid: 85.60%, Test: 86.29%\n",
            "Epoch: 65, Loss: 7359327.0000, Train: 89.34%, Valid: 85.62%, Test: 86.31%\n",
            "Epoch: 70, Loss: 7259961.0000, Train: 89.35%, Valid: 85.72%, Test: 86.51%\n",
            "Epoch: 75, Loss: 7173686.0000, Train: 89.59%, Valid: 85.82%, Test: 86.59%\n",
            "Epoch: 80, Loss: 7096786.5000, Train: 89.66%, Valid: 85.90%, Test: 86.67%\n",
            "Epoch: 85, Loss: 7025871.0000, Train: 89.66%, Valid: 85.94%, Test: 86.71%\n",
            "Epoch: 90, Loss: 6964534.0000, Train: 89.77%, Valid: 86.00%, Test: 86.80%\n",
            "Epoch: 95, Loss: 6908785.5000, Train: 89.72%, Valid: 85.96%, Test: 86.69%\n",
            "Epoch: 100, Loss: 6857368.5000, Train: 89.76%, Valid: 85.88%, Test: 86.71%\n",
            "Epoch: 105, Loss: 6809683.5000, Train: 89.88%, Valid: 85.88%, Test: 86.77%\n",
            "Epoch: 110, Loss: 6765300.5000, Train: 89.99%, Valid: 85.98%, Test: 86.67%\n",
            "Epoch: 115, Loss: 6723963.0000, Train: 90.00%, Valid: 85.94%, Test: 86.80%\n",
            "Epoch: 120, Loss: 6685114.5000, Train: 90.01%, Valid: 85.94%, Test: 86.80%\n",
            "Epoch: 125, Loss: 6648415.0000, Train: 90.06%, Valid: 85.94%, Test: 86.77%\n",
            "Epoch: 130, Loss: 6613683.5000, Train: 90.13%, Valid: 85.86%, Test: 86.82%\n",
            "Epoch: 135, Loss: 6595143.0000, Train: 90.12%, Valid: 85.86%, Test: 86.90%\n",
            "Epoch: 140, Loss: 6567820.5000, Train: 90.09%, Valid: 85.94%, Test: 86.90%\n",
            "Epoch: 145, Loss: 6546532.5000, Train: 90.16%, Valid: 85.96%, Test: 86.94%\n",
            "Epoch: 150, Loss: 6517345.0000, Train: 90.18%, Valid: 85.90%, Test: 87.02%\n",
            "Epoch: 155, Loss: 6502114.0000, Train: 90.01%, Valid: 85.92%, Test: 86.94%\n",
            "Epoch: 160, Loss: 6489704.0000, Train: 90.11%, Valid: 85.90%, Test: 87.02%\n",
            "Epoch: 165, Loss: 6456871.0000, Train: 90.18%, Valid: 85.90%, Test: 87.04%\n",
            "Epoch: 170, Loss: 6425414.0000, Train: 90.21%, Valid: 85.94%, Test: 86.94%\n",
            "Epoch: 175, Loss: 6401356.5000, Train: 90.19%, Valid: 85.98%, Test: 86.96%\n",
            "Epoch: 180, Loss: 6403729.0000, Train: 90.14%, Valid: 85.72%, Test: 86.96%\n",
            "Epoch: 185, Loss: 6445959.0000, Train: 90.34%, Valid: 86.18%, Test: 86.92%\n",
            "Epoch: 190, Loss: 6392167.5000, Train: 90.27%, Valid: 86.12%, Test: 87.04%\n",
            "Epoch: 195, Loss: 6358648.5000, Train: 90.32%, Valid: 86.00%, Test: 86.86%\n",
            "Run 04:\n",
            "Highest Train: 90.34\n",
            "Highest Valid: 86.20\n",
            "Highest Test: 87.04\n",
            "Chosen epoch: 199\n",
            "Final Train: 90.29\n",
            "Final Test: 86.88\n",
            "Epoch: 00, Loss: 30673972.0000, Train: 19.78%, Valid: 20.25%, Test: 19.07%\n",
            "Epoch: 05, Loss: 14287828.0000, Train: 42.59%, Valid: 43.52%, Test: 42.82%\n",
            "Epoch: 10, Loss: 12058509.0000, Train: 66.54%, Valid: 66.04%, Test: 65.03%\n",
            "Epoch: 15, Loss: 10852642.0000, Train: 78.51%, Valid: 76.38%, Test: 76.80%\n",
            "Epoch: 20, Loss: 10016182.0000, Train: 82.65%, Valid: 79.91%, Test: 81.38%\n",
            "Epoch: 25, Loss: 9393772.0000, Train: 85.26%, Valid: 82.71%, Test: 83.94%\n",
            "Epoch: 30, Loss: 8886186.0000, Train: 86.89%, Valid: 84.22%, Test: 85.15%\n",
            "Epoch: 35, Loss: 8492666.0000, Train: 87.84%, Valid: 84.87%, Test: 85.64%\n",
            "Epoch: 40, Loss: 8190468.0000, Train: 88.41%, Valid: 85.13%, Test: 85.88%\n",
            "Epoch: 45, Loss: 7940788.0000, Train: 88.80%, Valid: 85.37%, Test: 86.00%\n",
            "Epoch: 50, Loss: 7730114.0000, Train: 89.04%, Valid: 85.51%, Test: 86.04%\n",
            "Epoch: 55, Loss: 7550738.0000, Train: 89.25%, Valid: 85.88%, Test: 86.29%\n",
            "Epoch: 60, Loss: 7395602.5000, Train: 89.44%, Valid: 85.98%, Test: 86.39%\n",
            "Epoch: 65, Loss: 7262642.0000, Train: 89.54%, Valid: 85.92%, Test: 86.51%\n",
            "Epoch: 70, Loss: 7145852.5000, Train: 89.72%, Valid: 85.84%, Test: 86.55%\n",
            "Epoch: 75, Loss: 7044574.5000, Train: 89.84%, Valid: 85.92%, Test: 86.82%\n",
            "Epoch: 80, Loss: 6953961.5000, Train: 89.93%, Valid: 85.88%, Test: 86.96%\n",
            "Epoch: 85, Loss: 6872330.5000, Train: 89.98%, Valid: 85.94%, Test: 87.00%\n",
            "Epoch: 90, Loss: 6798289.0000, Train: 90.05%, Valid: 85.98%, Test: 86.82%\n",
            "Epoch: 95, Loss: 6728955.5000, Train: 90.12%, Valid: 85.96%, Test: 86.71%\n",
            "Epoch: 100, Loss: 6665166.0000, Train: 90.27%, Valid: 85.92%, Test: 86.86%\n",
            "Epoch: 105, Loss: 6605443.0000, Train: 90.31%, Valid: 85.98%, Test: 86.73%\n",
            "Epoch: 110, Loss: 6549378.0000, Train: 90.31%, Valid: 86.18%, Test: 86.75%\n",
            "Epoch: 115, Loss: 6498343.5000, Train: 90.37%, Valid: 86.08%, Test: 86.69%\n",
            "Epoch: 120, Loss: 6464578.0000, Train: 90.37%, Valid: 86.31%, Test: 86.75%\n",
            "Epoch: 125, Loss: 6409920.5000, Train: 90.45%, Valid: 86.22%, Test: 86.75%\n",
            "Epoch: 130, Loss: 6375137.5000, Train: 90.55%, Valid: 86.16%, Test: 86.82%\n",
            "Epoch: 135, Loss: 6354529.0000, Train: 90.51%, Valid: 86.00%, Test: 86.86%\n",
            "Epoch: 140, Loss: 6337054.0000, Train: 90.57%, Valid: 85.98%, Test: 86.86%\n",
            "Epoch: 145, Loss: 6305185.5000, Train: 90.57%, Valid: 86.08%, Test: 86.86%\n",
            "Epoch: 150, Loss: 6335552.0000, Train: 90.67%, Valid: 86.00%, Test: 87.02%\n",
            "Epoch: 155, Loss: 6275620.5000, Train: 90.79%, Valid: 86.31%, Test: 86.90%\n",
            "Epoch: 160, Loss: 6219153.0000, Train: 90.86%, Valid: 86.31%, Test: 86.88%\n",
            "Epoch: 165, Loss: 6200330.0000, Train: 90.82%, Valid: 85.98%, Test: 86.80%\n",
            "Epoch: 170, Loss: 6237635.0000, Train: 90.98%, Valid: 86.24%, Test: 87.08%\n",
            "Epoch: 175, Loss: 6145297.0000, Train: 90.96%, Valid: 86.29%, Test: 87.10%\n",
            "Epoch: 180, Loss: 6129573.0000, Train: 91.00%, Valid: 86.26%, Test: 86.98%\n",
            "Epoch: 185, Loss: 6118807.0000, Train: 90.86%, Valid: 85.82%, Test: 86.82%\n",
            "Epoch: 190, Loss: 6162580.0000, Train: 90.90%, Valid: 86.10%, Test: 87.12%\n",
            "Epoch: 195, Loss: 6101544.5000, Train: 90.99%, Valid: 85.96%, Test: 87.10%\n",
            "Run 05:\n",
            "Highest Train: 91.06\n",
            "Highest Valid: 86.49\n",
            "Highest Test: 87.22\n",
            "Chosen epoch: 147\n",
            "Final Train: 90.67\n",
            "Final Test: 86.96\n",
            "All runs:\n",
            "Highest Train: 90.63 ± 0.36\n",
            "Highest Test: 86.95 ± 0.24\n",
            "Highest Valid: 86.56 ± 0.24\n",
            "  Final Train: 90.35 ± 0.33\n",
            "   Final Test: 86.73 ± 0.20\n",
            "Saving results to logs/pubmed_edge.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 GKD/main.py --dataset pubmed --rand_split --use_bn --base_model gcn --mode train  --dist_mode pgkd --use_kd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l973p48EC-Pn",
        "outputId": "1c0e1444-a945-4080-e507-6fd5bb46619b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(data_dir='data', dataset='pubmed', sub_dataset='', cpu=False, seed=42, train_prop=0.5, valid_prop=0.25, protocol='semi', rand_split=True, metric='acc', runs=5, epochs=200, hidden_channels=32, num_layers=3, gat_heads=8, out_heads=1, hops=1, lp_alpha=0.1, gpr_alpha=0.1, jk_type='max', directed=False, num_mlp_layers=1, display_step=5, cached=False, print_prop=False, priv_type='edge', priv_ratio=0.5, save_model=False, save_name='gcn', log_name='none', base_model='gcn', not_load_teacher=False, mode='train', dist_mode='pgkd', weight_decay=0.05, dropout=0.0, lr=0.01, use_bn=True, use_batch=False, batch_size=2048, oracle=False, device=0, alpha=0.5, delta=0.1, use_kd=True, beta=0.0, tau=1.0, kernel='sigmoid', t=1.0, include_last=False, s=2, m=1, lr2=0.001, sim='l2', ker_norm=False)\n",
            "cuda:0\n",
            "pubmed\n",
            "Num nodes: 19717\n",
            "torch.Size([19717, 1])\n",
            "num nodes 19717 | num classes 3 | num node feats 500\n",
            "MODEL: GeoDist(\n",
            "  (k): Kernel(\n",
            "    (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  )\n",
            "  (teacher_gnn): ModuleList(\n",
            "    (0): Linear(in_features=500, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (student_gnn): ModuleList(\n",
            "    (0): Linear(in_features=500, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  (bns2d): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            ")\n",
            "Epoch: 00, Loss: 6341668864.0000, Train: 43.60%, Valid: 44.57%, Test: 43.91%\n",
            "Epoch: 05, Loss: 2130430976.0000, Train: 73.25%, Valid: 73.04%, Test: 72.35%\n",
            "Epoch: 10, Loss: 1683976192.0000, Train: 84.06%, Valid: 82.35%, Test: 82.72%\n",
            "Epoch: 15, Loss: 1460921600.0000, Train: 86.42%, Valid: 84.60%, Test: 84.99%\n",
            "Epoch: 20, Loss: 1310125696.0000, Train: 87.03%, Valid: 85.49%, Test: 85.38%\n",
            "Epoch: 25, Loss: 1197878016.0000, Train: 87.61%, Valid: 86.08%, Test: 85.88%\n",
            "Epoch: 30, Loss: 1106704256.0000, Train: 88.14%, Valid: 86.51%, Test: 86.13%\n",
            "Epoch: 35, Loss: 1033197440.0000, Train: 88.54%, Valid: 86.91%, Test: 86.43%\n",
            "Epoch: 40, Loss: 971379392.0000, Train: 88.96%, Valid: 87.16%, Test: 86.67%\n",
            "Epoch: 45, Loss: 918181376.0000, Train: 89.18%, Valid: 87.24%, Test: 86.75%\n",
            "Epoch: 50, Loss: 871226112.0000, Train: 89.47%, Valid: 87.32%, Test: 87.26%\n",
            "Epoch: 55, Loss: 828962816.0000, Train: 89.58%, Valid: 87.26%, Test: 87.42%\n",
            "Epoch: 60, Loss: 791813760.0000, Train: 89.78%, Valid: 87.30%, Test: 87.69%\n",
            "Epoch: 65, Loss: 758140352.0000, Train: 89.91%, Valid: 87.40%, Test: 87.75%\n",
            "Epoch: 70, Loss: 726892800.0000, Train: 89.94%, Valid: 87.58%, Test: 87.81%\n",
            "Epoch: 75, Loss: 698334592.0000, Train: 89.98%, Valid: 87.64%, Test: 87.73%\n",
            "Epoch: 80, Loss: 672059904.0000, Train: 90.10%, Valid: 87.50%, Test: 87.79%\n",
            "Epoch: 85, Loss: 648003392.0000, Train: 90.22%, Valid: 87.50%, Test: 87.83%\n",
            "Epoch: 90, Loss: 625407680.0000, Train: 90.26%, Valid: 87.36%, Test: 87.91%\n",
            "Epoch: 95, Loss: 603210880.0000, Train: 90.31%, Valid: 87.42%, Test: 87.99%\n",
            "Epoch: 100, Loss: 581274368.0000, Train: 90.37%, Valid: 87.26%, Test: 87.97%\n",
            "Epoch: 105, Loss: 560540352.0000, Train: 90.39%, Valid: 87.26%, Test: 87.97%\n",
            "Epoch: 110, Loss: 542478848.0000, Train: 90.43%, Valid: 87.22%, Test: 87.99%\n",
            "Epoch: 115, Loss: 526737216.0000, Train: 90.40%, Valid: 87.28%, Test: 87.89%\n",
            "Epoch: 120, Loss: 513423808.0000, Train: 90.44%, Valid: 87.16%, Test: 87.87%\n",
            "Epoch: 125, Loss: 519180928.0000, Train: 90.42%, Valid: 87.50%, Test: 87.91%\n",
            "Epoch: 130, Loss: 505175552.0000, Train: 90.54%, Valid: 87.28%, Test: 87.87%\n",
            "Epoch: 135, Loss: 482315136.0000, Train: 90.58%, Valid: 87.32%, Test: 87.87%\n",
            "Epoch: 140, Loss: 471023104.0000, Train: 90.56%, Valid: 87.32%, Test: 87.77%\n",
            "Epoch: 145, Loss: 460105792.0000, Train: 90.63%, Valid: 87.24%, Test: 87.91%\n",
            "Epoch: 150, Loss: 448458176.0000, Train: 90.68%, Valid: 87.36%, Test: 87.87%\n",
            "Epoch: 155, Loss: 435788576.0000, Train: 90.61%, Valid: 87.22%, Test: 87.89%\n",
            "Epoch: 160, Loss: 423202816.0000, Train: 90.57%, Valid: 87.16%, Test: 87.87%\n",
            "Epoch: 165, Loss: 411613632.0000, Train: 90.62%, Valid: 87.14%, Test: 87.81%\n",
            "Epoch: 170, Loss: 406094272.0000, Train: 90.50%, Valid: 87.20%, Test: 87.89%\n",
            "Epoch: 175, Loss: 392041472.0000, Train: 90.47%, Valid: 87.04%, Test: 87.79%\n",
            "Epoch: 180, Loss: 384761664.0000, Train: 90.46%, Valid: 87.06%, Test: 87.65%\n",
            "Epoch: 185, Loss: 386706976.0000, Train: 90.47%, Valid: 86.87%, Test: 87.69%\n",
            "Epoch: 190, Loss: 377102304.0000, Train: 90.53%, Valid: 86.85%, Test: 87.65%\n",
            "Epoch: 195, Loss: 374441024.0000, Train: 90.48%, Valid: 86.95%, Test: 87.69%\n",
            "Run 01:\n",
            "Highest Train: 90.74\n",
            "Highest Valid: 87.69\n",
            "Highest Test: 88.05\n",
            "Chosen epoch: 74\n",
            "Final Train: 89.97\n",
            "Final Test: 87.77\n",
            "Epoch: 00, Loss: 7275892224.0000, Train: 49.29%, Valid: 50.09%, Test: 50.22%\n",
            "Epoch: 05, Loss: 2467877120.0000, Train: 65.33%, Valid: 64.29%, Test: 64.83%\n",
            "Epoch: 10, Loss: 1793344000.0000, Train: 79.39%, Valid: 78.21%, Test: 78.48%\n",
            "Epoch: 15, Loss: 1544397440.0000, Train: 85.42%, Valid: 84.22%, Test: 84.00%\n",
            "Epoch: 20, Loss: 1386330624.0000, Train: 86.71%, Valid: 84.95%, Test: 84.99%\n",
            "Epoch: 25, Loss: 1273520128.0000, Train: 87.37%, Valid: 85.17%, Test: 85.78%\n",
            "Epoch: 30, Loss: 1186658816.0000, Train: 87.57%, Valid: 85.58%, Test: 86.13%\n",
            "Epoch: 35, Loss: 1111003648.0000, Train: 87.83%, Valid: 85.62%, Test: 86.41%\n",
            "Epoch: 40, Loss: 1045706816.0000, Train: 88.09%, Valid: 85.70%, Test: 86.65%\n",
            "Epoch: 45, Loss: 990270528.0000, Train: 88.43%, Valid: 86.02%, Test: 86.92%\n",
            "Epoch: 50, Loss: 941178048.0000, Train: 88.89%, Valid: 86.22%, Test: 87.02%\n",
            "Epoch: 55, Loss: 896254464.0000, Train: 89.15%, Valid: 86.39%, Test: 87.34%\n",
            "Epoch: 60, Loss: 854174976.0000, Train: 89.29%, Valid: 86.59%, Test: 87.42%\n",
            "Epoch: 65, Loss: 815751936.0000, Train: 89.46%, Valid: 86.65%, Test: 87.51%\n",
            "Epoch: 70, Loss: 780602112.0000, Train: 89.62%, Valid: 86.79%, Test: 87.73%\n",
            "Epoch: 75, Loss: 747699008.0000, Train: 89.69%, Valid: 86.83%, Test: 87.81%\n",
            "Epoch: 80, Loss: 717251584.0000, Train: 89.76%, Valid: 86.83%, Test: 87.85%\n",
            "Epoch: 85, Loss: 690596288.0000, Train: 89.82%, Valid: 87.00%, Test: 87.87%\n",
            "Epoch: 90, Loss: 666916864.0000, Train: 89.87%, Valid: 86.98%, Test: 87.73%\n",
            "Epoch: 95, Loss: 645513344.0000, Train: 89.91%, Valid: 86.91%, Test: 87.73%\n",
            "Epoch: 100, Loss: 625573952.0000, Train: 90.09%, Valid: 87.00%, Test: 87.69%\n",
            "Epoch: 105, Loss: 606777088.0000, Train: 90.12%, Valid: 86.95%, Test: 87.69%\n",
            "Epoch: 110, Loss: 589392192.0000, Train: 90.10%, Valid: 86.89%, Test: 87.65%\n",
            "Epoch: 115, Loss: 573516288.0000, Train: 90.15%, Valid: 86.95%, Test: 87.53%\n",
            "Epoch: 120, Loss: 570112896.0000, Train: 90.09%, Valid: 87.02%, Test: 87.53%\n",
            "Epoch: 125, Loss: 555243584.0000, Train: 90.11%, Valid: 87.04%, Test: 87.59%\n",
            "Epoch: 130, Loss: 541110400.0000, Train: 90.14%, Valid: 87.04%, Test: 87.67%\n",
            "Epoch: 135, Loss: 527177984.0000, Train: 90.17%, Valid: 87.08%, Test: 87.71%\n",
            "Epoch: 140, Loss: 515822336.0000, Train: 90.22%, Valid: 87.00%, Test: 87.71%\n",
            "Epoch: 145, Loss: 503587200.0000, Train: 90.15%, Valid: 86.98%, Test: 87.77%\n",
            "Epoch: 150, Loss: 499546496.0000, Train: 90.17%, Valid: 87.02%, Test: 87.55%\n",
            "Epoch: 155, Loss: 488097920.0000, Train: 90.20%, Valid: 86.98%, Test: 87.71%\n",
            "Epoch: 160, Loss: 478706944.0000, Train: 90.25%, Valid: 86.89%, Test: 87.63%\n",
            "Epoch: 165, Loss: 492284480.0000, Train: 90.30%, Valid: 86.93%, Test: 87.65%\n",
            "Epoch: 170, Loss: 471944320.0000, Train: 90.22%, Valid: 86.89%, Test: 87.57%\n",
            "Epoch: 175, Loss: 450154880.0000, Train: 90.21%, Valid: 87.00%, Test: 87.55%\n",
            "Epoch: 180, Loss: 444149824.0000, Train: 90.27%, Valid: 87.00%, Test: 87.69%\n",
            "Epoch: 185, Loss: 434104128.0000, Train: 90.33%, Valid: 86.87%, Test: 87.75%\n",
            "Epoch: 190, Loss: 427125312.0000, Train: 90.30%, Valid: 86.85%, Test: 87.79%\n",
            "Epoch: 195, Loss: 423917824.0000, Train: 90.30%, Valid: 86.77%, Test: 87.77%\n",
            "Run 02:\n",
            "Highest Train: 90.36\n",
            "Highest Valid: 87.10\n",
            "Highest Test: 87.91\n",
            "Chosen epoch: 135\n",
            "Final Train: 90.09\n",
            "Final Test: 87.71\n",
            "Epoch: 00, Loss: 5135213568.0000, Train: 49.96%, Valid: 50.46%, Test: 50.14%\n",
            "Epoch: 05, Loss: 1740666112.0000, Train: 72.13%, Valid: 70.99%, Test: 71.48%\n",
            "Epoch: 10, Loss: 1288291200.0000, Train: 82.55%, Valid: 81.19%, Test: 81.66%\n",
            "Epoch: 15, Loss: 1090563072.0000, Train: 84.59%, Valid: 83.36%, Test: 83.35%\n",
            "Epoch: 20, Loss: 969965440.0000, Train: 85.17%, Valid: 84.07%, Test: 84.36%\n",
            "Epoch: 25, Loss: 885697344.0000, Train: 85.91%, Valid: 84.56%, Test: 85.19%\n",
            "Epoch: 30, Loss: 821240960.0000, Train: 86.55%, Valid: 84.91%, Test: 85.62%\n",
            "Epoch: 35, Loss: 770782080.0000, Train: 87.04%, Valid: 85.15%, Test: 85.66%\n",
            "Epoch: 40, Loss: 728868096.0000, Train: 87.32%, Valid: 85.55%, Test: 86.13%\n",
            "Epoch: 45, Loss: 693433600.0000, Train: 87.67%, Valid: 85.88%, Test: 86.39%\n",
            "Epoch: 50, Loss: 662571840.0000, Train: 87.94%, Valid: 85.76%, Test: 86.51%\n",
            "Epoch: 55, Loss: 636015744.0000, Train: 88.19%, Valid: 86.02%, Test: 86.67%\n",
            "Epoch: 60, Loss: 612891776.0000, Train: 88.40%, Valid: 86.24%, Test: 86.77%\n",
            "Epoch: 65, Loss: 592857664.0000, Train: 88.53%, Valid: 86.35%, Test: 86.82%\n",
            "Epoch: 70, Loss: 575558912.0000, Train: 88.46%, Valid: 86.43%, Test: 86.82%\n",
            "Epoch: 75, Loss: 560657856.0000, Train: 88.61%, Valid: 86.57%, Test: 87.04%\n",
            "Epoch: 80, Loss: 547085952.0000, Train: 88.80%, Valid: 86.65%, Test: 87.10%\n",
            "Epoch: 85, Loss: 534097984.0000, Train: 88.84%, Valid: 86.77%, Test: 87.08%\n",
            "Epoch: 90, Loss: 521675840.0000, Train: 88.86%, Valid: 86.71%, Test: 87.12%\n",
            "Epoch: 95, Loss: 509401440.0000, Train: 88.82%, Valid: 86.67%, Test: 87.30%\n",
            "Epoch: 100, Loss: 497714496.0000, Train: 88.91%, Valid: 86.59%, Test: 87.40%\n",
            "Epoch: 105, Loss: 486494944.0000, Train: 88.91%, Valid: 86.73%, Test: 87.34%\n",
            "Epoch: 110, Loss: 475710176.0000, Train: 88.96%, Valid: 86.75%, Test: 87.32%\n",
            "Epoch: 115, Loss: 465522432.0000, Train: 88.97%, Valid: 86.75%, Test: 87.36%\n",
            "Epoch: 120, Loss: 456060800.0000, Train: 89.04%, Valid: 86.79%, Test: 87.34%\n",
            "Epoch: 125, Loss: 447406112.0000, Train: 89.03%, Valid: 86.87%, Test: 87.42%\n",
            "Epoch: 130, Loss: 439033664.0000, Train: 89.13%, Valid: 86.77%, Test: 87.48%\n",
            "Epoch: 135, Loss: 430836096.0000, Train: 89.16%, Valid: 86.83%, Test: 87.48%\n",
            "Epoch: 140, Loss: 423079488.0000, Train: 89.23%, Valid: 86.91%, Test: 87.61%\n",
            "Epoch: 145, Loss: 415263680.0000, Train: 89.28%, Valid: 86.95%, Test: 87.55%\n",
            "Epoch: 150, Loss: 407564608.0000, Train: 89.38%, Valid: 86.98%, Test: 87.55%\n",
            "Epoch: 155, Loss: 400236096.0000, Train: 89.42%, Valid: 87.02%, Test: 87.69%\n",
            "Epoch: 160, Loss: 393414080.0000, Train: 89.41%, Valid: 86.95%, Test: 87.63%\n",
            "Epoch: 165, Loss: 387319456.0000, Train: 89.47%, Valid: 87.10%, Test: 87.48%\n",
            "Epoch: 170, Loss: 381911424.0000, Train: 89.43%, Valid: 87.10%, Test: 87.55%\n",
            "Epoch: 175, Loss: 376938368.0000, Train: 89.50%, Valid: 87.02%, Test: 87.42%\n",
            "Epoch: 180, Loss: 372027296.0000, Train: 89.48%, Valid: 87.02%, Test: 87.53%\n",
            "Epoch: 185, Loss: 367025472.0000, Train: 89.51%, Valid: 87.16%, Test: 87.51%\n",
            "Epoch: 190, Loss: 362140288.0000, Train: 89.54%, Valid: 87.16%, Test: 87.40%\n",
            "Epoch: 195, Loss: 357529856.0000, Train: 89.57%, Valid: 87.10%, Test: 87.53%\n",
            "Run 03:\n",
            "Highest Train: 89.61\n",
            "Highest Valid: 87.20\n",
            "Highest Test: 87.71\n",
            "Chosen epoch: 192\n",
            "Final Train: 89.52\n",
            "Final Test: 87.42\n",
            "Epoch: 00, Loss: 6822263296.0000, Train: 37.61%, Valid: 36.07%, Test: 37.28%\n",
            "Epoch: 05, Loss: 2091622144.0000, Train: 58.41%, Valid: 57.74%, Test: 57.18%\n",
            "Epoch: 10, Loss: 1604727808.0000, Train: 69.71%, Valid: 69.43%, Test: 69.19%\n",
            "Epoch: 15, Loss: 1385164800.0000, Train: 82.72%, Valid: 81.72%, Test: 81.05%\n",
            "Epoch: 20, Loss: 1240141696.0000, Train: 85.98%, Valid: 85.19%, Test: 84.22%\n",
            "Epoch: 25, Loss: 1133358592.0000, Train: 86.64%, Valid: 85.76%, Test: 85.33%\n",
            "Epoch: 30, Loss: 1054602496.0000, Train: 87.29%, Valid: 85.90%, Test: 85.86%\n",
            "Epoch: 35, Loss: 990736832.0000, Train: 87.77%, Valid: 86.14%, Test: 86.11%\n",
            "Epoch: 40, Loss: 936944064.0000, Train: 88.09%, Valid: 86.49%, Test: 86.17%\n",
            "Epoch: 45, Loss: 892668288.0000, Train: 88.34%, Valid: 86.49%, Test: 86.37%\n",
            "Epoch: 50, Loss: 856388416.0000, Train: 88.45%, Valid: 86.51%, Test: 86.45%\n",
            "Epoch: 55, Loss: 825528576.0000, Train: 88.58%, Valid: 86.51%, Test: 86.59%\n",
            "Epoch: 60, Loss: 799541376.0000, Train: 88.59%, Valid: 86.59%, Test: 86.80%\n",
            "Epoch: 65, Loss: 776279872.0000, Train: 88.62%, Valid: 86.69%, Test: 86.80%\n",
            "Epoch: 70, Loss: 752020096.0000, Train: 88.79%, Valid: 86.69%, Test: 86.73%\n",
            "Epoch: 75, Loss: 726141824.0000, Train: 88.97%, Valid: 86.81%, Test: 86.94%\n",
            "Epoch: 80, Loss: 704092672.0000, Train: 89.11%, Valid: 86.83%, Test: 86.90%\n",
            "Epoch: 85, Loss: 684083008.0000, Train: 89.22%, Valid: 86.81%, Test: 86.82%\n",
            "Epoch: 90, Loss: 665904512.0000, Train: 89.34%, Valid: 86.83%, Test: 86.69%\n",
            "Epoch: 95, Loss: 649414336.0000, Train: 89.42%, Valid: 86.75%, Test: 86.63%\n",
            "Epoch: 100, Loss: 633645696.0000, Train: 89.35%, Valid: 86.73%, Test: 86.69%\n",
            "Epoch: 105, Loss: 617939072.0000, Train: 89.35%, Valid: 86.73%, Test: 86.69%\n",
            "Epoch: 110, Loss: 603457152.0000, Train: 89.41%, Valid: 86.79%, Test: 86.75%\n",
            "Epoch: 115, Loss: 590839296.0000, Train: 89.42%, Valid: 86.85%, Test: 86.82%\n",
            "Epoch: 120, Loss: 578731840.0000, Train: 89.38%, Valid: 86.81%, Test: 86.84%\n",
            "Epoch: 125, Loss: 565709952.0000, Train: 89.44%, Valid: 86.81%, Test: 86.80%\n",
            "Epoch: 130, Loss: 550991296.0000, Train: 89.43%, Valid: 86.93%, Test: 86.84%\n",
            "Epoch: 135, Loss: 535780640.0000, Train: 89.39%, Valid: 86.91%, Test: 86.94%\n",
            "Epoch: 140, Loss: 522389632.0000, Train: 89.51%, Valid: 86.89%, Test: 86.82%\n",
            "Epoch: 145, Loss: 510725856.0000, Train: 89.51%, Valid: 86.81%, Test: 86.86%\n",
            "Epoch: 150, Loss: 499641728.0000, Train: 89.60%, Valid: 86.83%, Test: 86.84%\n",
            "Epoch: 155, Loss: 488803328.0000, Train: 89.58%, Valid: 86.95%, Test: 86.88%\n",
            "Epoch: 160, Loss: 478769856.0000, Train: 89.60%, Valid: 86.95%, Test: 87.04%\n",
            "Epoch: 165, Loss: 469199616.0000, Train: 89.59%, Valid: 86.98%, Test: 87.00%\n",
            "Epoch: 170, Loss: 458976256.0000, Train: 89.56%, Valid: 86.91%, Test: 86.98%\n",
            "Epoch: 175, Loss: 447513792.0000, Train: 89.57%, Valid: 86.81%, Test: 87.00%\n",
            "Epoch: 180, Loss: 436323584.0000, Train: 89.56%, Valid: 86.73%, Test: 87.04%\n",
            "Epoch: 185, Loss: 426182912.0000, Train: 89.56%, Valid: 86.71%, Test: 87.06%\n",
            "Epoch: 190, Loss: 416495296.0000, Train: 89.65%, Valid: 86.71%, Test: 87.12%\n",
            "Epoch: 195, Loss: 407107456.0000, Train: 89.59%, Valid: 86.67%, Test: 87.20%\n",
            "Run 04:\n",
            "Highest Train: 89.67\n",
            "Highest Valid: 87.04\n",
            "Highest Test: 87.20\n",
            "Chosen epoch: 164\n",
            "Final Train: 89.60\n",
            "Final Test: 86.96\n",
            "Epoch: 00, Loss: 6307809280.0000, Train: 31.14%, Valid: 32.20%, Test: 31.68%\n",
            "Epoch: 05, Loss: 2059269376.0000, Train: 33.91%, Valid: 34.35%, Test: 33.08%\n",
            "Epoch: 10, Loss: 1437769472.0000, Train: 43.30%, Valid: 43.44%, Test: 42.05%\n",
            "Epoch: 15, Loss: 1185809152.0000, Train: 62.54%, Valid: 62.00%, Test: 61.10%\n",
            "Epoch: 20, Loss: 1045061376.0000, Train: 77.34%, Valid: 77.48%, Test: 76.57%\n",
            "Epoch: 25, Loss: 945488384.0000, Train: 84.49%, Valid: 82.98%, Test: 83.61%\n",
            "Epoch: 30, Loss: 870518208.0000, Train: 86.28%, Valid: 84.48%, Test: 85.15%\n",
            "Epoch: 35, Loss: 813313664.0000, Train: 86.90%, Valid: 85.35%, Test: 85.64%\n",
            "Epoch: 40, Loss: 769463168.0000, Train: 87.49%, Valid: 85.80%, Test: 86.25%\n",
            "Epoch: 45, Loss: 736790912.0000, Train: 87.96%, Valid: 85.90%, Test: 86.80%\n",
            "Epoch: 50, Loss: 710478144.0000, Train: 88.20%, Valid: 86.49%, Test: 87.12%\n",
            "Epoch: 55, Loss: 689402368.0000, Train: 88.39%, Valid: 86.69%, Test: 87.24%\n",
            "Epoch: 60, Loss: 671978880.0000, Train: 88.58%, Valid: 86.69%, Test: 87.24%\n",
            "Epoch: 65, Loss: 656791680.0000, Train: 88.73%, Valid: 86.71%, Test: 87.46%\n",
            "Epoch: 70, Loss: 642303424.0000, Train: 88.82%, Valid: 86.69%, Test: 87.57%\n",
            "Epoch: 75, Loss: 627733760.0000, Train: 88.98%, Valid: 86.87%, Test: 87.81%\n",
            "Epoch: 80, Loss: 612738880.0000, Train: 89.05%, Valid: 87.00%, Test: 87.99%\n",
            "Epoch: 85, Loss: 597810560.0000, Train: 89.13%, Valid: 86.91%, Test: 87.85%\n",
            "Epoch: 90, Loss: 583410432.0000, Train: 89.25%, Valid: 86.91%, Test: 87.75%\n",
            "Epoch: 95, Loss: 569961600.0000, Train: 89.25%, Valid: 87.00%, Test: 87.65%\n",
            "Epoch: 100, Loss: 557307648.0000, Train: 89.30%, Valid: 86.95%, Test: 87.63%\n",
            "Epoch: 105, Loss: 545244928.0000, Train: 89.39%, Valid: 87.00%, Test: 87.69%\n",
            "Epoch: 110, Loss: 533701504.0000, Train: 89.42%, Valid: 86.91%, Test: 87.73%\n",
            "Epoch: 115, Loss: 522700576.0000, Train: 89.48%, Valid: 87.04%, Test: 87.57%\n",
            "Epoch: 120, Loss: 511820352.0000, Train: 89.55%, Valid: 87.00%, Test: 87.51%\n",
            "Epoch: 125, Loss: 501200800.0000, Train: 89.56%, Valid: 86.91%, Test: 87.63%\n",
            "Epoch: 130, Loss: 490950368.0000, Train: 89.61%, Valid: 86.71%, Test: 87.59%\n",
            "Epoch: 135, Loss: 481109696.0000, Train: 89.61%, Valid: 86.73%, Test: 87.59%\n",
            "Epoch: 140, Loss: 471420224.0000, Train: 89.60%, Valid: 86.83%, Test: 87.63%\n",
            "Epoch: 145, Loss: 462214912.0000, Train: 89.61%, Valid: 86.89%, Test: 87.65%\n",
            "Epoch: 150, Loss: 453316800.0000, Train: 89.61%, Valid: 86.81%, Test: 87.67%\n",
            "Epoch: 155, Loss: 444810688.0000, Train: 89.62%, Valid: 86.83%, Test: 87.59%\n",
            "Epoch: 160, Loss: 436482944.0000, Train: 89.54%, Valid: 86.79%, Test: 87.63%\n",
            "Epoch: 165, Loss: 428164064.0000, Train: 89.66%, Valid: 86.79%, Test: 87.61%\n",
            "Epoch: 170, Loss: 419286048.0000, Train: 89.68%, Valid: 86.79%, Test: 87.61%\n",
            "Epoch: 175, Loss: 409976960.0000, Train: 89.71%, Valid: 86.65%, Test: 87.57%\n",
            "Epoch: 180, Loss: 400658944.0000, Train: 89.72%, Valid: 86.65%, Test: 87.61%\n",
            "Epoch: 185, Loss: 391457536.0000, Train: 89.64%, Valid: 86.67%, Test: 87.71%\n",
            "Epoch: 190, Loss: 382664736.0000, Train: 89.57%, Valid: 86.71%, Test: 87.73%\n",
            "Epoch: 195, Loss: 373940864.0000, Train: 89.64%, Valid: 86.71%, Test: 87.69%\n",
            "Run 05:\n",
            "Highest Train: 89.75\n",
            "Highest Valid: 87.04\n",
            "Highest Test: 87.99\n",
            "Chosen epoch: 92\n",
            "Final Train: 89.26\n",
            "Final Test: 87.75\n",
            "All runs:\n",
            "Highest Train: 90.03 ± 0.50\n",
            "Highest Test: 87.77 ± 0.35\n",
            "Highest Valid: 87.21 ± 0.27\n",
            "  Final Train: 89.69 ± 0.34\n",
            "   Final Test: 87.52 ± 0.34\n",
            "Saving results to logs/pubmed_edge.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cora\n"
      ],
      "metadata": {
        "id": "QpZnQ-33Eqy3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pre-train Setting"
      ],
      "metadata": {
        "id": "M9I3DWddEu8O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 GKD/main.py --dataset cora --rand_split --use_bn --base_model gcn --mode pretrain --dist_mode no --save_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwyXeQMaFANV",
        "outputId": "bf39d00d-3410-48e9-8248-1465e30ee58e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(data_dir='data', dataset='cora', sub_dataset='', cpu=False, seed=42, train_prop=0.5, valid_prop=0.25, protocol='semi', rand_split=True, metric='acc', runs=5, epochs=200, hidden_channels=32, num_layers=3, gat_heads=8, out_heads=1, hops=1, lp_alpha=0.1, gpr_alpha=0.1, jk_type='max', directed=False, num_mlp_layers=1, display_step=5, cached=False, print_prop=False, priv_type='edge', priv_ratio=0.5, save_model=True, save_name='gcn', log_name='none', base_model='gcn', not_load_teacher=False, mode='pretrain', dist_mode='no', weight_decay=0.05, dropout=0.0, lr=0.01, use_bn=True, use_batch=False, batch_size=2048, oracle=False, device=0, alpha=0.5, delta=0.1, use_kd=False, beta=0.0, tau=1.0, kernel='sigmoid', t=1.0, include_last=False, s=2, m=1, lr2=0.001, sim='l2', ker_norm=False)\n",
            "cuda:0\n",
            "cora\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
            "Processing...\n",
            "Done!\n",
            "Num nodes: 2708\n",
            "torch.Size([2708, 1])\n",
            "num nodes 2708 | num classes 7 | num node feats 1433\n",
            "MODEL: GeoDist(\n",
            "  (k): Kernel(\n",
            "    (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  )\n",
            "  (teacher_gnn): ModuleList(\n",
            "    (0): Linear(in_features=1433, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (student_gnn): ModuleList(\n",
            "    (0): Linear(in_features=1433, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  (bns2d): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            ")\n",
            "Epoch: 00, Loss: 2.1624, Train: 72.16%, Valid: 67.36%, Test: 62.78%\n",
            "Epoch: 05, Loss: 0.4682, Train: 90.77%, Valid: 82.57%, Test: 84.34%\n",
            "Epoch: 10, Loss: 0.3759, Train: 92.02%, Valid: 84.19%, Test: 86.26%\n",
            "Epoch: 15, Loss: 0.3395, Train: 92.76%, Valid: 85.82%, Test: 85.82%\n",
            "Epoch: 20, Loss: 0.3102, Train: 93.80%, Valid: 85.08%, Test: 85.38%\n",
            "Epoch: 25, Loss: 0.2719, Train: 94.76%, Valid: 84.49%, Test: 84.64%\n",
            "Epoch: 30, Loss: 0.2299, Train: 95.86%, Valid: 84.05%, Test: 84.34%\n",
            "Epoch: 35, Loss: 0.1923, Train: 97.05%, Valid: 83.75%, Test: 80.65%\n",
            "Epoch: 40, Loss: 0.2072, Train: 96.68%, Valid: 82.42%, Test: 82.13%\n",
            "Epoch: 45, Loss: 0.1700, Train: 97.34%, Valid: 82.72%, Test: 81.09%\n",
            "Epoch: 50, Loss: 0.1510, Train: 98.01%, Valid: 82.87%, Test: 79.76%\n",
            "Epoch: 55, Loss: 0.2055, Train: 97.05%, Valid: 84.05%, Test: 81.98%\n",
            "Epoch: 60, Loss: 0.1682, Train: 97.86%, Valid: 82.57%, Test: 79.76%\n",
            "Epoch: 65, Loss: 0.1495, Train: 97.93%, Valid: 82.57%, Test: 78.73%\n",
            "Epoch: 70, Loss: 0.1640, Train: 97.19%, Valid: 81.24%, Test: 78.43%\n",
            "Epoch: 75, Loss: 0.1638, Train: 97.27%, Valid: 83.31%, Test: 80.35%\n",
            "Epoch: 80, Loss: 0.1413, Train: 98.38%, Valid: 82.42%, Test: 78.14%\n",
            "Epoch: 85, Loss: 0.1446, Train: 98.38%, Valid: 82.27%, Test: 78.14%\n",
            "Epoch: 90, Loss: 0.1675, Train: 96.97%, Valid: 82.72%, Test: 79.76%\n",
            "Epoch: 95, Loss: 0.1662, Train: 97.86%, Valid: 81.39%, Test: 78.43%\n",
            "Epoch: 100, Loss: 0.1425, Train: 98.45%, Valid: 81.54%, Test: 76.96%\n",
            "Epoch: 105, Loss: 0.1460, Train: 97.49%, Valid: 80.35%, Test: 77.10%\n",
            "Epoch: 110, Loss: 0.1661, Train: 97.27%, Valid: 81.39%, Test: 78.14%\n",
            "Epoch: 115, Loss: 0.1458, Train: 98.45%, Valid: 81.24%, Test: 77.99%\n",
            "Epoch: 120, Loss: 0.1359, Train: 98.15%, Valid: 80.65%, Test: 76.96%\n",
            "Epoch: 125, Loss: 0.1704, Train: 96.90%, Valid: 80.06%, Test: 77.99%\n",
            "Epoch: 130, Loss: 0.1507, Train: 98.15%, Valid: 81.54%, Test: 77.55%\n",
            "Epoch: 135, Loss: 0.1326, Train: 98.45%, Valid: 80.35%, Test: 76.37%\n",
            "Epoch: 140, Loss: 0.1445, Train: 97.34%, Valid: 79.91%, Test: 76.22%\n",
            "Epoch: 145, Loss: 0.1917, Train: 96.38%, Valid: 83.16%, Test: 80.21%\n",
            "Epoch: 150, Loss: 0.1530, Train: 97.86%, Valid: 81.68%, Test: 79.03%\n",
            "Epoch: 155, Loss: 0.1338, Train: 98.23%, Valid: 80.50%, Test: 75.92%\n",
            "Epoch: 160, Loss: 0.1484, Train: 96.01%, Valid: 81.54%, Test: 76.66%\n",
            "Epoch: 165, Loss: 0.1730, Train: 97.27%, Valid: 80.95%, Test: 77.99%\n",
            "Epoch: 170, Loss: 0.1448, Train: 98.08%, Valid: 81.68%, Test: 77.55%\n",
            "Epoch: 175, Loss: 0.1316, Train: 98.01%, Valid: 81.68%, Test: 76.07%\n",
            "Epoch: 180, Loss: 0.1368, Train: 97.86%, Valid: 80.80%, Test: 74.74%\n",
            "Epoch: 185, Loss: 0.1807, Train: 97.12%, Valid: 81.98%, Test: 79.76%\n",
            "Epoch: 190, Loss: 0.1493, Train: 98.01%, Valid: 82.57%, Test: 79.17%\n",
            "Epoch: 195, Loss: 0.1355, Train: 98.23%, Valid: 81.68%, Test: 77.25%\n",
            "Run 01:\n",
            "Highest Train: 98.89\n",
            "Highest Valid: 86.26\n",
            "Highest Test: 86.56\n",
            "Chosen epoch: 19\n",
            "Final Train: 93.43\n",
            "Final Test: 85.67\n",
            "Epoch: 00, Loss: 2.7245, Train: 66.03%, Valid: 63.52%, Test: 54.80%\n",
            "Epoch: 05, Loss: 0.4976, Train: 91.14%, Valid: 84.49%, Test: 82.72%\n",
            "Epoch: 10, Loss: 0.3880, Train: 92.10%, Valid: 85.08%, Test: 86.12%\n",
            "Epoch: 15, Loss: 0.3468, Train: 92.91%, Valid: 85.08%, Test: 85.67%\n",
            "Epoch: 20, Loss: 0.3203, Train: 93.43%, Valid: 84.64%, Test: 85.23%\n",
            "Epoch: 25, Loss: 0.2836, Train: 94.83%, Valid: 84.93%, Test: 84.49%\n",
            "Epoch: 30, Loss: 0.2396, Train: 95.72%, Valid: 84.34%, Test: 81.83%\n",
            "Epoch: 35, Loss: 0.2016, Train: 96.09%, Valid: 83.16%, Test: 79.17%\n",
            "Epoch: 40, Loss: 0.1868, Train: 97.12%, Valid: 84.49%, Test: 79.47%\n",
            "Epoch: 45, Loss: 0.1648, Train: 97.93%, Valid: 81.54%, Test: 76.07%\n",
            "Epoch: 50, Loss: 0.2032, Train: 96.45%, Valid: 82.13%, Test: 78.43%\n",
            "Epoch: 55, Loss: 0.1751, Train: 97.42%, Valid: 82.57%, Test: 78.73%\n",
            "Epoch: 60, Loss: 0.1513, Train: 98.08%, Valid: 80.65%, Test: 75.92%\n",
            "Epoch: 65, Loss: 0.1724, Train: 97.27%, Valid: 82.42%, Test: 75.63%\n",
            "Epoch: 70, Loss: 0.1713, Train: 97.05%, Valid: 81.39%, Test: 75.33%\n",
            "Epoch: 75, Loss: 0.1580, Train: 97.49%, Valid: 81.54%, Test: 75.78%\n",
            "Epoch: 80, Loss: 0.1462, Train: 98.01%, Valid: 81.68%, Test: 74.74%\n",
            "Epoch: 85, Loss: 0.1574, Train: 97.71%, Valid: 81.68%, Test: 75.48%\n",
            "Epoch: 90, Loss: 0.1533, Train: 98.08%, Valid: 80.50%, Test: 75.33%\n",
            "Epoch: 95, Loss: 0.1550, Train: 98.15%, Valid: 81.98%, Test: 75.63%\n",
            "Epoch: 100, Loss: 0.1371, Train: 98.67%, Valid: 80.80%, Test: 74.45%\n",
            "Epoch: 105, Loss: 0.1769, Train: 97.42%, Valid: 83.31%, Test: 77.25%\n",
            "Epoch: 110, Loss: 0.1519, Train: 97.64%, Valid: 81.39%, Test: 76.66%\n",
            "Epoch: 115, Loss: 0.1394, Train: 98.01%, Valid: 80.95%, Test: 74.89%\n",
            "Epoch: 120, Loss: 0.1787, Train: 96.23%, Valid: 83.01%, Test: 74.59%\n",
            "Epoch: 125, Loss: 0.1728, Train: 97.34%, Valid: 82.13%, Test: 77.70%\n",
            "Epoch: 130, Loss: 0.1482, Train: 98.23%, Valid: 80.06%, Test: 76.51%\n",
            "Epoch: 135, Loss: 0.1333, Train: 98.74%, Valid: 81.39%, Test: 73.26%\n",
            "Epoch: 140, Loss: 0.2010, Train: 95.64%, Valid: 82.57%, Test: 78.58%\n",
            "Epoch: 145, Loss: 0.1801, Train: 97.05%, Valid: 82.42%, Test: 76.96%\n",
            "Epoch: 150, Loss: 0.1514, Train: 97.64%, Valid: 81.24%, Test: 75.78%\n",
            "Epoch: 155, Loss: 0.1398, Train: 98.23%, Valid: 81.68%, Test: 74.89%\n",
            "Epoch: 160, Loss: 0.1518, Train: 97.86%, Valid: 80.95%, Test: 74.15%\n",
            "Epoch: 165, Loss: 0.1649, Train: 96.53%, Valid: 81.68%, Test: 75.04%\n",
            "Epoch: 170, Loss: 0.1573, Train: 97.19%, Valid: 81.24%, Test: 74.45%\n",
            "Epoch: 175, Loss: 0.1517, Train: 98.30%, Valid: 80.95%, Test: 75.78%\n",
            "Epoch: 180, Loss: 0.1434, Train: 98.30%, Valid: 80.95%, Test: 74.45%\n",
            "Epoch: 185, Loss: 0.2006, Train: 96.31%, Valid: 81.98%, Test: 73.56%\n",
            "Epoch: 190, Loss: 0.1747, Train: 97.19%, Valid: 81.83%, Test: 76.22%\n",
            "Epoch: 195, Loss: 0.1451, Train: 97.93%, Valid: 81.39%, Test: 76.96%\n",
            "Run 02:\n",
            "Highest Train: 99.04\n",
            "Highest Valid: 85.23\n",
            "Highest Test: 86.26\n",
            "Chosen epoch: 14\n",
            "Final Train: 92.54\n",
            "Final Test: 85.97\n",
            "Epoch: 00, Loss: 2.3012, Train: 74.22%, Valid: 68.98%, Test: 66.62%\n",
            "Epoch: 05, Loss: 0.4808, Train: 91.14%, Valid: 84.49%, Test: 85.38%\n",
            "Epoch: 10, Loss: 0.3755, Train: 92.32%, Valid: 85.67%, Test: 86.56%\n",
            "Epoch: 15, Loss: 0.3314, Train: 92.98%, Valid: 85.08%, Test: 85.82%\n",
            "Epoch: 20, Loss: 0.2972, Train: 94.09%, Valid: 84.93%, Test: 86.41%\n",
            "Epoch: 25, Loss: 0.2568, Train: 95.05%, Valid: 84.64%, Test: 84.19%\n",
            "Epoch: 30, Loss: 0.2155, Train: 96.23%, Valid: 84.79%, Test: 82.87%\n",
            "Epoch: 35, Loss: 0.1924, Train: 96.38%, Valid: 82.72%, Test: 81.09%\n",
            "Epoch: 40, Loss: 0.1827, Train: 97.27%, Valid: 83.60%, Test: 79.76%\n",
            "Epoch: 45, Loss: 0.1651, Train: 97.19%, Valid: 83.01%, Test: 78.43%\n",
            "Epoch: 50, Loss: 0.1748, Train: 97.19%, Valid: 83.01%, Test: 79.32%\n",
            "Epoch: 55, Loss: 0.1595, Train: 97.78%, Valid: 82.72%, Test: 78.73%\n",
            "Epoch: 60, Loss: 0.1722, Train: 96.31%, Valid: 81.68%, Test: 77.40%\n",
            "Epoch: 65, Loss: 0.1619, Train: 97.56%, Valid: 82.13%, Test: 77.99%\n",
            "Epoch: 70, Loss: 0.1534, Train: 97.49%, Valid: 82.13%, Test: 76.96%\n",
            "Epoch: 75, Loss: 0.1483, Train: 97.49%, Valid: 80.80%, Test: 75.48%\n",
            "Epoch: 80, Loss: 0.1647, Train: 97.27%, Valid: 80.80%, Test: 77.84%\n",
            "Epoch: 85, Loss: 0.1731, Train: 97.42%, Valid: 83.46%, Test: 76.96%\n",
            "Epoch: 90, Loss: 0.1522, Train: 97.64%, Valid: 80.80%, Test: 77.25%\n",
            "Epoch: 95, Loss: 0.1538, Train: 97.86%, Valid: 81.68%, Test: 76.37%\n",
            "Epoch: 100, Loss: 0.1411, Train: 97.86%, Valid: 82.13%, Test: 77.10%\n",
            "Epoch: 105, Loss: 0.1316, Train: 98.23%, Valid: 80.95%, Test: 75.18%\n",
            "Epoch: 110, Loss: 0.1852, Train: 97.05%, Valid: 83.01%, Test: 78.58%\n",
            "Epoch: 115, Loss: 0.1562, Train: 97.78%, Valid: 79.62%, Test: 75.63%\n",
            "Epoch: 120, Loss: 0.1384, Train: 97.64%, Valid: 80.95%, Test: 75.33%\n",
            "Epoch: 125, Loss: 0.1392, Train: 98.45%, Valid: 81.39%, Test: 75.18%\n",
            "Epoch: 130, Loss: 0.1490, Train: 97.56%, Valid: 79.76%, Test: 75.92%\n",
            "Epoch: 135, Loss: 0.1586, Train: 97.05%, Valid: 81.39%, Test: 77.10%\n",
            "Epoch: 140, Loss: 0.1382, Train: 98.15%, Valid: 80.06%, Test: 76.07%\n",
            "Epoch: 145, Loss: 0.1340, Train: 98.01%, Valid: 81.39%, Test: 72.82%\n",
            "Epoch: 150, Loss: 0.1773, Train: 96.16%, Valid: 83.01%, Test: 77.25%\n",
            "Epoch: 155, Loss: 0.1565, Train: 97.64%, Valid: 81.98%, Test: 75.04%\n",
            "Epoch: 160, Loss: 0.1337, Train: 98.30%, Valid: 81.83%, Test: 73.86%\n",
            "Epoch: 165, Loss: 0.1542, Train: 96.90%, Valid: 81.54%, Test: 75.48%\n",
            "Epoch: 170, Loss: 0.1573, Train: 98.01%, Valid: 80.50%, Test: 76.07%\n",
            "Epoch: 175, Loss: 0.1363, Train: 98.01%, Valid: 81.54%, Test: 73.12%\n",
            "Epoch: 180, Loss: 0.1357, Train: 98.01%, Valid: 80.95%, Test: 73.86%\n",
            "Epoch: 185, Loss: 0.1405, Train: 97.64%, Valid: 80.80%, Test: 72.67%\n",
            "Epoch: 190, Loss: 0.1520, Train: 98.01%, Valid: 81.24%, Test: 76.07%\n",
            "Epoch: 195, Loss: 0.1313, Train: 98.30%, Valid: 81.68%, Test: 73.41%\n",
            "Run 03:\n",
            "Highest Train: 98.74\n",
            "Highest Valid: 85.82\n",
            "Highest Test: 86.71\n",
            "Chosen epoch: 13\n",
            "Final Train: 92.32\n",
            "Final Test: 85.97\n",
            "Epoch: 00, Loss: 2.2047, Train: 78.43%, Valid: 72.82%, Test: 68.24%\n",
            "Epoch: 05, Loss: 0.4803, Train: 91.43%, Valid: 84.34%, Test: 84.64%\n",
            "Epoch: 10, Loss: 0.3830, Train: 92.61%, Valid: 84.79%, Test: 85.67%\n",
            "Epoch: 15, Loss: 0.3388, Train: 93.21%, Valid: 85.38%, Test: 85.82%\n",
            "Epoch: 20, Loss: 0.2988, Train: 94.24%, Valid: 85.08%, Test: 84.05%\n",
            "Epoch: 25, Loss: 0.2512, Train: 95.49%, Valid: 83.90%, Test: 82.27%\n",
            "Epoch: 30, Loss: 0.2049, Train: 96.45%, Valid: 84.19%, Test: 80.80%\n",
            "Epoch: 35, Loss: 0.1853, Train: 96.97%, Valid: 84.05%, Test: 80.35%\n",
            "Epoch: 40, Loss: 0.1698, Train: 97.42%, Valid: 82.13%, Test: 77.84%\n",
            "Epoch: 45, Loss: 0.1721, Train: 97.27%, Valid: 82.72%, Test: 77.10%\n",
            "Epoch: 50, Loss: 0.1618, Train: 96.82%, Valid: 81.83%, Test: 77.25%\n",
            "Epoch: 55, Loss: 0.1645, Train: 97.56%, Valid: 81.83%, Test: 77.40%\n",
            "Epoch: 60, Loss: 0.1684, Train: 96.53%, Valid: 82.13%, Test: 77.10%\n",
            "Epoch: 65, Loss: 0.1639, Train: 97.78%, Valid: 82.13%, Test: 76.96%\n",
            "Epoch: 70, Loss: 0.1518, Train: 97.56%, Valid: 80.50%, Test: 76.81%\n",
            "Epoch: 75, Loss: 0.1446, Train: 97.78%, Valid: 81.09%, Test: 77.25%\n",
            "Epoch: 80, Loss: 0.1559, Train: 97.78%, Valid: 80.21%, Test: 76.81%\n",
            "Epoch: 85, Loss: 0.1567, Train: 97.86%, Valid: 81.39%, Test: 76.51%\n",
            "Epoch: 90, Loss: 0.1416, Train: 98.08%, Valid: 83.01%, Test: 76.51%\n",
            "Epoch: 95, Loss: 0.1608, Train: 97.64%, Valid: 80.80%, Test: 76.81%\n",
            "Epoch: 100, Loss: 0.1584, Train: 98.15%, Valid: 82.13%, Test: 76.96%\n",
            "Epoch: 105, Loss: 0.1349, Train: 98.38%, Valid: 81.09%, Test: 75.63%\n",
            "Epoch: 110, Loss: 0.1379, Train: 98.08%, Valid: 80.95%, Test: 73.56%\n",
            "Epoch: 115, Loss: 0.1548, Train: 97.34%, Valid: 81.24%, Test: 75.48%\n",
            "Epoch: 120, Loss: 0.1511, Train: 98.15%, Valid: 81.24%, Test: 76.51%\n",
            "Epoch: 125, Loss: 0.1384, Train: 98.38%, Valid: 81.24%, Test: 74.45%\n",
            "Epoch: 130, Loss: 0.1499, Train: 98.01%, Valid: 81.09%, Test: 73.86%\n",
            "Epoch: 135, Loss: 0.1455, Train: 97.71%, Valid: 82.72%, Test: 75.78%\n",
            "Epoch: 140, Loss: 0.1564, Train: 97.86%, Valid: 81.83%, Test: 76.51%\n",
            "Epoch: 145, Loss: 0.1409, Train: 97.93%, Valid: 81.24%, Test: 75.78%\n",
            "Epoch: 150, Loss: 0.1354, Train: 98.52%, Valid: 81.39%, Test: 74.15%\n",
            "Epoch: 155, Loss: 0.1434, Train: 97.64%, Valid: 80.80%, Test: 72.67%\n",
            "Epoch: 160, Loss: 0.1625, Train: 97.78%, Valid: 80.65%, Test: 74.30%\n",
            "Epoch: 165, Loss: 0.1396, Train: 98.23%, Valid: 82.13%, Test: 74.45%\n",
            "Epoch: 170, Loss: 0.1351, Train: 97.78%, Valid: 79.47%, Test: 71.34%\n",
            "Epoch: 175, Loss: 0.1628, Train: 97.64%, Valid: 82.87%, Test: 75.04%\n",
            "Epoch: 180, Loss: 0.1510, Train: 98.01%, Valid: 81.09%, Test: 75.33%\n",
            "Epoch: 185, Loss: 0.1336, Train: 97.86%, Valid: 81.39%, Test: 74.00%\n",
            "Epoch: 190, Loss: 0.1360, Train: 98.01%, Valid: 81.09%, Test: 74.15%\n",
            "Epoch: 195, Loss: 0.1354, Train: 98.23%, Valid: 80.06%, Test: 73.26%\n",
            "Run 04:\n",
            "Highest Train: 98.67\n",
            "Highest Valid: 85.67\n",
            "Highest Test: 86.12\n",
            "Chosen epoch: 20\n",
            "Final Train: 94.02\n",
            "Final Test: 84.64\n",
            "Epoch: 00, Loss: 2.2025, Train: 79.84%, Valid: 75.92%, Test: 73.12%\n",
            "Epoch: 05, Loss: 0.4655, Train: 91.14%, Valid: 84.19%, Test: 86.12%\n",
            "Epoch: 10, Loss: 0.3633, Train: 92.98%, Valid: 84.79%, Test: 86.26%\n",
            "Epoch: 15, Loss: 0.3239, Train: 93.35%, Valid: 84.49%, Test: 85.52%\n",
            "Epoch: 20, Loss: 0.2948, Train: 94.61%, Valid: 84.64%, Test: 85.38%\n",
            "Epoch: 25, Loss: 0.2567, Train: 95.49%, Valid: 84.49%, Test: 83.16%\n",
            "Epoch: 30, Loss: 0.2157, Train: 96.90%, Valid: 83.75%, Test: 81.68%\n",
            "Epoch: 35, Loss: 0.2073, Train: 96.01%, Valid: 83.31%, Test: 80.95%\n",
            "Epoch: 40, Loss: 0.1784, Train: 97.49%, Valid: 82.72%, Test: 79.17%\n",
            "Epoch: 45, Loss: 0.1695, Train: 97.71%, Valid: 81.98%, Test: 79.76%\n",
            "Epoch: 50, Loss: 0.2047, Train: 96.31%, Valid: 84.05%, Test: 79.91%\n",
            "Epoch: 55, Loss: 0.1723, Train: 97.64%, Valid: 83.46%, Test: 77.40%\n",
            "Epoch: 60, Loss: 0.1509, Train: 98.38%, Valid: 81.83%, Test: 77.70%\n",
            "Epoch: 65, Loss: 0.1793, Train: 97.27%, Valid: 80.95%, Test: 76.66%\n",
            "Epoch: 70, Loss: 0.1601, Train: 97.64%, Valid: 81.83%, Test: 77.70%\n",
            "Epoch: 75, Loss: 0.1453, Train: 98.67%, Valid: 81.39%, Test: 76.22%\n",
            "Epoch: 80, Loss: 0.1488, Train: 98.30%, Valid: 81.09%, Test: 75.63%\n",
            "Epoch: 85, Loss: 0.1694, Train: 97.05%, Valid: 81.83%, Test: 77.10%\n",
            "Epoch: 90, Loss: 0.1433, Train: 98.30%, Valid: 81.54%, Test: 76.96%\n",
            "Epoch: 95, Loss: 0.1341, Train: 98.08%, Valid: 81.09%, Test: 74.45%\n",
            "Epoch: 100, Loss: 0.1520, Train: 97.86%, Valid: 81.24%, Test: 74.89%\n",
            "Epoch: 105, Loss: 0.1560, Train: 97.86%, Valid: 81.98%, Test: 76.51%\n",
            "Epoch: 110, Loss: 0.1423, Train: 98.30%, Valid: 81.09%, Test: 74.15%\n",
            "Epoch: 115, Loss: 0.1522, Train: 96.97%, Valid: 79.91%, Test: 74.15%\n",
            "Epoch: 120, Loss: 0.1553, Train: 97.78%, Valid: 81.83%, Test: 77.10%\n",
            "Epoch: 125, Loss: 0.1349, Train: 98.45%, Valid: 80.06%, Test: 75.18%\n",
            "Epoch: 130, Loss: 0.1393, Train: 97.42%, Valid: 80.50%, Test: 73.26%\n",
            "Epoch: 135, Loss: 0.1536, Train: 97.49%, Valid: 81.54%, Test: 74.74%\n",
            "Epoch: 140, Loss: 0.1342, Train: 98.08%, Valid: 81.09%, Test: 74.30%\n",
            "Epoch: 145, Loss: 0.1375, Train: 98.30%, Valid: 81.54%, Test: 73.71%\n",
            "Epoch: 150, Loss: 0.1387, Train: 98.15%, Valid: 81.09%, Test: 75.63%\n",
            "Epoch: 155, Loss: 0.1574, Train: 97.42%, Valid: 82.42%, Test: 72.97%\n",
            "Epoch: 160, Loss: 0.1492, Train: 97.78%, Valid: 80.65%, Test: 75.92%\n",
            "Epoch: 165, Loss: 0.1382, Train: 98.74%, Valid: 81.09%, Test: 76.07%\n",
            "Epoch: 170, Loss: 0.1512, Train: 97.49%, Valid: 81.54%, Test: 73.26%\n",
            "Epoch: 175, Loss: 0.1423, Train: 98.08%, Valid: 83.01%, Test: 76.37%\n",
            "Epoch: 180, Loss: 0.1376, Train: 98.82%, Valid: 80.35%, Test: 74.30%\n",
            "Epoch: 185, Loss: 0.1541, Train: 97.27%, Valid: 80.65%, Test: 72.38%\n",
            "Epoch: 190, Loss: 0.1533, Train: 98.08%, Valid: 81.09%, Test: 74.45%\n",
            "Epoch: 195, Loss: 0.1346, Train: 98.60%, Valid: 81.68%, Test: 74.00%\n",
            "Run 05:\n",
            "Highest Train: 99.04\n",
            "Highest Valid: 85.08\n",
            "Highest Test: 86.41\n",
            "Chosen epoch: 22\n",
            "Final Train: 94.61\n",
            "Final Test: 85.23\n",
            "All runs:\n",
            "Highest Train: 98.88 ± 0.17\n",
            "Highest Test: 86.41 ± 0.23\n",
            "Highest Valid: 85.61 ± 0.47\n",
            "  Final Train: 93.38 ± 0.97\n",
            "   Final Test: 85.49 ± 0.57\n",
            "Saving results to logs/cora_edge.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Edge Aware Setting"
      ],
      "metadata": {
        "id": "xpyzuOx7F_XZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 GKD/main.py --dataset cora --rand_split --use_bn --base_model gcn --mode train --priv_type edge --dist_mode gkd --kernel sigmoid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HqL1jNjGCQJ",
        "outputId": "3f9d5016-3a08-4d4a-eaa2-c105170ff9e8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(data_dir='data', dataset='cora', sub_dataset='', cpu=False, seed=42, train_prop=0.5, valid_prop=0.25, protocol='semi', rand_split=True, metric='acc', runs=5, epochs=200, hidden_channels=32, num_layers=3, gat_heads=8, out_heads=1, hops=1, lp_alpha=0.1, gpr_alpha=0.1, jk_type='max', directed=False, num_mlp_layers=1, display_step=5, cached=False, print_prop=False, priv_type='edge', priv_ratio=0.5, save_model=False, save_name='gcn', log_name='none', base_model='gcn', not_load_teacher=False, mode='train', dist_mode='gkd', weight_decay=0.05, dropout=0.0, lr=0.01, use_bn=True, use_batch=False, batch_size=2048, oracle=False, device=0, alpha=0.5, delta=0.1, use_kd=False, beta=0.0, tau=1.0, kernel='sigmoid', t=1.0, include_last=False, s=2, m=1, lr2=0.001, sim='l2', ker_norm=False)\n",
            "cuda:0\n",
            "cora\n",
            "Num nodes: 2708\n",
            "torch.Size([2708, 1])\n",
            "num nodes 2708 | num classes 7 | num node feats 1433\n",
            "MODEL: GeoDist(\n",
            "  (k): Kernel(\n",
            "    (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  )\n",
            "  (teacher_gnn): ModuleList(\n",
            "    (0): Linear(in_features=1433, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (student_gnn): ModuleList(\n",
            "    (0): Linear(in_features=1433, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  (bns2d): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            ")\n",
            "Epoch: 00, Loss: 580697.3750, Train: 32.57%, Valid: 29.84%, Test: 26.88%\n",
            "Epoch: 05, Loss: 145588.3125, Train: 38.63%, Valid: 34.27%, Test: 38.55%\n",
            "Epoch: 10, Loss: 112488.3047, Train: 56.13%, Valid: 51.99%, Test: 54.80%\n",
            "Epoch: 15, Loss: 94836.8984, Train: 64.03%, Valid: 60.12%, Test: 64.70%\n",
            "Epoch: 20, Loss: 84084.3594, Train: 69.94%, Valid: 66.17%, Test: 71.20%\n",
            "Epoch: 25, Loss: 76261.1719, Train: 78.29%, Valid: 74.30%, Test: 78.43%\n",
            "Epoch: 30, Loss: 70379.8750, Train: 84.79%, Valid: 80.50%, Test: 84.49%\n",
            "Epoch: 35, Loss: 65676.4609, Train: 87.15%, Valid: 82.13%, Test: 87.15%\n",
            "Epoch: 40, Loss: 61899.3359, Train: 88.55%, Valid: 82.13%, Test: 88.04%\n",
            "Epoch: 45, Loss: 58711.6875, Train: 88.55%, Valid: 83.01%, Test: 87.74%\n",
            "Epoch: 50, Loss: 55978.4609, Train: 89.44%, Valid: 83.46%, Test: 87.59%\n",
            "Epoch: 55, Loss: 53563.4023, Train: 89.73%, Valid: 83.75%, Test: 87.74%\n",
            "Epoch: 60, Loss: 51456.7070, Train: 90.03%, Valid: 83.90%, Test: 87.59%\n",
            "Epoch: 65, Loss: 49592.6836, Train: 90.18%, Valid: 83.60%, Test: 87.59%\n",
            "Epoch: 70, Loss: 47910.6406, Train: 90.62%, Valid: 83.31%, Test: 87.30%\n",
            "Epoch: 75, Loss: 46398.8984, Train: 90.84%, Valid: 83.46%, Test: 87.59%\n",
            "Epoch: 80, Loss: 45012.3906, Train: 90.62%, Valid: 83.60%, Test: 87.59%\n",
            "Epoch: 85, Loss: 43766.2539, Train: 90.77%, Valid: 83.90%, Test: 87.59%\n",
            "Epoch: 90, Loss: 42619.4023, Train: 90.99%, Valid: 84.05%, Test: 87.59%\n",
            "Epoch: 95, Loss: 41674.6641, Train: 91.21%, Valid: 84.05%, Test: 87.44%\n",
            "Epoch: 100, Loss: 40720.1406, Train: 91.14%, Valid: 83.90%, Test: 87.74%\n",
            "Epoch: 105, Loss: 39744.1445, Train: 91.14%, Valid: 83.60%, Test: 87.89%\n",
            "Epoch: 110, Loss: 38823.6211, Train: 91.14%, Valid: 83.01%, Test: 87.74%\n",
            "Epoch: 115, Loss: 38052.2617, Train: 91.14%, Valid: 83.16%, Test: 87.59%\n",
            "Epoch: 120, Loss: 37303.4570, Train: 91.21%, Valid: 83.01%, Test: 87.59%\n",
            "Epoch: 125, Loss: 36582.8594, Train: 91.29%, Valid: 82.87%, Test: 88.04%\n",
            "Epoch: 130, Loss: 35987.2305, Train: 91.14%, Valid: 82.87%, Test: 88.04%\n",
            "Epoch: 135, Loss: 35329.8750, Train: 91.29%, Valid: 83.01%, Test: 88.04%\n",
            "Epoch: 140, Loss: 34770.1836, Train: 91.36%, Valid: 82.42%, Test: 88.04%\n",
            "Epoch: 145, Loss: 34383.5938, Train: 91.43%, Valid: 83.01%, Test: 88.04%\n",
            "Epoch: 150, Loss: 33907.0039, Train: 91.14%, Valid: 82.87%, Test: 88.18%\n",
            "Epoch: 155, Loss: 33357.8164, Train: 91.21%, Valid: 83.16%, Test: 88.18%\n",
            "Epoch: 160, Loss: 32866.2773, Train: 91.06%, Valid: 83.31%, Test: 88.18%\n",
            "Epoch: 165, Loss: 32430.5410, Train: 91.29%, Valid: 83.31%, Test: 88.18%\n",
            "Epoch: 170, Loss: 32204.4883, Train: 91.14%, Valid: 83.01%, Test: 88.33%\n",
            "Epoch: 175, Loss: 31769.3730, Train: 91.06%, Valid: 83.16%, Test: 88.33%\n",
            "Epoch: 180, Loss: 31662.2168, Train: 91.21%, Valid: 83.01%, Test: 88.63%\n",
            "Epoch: 185, Loss: 31141.0273, Train: 91.21%, Valid: 82.87%, Test: 88.63%\n",
            "Epoch: 190, Loss: 30786.9980, Train: 91.14%, Valid: 82.72%, Test: 88.33%\n",
            "Epoch: 195, Loss: 30663.6836, Train: 91.29%, Valid: 82.57%, Test: 88.48%\n",
            "Run 01:\n",
            "Highest Train: 91.43\n",
            "Highest Valid: 84.19\n",
            "Highest Test: 88.63\n",
            "Chosen epoch: 93\n",
            "Final Train: 90.99\n",
            "Final Test: 87.59\n",
            "Epoch: 00, Loss: 581394.8750, Train: 17.28%, Valid: 14.77%, Test: 15.07%\n",
            "Epoch: 05, Loss: 139934.3281, Train: 29.84%, Valid: 24.08%, Test: 25.85%\n",
            "Epoch: 10, Loss: 107692.4375, Train: 43.35%, Valid: 38.11%, Test: 38.40%\n",
            "Epoch: 15, Loss: 92026.6484, Train: 56.79%, Valid: 49.63%, Test: 51.70%\n",
            "Epoch: 20, Loss: 82127.8203, Train: 74.30%, Valid: 68.24%, Test: 71.05%\n",
            "Epoch: 25, Loss: 75027.1875, Train: 84.71%, Valid: 79.91%, Test: 83.46%\n",
            "Epoch: 30, Loss: 69429.9766, Train: 88.85%, Valid: 82.13%, Test: 86.56%\n",
            "Epoch: 35, Loss: 64889.2344, Train: 89.44%, Valid: 82.72%, Test: 87.30%\n",
            "Epoch: 40, Loss: 61174.9102, Train: 89.73%, Valid: 82.57%, Test: 87.30%\n",
            "Epoch: 45, Loss: 57917.3672, Train: 89.96%, Valid: 82.87%, Test: 87.30%\n",
            "Epoch: 50, Loss: 55175.2031, Train: 90.18%, Valid: 83.01%, Test: 87.59%\n",
            "Epoch: 55, Loss: 52769.7969, Train: 90.25%, Valid: 83.60%, Test: 87.89%\n",
            "Epoch: 60, Loss: 50641.6523, Train: 90.47%, Valid: 83.31%, Test: 88.04%\n",
            "Epoch: 65, Loss: 48765.0625, Train: 90.55%, Valid: 83.31%, Test: 87.89%\n",
            "Epoch: 70, Loss: 47074.6602, Train: 90.99%, Valid: 83.01%, Test: 88.48%\n",
            "Epoch: 75, Loss: 45565.7266, Train: 90.99%, Valid: 83.60%, Test: 88.33%\n",
            "Epoch: 80, Loss: 44192.6680, Train: 91.14%, Valid: 83.60%, Test: 88.33%\n",
            "Epoch: 85, Loss: 42941.2812, Train: 91.14%, Valid: 83.60%, Test: 88.04%\n",
            "Epoch: 90, Loss: 41787.8008, Train: 91.29%, Valid: 83.90%, Test: 88.04%\n",
            "Epoch: 95, Loss: 40718.8789, Train: 91.21%, Valid: 84.05%, Test: 88.04%\n",
            "Epoch: 100, Loss: 39742.5117, Train: 91.29%, Valid: 84.05%, Test: 88.04%\n",
            "Epoch: 105, Loss: 38908.1211, Train: 91.29%, Valid: 84.05%, Test: 87.59%\n",
            "Epoch: 110, Loss: 38007.4492, Train: 91.21%, Valid: 83.75%, Test: 87.59%\n",
            "Epoch: 115, Loss: 37291.2852, Train: 91.14%, Valid: 83.75%, Test: 87.74%\n",
            "Epoch: 120, Loss: 36544.9219, Train: 91.14%, Valid: 83.75%, Test: 87.89%\n",
            "Epoch: 125, Loss: 35849.2539, Train: 91.21%, Valid: 83.75%, Test: 87.89%\n",
            "Epoch: 130, Loss: 35173.4844, Train: 91.29%, Valid: 83.60%, Test: 88.18%\n",
            "Epoch: 135, Loss: 34631.4492, Train: 91.29%, Valid: 83.75%, Test: 88.33%\n",
            "Epoch: 140, Loss: 33994.6289, Train: 91.36%, Valid: 83.75%, Test: 88.33%\n",
            "Epoch: 145, Loss: 33509.3359, Train: 91.21%, Valid: 83.90%, Test: 88.48%\n",
            "Epoch: 150, Loss: 33239.3242, Train: 91.21%, Valid: 83.46%, Test: 88.33%\n",
            "Epoch: 155, Loss: 32551.0215, Train: 90.99%, Valid: 83.75%, Test: 88.48%\n",
            "Epoch: 160, Loss: 32198.3828, Train: 90.99%, Valid: 83.75%, Test: 88.48%\n",
            "Epoch: 165, Loss: 31816.0117, Train: 91.21%, Valid: 84.05%, Test: 88.33%\n",
            "Epoch: 170, Loss: 31735.6680, Train: 91.21%, Valid: 83.60%, Test: 88.77%\n",
            "Epoch: 175, Loss: 31084.3438, Train: 91.29%, Valid: 83.75%, Test: 88.77%\n",
            "Epoch: 180, Loss: 30862.4570, Train: 91.29%, Valid: 83.75%, Test: 88.77%\n",
            "Epoch: 185, Loss: 30592.9102, Train: 91.36%, Valid: 83.90%, Test: 88.63%\n",
            "Epoch: 190, Loss: 30089.3477, Train: 91.43%, Valid: 83.60%, Test: 88.63%\n",
            "Epoch: 195, Loss: 29742.6484, Train: 91.43%, Valid: 83.60%, Test: 88.63%\n",
            "Run 02:\n",
            "Highest Train: 91.51\n",
            "Highest Valid: 84.05\n",
            "Highest Test: 89.07\n",
            "Chosen epoch: 92\n",
            "Final Train: 91.29\n",
            "Final Test: 88.04\n",
            "Epoch: 00, Loss: 577275.9375, Train: 9.60%, Valid: 6.35%, Test: 9.75%\n",
            "Epoch: 05, Loss: 148441.1875, Train: 31.39%, Valid: 24.22%, Test: 30.87%\n",
            "Epoch: 10, Loss: 115764.7344, Train: 42.61%, Valid: 33.68%, Test: 39.00%\n",
            "Epoch: 15, Loss: 99384.2500, Train: 46.45%, Valid: 39.00%, Test: 42.84%\n",
            "Epoch: 20, Loss: 89416.3594, Train: 61.08%, Valid: 55.54%, Test: 59.68%\n",
            "Epoch: 25, Loss: 81932.2812, Train: 75.70%, Valid: 70.46%, Test: 75.48%\n",
            "Epoch: 30, Loss: 75967.8672, Train: 81.24%, Valid: 75.04%, Test: 80.95%\n",
            "Epoch: 35, Loss: 71317.8125, Train: 82.72%, Valid: 77.25%, Test: 82.72%\n",
            "Epoch: 40, Loss: 67432.6250, Train: 85.16%, Valid: 79.32%, Test: 83.46%\n",
            "Epoch: 45, Loss: 64139.3047, Train: 86.71%, Valid: 80.95%, Test: 85.52%\n",
            "Epoch: 50, Loss: 61313.1523, Train: 87.59%, Valid: 82.27%, Test: 86.12%\n",
            "Epoch: 55, Loss: 58871.7578, Train: 87.74%, Valid: 82.42%, Test: 86.71%\n",
            "Epoch: 60, Loss: 56725.2422, Train: 87.96%, Valid: 81.83%, Test: 86.56%\n",
            "Epoch: 65, Loss: 54818.1367, Train: 88.11%, Valid: 81.68%, Test: 87.00%\n",
            "Epoch: 70, Loss: 53092.1914, Train: 88.18%, Valid: 81.83%, Test: 86.85%\n",
            "Epoch: 75, Loss: 51507.2695, Train: 88.40%, Valid: 82.27%, Test: 87.15%\n",
            "Epoch: 80, Loss: 50066.6875, Train: 88.63%, Valid: 82.57%, Test: 87.59%\n",
            "Epoch: 85, Loss: 48749.1797, Train: 88.85%, Valid: 82.42%, Test: 87.15%\n",
            "Epoch: 90, Loss: 47539.4023, Train: 89.07%, Valid: 82.57%, Test: 87.15%\n",
            "Epoch: 95, Loss: 46422.6016, Train: 89.07%, Valid: 82.57%, Test: 87.30%\n",
            "Epoch: 100, Loss: 45388.2461, Train: 89.22%, Valid: 82.13%, Test: 87.15%\n",
            "Epoch: 105, Loss: 44426.9297, Train: 89.07%, Valid: 82.13%, Test: 87.15%\n",
            "Epoch: 110, Loss: 43528.9648, Train: 89.22%, Valid: 81.83%, Test: 87.00%\n",
            "Epoch: 115, Loss: 42693.1133, Train: 89.29%, Valid: 82.13%, Test: 86.71%\n",
            "Epoch: 120, Loss: 41911.2969, Train: 89.44%, Valid: 82.13%, Test: 87.15%\n",
            "Epoch: 125, Loss: 41172.5469, Train: 89.51%, Valid: 82.13%, Test: 87.15%\n",
            "Epoch: 130, Loss: 40590.9727, Train: 89.59%, Valid: 82.13%, Test: 87.00%\n",
            "Epoch: 135, Loss: 39877.8438, Train: 89.51%, Valid: 82.13%, Test: 87.00%\n",
            "Epoch: 140, Loss: 39289.2891, Train: 89.51%, Valid: 82.27%, Test: 87.30%\n",
            "Epoch: 145, Loss: 38722.2695, Train: 89.44%, Valid: 82.42%, Test: 87.00%\n",
            "Epoch: 150, Loss: 38098.7539, Train: 89.44%, Valid: 82.13%, Test: 87.00%\n",
            "Epoch: 155, Loss: 37614.9023, Train: 89.51%, Valid: 82.13%, Test: 86.85%\n",
            "Epoch: 160, Loss: 37602.9492, Train: 89.59%, Valid: 82.27%, Test: 86.85%\n",
            "Epoch: 165, Loss: 36971.6797, Train: 89.59%, Valid: 82.27%, Test: 86.85%\n",
            "Epoch: 170, Loss: 36600.9922, Train: 89.51%, Valid: 82.57%, Test: 86.85%\n",
            "Epoch: 175, Loss: 36059.7930, Train: 89.51%, Valid: 82.42%, Test: 86.85%\n",
            "Epoch: 180, Loss: 35933.3203, Train: 89.51%, Valid: 82.42%, Test: 87.00%\n",
            "Epoch: 185, Loss: 35489.0117, Train: 89.66%, Valid: 82.42%, Test: 87.30%\n",
            "Epoch: 190, Loss: 35187.5117, Train: 89.66%, Valid: 82.27%, Test: 87.30%\n",
            "Epoch: 195, Loss: 34757.5117, Train: 89.59%, Valid: 82.42%, Test: 87.44%\n",
            "Run 03:\n",
            "Highest Train: 89.66\n",
            "Highest Valid: 82.72\n",
            "Highest Test: 87.59\n",
            "Chosen epoch: 197\n",
            "Final Train: 89.44\n",
            "Final Test: 87.44\n",
            "Epoch: 00, Loss: 580695.2500, Train: 9.90%, Valid: 7.68%, Test: 8.27%\n",
            "Epoch: 05, Loss: 154034.0312, Train: 19.57%, Valid: 19.20%, Test: 17.43%\n",
            "Epoch: 10, Loss: 118971.6328, Train: 36.93%, Valid: 34.86%, Test: 32.94%\n",
            "Epoch: 15, Loss: 101694.6094, Train: 60.93%, Valid: 55.54%, Test: 55.54%\n",
            "Epoch: 20, Loss: 90536.9375, Train: 72.82%, Valid: 66.03%, Test: 68.24%\n",
            "Epoch: 25, Loss: 82340.7891, Train: 78.43%, Valid: 71.20%, Test: 74.00%\n",
            "Epoch: 30, Loss: 76058.8516, Train: 82.13%, Valid: 74.15%, Test: 78.43%\n",
            "Epoch: 35, Loss: 71044.7891, Train: 83.53%, Valid: 75.63%, Test: 80.65%\n",
            "Epoch: 40, Loss: 66849.1641, Train: 85.60%, Valid: 77.55%, Test: 82.13%\n",
            "Epoch: 45, Loss: 63313.5977, Train: 87.74%, Valid: 80.35%, Test: 84.79%\n",
            "Epoch: 50, Loss: 60281.3867, Train: 88.48%, Valid: 81.68%, Test: 85.67%\n",
            "Epoch: 55, Loss: 57661.9297, Train: 89.00%, Valid: 81.83%, Test: 86.71%\n",
            "Epoch: 60, Loss: 55383.8477, Train: 89.59%, Valid: 82.27%, Test: 87.15%\n",
            "Epoch: 65, Loss: 53369.9062, Train: 89.96%, Valid: 82.57%, Test: 87.15%\n",
            "Epoch: 70, Loss: 51558.3945, Train: 90.25%, Valid: 82.87%, Test: 87.30%\n",
            "Epoch: 75, Loss: 49931.1172, Train: 90.40%, Valid: 82.72%, Test: 88.04%\n",
            "Epoch: 80, Loss: 48473.6367, Train: 90.32%, Valid: 82.72%, Test: 88.04%\n",
            "Epoch: 85, Loss: 47139.8320, Train: 90.40%, Valid: 82.72%, Test: 88.04%\n",
            "Epoch: 90, Loss: 45924.3281, Train: 90.62%, Valid: 82.57%, Test: 87.89%\n",
            "Epoch: 95, Loss: 44809.3789, Train: 90.77%, Valid: 82.72%, Test: 87.89%\n",
            "Epoch: 100, Loss: 43778.0039, Train: 91.06%, Valid: 82.72%, Test: 87.89%\n",
            "Epoch: 105, Loss: 42814.7148, Train: 91.06%, Valid: 82.87%, Test: 87.89%\n",
            "Epoch: 110, Loss: 41924.4141, Train: 91.06%, Valid: 82.87%, Test: 88.04%\n",
            "Epoch: 115, Loss: 41095.7773, Train: 90.92%, Valid: 82.87%, Test: 88.04%\n",
            "Epoch: 120, Loss: 40319.4102, Train: 90.99%, Valid: 83.01%, Test: 87.89%\n",
            "Epoch: 125, Loss: 39590.9648, Train: 91.21%, Valid: 83.31%, Test: 87.89%\n",
            "Epoch: 130, Loss: 38911.0156, Train: 91.29%, Valid: 83.60%, Test: 88.04%\n",
            "Epoch: 135, Loss: 38291.1094, Train: 91.36%, Valid: 83.46%, Test: 88.04%\n",
            "Epoch: 140, Loss: 37685.5469, Train: 91.21%, Valid: 83.46%, Test: 88.04%\n",
            "Epoch: 145, Loss: 37154.4922, Train: 91.21%, Valid: 83.31%, Test: 88.18%\n",
            "Epoch: 150, Loss: 36702.0586, Train: 91.36%, Valid: 83.31%, Test: 88.18%\n",
            "Epoch: 155, Loss: 36129.4805, Train: 91.43%, Valid: 83.31%, Test: 88.18%\n",
            "Epoch: 160, Loss: 35666.9336, Train: 91.43%, Valid: 83.31%, Test: 88.18%\n",
            "Epoch: 165, Loss: 35432.0430, Train: 91.43%, Valid: 83.16%, Test: 88.04%\n",
            "Epoch: 170, Loss: 34959.8711, Train: 91.36%, Valid: 83.01%, Test: 88.04%\n",
            "Epoch: 175, Loss: 34511.2617, Train: 91.43%, Valid: 83.01%, Test: 88.18%\n",
            "Epoch: 180, Loss: 34207.4375, Train: 91.51%, Valid: 82.87%, Test: 88.04%\n",
            "Epoch: 185, Loss: 33836.0000, Train: 91.51%, Valid: 82.57%, Test: 88.18%\n",
            "Epoch: 190, Loss: 33418.3125, Train: 91.29%, Valid: 82.87%, Test: 88.04%\n",
            "Epoch: 195, Loss: 33490.2500, Train: 91.36%, Valid: 82.72%, Test: 87.89%\n",
            "Run 04:\n",
            "Highest Train: 91.73\n",
            "Highest Valid: 83.60\n",
            "Highest Test: 88.33\n",
            "Chosen epoch: 130\n",
            "Final Train: 91.21\n",
            "Final Test: 88.04\n",
            "Epoch: 00, Loss: 579095.8125, Train: 22.38%, Valid: 22.90%, Test: 21.86%\n",
            "Epoch: 05, Loss: 167397.9531, Train: 29.17%, Valid: 32.79%, Test: 29.69%\n",
            "Epoch: 10, Loss: 127774.9844, Train: 41.29%, Valid: 40.92%, Test: 39.29%\n",
            "Epoch: 15, Loss: 108167.0391, Train: 60.78%, Valid: 56.28%, Test: 57.02%\n",
            "Epoch: 20, Loss: 95727.7969, Train: 71.20%, Valid: 67.95%, Test: 69.42%\n",
            "Epoch: 25, Loss: 86452.3594, Train: 78.14%, Valid: 71.20%, Test: 76.51%\n",
            "Epoch: 30, Loss: 79332.0078, Train: 83.09%, Valid: 76.37%, Test: 80.95%\n",
            "Epoch: 35, Loss: 73537.8750, Train: 84.79%, Valid: 77.84%, Test: 82.42%\n",
            "Epoch: 40, Loss: 68735.4453, Train: 87.52%, Valid: 79.47%, Test: 85.38%\n",
            "Epoch: 45, Loss: 64773.0859, Train: 89.29%, Valid: 81.24%, Test: 87.44%\n",
            "Epoch: 50, Loss: 61321.5742, Train: 89.88%, Valid: 82.57%, Test: 88.33%\n",
            "Epoch: 55, Loss: 58367.6094, Train: 90.92%, Valid: 83.60%, Test: 88.63%\n",
            "Epoch: 60, Loss: 55807.7461, Train: 91.21%, Valid: 83.90%, Test: 89.07%\n",
            "Epoch: 65, Loss: 53586.8125, Train: 91.29%, Valid: 84.19%, Test: 89.36%\n",
            "Epoch: 70, Loss: 51617.3906, Train: 91.36%, Valid: 84.19%, Test: 89.07%\n",
            "Epoch: 75, Loss: 49838.1055, Train: 91.36%, Valid: 84.19%, Test: 89.36%\n",
            "Epoch: 80, Loss: 48275.7148, Train: 91.73%, Valid: 84.05%, Test: 89.22%\n",
            "Epoch: 85, Loss: 46886.8320, Train: 91.80%, Valid: 84.05%, Test: 89.22%\n",
            "Epoch: 90, Loss: 45613.0078, Train: 91.73%, Valid: 83.75%, Test: 89.22%\n",
            "Epoch: 95, Loss: 44478.6836, Train: 91.73%, Valid: 83.90%, Test: 89.36%\n",
            "Epoch: 100, Loss: 43675.6133, Train: 91.88%, Valid: 83.75%, Test: 89.51%\n",
            "Epoch: 105, Loss: 42637.6953, Train: 92.02%, Valid: 83.75%, Test: 89.22%\n",
            "Epoch: 110, Loss: 41669.1953, Train: 92.02%, Valid: 83.60%, Test: 89.22%\n",
            "Epoch: 115, Loss: 40849.2617, Train: 92.17%, Valid: 83.75%, Test: 89.22%\n",
            "Epoch: 120, Loss: 40086.5117, Train: 92.10%, Valid: 83.75%, Test: 89.07%\n",
            "Epoch: 125, Loss: 39297.0156, Train: 92.02%, Valid: 83.90%, Test: 89.07%\n",
            "Epoch: 130, Loss: 38809.8164, Train: 92.10%, Valid: 83.90%, Test: 89.07%\n",
            "Epoch: 135, Loss: 37965.8203, Train: 92.39%, Valid: 83.90%, Test: 89.22%\n",
            "Epoch: 140, Loss: 37689.3867, Train: 92.39%, Valid: 83.46%, Test: 89.07%\n",
            "Epoch: 145, Loss: 37071.0781, Train: 92.39%, Valid: 83.60%, Test: 89.36%\n",
            "Epoch: 150, Loss: 36354.0859, Train: 92.39%, Valid: 83.60%, Test: 89.22%\n",
            "Epoch: 155, Loss: 35827.3125, Train: 92.54%, Valid: 83.60%, Test: 89.22%\n",
            "Epoch: 160, Loss: 35688.6719, Train: 92.39%, Valid: 83.46%, Test: 89.22%\n",
            "Epoch: 165, Loss: 35030.0430, Train: 92.25%, Valid: 83.31%, Test: 89.22%\n",
            "Epoch: 170, Loss: 34887.7617, Train: 92.25%, Valid: 83.46%, Test: 89.22%\n",
            "Epoch: 175, Loss: 34110.9258, Train: 92.25%, Valid: 83.31%, Test: 89.22%\n",
            "Epoch: 180, Loss: 34240.4805, Train: 92.32%, Valid: 83.31%, Test: 89.07%\n",
            "Epoch: 185, Loss: 33606.2031, Train: 92.32%, Valid: 83.46%, Test: 88.92%\n",
            "Epoch: 190, Loss: 33538.3633, Train: 92.47%, Valid: 83.31%, Test: 88.92%\n",
            "Epoch: 195, Loss: 33297.6172, Train: 92.39%, Valid: 83.31%, Test: 88.92%\n",
            "Run 05:\n",
            "Highest Train: 92.61\n",
            "Highest Valid: 84.34\n",
            "Highest Test: 89.51\n",
            "Chosen epoch: 72\n",
            "Final Train: 91.29\n",
            "Final Test: 89.07\n",
            "All runs:\n",
            "Highest Train: 91.39 ± 1.07\n",
            "Highest Test: 88.63 ± 0.73\n",
            "Highest Valid: 83.78 ± 0.66\n",
            "  Final Train: 90.84 ± 0.79\n",
            "   Final Test: 88.04 ± 0.64\n",
            "Saving results to logs/cora_edge.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 GKD/main.py --dataset cora --rand_split --use_bn --base_model gcn --mode train --priv_type edge --dist_mode gkd --kernel gaussian"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPr8DQN5GJXn",
        "outputId": "4ffe4b20-c7c1-4d83-e214-be7f1e2308a7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(data_dir='data', dataset='cora', sub_dataset='', cpu=False, seed=42, train_prop=0.5, valid_prop=0.25, protocol='semi', rand_split=True, metric='acc', runs=5, epochs=200, hidden_channels=32, num_layers=3, gat_heads=8, out_heads=1, hops=1, lp_alpha=0.1, gpr_alpha=0.1, jk_type='max', directed=False, num_mlp_layers=1, display_step=5, cached=False, print_prop=False, priv_type='edge', priv_ratio=0.5, save_model=False, save_name='gcn', log_name='none', base_model='gcn', not_load_teacher=False, mode='train', dist_mode='gkd', weight_decay=0.05, dropout=0.0, lr=0.01, use_bn=True, use_batch=False, batch_size=2048, oracle=False, device=0, alpha=0.5, delta=0.1, use_kd=False, beta=0.0, tau=1.0, kernel='gaussian', t=1.0, include_last=False, s=2, m=1, lr2=0.001, sim='l2', ker_norm=False)\n",
            "cuda:0\n",
            "cora\n",
            "Num nodes: 2708\n",
            "torch.Size([2708, 1])\n",
            "num nodes 2708 | num classes 7 | num node feats 1433\n",
            "MODEL: GeoDist(\n",
            "  (k): Kernel(\n",
            "    (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  )\n",
            "  (teacher_gnn): ModuleList(\n",
            "    (0): Linear(in_features=1433, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (student_gnn): ModuleList(\n",
            "    (0): Linear(in_features=1433, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  (bns2d): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            ")\n",
            "Epoch: 00, Loss: 219.9620, Train: 32.35%, Valid: 26.74%, Test: 27.03%\n",
            "Epoch: 05, Loss: 142.0029, Train: 35.67%, Valid: 30.13%, Test: 30.13%\n",
            "Epoch: 10, Loss: 123.6651, Train: 54.14%, Valid: 48.89%, Test: 47.56%\n",
            "Epoch: 15, Loss: 114.3873, Train: 64.03%, Valid: 58.94%, Test: 62.48%\n",
            "Epoch: 20, Loss: 107.6109, Train: 69.94%, Valid: 64.84%, Test: 69.28%\n",
            "Epoch: 25, Loss: 102.5086, Train: 74.96%, Valid: 70.90%, Test: 73.41%\n",
            "Epoch: 30, Loss: 98.4273, Train: 80.58%, Valid: 76.07%, Test: 80.50%\n",
            "Epoch: 35, Loss: 94.9640, Train: 82.87%, Valid: 77.25%, Test: 82.27%\n",
            "Epoch: 40, Loss: 91.8386, Train: 83.60%, Valid: 78.14%, Test: 83.46%\n",
            "Epoch: 45, Loss: 89.2237, Train: 84.34%, Valid: 78.88%, Test: 84.05%\n",
            "Epoch: 50, Loss: 86.9333, Train: 85.82%, Valid: 78.88%, Test: 84.79%\n",
            "Epoch: 55, Loss: 84.9293, Train: 86.41%, Valid: 79.03%, Test: 85.08%\n",
            "Epoch: 60, Loss: 83.1039, Train: 86.71%, Valid: 79.62%, Test: 85.08%\n",
            "Epoch: 65, Loss: 81.3221, Train: 87.30%, Valid: 80.21%, Test: 85.38%\n",
            "Epoch: 70, Loss: 79.7526, Train: 87.52%, Valid: 80.50%, Test: 85.67%\n",
            "Epoch: 75, Loss: 78.3195, Train: 87.30%, Valid: 80.95%, Test: 85.67%\n",
            "Epoch: 80, Loss: 76.9930, Train: 87.74%, Valid: 81.09%, Test: 85.82%\n",
            "Epoch: 85, Loss: 75.7516, Train: 88.48%, Valid: 82.27%, Test: 85.97%\n",
            "Epoch: 90, Loss: 74.7664, Train: 88.70%, Valid: 82.57%, Test: 86.26%\n",
            "Epoch: 95, Loss: 73.9026, Train: 88.77%, Valid: 82.87%, Test: 86.56%\n",
            "Epoch: 100, Loss: 73.1606, Train: 89.36%, Valid: 82.72%, Test: 86.71%\n",
            "Epoch: 105, Loss: 72.6775, Train: 89.22%, Valid: 83.16%, Test: 87.15%\n",
            "Epoch: 110, Loss: 72.6027, Train: 89.44%, Valid: 83.46%, Test: 87.44%\n",
            "Epoch: 115, Loss: 71.5549, Train: 89.36%, Valid: 83.16%, Test: 87.59%\n",
            "Epoch: 120, Loss: 70.8270, Train: 89.88%, Valid: 83.01%, Test: 87.59%\n",
            "Epoch: 125, Loss: 71.1228, Train: 89.73%, Valid: 83.31%, Test: 87.00%\n",
            "Epoch: 130, Loss: 70.2275, Train: 89.88%, Valid: 83.16%, Test: 87.30%\n",
            "Epoch: 135, Loss: 69.4356, Train: 90.18%, Valid: 83.60%, Test: 87.15%\n",
            "Epoch: 140, Loss: 69.9510, Train: 90.18%, Valid: 83.31%, Test: 86.85%\n",
            "Epoch: 145, Loss: 69.9275, Train: 90.10%, Valid: 83.01%, Test: 87.44%\n",
            "Epoch: 150, Loss: 68.7877, Train: 90.32%, Valid: 83.01%, Test: 88.04%\n",
            "Epoch: 155, Loss: 68.2634, Train: 90.47%, Valid: 84.34%, Test: 87.74%\n",
            "Epoch: 160, Loss: 68.0197, Train: 90.25%, Valid: 84.05%, Test: 87.74%\n",
            "Epoch: 165, Loss: 68.8178, Train: 90.40%, Valid: 83.16%, Test: 87.00%\n",
            "Epoch: 170, Loss: 69.7616, Train: 90.18%, Valid: 84.05%, Test: 87.44%\n",
            "Epoch: 175, Loss: 68.6695, Train: 90.18%, Valid: 83.90%, Test: 87.30%\n",
            "Epoch: 180, Loss: 67.6756, Train: 90.18%, Valid: 83.75%, Test: 87.44%\n",
            "Epoch: 185, Loss: 66.9876, Train: 90.69%, Valid: 83.31%, Test: 87.59%\n",
            "Epoch: 190, Loss: 66.8744, Train: 90.77%, Valid: 83.60%, Test: 87.59%\n",
            "Epoch: 195, Loss: 68.3574, Train: 90.47%, Valid: 83.60%, Test: 87.89%\n",
            "Run 01:\n",
            "Highest Train: 91.06\n",
            "Highest Valid: 84.64\n",
            "Highest Test: 88.48\n",
            "Chosen epoch: 172\n",
            "Final Train: 90.10\n",
            "Final Test: 87.59\n",
            "Epoch: 00, Loss: 252.0038, Train: 19.57%, Valid: 18.91%, Test: 19.20%\n",
            "Epoch: 05, Loss: 168.2714, Train: 32.20%, Valid: 30.28%, Test: 29.84%\n",
            "Epoch: 10, Loss: 147.4263, Train: 48.74%, Valid: 46.23%, Test: 45.79%\n",
            "Epoch: 15, Loss: 135.4277, Train: 64.03%, Valid: 61.30%, Test: 60.71%\n",
            "Epoch: 20, Loss: 126.9140, Train: 72.75%, Valid: 68.54%, Test: 68.83%\n",
            "Epoch: 25, Loss: 120.6556, Train: 77.92%, Valid: 74.00%, Test: 75.48%\n",
            "Epoch: 30, Loss: 115.6677, Train: 81.54%, Valid: 76.81%, Test: 78.88%\n",
            "Epoch: 35, Loss: 111.5481, Train: 84.19%, Valid: 77.84%, Test: 81.68%\n",
            "Epoch: 40, Loss: 108.0415, Train: 85.45%, Valid: 79.17%, Test: 82.72%\n",
            "Epoch: 45, Loss: 104.9146, Train: 85.67%, Valid: 80.06%, Test: 84.19%\n",
            "Epoch: 50, Loss: 102.1367, Train: 85.45%, Valid: 80.21%, Test: 85.23%\n",
            "Epoch: 55, Loss: 99.6214, Train: 86.12%, Valid: 80.21%, Test: 85.52%\n",
            "Epoch: 60, Loss: 97.3795, Train: 86.78%, Valid: 79.76%, Test: 85.67%\n",
            "Epoch: 65, Loss: 95.2630, Train: 87.08%, Valid: 80.35%, Test: 85.52%\n",
            "Epoch: 70, Loss: 93.4178, Train: 87.37%, Valid: 80.95%, Test: 85.08%\n",
            "Epoch: 75, Loss: 91.5943, Train: 87.52%, Valid: 81.24%, Test: 85.23%\n",
            "Epoch: 80, Loss: 89.9605, Train: 87.67%, Valid: 80.65%, Test: 85.38%\n",
            "Epoch: 85, Loss: 88.3247, Train: 87.59%, Valid: 80.65%, Test: 85.08%\n",
            "Epoch: 90, Loss: 86.9242, Train: 87.74%, Valid: 80.65%, Test: 85.38%\n",
            "Epoch: 95, Loss: 85.7308, Train: 87.96%, Valid: 80.65%, Test: 85.38%\n",
            "Epoch: 100, Loss: 84.0795, Train: 88.04%, Valid: 80.80%, Test: 85.38%\n",
            "Epoch: 105, Loss: 84.1308, Train: 88.11%, Valid: 80.50%, Test: 85.52%\n",
            "Epoch: 110, Loss: 86.0501, Train: 88.63%, Valid: 81.39%, Test: 85.97%\n",
            "Epoch: 115, Loss: 82.9750, Train: 88.63%, Valid: 81.24%, Test: 86.56%\n",
            "Epoch: 120, Loss: 81.5646, Train: 89.00%, Valid: 81.54%, Test: 86.56%\n",
            "Epoch: 125, Loss: 80.4415, Train: 89.22%, Valid: 81.98%, Test: 85.97%\n",
            "Epoch: 130, Loss: 79.6814, Train: 89.51%, Valid: 81.39%, Test: 86.41%\n",
            "Epoch: 135, Loss: 79.2248, Train: 89.73%, Valid: 82.42%, Test: 86.56%\n",
            "Epoch: 140, Loss: 78.9476, Train: 89.88%, Valid: 82.72%, Test: 87.00%\n",
            "Epoch: 145, Loss: 79.1086, Train: 89.96%, Valid: 83.60%, Test: 87.15%\n",
            "Epoch: 150, Loss: 78.5946, Train: 90.03%, Valid: 84.05%, Test: 87.44%\n",
            "Epoch: 155, Loss: 80.4018, Train: 90.10%, Valid: 84.19%, Test: 87.15%\n",
            "Epoch: 160, Loss: 78.6363, Train: 89.73%, Valid: 83.46%, Test: 87.30%\n",
            "Epoch: 165, Loss: 77.3387, Train: 90.03%, Valid: 83.46%, Test: 87.59%\n",
            "Epoch: 170, Loss: 76.8764, Train: 89.96%, Valid: 84.34%, Test: 87.30%\n",
            "Epoch: 175, Loss: 76.6903, Train: 90.32%, Valid: 83.60%, Test: 87.44%\n",
            "Epoch: 180, Loss: 77.9975, Train: 90.32%, Valid: 83.46%, Test: 87.30%\n",
            "Epoch: 185, Loss: 77.3877, Train: 90.55%, Valid: 83.75%, Test: 87.59%\n",
            "Epoch: 190, Loss: 76.5038, Train: 90.32%, Valid: 84.05%, Test: 87.00%\n",
            "Epoch: 195, Loss: 75.8936, Train: 90.47%, Valid: 83.60%, Test: 87.59%\n",
            "Run 02:\n",
            "Highest Train: 90.55\n",
            "Highest Valid: 84.34\n",
            "Highest Test: 87.74\n",
            "Chosen epoch: 171\n",
            "Final Train: 89.96\n",
            "Final Test: 87.30\n",
            "Epoch: 00, Loss: 215.0181, Train: 18.17%, Valid: 16.25%, Test: 16.84%\n",
            "Epoch: 05, Loss: 138.5292, Train: 33.46%, Valid: 27.47%, Test: 30.72%\n",
            "Epoch: 10, Loss: 122.6947, Train: 42.47%, Valid: 39.59%, Test: 41.06%\n",
            "Epoch: 15, Loss: 114.5251, Train: 58.86%, Valid: 56.28%, Test: 58.35%\n",
            "Epoch: 20, Loss: 108.6815, Train: 67.28%, Valid: 64.11%, Test: 66.91%\n",
            "Epoch: 25, Loss: 104.1067, Train: 74.15%, Valid: 68.83%, Test: 73.12%\n",
            "Epoch: 30, Loss: 100.3826, Train: 78.29%, Valid: 71.94%, Test: 78.29%\n",
            "Epoch: 35, Loss: 97.2038, Train: 80.43%, Valid: 74.45%, Test: 80.95%\n",
            "Epoch: 40, Loss: 94.4998, Train: 81.98%, Valid: 76.51%, Test: 82.13%\n",
            "Epoch: 45, Loss: 92.1102, Train: 82.50%, Valid: 77.99%, Test: 82.72%\n",
            "Epoch: 50, Loss: 89.8886, Train: 83.60%, Valid: 78.43%, Test: 83.01%\n",
            "Epoch: 55, Loss: 87.9486, Train: 84.34%, Valid: 78.43%, Test: 83.46%\n",
            "Epoch: 60, Loss: 86.1392, Train: 84.93%, Valid: 79.17%, Test: 83.60%\n",
            "Epoch: 65, Loss: 84.4833, Train: 85.23%, Valid: 79.17%, Test: 84.49%\n",
            "Epoch: 70, Loss: 82.9555, Train: 86.12%, Valid: 79.17%, Test: 84.79%\n",
            "Epoch: 75, Loss: 81.4781, Train: 86.26%, Valid: 79.91%, Test: 84.79%\n",
            "Epoch: 80, Loss: 80.1026, Train: 86.34%, Valid: 80.65%, Test: 84.79%\n",
            "Epoch: 85, Loss: 78.9525, Train: 86.34%, Valid: 81.09%, Test: 84.64%\n",
            "Epoch: 90, Loss: 77.7114, Train: 86.56%, Valid: 81.24%, Test: 84.49%\n",
            "Epoch: 95, Loss: 76.8063, Train: 86.71%, Valid: 81.68%, Test: 84.64%\n",
            "Epoch: 100, Loss: 75.8349, Train: 87.00%, Valid: 82.72%, Test: 84.79%\n",
            "Epoch: 105, Loss: 76.0728, Train: 87.74%, Valid: 82.72%, Test: 85.08%\n",
            "Epoch: 110, Loss: 75.0145, Train: 87.67%, Valid: 83.60%, Test: 85.38%\n",
            "Epoch: 115, Loss: 74.3931, Train: 87.67%, Valid: 83.90%, Test: 85.23%\n",
            "Epoch: 120, Loss: 73.9107, Train: 88.04%, Valid: 83.16%, Test: 86.26%\n",
            "Epoch: 125, Loss: 74.0401, Train: 88.55%, Valid: 82.87%, Test: 86.26%\n",
            "Epoch: 130, Loss: 73.1225, Train: 88.77%, Valid: 83.16%, Test: 86.26%\n",
            "Epoch: 135, Loss: 73.2805, Train: 88.40%, Valid: 82.72%, Test: 86.41%\n",
            "Epoch: 140, Loss: 72.6508, Train: 88.33%, Valid: 83.90%, Test: 86.26%\n",
            "Epoch: 145, Loss: 72.4058, Train: 88.63%, Valid: 83.90%, Test: 86.56%\n",
            "Epoch: 150, Loss: 72.4990, Train: 88.85%, Valid: 83.90%, Test: 86.71%\n",
            "Epoch: 155, Loss: 71.7975, Train: 88.63%, Valid: 84.34%, Test: 86.56%\n",
            "Epoch: 160, Loss: 71.3172, Train: 88.85%, Valid: 84.34%, Test: 87.00%\n",
            "Epoch: 165, Loss: 73.5801, Train: 89.07%, Valid: 84.34%, Test: 86.71%\n",
            "Epoch: 170, Loss: 72.0428, Train: 89.36%, Valid: 85.08%, Test: 86.85%\n",
            "Epoch: 175, Loss: 71.1863, Train: 89.29%, Valid: 84.19%, Test: 87.00%\n",
            "Epoch: 180, Loss: 71.5698, Train: 89.14%, Valid: 84.93%, Test: 86.56%\n",
            "Epoch: 185, Loss: 70.8210, Train: 89.07%, Valid: 84.64%, Test: 87.00%\n",
            "Epoch: 190, Loss: 71.0484, Train: 89.14%, Valid: 84.49%, Test: 87.44%\n",
            "Epoch: 195, Loss: 70.4195, Train: 89.14%, Valid: 84.05%, Test: 87.30%\n",
            "Run 03:\n",
            "Highest Train: 89.66\n",
            "Highest Valid: 85.08\n",
            "Highest Test: 87.74\n",
            "Chosen epoch: 171\n",
            "Final Train: 89.36\n",
            "Final Test: 86.85\n",
            "Epoch: 00, Loss: 225.3577, Train: 10.93%, Valid: 9.60%, Test: 10.93%\n",
            "Epoch: 05, Loss: 152.2590, Train: 20.97%, Valid: 17.73%, Test: 13.74%\n",
            "Epoch: 10, Loss: 133.5266, Train: 38.33%, Valid: 32.79%, Test: 30.58%\n",
            "Epoch: 15, Loss: 123.5227, Train: 61.60%, Valid: 57.02%, Test: 58.49%\n",
            "Epoch: 20, Loss: 116.3951, Train: 70.61%, Valid: 66.91%, Test: 67.95%\n",
            "Epoch: 25, Loss: 110.9020, Train: 77.40%, Valid: 73.56%, Test: 75.33%\n",
            "Epoch: 30, Loss: 106.5039, Train: 79.47%, Valid: 75.78%, Test: 78.29%\n",
            "Epoch: 35, Loss: 102.8491, Train: 81.83%, Valid: 77.10%, Test: 80.06%\n",
            "Epoch: 40, Loss: 99.7313, Train: 83.60%, Valid: 78.29%, Test: 82.13%\n",
            "Epoch: 45, Loss: 96.9103, Train: 84.64%, Valid: 79.62%, Test: 83.31%\n",
            "Epoch: 50, Loss: 94.3182, Train: 85.38%, Valid: 79.91%, Test: 83.46%\n",
            "Epoch: 55, Loss: 91.8746, Train: 85.97%, Valid: 80.35%, Test: 84.64%\n",
            "Epoch: 60, Loss: 89.6490, Train: 86.26%, Valid: 80.35%, Test: 84.49%\n",
            "Epoch: 65, Loss: 87.4988, Train: 86.56%, Valid: 80.80%, Test: 84.05%\n",
            "Epoch: 70, Loss: 85.4944, Train: 87.00%, Valid: 80.95%, Test: 84.05%\n",
            "Epoch: 75, Loss: 83.7116, Train: 88.18%, Valid: 81.09%, Test: 84.49%\n",
            "Epoch: 80, Loss: 82.1162, Train: 88.26%, Valid: 81.39%, Test: 85.08%\n",
            "Epoch: 85, Loss: 80.7556, Train: 88.63%, Valid: 81.24%, Test: 85.08%\n",
            "Epoch: 90, Loss: 79.5257, Train: 89.07%, Valid: 80.65%, Test: 85.97%\n",
            "Epoch: 95, Loss: 78.4475, Train: 88.92%, Valid: 81.39%, Test: 85.82%\n",
            "Epoch: 100, Loss: 77.8254, Train: 89.44%, Valid: 81.24%, Test: 86.41%\n",
            "Epoch: 105, Loss: 77.3040, Train: 89.88%, Valid: 81.83%, Test: 87.15%\n",
            "Epoch: 110, Loss: 76.4784, Train: 90.25%, Valid: 82.27%, Test: 87.30%\n",
            "Epoch: 115, Loss: 75.7379, Train: 90.55%, Valid: 82.13%, Test: 87.44%\n",
            "Epoch: 120, Loss: 76.3211, Train: 90.84%, Valid: 82.72%, Test: 88.33%\n",
            "Epoch: 125, Loss: 77.0239, Train: 90.40%, Valid: 82.57%, Test: 87.44%\n",
            "Epoch: 130, Loss: 75.3527, Train: 90.55%, Valid: 83.75%, Test: 86.85%\n",
            "Epoch: 135, Loss: 74.0831, Train: 90.77%, Valid: 83.60%, Test: 87.74%\n",
            "Epoch: 140, Loss: 73.2892, Train: 90.84%, Valid: 83.16%, Test: 87.30%\n",
            "Epoch: 145, Loss: 73.1808, Train: 90.99%, Valid: 83.01%, Test: 87.30%\n",
            "Epoch: 150, Loss: 73.0525, Train: 90.92%, Valid: 82.72%, Test: 87.59%\n",
            "Epoch: 155, Loss: 73.2863, Train: 90.92%, Valid: 83.31%, Test: 87.30%\n",
            "Epoch: 160, Loss: 72.9663, Train: 91.06%, Valid: 83.01%, Test: 87.89%\n",
            "Epoch: 165, Loss: 72.8850, Train: 91.29%, Valid: 82.87%, Test: 88.18%\n",
            "Epoch: 170, Loss: 72.2374, Train: 90.92%, Valid: 82.42%, Test: 87.44%\n",
            "Epoch: 175, Loss: 72.1028, Train: 91.21%, Valid: 83.01%, Test: 88.18%\n",
            "Epoch: 180, Loss: 72.6816, Train: 91.29%, Valid: 83.01%, Test: 87.44%\n",
            "Epoch: 185, Loss: 72.3009, Train: 91.29%, Valid: 82.72%, Test: 88.18%\n",
            "Epoch: 190, Loss: 71.6553, Train: 91.21%, Valid: 83.16%, Test: 87.15%\n",
            "Epoch: 195, Loss: 72.2433, Train: 91.51%, Valid: 83.16%, Test: 87.74%\n",
            "Run 04:\n",
            "Highest Train: 91.88\n",
            "Highest Valid: 83.75\n",
            "Highest Test: 88.33\n",
            "Chosen epoch: 131\n",
            "Final Train: 90.55\n",
            "Final Test: 86.85\n",
            "Epoch: 00, Loss: 228.5763, Train: 24.15%, Valid: 25.85%, Test: 23.34%\n",
            "Epoch: 05, Loss: 153.0133, Train: 42.17%, Valid: 44.31%, Test: 41.36%\n",
            "Epoch: 10, Loss: 137.7126, Train: 51.92%, Valid: 49.19%, Test: 50.66%\n",
            "Epoch: 15, Loss: 128.3604, Train: 55.83%, Valid: 53.03%, Test: 55.54%\n",
            "Epoch: 20, Loss: 121.6765, Train: 63.88%, Valid: 61.15%, Test: 65.88%\n",
            "Epoch: 25, Loss: 116.5270, Train: 70.09%, Valid: 66.91%, Test: 70.90%\n",
            "Epoch: 30, Loss: 111.9388, Train: 73.63%, Valid: 70.31%, Test: 75.04%\n",
            "Epoch: 35, Loss: 107.9443, Train: 78.06%, Valid: 74.30%, Test: 77.84%\n",
            "Epoch: 40, Loss: 104.5768, Train: 79.99%, Valid: 75.33%, Test: 80.50%\n",
            "Epoch: 45, Loss: 101.7514, Train: 81.91%, Valid: 76.66%, Test: 81.54%\n",
            "Epoch: 50, Loss: 99.1720, Train: 83.16%, Valid: 79.17%, Test: 84.34%\n",
            "Epoch: 55, Loss: 96.9342, Train: 84.12%, Valid: 79.91%, Test: 84.64%\n",
            "Epoch: 60, Loss: 94.8819, Train: 85.23%, Valid: 81.24%, Test: 84.93%\n",
            "Epoch: 65, Loss: 93.0391, Train: 85.89%, Valid: 81.54%, Test: 84.79%\n",
            "Epoch: 70, Loss: 91.3316, Train: 86.04%, Valid: 82.57%, Test: 85.97%\n",
            "Epoch: 75, Loss: 89.7498, Train: 86.63%, Valid: 83.01%, Test: 86.12%\n",
            "Epoch: 80, Loss: 88.3564, Train: 87.22%, Valid: 82.87%, Test: 86.85%\n",
            "Epoch: 85, Loss: 86.9678, Train: 87.52%, Valid: 82.87%, Test: 87.00%\n",
            "Epoch: 90, Loss: 85.6929, Train: 87.81%, Valid: 82.72%, Test: 87.00%\n",
            "Epoch: 95, Loss: 84.4772, Train: 88.40%, Valid: 83.01%, Test: 86.71%\n",
            "Epoch: 100, Loss: 83.4956, Train: 88.77%, Valid: 83.46%, Test: 87.89%\n",
            "Epoch: 105, Loss: 82.8265, Train: 88.77%, Valid: 83.31%, Test: 87.59%\n",
            "Epoch: 110, Loss: 81.9811, Train: 88.77%, Valid: 83.75%, Test: 87.44%\n",
            "Epoch: 115, Loss: 80.9818, Train: 89.29%, Valid: 83.75%, Test: 87.44%\n",
            "Epoch: 120, Loss: 80.2571, Train: 89.29%, Valid: 83.60%, Test: 87.74%\n",
            "Epoch: 125, Loss: 80.4262, Train: 89.59%, Valid: 83.75%, Test: 87.89%\n",
            "Epoch: 130, Loss: 79.4587, Train: 88.92%, Valid: 83.90%, Test: 87.74%\n",
            "Epoch: 135, Loss: 79.0909, Train: 89.59%, Valid: 84.05%, Test: 87.59%\n",
            "Epoch: 140, Loss: 78.8478, Train: 89.73%, Valid: 83.31%, Test: 87.30%\n",
            "Epoch: 145, Loss: 79.3242, Train: 89.88%, Valid: 83.90%, Test: 87.89%\n",
            "Epoch: 150, Loss: 78.1315, Train: 89.73%, Valid: 83.46%, Test: 88.04%\n",
            "Epoch: 155, Loss: 77.6557, Train: 90.47%, Valid: 84.19%, Test: 88.18%\n",
            "Epoch: 160, Loss: 77.1675, Train: 90.62%, Valid: 83.90%, Test: 88.48%\n",
            "Epoch: 165, Loss: 77.5303, Train: 90.47%, Valid: 84.49%, Test: 88.33%\n",
            "Epoch: 170, Loss: 76.9647, Train: 90.55%, Valid: 83.90%, Test: 88.33%\n",
            "Epoch: 175, Loss: 76.8490, Train: 91.21%, Valid: 84.05%, Test: 88.04%\n",
            "Epoch: 180, Loss: 76.4391, Train: 90.69%, Valid: 84.19%, Test: 88.04%\n",
            "Epoch: 185, Loss: 77.0916, Train: 90.99%, Valid: 83.75%, Test: 88.04%\n",
            "Epoch: 190, Loss: 76.3858, Train: 91.14%, Valid: 84.79%, Test: 88.18%\n",
            "Epoch: 195, Loss: 75.7863, Train: 91.51%, Valid: 84.19%, Test: 87.59%\n",
            "Run 05:\n",
            "Highest Train: 91.73\n",
            "Highest Valid: 84.79\n",
            "Highest Test: 88.92\n",
            "Chosen epoch: 191\n",
            "Final Train: 91.14\n",
            "Final Test: 88.18\n",
            "All runs:\n",
            "Highest Train: 90.97 ± 0.91\n",
            "Highest Test: 88.24 ± 0.51\n",
            "Highest Valid: 84.52 ± 0.51\n",
            "  Final Train: 90.22 ± 0.66\n",
            "   Final Test: 87.36 ± 0.56\n",
            "Saving results to logs/cora_edge.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 GKD/main.py --dataset cora--rand_split --use_bn --base_model gcn --mode train --priv_type edge --dist_mode gkd --use_kd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfFE-N_1GOKe",
        "outputId": "82f1a935-66a7-45e9-81d7-ee89ebb31a5a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(data_dir='data', dataset='cora--rand_split', sub_dataset='', cpu=False, seed=42, train_prop=0.5, valid_prop=0.25, protocol='semi', rand_split=False, metric='acc', runs=5, epochs=200, hidden_channels=32, num_layers=3, gat_heads=8, out_heads=1, hops=1, lp_alpha=0.1, gpr_alpha=0.1, jk_type='max', directed=False, num_mlp_layers=1, display_step=5, cached=False, print_prop=False, priv_type='edge', priv_ratio=0.5, save_model=False, save_name='gcn', log_name='none', base_model='gcn', not_load_teacher=False, mode='train', dist_mode='gkd', weight_decay=0.05, dropout=0.0, lr=0.01, use_bn=True, use_batch=False, batch_size=2048, oracle=False, device=0, alpha=0.5, delta=0.1, use_kd=True, beta=0.0, tau=1.0, kernel='sigmoid', t=1.0, include_last=False, s=2, m=1, lr2=0.001, sim='l2', ker_norm=False)\n",
            "cuda:0\n",
            "cora--rand_split\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/GKD/main.py\", line 47, in <module>\n",
            "    dataset = load_nc_dataset(args.dataset, args.sub_dataset, args.data_dir)\n",
            "  File \"/content/GKD/dataset.py\", line 123, in load_nc_dataset\n",
            "    raise ValueError('Invalid dataname')\n",
            "ValueError: Invalid dataname\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 GKD/main.py --dataset cora --rand_split --use_bn --base_model gcn --mode train --priv_type edge --dist_mode gkd --use_kd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Za2QOrLGSIO",
        "outputId": "520a63e7-9ac1-442c-bd9e-c317349f08e5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(data_dir='data', dataset='cora', sub_dataset='', cpu=False, seed=42, train_prop=0.5, valid_prop=0.25, protocol='semi', rand_split=True, metric='acc', runs=5, epochs=200, hidden_channels=32, num_layers=3, gat_heads=8, out_heads=1, hops=1, lp_alpha=0.1, gpr_alpha=0.1, jk_type='max', directed=False, num_mlp_layers=1, display_step=5, cached=False, print_prop=False, priv_type='edge', priv_ratio=0.5, save_model=False, save_name='gcn', log_name='none', base_model='gcn', not_load_teacher=False, mode='train', dist_mode='gkd', weight_decay=0.05, dropout=0.0, lr=0.01, use_bn=True, use_batch=False, batch_size=2048, oracle=False, device=0, alpha=0.5, delta=0.1, use_kd=True, beta=0.0, tau=1.0, kernel='sigmoid', t=1.0, include_last=False, s=2, m=1, lr2=0.001, sim='l2', ker_norm=False)\n",
            "cuda:0\n",
            "cora\n",
            "Num nodes: 2708\n",
            "torch.Size([2708, 1])\n",
            "num nodes 2708 | num classes 7 | num node feats 1433\n",
            "MODEL: GeoDist(\n",
            "  (k): Kernel(\n",
            "    (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  )\n",
            "  (teacher_gnn): ModuleList(\n",
            "    (0): Linear(in_features=1433, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (student_gnn): ModuleList(\n",
            "    (0): Linear(in_features=1433, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  (bns2d): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            ")\n",
            "Epoch: 00, Loss: 580697.3750, Train: 32.57%, Valid: 29.84%, Test: 26.88%\n",
            "Epoch: 05, Loss: 145588.3125, Train: 38.63%, Valid: 34.27%, Test: 38.55%\n",
            "Epoch: 10, Loss: 112488.2891, Train: 56.13%, Valid: 51.99%, Test: 54.80%\n",
            "Epoch: 15, Loss: 94836.8984, Train: 64.03%, Valid: 60.12%, Test: 64.70%\n",
            "Epoch: 20, Loss: 84084.3594, Train: 69.94%, Valid: 66.17%, Test: 71.20%\n",
            "Epoch: 25, Loss: 76261.1719, Train: 78.29%, Valid: 74.30%, Test: 78.43%\n",
            "Epoch: 30, Loss: 70379.8750, Train: 84.79%, Valid: 80.50%, Test: 84.49%\n",
            "Epoch: 35, Loss: 65676.4609, Train: 87.15%, Valid: 82.13%, Test: 87.15%\n",
            "Epoch: 40, Loss: 61899.3359, Train: 88.55%, Valid: 82.13%, Test: 88.04%\n",
            "Epoch: 45, Loss: 58711.6953, Train: 88.55%, Valid: 83.01%, Test: 87.74%\n",
            "Epoch: 50, Loss: 55978.4609, Train: 89.44%, Valid: 83.46%, Test: 87.59%\n",
            "Epoch: 55, Loss: 53563.4023, Train: 89.73%, Valid: 83.75%, Test: 87.74%\n",
            "Epoch: 60, Loss: 51456.7109, Train: 90.03%, Valid: 83.90%, Test: 87.59%\n",
            "Epoch: 65, Loss: 49592.6836, Train: 90.18%, Valid: 83.60%, Test: 87.59%\n",
            "Epoch: 70, Loss: 47910.6406, Train: 90.62%, Valid: 83.31%, Test: 87.30%\n",
            "Epoch: 75, Loss: 46398.8984, Train: 90.84%, Valid: 83.46%, Test: 87.59%\n",
            "Epoch: 80, Loss: 45012.3906, Train: 90.62%, Valid: 83.60%, Test: 87.59%\n",
            "Epoch: 85, Loss: 43766.2500, Train: 90.77%, Valid: 83.90%, Test: 87.59%\n",
            "Epoch: 90, Loss: 42619.4023, Train: 90.99%, Valid: 84.05%, Test: 87.59%\n",
            "Epoch: 95, Loss: 41674.4883, Train: 91.21%, Valid: 84.05%, Test: 87.44%\n",
            "Epoch: 100, Loss: 40720.0117, Train: 91.14%, Valid: 83.90%, Test: 87.74%\n",
            "Epoch: 105, Loss: 39744.2617, Train: 91.14%, Valid: 83.60%, Test: 87.89%\n",
            "Epoch: 110, Loss: 38823.6211, Train: 91.14%, Valid: 83.01%, Test: 87.74%\n",
            "Epoch: 115, Loss: 38052.3125, Train: 91.14%, Valid: 83.16%, Test: 87.59%\n",
            "Epoch: 120, Loss: 37303.5312, Train: 91.21%, Valid: 83.01%, Test: 87.59%\n",
            "Epoch: 125, Loss: 36582.8945, Train: 91.29%, Valid: 82.87%, Test: 88.04%\n",
            "Epoch: 130, Loss: 35986.1250, Train: 91.14%, Valid: 82.87%, Test: 88.04%\n",
            "Epoch: 135, Loss: 35328.0859, Train: 91.29%, Valid: 83.01%, Test: 88.04%\n",
            "Epoch: 140, Loss: 34783.0820, Train: 91.43%, Valid: 82.42%, Test: 88.04%\n",
            "Epoch: 145, Loss: 34336.3281, Train: 91.43%, Valid: 82.87%, Test: 88.04%\n",
            "Epoch: 150, Loss: 33877.7461, Train: 91.21%, Valid: 82.87%, Test: 88.18%\n",
            "Epoch: 155, Loss: 33375.7969, Train: 91.21%, Valid: 83.16%, Test: 88.18%\n",
            "Epoch: 160, Loss: 32877.9414, Train: 91.21%, Valid: 83.16%, Test: 88.18%\n",
            "Epoch: 165, Loss: 32337.5625, Train: 91.14%, Valid: 83.16%, Test: 88.18%\n",
            "Epoch: 170, Loss: 31926.2637, Train: 91.06%, Valid: 83.01%, Test: 88.33%\n",
            "Epoch: 175, Loss: 31737.8027, Train: 91.21%, Valid: 83.01%, Test: 88.33%\n",
            "Epoch: 180, Loss: 31544.1777, Train: 90.99%, Valid: 82.87%, Test: 88.48%\n",
            "Epoch: 185, Loss: 31233.4863, Train: 91.29%, Valid: 82.72%, Test: 88.63%\n",
            "Epoch: 190, Loss: 30780.9121, Train: 91.06%, Valid: 83.16%, Test: 88.48%\n",
            "Epoch: 195, Loss: 30454.9648, Train: 91.14%, Valid: 83.01%, Test: 88.33%\n",
            "Run 01:\n",
            "Highest Train: 91.43\n",
            "Highest Valid: 84.19\n",
            "Highest Test: 88.63\n",
            "Chosen epoch: 93\n",
            "Final Train: 90.99\n",
            "Final Test: 87.59\n",
            "Epoch: 00, Loss: 581394.8750, Train: 17.28%, Valid: 14.77%, Test: 15.07%\n",
            "Epoch: 05, Loss: 139934.3281, Train: 29.84%, Valid: 24.08%, Test: 25.85%\n",
            "Epoch: 10, Loss: 107692.4375, Train: 43.35%, Valid: 38.11%, Test: 38.40%\n",
            "Epoch: 15, Loss: 92026.6484, Train: 56.79%, Valid: 49.63%, Test: 51.70%\n",
            "Epoch: 20, Loss: 82127.8203, Train: 74.30%, Valid: 68.24%, Test: 71.05%\n",
            "Epoch: 25, Loss: 75027.1875, Train: 84.71%, Valid: 79.91%, Test: 83.46%\n",
            "Epoch: 30, Loss: 69429.9688, Train: 88.85%, Valid: 82.13%, Test: 86.56%\n",
            "Epoch: 35, Loss: 64889.2305, Train: 89.44%, Valid: 82.72%, Test: 87.30%\n",
            "Epoch: 40, Loss: 61174.9102, Train: 89.73%, Valid: 82.57%, Test: 87.30%\n",
            "Epoch: 45, Loss: 57917.3672, Train: 89.96%, Valid: 82.87%, Test: 87.30%\n",
            "Epoch: 50, Loss: 55175.2031, Train: 90.18%, Valid: 83.01%, Test: 87.59%\n",
            "Epoch: 55, Loss: 52769.7969, Train: 90.25%, Valid: 83.60%, Test: 87.89%\n",
            "Epoch: 60, Loss: 50641.6523, Train: 90.47%, Valid: 83.31%, Test: 88.04%\n",
            "Epoch: 65, Loss: 48765.0625, Train: 90.55%, Valid: 83.31%, Test: 87.89%\n",
            "Epoch: 70, Loss: 47074.6602, Train: 90.99%, Valid: 83.01%, Test: 88.48%\n",
            "Epoch: 75, Loss: 45565.7266, Train: 90.99%, Valid: 83.60%, Test: 88.33%\n",
            "Epoch: 80, Loss: 44192.6680, Train: 91.14%, Valid: 83.60%, Test: 88.33%\n",
            "Epoch: 85, Loss: 42941.2812, Train: 91.14%, Valid: 83.60%, Test: 88.04%\n",
            "Epoch: 90, Loss: 41787.8008, Train: 91.29%, Valid: 83.90%, Test: 88.04%\n",
            "Epoch: 95, Loss: 40718.8789, Train: 91.21%, Valid: 84.05%, Test: 88.04%\n",
            "Epoch: 100, Loss: 39742.5469, Train: 91.29%, Valid: 84.05%, Test: 88.04%\n",
            "Epoch: 105, Loss: 38907.8008, Train: 91.29%, Valid: 84.05%, Test: 87.59%\n",
            "Epoch: 110, Loss: 38007.5117, Train: 91.21%, Valid: 83.75%, Test: 87.59%\n",
            "Epoch: 115, Loss: 37291.2930, Train: 91.14%, Valid: 83.75%, Test: 87.74%\n",
            "Epoch: 120, Loss: 36544.8711, Train: 91.14%, Valid: 83.75%, Test: 87.89%\n",
            "Epoch: 125, Loss: 35848.4062, Train: 91.21%, Valid: 83.75%, Test: 87.89%\n",
            "Epoch: 130, Loss: 35173.9727, Train: 91.29%, Valid: 83.60%, Test: 88.18%\n",
            "Epoch: 135, Loss: 34625.2305, Train: 91.29%, Valid: 83.75%, Test: 88.33%\n",
            "Epoch: 140, Loss: 33996.8477, Train: 91.36%, Valid: 83.90%, Test: 88.33%\n",
            "Epoch: 145, Loss: 33474.1445, Train: 91.29%, Valid: 83.90%, Test: 88.48%\n",
            "Epoch: 150, Loss: 33496.6133, Train: 91.14%, Valid: 83.46%, Test: 88.33%\n",
            "Epoch: 155, Loss: 32654.4414, Train: 90.99%, Valid: 83.60%, Test: 88.33%\n",
            "Epoch: 160, Loss: 32090.0938, Train: 90.99%, Valid: 83.60%, Test: 88.33%\n",
            "Epoch: 165, Loss: 31827.5703, Train: 91.14%, Valid: 84.05%, Test: 88.48%\n",
            "Epoch: 170, Loss: 31400.4082, Train: 91.21%, Valid: 83.75%, Test: 88.77%\n",
            "Epoch: 175, Loss: 31141.2715, Train: 91.36%, Valid: 83.75%, Test: 88.77%\n",
            "Epoch: 180, Loss: 30810.3945, Train: 91.29%, Valid: 83.75%, Test: 88.63%\n",
            "Epoch: 185, Loss: 30362.9258, Train: 91.43%, Valid: 83.60%, Test: 88.63%\n",
            "Epoch: 190, Loss: 30001.9727, Train: 91.43%, Valid: 83.46%, Test: 88.63%\n",
            "Epoch: 195, Loss: 29964.4941, Train: 91.51%, Valid: 83.60%, Test: 88.63%\n",
            "Run 02:\n",
            "Highest Train: 91.58\n",
            "Highest Valid: 84.19\n",
            "Highest Test: 88.92\n",
            "Chosen epoch: 150\n",
            "Final Train: 91.14\n",
            "Final Test: 88.48\n",
            "Epoch: 00, Loss: 577275.9375, Train: 9.60%, Valid: 6.35%, Test: 9.75%\n",
            "Epoch: 05, Loss: 148441.1875, Train: 31.39%, Valid: 24.22%, Test: 30.87%\n",
            "Epoch: 10, Loss: 115764.7344, Train: 42.61%, Valid: 33.68%, Test: 39.00%\n",
            "Epoch: 15, Loss: 99384.2500, Train: 46.45%, Valid: 39.00%, Test: 42.84%\n",
            "Epoch: 20, Loss: 89416.3594, Train: 61.08%, Valid: 55.54%, Test: 59.68%\n",
            "Epoch: 25, Loss: 81932.2812, Train: 75.70%, Valid: 70.46%, Test: 75.48%\n",
            "Epoch: 30, Loss: 75967.8672, Train: 81.24%, Valid: 75.04%, Test: 80.95%\n",
            "Epoch: 35, Loss: 71317.8047, Train: 82.72%, Valid: 77.25%, Test: 82.72%\n",
            "Epoch: 40, Loss: 67432.6250, Train: 85.16%, Valid: 79.32%, Test: 83.46%\n",
            "Epoch: 45, Loss: 64139.3086, Train: 86.71%, Valid: 80.95%, Test: 85.52%\n",
            "Epoch: 50, Loss: 61313.1562, Train: 87.59%, Valid: 82.27%, Test: 86.12%\n",
            "Epoch: 55, Loss: 58871.7539, Train: 87.74%, Valid: 82.42%, Test: 86.71%\n",
            "Epoch: 60, Loss: 56725.2422, Train: 87.96%, Valid: 81.83%, Test: 86.56%\n",
            "Epoch: 65, Loss: 54818.1367, Train: 88.11%, Valid: 81.68%, Test: 87.00%\n",
            "Epoch: 70, Loss: 53092.1914, Train: 88.18%, Valid: 81.83%, Test: 86.85%\n",
            "Epoch: 75, Loss: 51507.2695, Train: 88.40%, Valid: 82.27%, Test: 87.15%\n",
            "Epoch: 80, Loss: 50066.6836, Train: 88.63%, Valid: 82.57%, Test: 87.59%\n",
            "Epoch: 85, Loss: 48749.1797, Train: 88.85%, Valid: 82.42%, Test: 87.15%\n",
            "Epoch: 90, Loss: 47539.4062, Train: 89.07%, Valid: 82.57%, Test: 87.15%\n",
            "Epoch: 95, Loss: 46422.6016, Train: 89.07%, Valid: 82.57%, Test: 87.30%\n",
            "Epoch: 100, Loss: 45388.2461, Train: 89.22%, Valid: 82.13%, Test: 87.15%\n",
            "Epoch: 105, Loss: 44426.9297, Train: 89.07%, Valid: 82.13%, Test: 87.15%\n",
            "Epoch: 110, Loss: 43528.9648, Train: 89.22%, Valid: 81.83%, Test: 87.00%\n",
            "Epoch: 115, Loss: 42693.1172, Train: 89.29%, Valid: 82.13%, Test: 86.71%\n",
            "Epoch: 120, Loss: 41911.2969, Train: 89.44%, Valid: 82.13%, Test: 87.15%\n",
            "Epoch: 125, Loss: 41172.7500, Train: 89.51%, Valid: 82.13%, Test: 87.15%\n",
            "Epoch: 130, Loss: 40612.8555, Train: 89.59%, Valid: 82.13%, Test: 86.85%\n",
            "Epoch: 135, Loss: 39882.5391, Train: 89.51%, Valid: 82.13%, Test: 87.00%\n",
            "Epoch: 140, Loss: 39294.4688, Train: 89.51%, Valid: 82.27%, Test: 87.30%\n",
            "Epoch: 145, Loss: 38724.4648, Train: 89.44%, Valid: 82.42%, Test: 87.00%\n",
            "Epoch: 150, Loss: 38102.4922, Train: 89.44%, Valid: 82.13%, Test: 87.00%\n",
            "Epoch: 155, Loss: 37612.0000, Train: 89.44%, Valid: 82.27%, Test: 86.85%\n",
            "Epoch: 160, Loss: 37492.8516, Train: 89.44%, Valid: 81.98%, Test: 86.85%\n",
            "Epoch: 165, Loss: 37023.0742, Train: 89.44%, Valid: 82.27%, Test: 86.85%\n",
            "Epoch: 170, Loss: 36497.4531, Train: 89.36%, Valid: 82.57%, Test: 86.85%\n",
            "Epoch: 175, Loss: 36034.6953, Train: 89.36%, Valid: 82.72%, Test: 86.85%\n",
            "Epoch: 180, Loss: 35590.7695, Train: 89.36%, Valid: 82.42%, Test: 86.85%\n",
            "Epoch: 185, Loss: 35627.5625, Train: 89.59%, Valid: 82.42%, Test: 87.15%\n",
            "Epoch: 190, Loss: 35088.2656, Train: 89.59%, Valid: 82.27%, Test: 87.44%\n",
            "Epoch: 195, Loss: 34796.6211, Train: 89.51%, Valid: 82.42%, Test: 87.44%\n",
            "Run 03:\n",
            "Highest Train: 89.66\n",
            "Highest Valid: 82.72\n",
            "Highest Test: 87.59\n",
            "Chosen epoch: 176\n",
            "Final Train: 89.36\n",
            "Final Test: 86.85\n",
            "Epoch: 00, Loss: 580695.2500, Train: 9.90%, Valid: 7.68%, Test: 8.27%\n",
            "Epoch: 05, Loss: 154034.0156, Train: 19.57%, Valid: 19.20%, Test: 17.43%\n",
            "Epoch: 10, Loss: 118971.6328, Train: 36.93%, Valid: 34.86%, Test: 32.94%\n",
            "Epoch: 15, Loss: 101694.6094, Train: 60.93%, Valid: 55.54%, Test: 55.54%\n",
            "Epoch: 20, Loss: 90536.9375, Train: 72.82%, Valid: 66.03%, Test: 68.24%\n",
            "Epoch: 25, Loss: 82340.7891, Train: 78.43%, Valid: 71.20%, Test: 74.00%\n",
            "Epoch: 30, Loss: 76058.8516, Train: 82.13%, Valid: 74.15%, Test: 78.43%\n",
            "Epoch: 35, Loss: 71044.7891, Train: 83.53%, Valid: 75.63%, Test: 80.65%\n",
            "Epoch: 40, Loss: 66849.1641, Train: 85.60%, Valid: 77.55%, Test: 82.13%\n",
            "Epoch: 45, Loss: 63313.5938, Train: 87.74%, Valid: 80.35%, Test: 84.79%\n",
            "Epoch: 50, Loss: 60281.3867, Train: 88.48%, Valid: 81.68%, Test: 85.67%\n",
            "Epoch: 55, Loss: 57661.9297, Train: 89.00%, Valid: 81.83%, Test: 86.71%\n",
            "Epoch: 60, Loss: 55383.8477, Train: 89.59%, Valid: 82.27%, Test: 87.15%\n",
            "Epoch: 65, Loss: 53369.9062, Train: 89.96%, Valid: 82.57%, Test: 87.15%\n",
            "Epoch: 70, Loss: 51558.3945, Train: 90.25%, Valid: 82.87%, Test: 87.30%\n",
            "Epoch: 75, Loss: 49931.1172, Train: 90.40%, Valid: 82.72%, Test: 88.04%\n",
            "Epoch: 80, Loss: 48473.6602, Train: 90.32%, Valid: 82.72%, Test: 88.04%\n",
            "Epoch: 85, Loss: 47139.8867, Train: 90.40%, Valid: 82.72%, Test: 88.04%\n",
            "Epoch: 90, Loss: 45924.3828, Train: 90.62%, Valid: 82.57%, Test: 87.89%\n",
            "Epoch: 95, Loss: 44809.4180, Train: 90.77%, Valid: 82.72%, Test: 87.89%\n",
            "Epoch: 100, Loss: 43778.0195, Train: 91.06%, Valid: 82.72%, Test: 87.89%\n",
            "Epoch: 105, Loss: 42814.9102, Train: 91.06%, Valid: 82.87%, Test: 87.89%\n",
            "Epoch: 110, Loss: 41924.7070, Train: 91.06%, Valid: 82.87%, Test: 88.04%\n",
            "Epoch: 115, Loss: 41096.3633, Train: 90.92%, Valid: 82.87%, Test: 88.04%\n",
            "Epoch: 120, Loss: 40320.0586, Train: 90.99%, Valid: 83.01%, Test: 87.89%\n",
            "Epoch: 125, Loss: 39591.5664, Train: 91.21%, Valid: 83.31%, Test: 87.89%\n",
            "Epoch: 130, Loss: 38910.9531, Train: 91.36%, Valid: 83.60%, Test: 88.04%\n",
            "Epoch: 135, Loss: 38268.1914, Train: 91.36%, Valid: 83.31%, Test: 88.04%\n",
            "Epoch: 140, Loss: 37706.8633, Train: 91.21%, Valid: 83.46%, Test: 88.04%\n",
            "Epoch: 145, Loss: 37229.4766, Train: 91.14%, Valid: 83.31%, Test: 88.04%\n",
            "Epoch: 150, Loss: 36726.5352, Train: 91.29%, Valid: 83.46%, Test: 88.18%\n",
            "Epoch: 155, Loss: 36182.3516, Train: 91.43%, Valid: 83.46%, Test: 88.18%\n",
            "Epoch: 160, Loss: 35785.8711, Train: 91.51%, Valid: 83.31%, Test: 88.18%\n",
            "Epoch: 165, Loss: 35354.0234, Train: 91.51%, Valid: 83.16%, Test: 88.18%\n",
            "Epoch: 170, Loss: 34918.3555, Train: 91.51%, Valid: 82.87%, Test: 88.18%\n",
            "Epoch: 175, Loss: 34502.1562, Train: 91.36%, Valid: 82.72%, Test: 88.04%\n",
            "Epoch: 180, Loss: 34239.8320, Train: 91.43%, Valid: 82.57%, Test: 88.04%\n",
            "Epoch: 185, Loss: 33787.7383, Train: 91.51%, Valid: 82.42%, Test: 88.04%\n",
            "Epoch: 190, Loss: 33391.8828, Train: 91.36%, Valid: 82.72%, Test: 87.89%\n",
            "Epoch: 195, Loss: 33126.9297, Train: 91.43%, Valid: 82.87%, Test: 88.04%\n",
            "Run 04:\n",
            "Highest Train: 91.73\n",
            "Highest Valid: 83.60\n",
            "Highest Test: 88.33\n",
            "Chosen epoch: 130\n",
            "Final Train: 91.21\n",
            "Final Test: 88.04\n",
            "Epoch: 00, Loss: 579095.8125, Train: 22.38%, Valid: 22.90%, Test: 21.86%\n",
            "Epoch: 05, Loss: 167397.9531, Train: 29.17%, Valid: 32.79%, Test: 29.69%\n",
            "Epoch: 10, Loss: 127774.9844, Train: 41.29%, Valid: 40.92%, Test: 39.29%\n",
            "Epoch: 15, Loss: 108167.0391, Train: 60.78%, Valid: 56.28%, Test: 57.02%\n",
            "Epoch: 20, Loss: 95727.7969, Train: 71.20%, Valid: 67.95%, Test: 69.42%\n",
            "Epoch: 25, Loss: 86452.3594, Train: 78.14%, Valid: 71.20%, Test: 76.51%\n",
            "Epoch: 30, Loss: 79332.0078, Train: 83.09%, Valid: 76.37%, Test: 80.95%\n",
            "Epoch: 35, Loss: 73537.8750, Train: 84.79%, Valid: 77.84%, Test: 82.42%\n",
            "Epoch: 40, Loss: 68735.4375, Train: 87.52%, Valid: 79.47%, Test: 85.38%\n",
            "Epoch: 45, Loss: 64773.0820, Train: 89.29%, Valid: 81.24%, Test: 87.44%\n",
            "Epoch: 50, Loss: 61321.5742, Train: 89.88%, Valid: 82.57%, Test: 88.33%\n",
            "Epoch: 55, Loss: 58367.6094, Train: 90.92%, Valid: 83.60%, Test: 88.63%\n",
            "Epoch: 60, Loss: 55807.7383, Train: 91.21%, Valid: 83.90%, Test: 89.07%\n",
            "Epoch: 65, Loss: 53586.8711, Train: 91.29%, Valid: 84.19%, Test: 89.36%\n",
            "Epoch: 70, Loss: 51617.4297, Train: 91.36%, Valid: 84.19%, Test: 89.07%\n",
            "Epoch: 75, Loss: 49838.1445, Train: 91.36%, Valid: 84.19%, Test: 89.36%\n",
            "Epoch: 80, Loss: 48275.7500, Train: 91.73%, Valid: 84.05%, Test: 89.22%\n",
            "Epoch: 85, Loss: 46886.7773, Train: 91.80%, Valid: 84.05%, Test: 89.22%\n",
            "Epoch: 90, Loss: 45613.1250, Train: 91.73%, Valid: 83.75%, Test: 89.22%\n",
            "Epoch: 95, Loss: 44471.6367, Train: 91.73%, Valid: 83.90%, Test: 89.36%\n",
            "Epoch: 100, Loss: 43666.0352, Train: 91.88%, Valid: 83.75%, Test: 89.51%\n",
            "Epoch: 105, Loss: 42648.3672, Train: 92.10%, Valid: 83.75%, Test: 89.22%\n",
            "Epoch: 110, Loss: 41696.6914, Train: 92.02%, Valid: 83.60%, Test: 89.22%\n",
            "Epoch: 115, Loss: 40825.8711, Train: 92.17%, Valid: 83.75%, Test: 89.22%\n",
            "Epoch: 120, Loss: 40098.0977, Train: 92.25%, Valid: 83.75%, Test: 89.07%\n",
            "Epoch: 125, Loss: 39267.2812, Train: 92.02%, Valid: 83.75%, Test: 89.07%\n",
            "Epoch: 130, Loss: 38748.3281, Train: 92.02%, Valid: 83.90%, Test: 89.07%\n",
            "Epoch: 135, Loss: 37969.3828, Train: 92.39%, Valid: 83.90%, Test: 89.07%\n",
            "Epoch: 140, Loss: 37660.8398, Train: 92.39%, Valid: 83.46%, Test: 89.07%\n",
            "Epoch: 145, Loss: 37075.3672, Train: 92.47%, Valid: 83.60%, Test: 89.51%\n",
            "Epoch: 150, Loss: 36480.2891, Train: 92.47%, Valid: 83.60%, Test: 89.22%\n",
            "Epoch: 155, Loss: 35800.1250, Train: 92.39%, Valid: 83.60%, Test: 89.07%\n",
            "Epoch: 160, Loss: 35794.5859, Train: 92.47%, Valid: 83.60%, Test: 89.07%\n",
            "Epoch: 165, Loss: 35226.7188, Train: 92.32%, Valid: 83.60%, Test: 89.07%\n",
            "Epoch: 170, Loss: 34789.8750, Train: 92.32%, Valid: 83.46%, Test: 89.36%\n",
            "Epoch: 175, Loss: 34492.4062, Train: 92.39%, Valid: 83.46%, Test: 89.36%\n",
            "Epoch: 180, Loss: 33869.4297, Train: 92.47%, Valid: 83.31%, Test: 89.22%\n",
            "Epoch: 185, Loss: 33654.3281, Train: 92.39%, Valid: 83.16%, Test: 89.36%\n",
            "Epoch: 190, Loss: 33602.8555, Train: 92.25%, Valid: 83.16%, Test: 88.92%\n",
            "Epoch: 195, Loss: 32940.4883, Train: 92.39%, Valid: 83.16%, Test: 89.07%\n",
            "Run 05:\n",
            "Highest Train: 92.61\n",
            "Highest Valid: 84.34\n",
            "Highest Test: 89.51\n",
            "Chosen epoch: 72\n",
            "Final Train: 91.29\n",
            "Final Test: 89.07\n",
            "All runs:\n",
            "Highest Train: 91.40 ± 1.08\n",
            "Highest Test: 88.60 ± 0.71\n",
            "Highest Valid: 83.81 ± 0.67\n",
            "  Final Train: 90.80 ± 0.81\n",
            "   Final Test: 88.01 ± 0.84\n",
            "Saving results to logs/cora_edge.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 GKD/main.py --dataset cora --rand_split --use_bn --base_model gcn --mode train --priv_type edge --dist_mode pgkd --use_kd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SfGE5k1GURc",
        "outputId": "31ea3129-f191-4fc2-cbb4-53a523c30afa"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(data_dir='data', dataset='cora', sub_dataset='', cpu=False, seed=42, train_prop=0.5, valid_prop=0.25, protocol='semi', rand_split=True, metric='acc', runs=5, epochs=200, hidden_channels=32, num_layers=3, gat_heads=8, out_heads=1, hops=1, lp_alpha=0.1, gpr_alpha=0.1, jk_type='max', directed=False, num_mlp_layers=1, display_step=5, cached=False, print_prop=False, priv_type='edge', priv_ratio=0.5, save_model=False, save_name='gcn', log_name='none', base_model='gcn', not_load_teacher=False, mode='train', dist_mode='pgkd', weight_decay=0.05, dropout=0.0, lr=0.01, use_bn=True, use_batch=False, batch_size=2048, oracle=False, device=0, alpha=0.5, delta=0.1, use_kd=True, beta=0.0, tau=1.0, kernel='sigmoid', t=1.0, include_last=False, s=2, m=1, lr2=0.001, sim='l2', ker_norm=False)\n",
            "cuda:0\n",
            "cora\n",
            "Num nodes: 2708\n",
            "torch.Size([2708, 1])\n",
            "num nodes 2708 | num classes 7 | num node feats 1433\n",
            "MODEL: GeoDist(\n",
            "  (k): Kernel(\n",
            "    (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  )\n",
            "  (teacher_gnn): ModuleList(\n",
            "    (0): Linear(in_features=1433, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (student_gnn): ModuleList(\n",
            "    (0): Linear(in_features=1433, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  (bns2d): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            ")\n",
            "Epoch: 00, Loss: 69602560.0000, Train: 29.69%, Valid: 26.44%, Test: 25.70%\n",
            "Epoch: 05, Loss: 16549491.0000, Train: 34.93%, Valid: 33.53%, Test: 30.72%\n",
            "Epoch: 10, Loss: 11642521.0000, Train: 48.52%, Valid: 44.46%, Test: 44.46%\n",
            "Epoch: 15, Loss: 9567569.0000, Train: 61.45%, Valid: 57.16%, Test: 60.27%\n",
            "Epoch: 20, Loss: 8263298.5000, Train: 72.53%, Valid: 68.24%, Test: 71.49%\n",
            "Epoch: 25, Loss: 7349686.5000, Train: 81.68%, Valid: 76.51%, Test: 80.80%\n",
            "Epoch: 30, Loss: 6697715.0000, Train: 83.83%, Valid: 77.55%, Test: 83.31%\n",
            "Epoch: 35, Loss: 6189750.5000, Train: 84.93%, Valid: 78.73%, Test: 82.87%\n",
            "Epoch: 40, Loss: 5772643.5000, Train: 87.67%, Valid: 80.50%, Test: 86.26%\n",
            "Epoch: 45, Loss: 5443646.5000, Train: 88.77%, Valid: 81.83%, Test: 86.26%\n",
            "Epoch: 50, Loss: 5175763.5000, Train: 89.36%, Valid: 82.13%, Test: 87.30%\n",
            "Epoch: 55, Loss: 4948788.5000, Train: 89.88%, Valid: 82.87%, Test: 87.15%\n",
            "Epoch: 60, Loss: 4754099.5000, Train: 90.10%, Valid: 82.87%, Test: 87.89%\n",
            "Epoch: 65, Loss: 4586291.5000, Train: 89.96%, Valid: 83.16%, Test: 87.59%\n",
            "Epoch: 70, Loss: 4435200.5000, Train: 90.10%, Valid: 83.16%, Test: 87.59%\n",
            "Epoch: 75, Loss: 4297589.5000, Train: 90.32%, Valid: 83.60%, Test: 87.74%\n",
            "Epoch: 80, Loss: 4168610.2500, Train: 90.69%, Valid: 83.60%, Test: 87.59%\n",
            "Epoch: 85, Loss: 4051700.5000, Train: 90.84%, Valid: 83.31%, Test: 87.74%\n",
            "Epoch: 90, Loss: 3944869.2500, Train: 90.99%, Valid: 83.01%, Test: 87.59%\n",
            "Epoch: 95, Loss: 3846355.2500, Train: 91.06%, Valid: 82.87%, Test: 88.04%\n",
            "Epoch: 100, Loss: 3758480.5000, Train: 91.29%, Valid: 83.46%, Test: 87.74%\n",
            "Epoch: 105, Loss: 3673164.0000, Train: 91.36%, Valid: 82.87%, Test: 87.44%\n",
            "Epoch: 110, Loss: 3591098.2500, Train: 91.21%, Valid: 82.57%, Test: 87.44%\n",
            "Epoch: 115, Loss: 3511015.5000, Train: 91.14%, Valid: 82.72%, Test: 87.44%\n",
            "Epoch: 120, Loss: 3431994.2500, Train: 90.99%, Valid: 83.01%, Test: 87.59%\n",
            "Epoch: 125, Loss: 3364392.2500, Train: 91.14%, Valid: 82.72%, Test: 87.89%\n",
            "Epoch: 130, Loss: 3300329.7500, Train: 90.99%, Valid: 82.72%, Test: 87.74%\n",
            "Epoch: 135, Loss: 3239938.7500, Train: 91.14%, Valid: 82.72%, Test: 87.59%\n",
            "Epoch: 140, Loss: 3178549.2500, Train: 91.14%, Valid: 82.87%, Test: 87.59%\n",
            "Epoch: 145, Loss: 3119014.2500, Train: 91.29%, Valid: 82.72%, Test: 87.59%\n",
            "Epoch: 150, Loss: 3059808.2500, Train: 91.14%, Valid: 82.87%, Test: 87.74%\n",
            "Epoch: 155, Loss: 3003430.0000, Train: 90.99%, Valid: 83.16%, Test: 87.89%\n",
            "Epoch: 160, Loss: 2948640.2500, Train: 91.06%, Valid: 83.01%, Test: 87.74%\n",
            "Epoch: 165, Loss: 2892840.0000, Train: 90.84%, Valid: 82.87%, Test: 87.59%\n",
            "Epoch: 170, Loss: 2834932.2500, Train: 90.69%, Valid: 82.87%, Test: 87.44%\n",
            "Epoch: 175, Loss: 2781626.5000, Train: 90.62%, Valid: 83.01%, Test: 87.44%\n",
            "Epoch: 180, Loss: 2732471.7500, Train: 90.55%, Valid: 83.01%, Test: 87.59%\n",
            "Epoch: 185, Loss: 2684098.2500, Train: 90.40%, Valid: 83.01%, Test: 87.74%\n",
            "Epoch: 190, Loss: 2637968.2500, Train: 90.40%, Valid: 83.01%, Test: 87.59%\n",
            "Epoch: 195, Loss: 2594946.7500, Train: 90.18%, Valid: 83.16%, Test: 87.59%\n",
            "Run 01:\n",
            "Highest Train: 91.36\n",
            "Highest Valid: 83.75\n",
            "Highest Test: 88.04\n",
            "Chosen epoch: 84\n",
            "Final Train: 90.77\n",
            "Final Test: 87.74\n",
            "Epoch: 00, Loss: 59548296.0000, Train: 21.71%, Valid: 18.91%, Test: 21.42%\n",
            "Epoch: 05, Loss: 17831978.0000, Train: 28.51%, Valid: 23.93%, Test: 27.03%\n",
            "Epoch: 10, Loss: 12506883.0000, Train: 38.48%, Valid: 33.83%, Test: 36.19%\n",
            "Epoch: 15, Loss: 10143461.0000, Train: 52.51%, Valid: 48.89%, Test: 51.55%\n",
            "Epoch: 20, Loss: 8819839.0000, Train: 60.34%, Valid: 57.16%, Test: 59.82%\n",
            "Epoch: 25, Loss: 7902088.5000, Train: 70.97%, Valid: 68.83%, Test: 70.46%\n",
            "Epoch: 30, Loss: 7245257.0000, Train: 78.21%, Valid: 75.04%, Test: 77.40%\n",
            "Epoch: 35, Loss: 6788663.5000, Train: 81.02%, Valid: 76.66%, Test: 79.62%\n",
            "Epoch: 40, Loss: 6453596.5000, Train: 83.16%, Valid: 79.47%, Test: 81.68%\n",
            "Epoch: 45, Loss: 6183165.5000, Train: 84.79%, Valid: 80.80%, Test: 83.75%\n",
            "Epoch: 50, Loss: 5952085.0000, Train: 85.16%, Valid: 81.24%, Test: 84.05%\n",
            "Epoch: 55, Loss: 5739340.5000, Train: 85.97%, Valid: 80.95%, Test: 84.34%\n",
            "Epoch: 60, Loss: 5556381.0000, Train: 86.26%, Valid: 81.09%, Test: 84.34%\n",
            "Epoch: 65, Loss: 5399979.0000, Train: 85.89%, Valid: 81.09%, Test: 84.93%\n",
            "Epoch: 70, Loss: 5250542.5000, Train: 86.12%, Valid: 81.39%, Test: 85.08%\n",
            "Epoch: 75, Loss: 5111815.5000, Train: 86.04%, Valid: 81.24%, Test: 84.93%\n",
            "Epoch: 80, Loss: 4974675.5000, Train: 86.48%, Valid: 81.24%, Test: 85.08%\n",
            "Epoch: 85, Loss: 4837091.5000, Train: 86.71%, Valid: 81.39%, Test: 85.08%\n",
            "Epoch: 90, Loss: 4698818.0000, Train: 86.85%, Valid: 81.83%, Test: 85.38%\n",
            "Epoch: 95, Loss: 4568274.0000, Train: 87.15%, Valid: 82.13%, Test: 85.52%\n",
            "Epoch: 100, Loss: 4452950.5000, Train: 87.30%, Valid: 81.98%, Test: 85.82%\n",
            "Epoch: 105, Loss: 4348628.5000, Train: 87.74%, Valid: 82.42%, Test: 85.82%\n",
            "Epoch: 110, Loss: 4245585.5000, Train: 88.04%, Valid: 82.72%, Test: 85.97%\n",
            "Epoch: 115, Loss: 4146258.2500, Train: 88.11%, Valid: 82.57%, Test: 86.12%\n",
            "Epoch: 120, Loss: 4051934.2500, Train: 88.18%, Valid: 82.72%, Test: 86.56%\n",
            "Epoch: 125, Loss: 3968885.5000, Train: 88.33%, Valid: 83.01%, Test: 86.85%\n",
            "Epoch: 130, Loss: 3895617.5000, Train: 88.55%, Valid: 83.31%, Test: 86.85%\n",
            "Epoch: 135, Loss: 3825322.7500, Train: 88.48%, Valid: 83.01%, Test: 87.15%\n",
            "Epoch: 140, Loss: 3766378.0000, Train: 88.77%, Valid: 83.31%, Test: 87.74%\n",
            "Epoch: 145, Loss: 3717240.0000, Train: 89.00%, Valid: 83.75%, Test: 87.89%\n",
            "Epoch: 150, Loss: 3679123.7500, Train: 88.92%, Valid: 84.05%, Test: 87.59%\n",
            "Epoch: 155, Loss: 3648255.2500, Train: 88.63%, Valid: 84.05%, Test: 87.44%\n",
            "Epoch: 160, Loss: 3620273.2500, Train: 88.55%, Valid: 84.34%, Test: 87.00%\n",
            "Epoch: 165, Loss: 3595649.0000, Train: 88.55%, Valid: 84.34%, Test: 86.85%\n",
            "Epoch: 170, Loss: 3561449.2500, Train: 88.26%, Valid: 84.05%, Test: 85.97%\n",
            "Epoch: 175, Loss: 3508230.7500, Train: 88.33%, Valid: 83.60%, Test: 85.67%\n",
            "Epoch: 180, Loss: 3452203.2500, Train: 88.18%, Valid: 83.60%, Test: 85.82%\n",
            "Epoch: 185, Loss: 3395345.5000, Train: 87.89%, Valid: 83.46%, Test: 85.52%\n",
            "Epoch: 190, Loss: 3342699.5000, Train: 88.40%, Valid: 83.31%, Test: 85.67%\n",
            "Epoch: 195, Loss: 3290679.0000, Train: 88.18%, Valid: 83.01%, Test: 84.93%\n",
            "Run 02:\n",
            "Highest Train: 89.00\n",
            "Highest Valid: 84.49\n",
            "Highest Test: 87.89\n",
            "Chosen epoch: 163\n",
            "Final Train: 88.70\n",
            "Final Test: 86.85\n",
            "Epoch: 00, Loss: 62645952.0000, Train: 13.15%, Valid: 12.56%, Test: 13.15%\n",
            "Epoch: 05, Loss: 19307718.0000, Train: 23.56%, Valid: 23.63%, Test: 24.22%\n",
            "Epoch: 10, Loss: 13293215.0000, Train: 33.60%, Valid: 33.23%, Test: 32.35%\n",
            "Epoch: 15, Loss: 10904829.0000, Train: 39.14%, Valid: 40.32%, Test: 37.08%\n",
            "Epoch: 20, Loss: 9407970.0000, Train: 53.47%, Valid: 53.03%, Test: 50.81%\n",
            "Epoch: 25, Loss: 8358035.5000, Train: 63.52%, Valid: 61.74%, Test: 61.60%\n",
            "Epoch: 30, Loss: 7592181.5000, Train: 72.30%, Valid: 70.75%, Test: 71.34%\n",
            "Epoch: 35, Loss: 7006942.0000, Train: 78.06%, Valid: 75.18%, Test: 76.51%\n",
            "Epoch: 40, Loss: 6521303.0000, Train: 80.43%, Valid: 76.51%, Test: 79.47%\n",
            "Epoch: 45, Loss: 6123682.5000, Train: 81.39%, Valid: 77.55%, Test: 80.21%\n",
            "Epoch: 50, Loss: 5791234.0000, Train: 82.13%, Valid: 78.43%, Test: 80.65%\n",
            "Epoch: 55, Loss: 5503028.0000, Train: 82.94%, Valid: 78.88%, Test: 81.39%\n",
            "Epoch: 60, Loss: 5249871.5000, Train: 83.46%, Valid: 79.03%, Test: 81.39%\n",
            "Epoch: 65, Loss: 5024955.0000, Train: 84.42%, Valid: 79.32%, Test: 81.83%\n",
            "Epoch: 70, Loss: 4829733.0000, Train: 85.08%, Valid: 79.32%, Test: 83.60%\n",
            "Epoch: 75, Loss: 4655750.5000, Train: 85.52%, Valid: 80.06%, Test: 84.05%\n",
            "Epoch: 80, Loss: 4499579.5000, Train: 86.04%, Valid: 80.50%, Test: 84.49%\n",
            "Epoch: 85, Loss: 4357165.5000, Train: 85.97%, Valid: 80.95%, Test: 84.79%\n",
            "Epoch: 90, Loss: 4231146.5000, Train: 86.12%, Valid: 80.95%, Test: 85.52%\n",
            "Epoch: 95, Loss: 4112046.5000, Train: 86.34%, Valid: 80.80%, Test: 85.82%\n",
            "Epoch: 100, Loss: 4006496.2500, Train: 86.63%, Valid: 80.80%, Test: 86.26%\n",
            "Epoch: 105, Loss: 3904574.2500, Train: 86.78%, Valid: 80.80%, Test: 86.26%\n",
            "Epoch: 110, Loss: 3818106.0000, Train: 87.08%, Valid: 80.80%, Test: 86.41%\n",
            "Epoch: 115, Loss: 3734150.0000, Train: 87.00%, Valid: 81.09%, Test: 86.26%\n",
            "Epoch: 120, Loss: 3652173.0000, Train: 86.85%, Valid: 81.39%, Test: 86.41%\n",
            "Epoch: 125, Loss: 3575509.7500, Train: 86.85%, Valid: 81.68%, Test: 86.41%\n",
            "Epoch: 130, Loss: 3497984.5000, Train: 87.08%, Valid: 81.54%, Test: 86.41%\n",
            "Epoch: 135, Loss: 3426155.5000, Train: 87.08%, Valid: 81.68%, Test: 86.41%\n",
            "Epoch: 140, Loss: 3358240.0000, Train: 87.30%, Valid: 82.13%, Test: 86.56%\n",
            "Epoch: 145, Loss: 3291898.7500, Train: 87.22%, Valid: 82.42%, Test: 86.71%\n",
            "Epoch: 150, Loss: 3227916.7500, Train: 87.44%, Valid: 82.57%, Test: 86.71%\n",
            "Epoch: 155, Loss: 3165609.2500, Train: 87.44%, Valid: 82.57%, Test: 86.85%\n",
            "Epoch: 160, Loss: 3105432.2500, Train: 87.59%, Valid: 83.01%, Test: 86.85%\n",
            "Epoch: 165, Loss: 3047683.2500, Train: 87.81%, Valid: 83.01%, Test: 86.85%\n",
            "Epoch: 170, Loss: 2995281.2500, Train: 87.59%, Valid: 83.01%, Test: 86.71%\n",
            "Epoch: 175, Loss: 2948189.2500, Train: 87.67%, Valid: 83.16%, Test: 86.56%\n",
            "Epoch: 180, Loss: 2903594.5000, Train: 87.59%, Valid: 83.16%, Test: 86.85%\n",
            "Epoch: 185, Loss: 2859154.2500, Train: 87.67%, Valid: 83.46%, Test: 86.56%\n",
            "Epoch: 190, Loss: 2816174.5000, Train: 87.67%, Valid: 83.46%, Test: 86.71%\n",
            "Epoch: 195, Loss: 2775157.2500, Train: 87.67%, Valid: 83.46%, Test: 86.71%\n",
            "Run 03:\n",
            "Highest Train: 87.81\n",
            "Highest Valid: 83.75\n",
            "Highest Test: 86.85\n",
            "Chosen epoch: 200\n",
            "Final Train: 87.67\n",
            "Final Test: 86.85\n",
            "Epoch: 00, Loss: 78814000.0000, Train: 10.93%, Valid: 11.23%, Test: 14.33%\n",
            "Epoch: 05, Loss: 17273214.0000, Train: 17.95%, Valid: 14.92%, Test: 19.20%\n",
            "Epoch: 10, Loss: 11859543.0000, Train: 37.37%, Valid: 30.58%, Test: 33.97%\n",
            "Epoch: 15, Loss: 9592515.0000, Train: 58.79%, Valid: 54.21%, Test: 55.39%\n",
            "Epoch: 20, Loss: 8216951.5000, Train: 69.05%, Valid: 64.11%, Test: 65.44%\n",
            "Epoch: 25, Loss: 7273036.5000, Train: 72.60%, Valid: 69.13%, Test: 68.98%\n",
            "Epoch: 30, Loss: 6601908.5000, Train: 77.70%, Valid: 73.26%, Test: 74.00%\n",
            "Epoch: 35, Loss: 6093491.0000, Train: 81.76%, Valid: 76.96%, Test: 78.14%\n",
            "Epoch: 40, Loss: 5686679.0000, Train: 83.75%, Valid: 78.88%, Test: 79.62%\n",
            "Epoch: 45, Loss: 5368267.0000, Train: 85.75%, Valid: 81.83%, Test: 81.98%\n",
            "Epoch: 50, Loss: 5100766.5000, Train: 88.26%, Valid: 83.60%, Test: 84.19%\n",
            "Epoch: 55, Loss: 4878095.0000, Train: 89.22%, Valid: 84.93%, Test: 85.08%\n",
            "Epoch: 60, Loss: 4690024.5000, Train: 90.03%, Valid: 85.08%, Test: 85.67%\n",
            "Epoch: 65, Loss: 4534611.5000, Train: 90.40%, Valid: 84.93%, Test: 85.52%\n",
            "Epoch: 70, Loss: 4396072.5000, Train: 90.69%, Valid: 85.23%, Test: 85.23%\n",
            "Epoch: 75, Loss: 4265568.5000, Train: 90.92%, Valid: 85.08%, Test: 85.97%\n",
            "Epoch: 80, Loss: 4147489.2500, Train: 91.14%, Valid: 84.93%, Test: 86.41%\n",
            "Epoch: 85, Loss: 4045931.2500, Train: 91.36%, Valid: 84.79%, Test: 86.56%\n",
            "Epoch: 90, Loss: 3957163.0000, Train: 91.36%, Valid: 84.93%, Test: 86.41%\n",
            "Epoch: 95, Loss: 3877386.5000, Train: 91.58%, Valid: 85.38%, Test: 86.71%\n",
            "Epoch: 100, Loss: 3805684.2500, Train: 91.65%, Valid: 85.23%, Test: 86.85%\n",
            "Epoch: 105, Loss: 3740334.2500, Train: 91.80%, Valid: 85.38%, Test: 86.85%\n",
            "Epoch: 110, Loss: 3683891.0000, Train: 91.65%, Valid: 85.52%, Test: 86.71%\n",
            "Epoch: 115, Loss: 3632172.7500, Train: 91.95%, Valid: 85.52%, Test: 86.85%\n",
            "Epoch: 120, Loss: 3576832.2500, Train: 92.10%, Valid: 85.97%, Test: 86.85%\n",
            "Epoch: 125, Loss: 3519113.0000, Train: 92.17%, Valid: 85.97%, Test: 86.71%\n",
            "Epoch: 130, Loss: 3468277.7500, Train: 92.10%, Valid: 85.97%, Test: 86.56%\n",
            "Epoch: 135, Loss: 3420459.5000, Train: 92.25%, Valid: 85.67%, Test: 86.26%\n",
            "Epoch: 140, Loss: 3372995.2500, Train: 92.32%, Valid: 85.67%, Test: 86.41%\n",
            "Epoch: 145, Loss: 3328035.0000, Train: 92.47%, Valid: 85.52%, Test: 86.85%\n",
            "Epoch: 150, Loss: 3285206.2500, Train: 92.47%, Valid: 85.23%, Test: 87.44%\n",
            "Epoch: 155, Loss: 3238075.7500, Train: 92.54%, Valid: 85.38%, Test: 87.44%\n",
            "Epoch: 160, Loss: 3191607.7500, Train: 92.39%, Valid: 85.23%, Test: 87.44%\n",
            "Epoch: 165, Loss: 3144964.2500, Train: 92.17%, Valid: 84.64%, Test: 87.59%\n",
            "Epoch: 170, Loss: 3103545.7500, Train: 92.17%, Valid: 84.64%, Test: 87.44%\n",
            "Epoch: 175, Loss: 3066133.2500, Train: 92.10%, Valid: 84.79%, Test: 87.44%\n",
            "Epoch: 180, Loss: 3027028.7500, Train: 92.17%, Valid: 84.49%, Test: 87.30%\n",
            "Epoch: 185, Loss: 2986756.7500, Train: 92.25%, Valid: 84.64%, Test: 87.59%\n",
            "Epoch: 190, Loss: 2949912.2500, Train: 92.32%, Valid: 84.49%, Test: 87.74%\n",
            "Epoch: 195, Loss: 2911627.7500, Train: 92.39%, Valid: 84.79%, Test: 87.74%\n",
            "Run 04:\n",
            "Highest Train: 92.61\n",
            "Highest Valid: 85.97\n",
            "Highest Test: 87.89\n",
            "Chosen epoch: 121\n",
            "Final Train: 92.10\n",
            "Final Test: 86.85\n",
            "Epoch: 00, Loss: 59602568.0000, Train: 16.62%, Valid: 20.97%, Test: 19.20%\n",
            "Epoch: 05, Loss: 17569130.0000, Train: 16.62%, Valid: 17.28%, Test: 16.54%\n",
            "Epoch: 10, Loss: 12185057.0000, Train: 29.10%, Valid: 31.61%, Test: 27.77%\n",
            "Epoch: 15, Loss: 9661727.0000, Train: 49.04%, Valid: 46.82%, Test: 42.84%\n",
            "Epoch: 20, Loss: 8177100.5000, Train: 59.45%, Valid: 57.75%, Test: 55.10%\n",
            "Epoch: 25, Loss: 7176194.5000, Train: 67.43%, Valid: 63.81%, Test: 65.29%\n",
            "Epoch: 30, Loss: 6443794.5000, Train: 72.53%, Valid: 68.98%, Test: 71.94%\n",
            "Epoch: 35, Loss: 5899837.0000, Train: 78.95%, Valid: 73.86%, Test: 78.29%\n",
            "Epoch: 40, Loss: 5466398.5000, Train: 82.05%, Valid: 76.96%, Test: 81.24%\n",
            "Epoch: 45, Loss: 5112880.5000, Train: 83.31%, Valid: 77.84%, Test: 81.39%\n",
            "Epoch: 50, Loss: 4828725.5000, Train: 84.27%, Valid: 78.14%, Test: 82.57%\n",
            "Epoch: 55, Loss: 4573255.5000, Train: 85.89%, Valid: 79.91%, Test: 83.60%\n",
            "Epoch: 60, Loss: 4345981.5000, Train: 87.22%, Valid: 80.65%, Test: 84.64%\n",
            "Epoch: 65, Loss: 4149413.2500, Train: 87.59%, Valid: 81.83%, Test: 84.49%\n",
            "Epoch: 70, Loss: 3987434.0000, Train: 88.18%, Valid: 82.42%, Test: 84.79%\n",
            "Epoch: 75, Loss: 3844933.2500, Train: 88.85%, Valid: 82.72%, Test: 85.38%\n",
            "Epoch: 80, Loss: 3725279.2500, Train: 89.44%, Valid: 83.01%, Test: 85.52%\n",
            "Epoch: 85, Loss: 3619960.0000, Train: 89.88%, Valid: 83.16%, Test: 85.82%\n",
            "Epoch: 90, Loss: 3524510.2500, Train: 90.25%, Valid: 83.16%, Test: 86.12%\n",
            "Epoch: 95, Loss: 3442097.7500, Train: 90.47%, Valid: 83.16%, Test: 86.26%\n",
            "Epoch: 100, Loss: 3361895.7500, Train: 90.69%, Valid: 82.72%, Test: 86.56%\n",
            "Epoch: 105, Loss: 3293101.2500, Train: 90.92%, Valid: 83.31%, Test: 86.71%\n",
            "Epoch: 110, Loss: 3232263.0000, Train: 90.69%, Valid: 83.31%, Test: 86.85%\n",
            "Epoch: 115, Loss: 3170277.2500, Train: 90.99%, Valid: 83.60%, Test: 87.00%\n",
            "Epoch: 120, Loss: 3111632.7500, Train: 90.84%, Valid: 83.60%, Test: 87.30%\n",
            "Epoch: 125, Loss: 3055918.7500, Train: 90.77%, Valid: 83.31%, Test: 87.30%\n",
            "Epoch: 130, Loss: 3003952.2500, Train: 90.84%, Valid: 83.16%, Test: 87.74%\n",
            "Epoch: 135, Loss: 2957177.0000, Train: 90.77%, Valid: 83.16%, Test: 87.44%\n",
            "Epoch: 140, Loss: 2909053.2500, Train: 90.55%, Valid: 83.16%, Test: 87.59%\n",
            "Epoch: 145, Loss: 2853323.5000, Train: 90.69%, Valid: 83.46%, Test: 87.59%\n",
            "Epoch: 150, Loss: 2798160.7500, Train: 90.77%, Valid: 83.60%, Test: 87.59%\n",
            "Epoch: 155, Loss: 2741396.7500, Train: 90.69%, Valid: 83.90%, Test: 87.15%\n",
            "Epoch: 160, Loss: 2689943.0000, Train: 90.84%, Valid: 83.46%, Test: 87.15%\n",
            "Epoch: 165, Loss: 2640455.2500, Train: 90.84%, Valid: 83.60%, Test: 86.71%\n",
            "Epoch: 170, Loss: 2594360.5000, Train: 90.92%, Valid: 83.75%, Test: 86.41%\n",
            "Epoch: 175, Loss: 2550856.2500, Train: 90.99%, Valid: 83.60%, Test: 86.71%\n",
            "Epoch: 180, Loss: 2509501.5000, Train: 90.84%, Valid: 83.31%, Test: 86.41%\n",
            "Epoch: 185, Loss: 2469085.2500, Train: 90.77%, Valid: 83.46%, Test: 86.56%\n",
            "Epoch: 190, Loss: 2434773.7500, Train: 90.62%, Valid: 83.46%, Test: 86.85%\n",
            "Epoch: 195, Loss: 2405207.7500, Train: 90.92%, Valid: 83.75%, Test: 86.71%\n",
            "Run 05:\n",
            "Highest Train: 91.06\n",
            "Highest Valid: 83.90\n",
            "Highest Test: 87.74\n",
            "Chosen epoch: 153\n",
            "Final Train: 90.69\n",
            "Final Test: 87.59\n",
            "All runs:\n",
            "Highest Train: 90.37 ± 1.93\n",
            "Highest Test: 87.68 ± 0.47\n",
            "Highest Valid: 84.37 ± 0.94\n",
            "  Final Train: 89.99 ± 1.78\n",
            "   Final Test: 87.18 ± 0.45\n",
            "Saving results to logs/cora_edge.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Node Aware Setting"
      ],
      "metadata": {
        "id": "7CerADR6GeA2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 GKD/main.py --dataset cora --rand_split --use_bn --base_model gcn --mode train --dist_mode no --save_model\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeBZ4WvmGhR8",
        "outputId": "6fb1b006-472e-49e0-e2d0-df298816e341"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(data_dir='data', dataset='cora', sub_dataset='', cpu=False, seed=42, train_prop=0.5, valid_prop=0.25, protocol='semi', rand_split=True, metric='acc', runs=5, epochs=200, hidden_channels=32, num_layers=3, gat_heads=8, out_heads=1, hops=1, lp_alpha=0.1, gpr_alpha=0.1, jk_type='max', directed=False, num_mlp_layers=1, display_step=5, cached=False, print_prop=False, priv_type='edge', priv_ratio=0.5, save_model=True, save_name='gcn', log_name='none', base_model='gcn', not_load_teacher=False, mode='train', dist_mode='no', weight_decay=0.05, dropout=0.0, lr=0.01, use_bn=True, use_batch=False, batch_size=2048, oracle=False, device=0, alpha=0.5, delta=0.1, use_kd=False, beta=0.0, tau=1.0, kernel='sigmoid', t=1.0, include_last=False, s=2, m=1, lr2=0.001, sim='l2', ker_norm=False)\n",
            "cuda:0\n",
            "cora\n",
            "Num nodes: 2708\n",
            "torch.Size([2708, 1])\n",
            "num nodes 2708 | num classes 7 | num node feats 1433\n",
            "MODEL: GeoDist(\n",
            "  (k): Kernel(\n",
            "    (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  )\n",
            "  (teacher_gnn): ModuleList(\n",
            "    (0): Linear(in_features=1433, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (student_gnn): ModuleList(\n",
            "    (0): Linear(in_features=1433, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  (bns2d): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            ")\n",
            "Epoch: 00, Loss: 2.1900, Train: 71.79%, Valid: 60.41%, Test: 62.19%\n",
            "Epoch: 05, Loss: 0.4632, Train: 92.39%, Valid: 78.29%, Test: 83.90%\n",
            "Epoch: 10, Loss: 0.3330, Train: 94.09%, Valid: 80.35%, Test: 84.79%\n",
            "Epoch: 15, Loss: 0.2798, Train: 95.42%, Valid: 80.21%, Test: 86.56%\n",
            "Epoch: 20, Loss: 0.2372, Train: 96.60%, Valid: 79.62%, Test: 84.05%\n",
            "Epoch: 25, Loss: 0.1916, Train: 97.49%, Valid: 77.40%, Test: 83.01%\n",
            "Epoch: 30, Loss: 0.1535, Train: 97.71%, Valid: 75.48%, Test: 79.03%\n",
            "Epoch: 35, Loss: 0.1537, Train: 96.97%, Valid: 75.78%, Test: 81.24%\n",
            "Epoch: 40, Loss: 0.1315, Train: 98.30%, Valid: 74.15%, Test: 77.99%\n",
            "Epoch: 45, Loss: 0.1301, Train: 97.49%, Valid: 75.48%, Test: 76.96%\n",
            "Epoch: 50, Loss: 0.1528, Train: 97.86%, Valid: 74.45%, Test: 79.32%\n",
            "Epoch: 55, Loss: 0.1275, Train: 98.30%, Valid: 74.74%, Test: 76.22%\n",
            "Epoch: 60, Loss: 0.1240, Train: 96.45%, Valid: 70.31%, Test: 75.33%\n",
            "Epoch: 65, Loss: 0.1610, Train: 97.19%, Valid: 74.59%, Test: 77.99%\n",
            "Epoch: 70, Loss: 0.1250, Train: 98.45%, Valid: 72.38%, Test: 77.99%\n",
            "Epoch: 75, Loss: 0.1100, Train: 98.52%, Valid: 72.38%, Test: 75.33%\n",
            "Epoch: 80, Loss: 0.1361, Train: 97.12%, Valid: 73.41%, Test: 76.96%\n",
            "Epoch: 85, Loss: 0.1353, Train: 97.86%, Valid: 74.00%, Test: 77.70%\n",
            "Epoch: 90, Loss: 0.1121, Train: 98.38%, Valid: 72.38%, Test: 75.63%\n",
            "Epoch: 95, Loss: 0.1124, Train: 98.38%, Valid: 72.67%, Test: 76.37%\n",
            "Epoch: 100, Loss: 0.1601, Train: 97.34%, Valid: 73.86%, Test: 78.14%\n",
            "Epoch: 105, Loss: 0.1276, Train: 98.23%, Valid: 74.74%, Test: 78.29%\n",
            "Epoch: 110, Loss: 0.1066, Train: 98.67%, Valid: 70.75%, Test: 73.86%\n",
            "Epoch: 115, Loss: 0.1125, Train: 97.78%, Valid: 70.90%, Test: 75.92%\n",
            "Epoch: 120, Loss: 0.1448, Train: 97.78%, Valid: 75.33%, Test: 77.25%\n",
            "Epoch: 125, Loss: 0.1132, Train: 98.38%, Valid: 72.67%, Test: 75.18%\n",
            "Epoch: 130, Loss: 0.1043, Train: 98.74%, Valid: 71.20%, Test: 74.59%\n",
            "Epoch: 135, Loss: 0.1640, Train: 96.09%, Valid: 72.23%, Test: 76.81%\n",
            "Epoch: 140, Loss: 0.1652, Train: 97.49%, Valid: 75.33%, Test: 77.99%\n",
            "Epoch: 145, Loss: 0.1254, Train: 97.86%, Valid: 73.71%, Test: 76.07%\n",
            "Epoch: 150, Loss: 0.1086, Train: 98.52%, Valid: 73.41%, Test: 75.78%\n",
            "Epoch: 155, Loss: 0.1246, Train: 98.01%, Valid: 73.26%, Test: 77.25%\n",
            "Epoch: 160, Loss: 0.1233, Train: 98.01%, Valid: 72.53%, Test: 74.59%\n",
            "Epoch: 165, Loss: 0.1176, Train: 98.38%, Valid: 71.94%, Test: 75.78%\n",
            "Epoch: 170, Loss: 0.1199, Train: 98.45%, Valid: 72.67%, Test: 75.63%\n",
            "Epoch: 175, Loss: 0.1335, Train: 97.49%, Valid: 71.64%, Test: 76.22%\n",
            "Epoch: 180, Loss: 0.1160, Train: 97.93%, Valid: 72.53%, Test: 77.84%\n",
            "Epoch: 185, Loss: 0.1088, Train: 98.38%, Valid: 70.75%, Test: 74.45%\n",
            "Epoch: 190, Loss: 0.1137, Train: 98.30%, Valid: 71.34%, Test: 75.04%\n",
            "Epoch: 195, Loss: 0.1263, Train: 98.08%, Valid: 72.08%, Test: 74.89%\n",
            "Run 01:\n",
            "Highest Train: 98.89\n",
            "Highest Valid: 80.50\n",
            "Highest Test: 86.56\n",
            "Chosen epoch: 10\n",
            "Final Train: 93.72\n",
            "Final Test: 84.34\n",
            "Epoch: 00, Loss: 2.2949, Train: 67.73%, Valid: 60.12%, Test: 58.94%\n",
            "Epoch: 05, Loss: 0.4694, Train: 93.21%, Valid: 82.72%, Test: 82.72%\n",
            "Epoch: 10, Loss: 0.3315, Train: 94.46%, Valid: 82.42%, Test: 83.46%\n",
            "Epoch: 15, Loss: 0.2816, Train: 95.20%, Valid: 82.57%, Test: 83.90%\n",
            "Epoch: 20, Loss: 0.2460, Train: 95.79%, Valid: 81.68%, Test: 83.16%\n",
            "Epoch: 25, Loss: 0.2010, Train: 97.19%, Valid: 78.58%, Test: 81.68%\n",
            "Epoch: 30, Loss: 0.1593, Train: 97.86%, Valid: 78.14%, Test: 79.47%\n",
            "Epoch: 35, Loss: 0.1584, Train: 96.82%, Valid: 76.22%, Test: 78.29%\n",
            "Epoch: 40, Loss: 0.1407, Train: 97.78%, Valid: 73.71%, Test: 77.70%\n",
            "Epoch: 45, Loss: 0.1324, Train: 97.86%, Valid: 73.86%, Test: 77.70%\n",
            "Epoch: 50, Loss: 0.1444, Train: 97.78%, Valid: 74.74%, Test: 74.89%\n",
            "Epoch: 55, Loss: 0.1432, Train: 97.93%, Valid: 74.30%, Test: 76.66%\n",
            "Epoch: 60, Loss: 0.1298, Train: 97.71%, Valid: 72.38%, Test: 74.45%\n",
            "Epoch: 65, Loss: 0.1298, Train: 98.01%, Valid: 76.07%, Test: 75.33%\n",
            "Epoch: 70, Loss: 0.1451, Train: 97.19%, Valid: 73.71%, Test: 74.30%\n",
            "Epoch: 75, Loss: 0.1219, Train: 98.38%, Valid: 72.97%, Test: 74.30%\n",
            "Epoch: 80, Loss: 0.1270, Train: 97.71%, Valid: 72.82%, Test: 74.59%\n",
            "Epoch: 85, Loss: 0.1330, Train: 97.93%, Valid: 73.26%, Test: 74.30%\n",
            "Epoch: 90, Loss: 0.1117, Train: 98.52%, Valid: 69.42%, Test: 70.75%\n",
            "Epoch: 95, Loss: 0.1384, Train: 97.19%, Valid: 73.86%, Test: 75.78%\n",
            "Epoch: 100, Loss: 0.1359, Train: 97.93%, Valid: 73.86%, Test: 73.26%\n",
            "Epoch: 105, Loss: 0.1145, Train: 98.30%, Valid: 72.38%, Test: 75.78%\n",
            "Epoch: 110, Loss: 0.1164, Train: 98.08%, Valid: 70.31%, Test: 71.05%\n",
            "Epoch: 115, Loss: 0.1453, Train: 97.56%, Valid: 73.12%, Test: 76.07%\n",
            "Epoch: 120, Loss: 0.1220, Train: 98.52%, Valid: 71.49%, Test: 72.67%\n",
            "Epoch: 125, Loss: 0.1098, Train: 98.30%, Valid: 71.20%, Test: 72.23%\n",
            "Epoch: 130, Loss: 0.1342, Train: 98.08%, Valid: 71.79%, Test: 73.56%\n",
            "Epoch: 135, Loss: 0.1157, Train: 98.15%, Valid: 72.82%, Test: 73.12%\n",
            "Epoch: 140, Loss: 0.1130, Train: 98.52%, Valid: 70.16%, Test: 71.34%\n",
            "Epoch: 145, Loss: 0.1262, Train: 98.01%, Valid: 72.23%, Test: 73.86%\n",
            "Epoch: 150, Loss: 0.1363, Train: 98.45%, Valid: 74.45%, Test: 73.41%\n",
            "Epoch: 155, Loss: 0.1108, Train: 98.45%, Valid: 71.49%, Test: 71.64%\n",
            "Epoch: 160, Loss: 0.1166, Train: 98.15%, Valid: 71.20%, Test: 73.56%\n",
            "Epoch: 165, Loss: 0.1332, Train: 98.23%, Valid: 74.30%, Test: 72.38%\n",
            "Epoch: 170, Loss: 0.1172, Train: 97.93%, Valid: 70.01%, Test: 71.64%\n",
            "Epoch: 175, Loss: 0.1154, Train: 98.30%, Valid: 72.23%, Test: 71.49%\n",
            "Epoch: 180, Loss: 0.1111, Train: 98.38%, Valid: 70.61%, Test: 72.53%\n",
            "Epoch: 185, Loss: 0.1321, Train: 98.01%, Valid: 72.38%, Test: 73.71%\n",
            "Epoch: 190, Loss: 0.1236, Train: 98.15%, Valid: 72.23%, Test: 71.94%\n",
            "Epoch: 195, Loss: 0.1188, Train: 98.52%, Valid: 72.82%, Test: 72.38%\n",
            "Run 02:\n",
            "Highest Train: 98.82\n",
            "Highest Valid: 82.87\n",
            "Highest Test: 84.19\n",
            "Chosen epoch: 9\n",
            "Final Train: 94.09\n",
            "Final Test: 83.60\n",
            "Epoch: 00, Loss: 2.5658, Train: 63.00%, Valid: 52.88%, Test: 55.39%\n",
            "Epoch: 05, Loss: 0.4681, Train: 92.32%, Valid: 79.47%, Test: 83.16%\n",
            "Epoch: 10, Loss: 0.3346, Train: 93.28%, Valid: 82.57%, Test: 85.67%\n",
            "Epoch: 15, Loss: 0.2879, Train: 94.90%, Valid: 82.72%, Test: 85.23%\n",
            "Epoch: 20, Loss: 0.2543, Train: 96.09%, Valid: 83.16%, Test: 85.38%\n",
            "Epoch: 25, Loss: 0.2126, Train: 96.82%, Valid: 80.95%, Test: 83.46%\n",
            "Epoch: 30, Loss: 0.1676, Train: 98.01%, Valid: 78.29%, Test: 81.24%\n",
            "Epoch: 35, Loss: 0.1478, Train: 97.42%, Valid: 76.07%, Test: 78.58%\n",
            "Epoch: 40, Loss: 0.1480, Train: 98.01%, Valid: 76.07%, Test: 77.99%\n",
            "Epoch: 45, Loss: 0.1242, Train: 98.45%, Valid: 73.26%, Test: 77.10%\n",
            "Epoch: 50, Loss: 0.1376, Train: 98.38%, Valid: 73.41%, Test: 76.22%\n",
            "Epoch: 55, Loss: 0.1303, Train: 98.23%, Valid: 75.63%, Test: 77.84%\n",
            "Epoch: 60, Loss: 0.1219, Train: 99.04%, Valid: 72.38%, Test: 75.33%\n",
            "Epoch: 65, Loss: 0.1358, Train: 97.93%, Valid: 73.41%, Test: 77.40%\n",
            "Epoch: 70, Loss: 0.1229, Train: 98.74%, Valid: 71.94%, Test: 76.51%\n",
            "Epoch: 75, Loss: 0.1143, Train: 98.08%, Valid: 73.71%, Test: 74.74%\n",
            "Epoch: 80, Loss: 0.1106, Train: 97.93%, Valid: 70.90%, Test: 74.74%\n",
            "Epoch: 85, Loss: 0.1208, Train: 98.52%, Valid: 71.05%, Test: 75.92%\n",
            "Epoch: 90, Loss: 0.1102, Train: 98.30%, Valid: 71.94%, Test: 75.33%\n",
            "Epoch: 95, Loss: 0.1077, Train: 98.38%, Valid: 71.94%, Test: 75.04%\n",
            "Epoch: 100, Loss: 0.1206, Train: 98.23%, Valid: 71.49%, Test: 75.04%\n",
            "Epoch: 105, Loss: 0.1084, Train: 98.45%, Valid: 71.94%, Test: 74.59%\n",
            "Epoch: 110, Loss: 0.1076, Train: 97.93%, Valid: 72.53%, Test: 74.59%\n",
            "Epoch: 115, Loss: 0.1163, Train: 98.74%, Valid: 72.38%, Test: 76.66%\n",
            "Epoch: 120, Loss: 0.1049, Train: 98.89%, Valid: 72.38%, Test: 74.15%\n",
            "Epoch: 125, Loss: 0.1070, Train: 98.74%, Valid: 72.53%, Test: 74.59%\n",
            "Epoch: 130, Loss: 0.0999, Train: 98.97%, Valid: 70.61%, Test: 73.12%\n",
            "Epoch: 135, Loss: 0.1142, Train: 98.45%, Valid: 73.26%, Test: 75.63%\n",
            "Epoch: 140, Loss: 0.1186, Train: 98.45%, Valid: 70.90%, Test: 73.86%\n",
            "Epoch: 145, Loss: 0.1053, Train: 98.97%, Valid: 69.87%, Test: 75.04%\n",
            "Epoch: 150, Loss: 0.1136, Train: 98.52%, Valid: 71.49%, Test: 73.86%\n",
            "Epoch: 155, Loss: 0.0966, Train: 98.97%, Valid: 69.72%, Test: 71.05%\n",
            "Epoch: 160, Loss: 0.1114, Train: 98.38%, Valid: 70.90%, Test: 73.41%\n",
            "Epoch: 165, Loss: 0.1081, Train: 98.67%, Valid: 72.08%, Test: 73.26%\n",
            "Epoch: 170, Loss: 0.1046, Train: 98.67%, Valid: 71.64%, Test: 73.26%\n",
            "Epoch: 175, Loss: 0.1010, Train: 98.23%, Valid: 69.57%, Test: 72.38%\n",
            "Epoch: 180, Loss: 0.1123, Train: 98.08%, Valid: 70.31%, Test: 75.48%\n",
            "Epoch: 185, Loss: 0.1063, Train: 98.74%, Valid: 70.16%, Test: 71.79%\n",
            "Epoch: 190, Loss: 0.1142, Train: 98.52%, Valid: 72.67%, Test: 75.48%\n",
            "Epoch: 195, Loss: 0.1031, Train: 98.74%, Valid: 70.90%, Test: 73.41%\n",
            "Run 03:\n",
            "Highest Train: 99.19\n",
            "Highest Valid: 83.16\n",
            "Highest Test: 86.41\n",
            "Chosen epoch: 14\n",
            "Final Train: 94.46\n",
            "Final Test: 84.93\n",
            "Epoch: 00, Loss: 2.6067, Train: 63.96%, Valid: 50.81%, Test: 52.58%\n",
            "Epoch: 05, Loss: 0.4818, Train: 91.51%, Valid: 77.25%, Test: 77.99%\n",
            "Epoch: 10, Loss: 0.3448, Train: 93.94%, Valid: 78.88%, Test: 83.16%\n",
            "Epoch: 15, Loss: 0.2904, Train: 94.53%, Valid: 80.80%, Test: 84.64%\n",
            "Epoch: 20, Loss: 0.2565, Train: 95.35%, Valid: 80.80%, Test: 84.34%\n",
            "Epoch: 25, Loss: 0.2172, Train: 96.31%, Valid: 80.35%, Test: 83.16%\n",
            "Epoch: 30, Loss: 0.1787, Train: 97.05%, Valid: 78.88%, Test: 81.54%\n",
            "Epoch: 35, Loss: 0.1684, Train: 96.97%, Valid: 77.84%, Test: 78.73%\n",
            "Epoch: 40, Loss: 0.1404, Train: 98.01%, Valid: 77.10%, Test: 78.29%\n",
            "Epoch: 45, Loss: 0.1440, Train: 97.56%, Valid: 77.70%, Test: 77.99%\n",
            "Epoch: 50, Loss: 0.1385, Train: 98.45%, Valid: 75.48%, Test: 77.10%\n",
            "Epoch: 55, Loss: 0.1395, Train: 97.71%, Valid: 74.15%, Test: 76.96%\n",
            "Epoch: 60, Loss: 0.1406, Train: 97.34%, Valid: 72.67%, Test: 76.81%\n",
            "Epoch: 65, Loss: 0.1319, Train: 98.52%, Valid: 74.59%, Test: 75.92%\n",
            "Epoch: 70, Loss: 0.1347, Train: 97.78%, Valid: 71.94%, Test: 76.22%\n",
            "Epoch: 75, Loss: 0.1374, Train: 97.71%, Valid: 75.48%, Test: 78.88%\n",
            "Epoch: 80, Loss: 0.1218, Train: 98.23%, Valid: 73.86%, Test: 77.10%\n",
            "Epoch: 85, Loss: 0.1291, Train: 97.93%, Valid: 70.61%, Test: 75.78%\n",
            "Epoch: 90, Loss: 0.1263, Train: 98.15%, Valid: 72.67%, Test: 74.89%\n",
            "Epoch: 95, Loss: 0.1200, Train: 97.86%, Valid: 74.00%, Test: 74.74%\n",
            "Epoch: 100, Loss: 0.1235, Train: 98.08%, Valid: 73.26%, Test: 76.96%\n",
            "Epoch: 105, Loss: 0.1223, Train: 98.38%, Valid: 72.67%, Test: 75.48%\n",
            "Epoch: 110, Loss: 0.1312, Train: 98.23%, Valid: 72.53%, Test: 77.10%\n",
            "Epoch: 115, Loss: 0.1186, Train: 98.23%, Valid: 73.26%, Test: 74.59%\n",
            "Epoch: 120, Loss: 0.1259, Train: 98.23%, Valid: 73.56%, Test: 75.33%\n",
            "Epoch: 125, Loss: 0.1207, Train: 98.45%, Valid: 72.82%, Test: 74.15%\n",
            "Epoch: 130, Loss: 0.1151, Train: 98.60%, Valid: 73.26%, Test: 75.63%\n",
            "Epoch: 135, Loss: 0.1191, Train: 97.93%, Valid: 71.79%, Test: 75.48%\n",
            "Epoch: 140, Loss: 0.1233, Train: 98.01%, Valid: 73.41%, Test: 75.48%\n",
            "Epoch: 145, Loss: 0.1093, Train: 98.15%, Valid: 72.23%, Test: 74.15%\n",
            "Epoch: 150, Loss: 0.1144, Train: 98.30%, Valid: 71.49%, Test: 73.12%\n",
            "Epoch: 155, Loss: 0.1245, Train: 97.64%, Valid: 70.61%, Test: 75.04%\n",
            "Epoch: 160, Loss: 0.1159, Train: 98.45%, Valid: 72.08%, Test: 74.59%\n",
            "Epoch: 165, Loss: 0.1030, Train: 98.60%, Valid: 71.64%, Test: 74.15%\n",
            "Epoch: 170, Loss: 0.1110, Train: 97.34%, Valid: 71.94%, Test: 73.41%\n",
            "Epoch: 175, Loss: 0.1429, Train: 97.78%, Valid: 73.41%, Test: 76.07%\n",
            "Epoch: 180, Loss: 0.1183, Train: 98.52%, Valid: 72.38%, Test: 75.48%\n",
            "Epoch: 185, Loss: 0.1040, Train: 98.67%, Valid: 72.08%, Test: 74.45%\n",
            "Epoch: 190, Loss: 0.1310, Train: 97.64%, Valid: 72.23%, Test: 76.22%\n",
            "Epoch: 195, Loss: 0.1250, Train: 98.30%, Valid: 72.97%, Test: 75.63%\n",
            "Run 04:\n",
            "Highest Train: 99.04\n",
            "Highest Valid: 81.24\n",
            "Highest Test: 84.64\n",
            "Chosen epoch: 23\n",
            "Final Train: 95.72\n",
            "Final Test: 83.75\n",
            "Epoch: 00, Loss: 2.3849, Train: 66.77%, Valid: 55.83%, Test: 56.43%\n",
            "Epoch: 05, Loss: 0.4883, Train: 92.25%, Valid: 79.47%, Test: 83.75%\n",
            "Epoch: 10, Loss: 0.3500, Train: 93.57%, Valid: 78.58%, Test: 83.01%\n",
            "Epoch: 15, Loss: 0.2900, Train: 94.39%, Valid: 78.14%, Test: 84.19%\n",
            "Epoch: 20, Loss: 0.2470, Train: 95.86%, Valid: 78.58%, Test: 82.87%\n",
            "Epoch: 25, Loss: 0.2021, Train: 97.27%, Valid: 77.84%, Test: 82.42%\n",
            "Epoch: 30, Loss: 0.1579, Train: 98.23%, Valid: 77.70%, Test: 80.95%\n",
            "Epoch: 35, Loss: 0.1407, Train: 97.42%, Valid: 75.63%, Test: 78.43%\n",
            "Epoch: 40, Loss: 0.1408, Train: 97.93%, Valid: 75.04%, Test: 79.17%\n",
            "Epoch: 45, Loss: 0.1220, Train: 98.23%, Valid: 71.64%, Test: 77.10%\n",
            "Epoch: 50, Loss: 0.1175, Train: 98.08%, Valid: 69.57%, Test: 72.67%\n",
            "Epoch: 55, Loss: 0.1538, Train: 98.01%, Valid: 74.15%, Test: 77.70%\n",
            "Epoch: 60, Loss: 0.1239, Train: 98.30%, Valid: 71.79%, Test: 75.78%\n",
            "Epoch: 65, Loss: 0.1120, Train: 98.15%, Valid: 70.75%, Test: 74.89%\n",
            "Epoch: 70, Loss: 0.1381, Train: 97.71%, Valid: 71.49%, Test: 75.48%\n",
            "Epoch: 75, Loss: 0.1243, Train: 98.30%, Valid: 72.23%, Test: 75.33%\n",
            "Epoch: 80, Loss: 0.1063, Train: 98.60%, Valid: 70.31%, Test: 75.33%\n",
            "Epoch: 85, Loss: 0.1195, Train: 97.93%, Valid: 70.90%, Test: 74.89%\n",
            "Epoch: 90, Loss: 0.1449, Train: 97.93%, Valid: 71.34%, Test: 74.30%\n",
            "Epoch: 95, Loss: 0.1175, Train: 98.23%, Valid: 71.49%, Test: 74.15%\n",
            "Epoch: 100, Loss: 0.1065, Train: 98.45%, Valid: 70.31%, Test: 73.86%\n",
            "Epoch: 105, Loss: 0.1090, Train: 97.86%, Valid: 68.54%, Test: 74.00%\n",
            "Epoch: 110, Loss: 0.1367, Train: 98.15%, Valid: 74.15%, Test: 75.48%\n",
            "Epoch: 115, Loss: 0.1105, Train: 98.38%, Valid: 71.05%, Test: 73.26%\n",
            "Epoch: 120, Loss: 0.0984, Train: 98.45%, Valid: 68.54%, Test: 73.56%\n",
            "Epoch: 125, Loss: 0.1374, Train: 97.71%, Valid: 70.75%, Test: 74.45%\n",
            "Epoch: 130, Loss: 0.1203, Train: 98.23%, Valid: 70.75%, Test: 75.63%\n",
            "Epoch: 135, Loss: 0.1050, Train: 98.67%, Valid: 69.87%, Test: 72.23%\n",
            "Epoch: 140, Loss: 0.1088, Train: 97.86%, Valid: 69.72%, Test: 72.38%\n",
            "Epoch: 145, Loss: 0.1244, Train: 98.45%, Valid: 71.64%, Test: 75.33%\n",
            "Epoch: 150, Loss: 0.1124, Train: 98.52%, Valid: 70.16%, Test: 74.59%\n",
            "Epoch: 155, Loss: 0.1109, Train: 98.30%, Valid: 69.57%, Test: 72.67%\n",
            "Epoch: 160, Loss: 0.1083, Train: 98.30%, Valid: 71.34%, Test: 72.67%\n",
            "Epoch: 165, Loss: 0.1032, Train: 98.74%, Valid: 68.69%, Test: 73.56%\n",
            "Epoch: 170, Loss: 0.1441, Train: 98.01%, Valid: 73.41%, Test: 76.07%\n",
            "Epoch: 175, Loss: 0.1239, Train: 98.01%, Valid: 71.05%, Test: 75.48%\n",
            "Epoch: 180, Loss: 0.1070, Train: 98.60%, Valid: 69.42%, Test: 72.97%\n",
            "Epoch: 185, Loss: 0.1001, Train: 98.60%, Valid: 69.72%, Test: 72.53%\n",
            "Epoch: 190, Loss: 0.1300, Train: 97.64%, Valid: 70.61%, Test: 75.63%\n",
            "Epoch: 195, Loss: 0.1168, Train: 98.67%, Valid: 70.31%, Test: 73.71%\n",
            "Run 05:\n",
            "Highest Train: 98.97\n",
            "Highest Valid: 79.47\n",
            "Highest Test: 84.34\n",
            "Chosen epoch: 6\n",
            "Final Train: 92.25\n",
            "Final Test: 83.75\n",
            "All runs:\n",
            "Highest Train: 98.98 ± 0.14\n",
            "Highest Test: 85.23 ± 1.16\n",
            "Highest Valid: 81.45 ± 1.57\n",
            "  Final Train: 94.05 ± 1.26\n",
            "   Final Test: 84.08 ± 0.56\n",
            "Saving results to logs/cora_edge.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 GKD/main.py --dataset cora --rand_split --use_bn --base_model gcn --mode train  --dist_mode gkd --kernel sigmoid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKXIUosTGlBK",
        "outputId": "ce464d31-b5e5-4e6b-f4e1-14b783120612"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(data_dir='data', dataset='cora', sub_dataset='', cpu=False, seed=42, train_prop=0.5, valid_prop=0.25, protocol='semi', rand_split=True, metric='acc', runs=5, epochs=200, hidden_channels=32, num_layers=3, gat_heads=8, out_heads=1, hops=1, lp_alpha=0.1, gpr_alpha=0.1, jk_type='max', directed=False, num_mlp_layers=1, display_step=5, cached=False, print_prop=False, priv_type='edge', priv_ratio=0.5, save_model=False, save_name='gcn', log_name='none', base_model='gcn', not_load_teacher=False, mode='train', dist_mode='gkd', weight_decay=0.05, dropout=0.0, lr=0.01, use_bn=True, use_batch=False, batch_size=2048, oracle=False, device=0, alpha=0.5, delta=0.1, use_kd=False, beta=0.0, tau=1.0, kernel='sigmoid', t=1.0, include_last=False, s=2, m=1, lr2=0.001, sim='l2', ker_norm=False)\n",
            "cuda:0\n",
            "cora\n",
            "Num nodes: 2708\n",
            "torch.Size([2708, 1])\n",
            "num nodes 2708 | num classes 7 | num node feats 1433\n",
            "MODEL: GeoDist(\n",
            "  (k): Kernel(\n",
            "    (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  )\n",
            "  (teacher_gnn): ModuleList(\n",
            "    (0): Linear(in_features=1433, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (student_gnn): ModuleList(\n",
            "    (0): Linear(in_features=1433, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  (bns2d): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            ")\n",
            "Epoch: 00, Loss: 580697.3750, Train: 32.57%, Valid: 29.84%, Test: 26.88%\n",
            "Epoch: 05, Loss: 145588.3125, Train: 38.63%, Valid: 34.27%, Test: 38.55%\n",
            "Epoch: 10, Loss: 112488.3047, Train: 56.13%, Valid: 51.99%, Test: 54.80%\n",
            "Epoch: 15, Loss: 94836.8984, Train: 64.03%, Valid: 60.12%, Test: 64.70%\n",
            "Epoch: 20, Loss: 84084.3594, Train: 69.94%, Valid: 66.17%, Test: 71.20%\n",
            "Epoch: 25, Loss: 76261.1719, Train: 78.29%, Valid: 74.30%, Test: 78.43%\n",
            "Epoch: 30, Loss: 70379.8750, Train: 84.79%, Valid: 80.50%, Test: 84.49%\n",
            "Epoch: 35, Loss: 65676.4609, Train: 87.15%, Valid: 82.13%, Test: 87.15%\n",
            "Epoch: 40, Loss: 61899.3359, Train: 88.55%, Valid: 82.13%, Test: 88.04%\n",
            "Epoch: 45, Loss: 58711.6953, Train: 88.55%, Valid: 83.01%, Test: 87.74%\n",
            "Epoch: 50, Loss: 55978.4609, Train: 89.44%, Valid: 83.46%, Test: 87.59%\n",
            "Epoch: 55, Loss: 53563.4023, Train: 89.73%, Valid: 83.75%, Test: 87.74%\n",
            "Epoch: 60, Loss: 51456.7031, Train: 90.03%, Valid: 83.90%, Test: 87.59%\n",
            "Epoch: 65, Loss: 49592.6836, Train: 90.18%, Valid: 83.60%, Test: 87.59%\n",
            "Epoch: 70, Loss: 47910.6406, Train: 90.62%, Valid: 83.31%, Test: 87.30%\n",
            "Epoch: 75, Loss: 46398.8984, Train: 90.84%, Valid: 83.46%, Test: 87.59%\n",
            "Epoch: 80, Loss: 45012.3906, Train: 90.62%, Valid: 83.60%, Test: 87.59%\n",
            "Epoch: 85, Loss: 43766.2539, Train: 90.77%, Valid: 83.90%, Test: 87.59%\n",
            "Epoch: 90, Loss: 42619.4023, Train: 90.99%, Valid: 84.05%, Test: 87.59%\n",
            "Epoch: 95, Loss: 41674.8672, Train: 91.21%, Valid: 84.05%, Test: 87.44%\n",
            "Epoch: 100, Loss: 40720.2930, Train: 91.14%, Valid: 83.90%, Test: 87.74%\n",
            "Epoch: 105, Loss: 39744.0000, Train: 91.14%, Valid: 83.60%, Test: 87.89%\n",
            "Epoch: 110, Loss: 38823.6094, Train: 91.14%, Valid: 83.01%, Test: 87.74%\n",
            "Epoch: 115, Loss: 38052.2383, Train: 91.14%, Valid: 83.16%, Test: 87.59%\n",
            "Epoch: 120, Loss: 37303.6172, Train: 91.21%, Valid: 83.01%, Test: 87.59%\n",
            "Epoch: 125, Loss: 36583.0078, Train: 91.29%, Valid: 82.87%, Test: 88.04%\n",
            "Epoch: 130, Loss: 35987.2305, Train: 91.14%, Valid: 82.87%, Test: 88.04%\n",
            "Epoch: 135, Loss: 35325.7695, Train: 91.29%, Valid: 83.01%, Test: 88.04%\n",
            "Epoch: 140, Loss: 34758.7227, Train: 91.43%, Valid: 82.42%, Test: 87.89%\n",
            "Epoch: 145, Loss: 34453.5703, Train: 91.29%, Valid: 83.01%, Test: 88.04%\n",
            "Epoch: 150, Loss: 33892.0391, Train: 91.14%, Valid: 82.87%, Test: 88.18%\n",
            "Epoch: 155, Loss: 33370.7812, Train: 91.36%, Valid: 83.16%, Test: 88.18%\n",
            "Epoch: 160, Loss: 32876.3945, Train: 91.14%, Valid: 83.31%, Test: 88.18%\n",
            "Epoch: 165, Loss: 32485.9980, Train: 91.21%, Valid: 83.16%, Test: 88.18%\n",
            "Epoch: 170, Loss: 32189.6777, Train: 91.21%, Valid: 83.01%, Test: 88.33%\n",
            "Epoch: 175, Loss: 31677.3809, Train: 91.14%, Valid: 83.16%, Test: 88.18%\n",
            "Epoch: 180, Loss: 31979.9043, Train: 91.29%, Valid: 82.87%, Test: 88.63%\n",
            "Epoch: 185, Loss: 31250.0449, Train: 91.29%, Valid: 82.87%, Test: 88.18%\n",
            "Epoch: 190, Loss: 30529.8848, Train: 91.29%, Valid: 82.72%, Test: 88.48%\n",
            "Epoch: 195, Loss: 30355.3594, Train: 91.14%, Valid: 82.57%, Test: 88.48%\n",
            "Run 01:\n",
            "Highest Train: 91.43\n",
            "Highest Valid: 84.19\n",
            "Highest Test: 88.77\n",
            "Chosen epoch: 93\n",
            "Final Train: 90.99\n",
            "Final Test: 87.59\n",
            "Epoch: 00, Loss: 581394.8750, Train: 17.28%, Valid: 14.77%, Test: 15.07%\n",
            "Epoch: 05, Loss: 139934.3281, Train: 29.84%, Valid: 24.08%, Test: 25.85%\n",
            "Epoch: 10, Loss: 107692.4297, Train: 43.35%, Valid: 38.11%, Test: 38.40%\n",
            "Epoch: 15, Loss: 92026.6484, Train: 56.79%, Valid: 49.63%, Test: 51.70%\n",
            "Epoch: 20, Loss: 82127.8203, Train: 74.30%, Valid: 68.24%, Test: 71.05%\n",
            "Epoch: 25, Loss: 75027.1875, Train: 84.71%, Valid: 79.91%, Test: 83.46%\n",
            "Epoch: 30, Loss: 69429.9766, Train: 88.85%, Valid: 82.13%, Test: 86.56%\n",
            "Epoch: 35, Loss: 64889.2344, Train: 89.44%, Valid: 82.72%, Test: 87.30%\n",
            "Epoch: 40, Loss: 61174.9102, Train: 89.73%, Valid: 82.57%, Test: 87.30%\n",
            "Epoch: 45, Loss: 57917.3672, Train: 89.96%, Valid: 82.87%, Test: 87.30%\n",
            "Epoch: 50, Loss: 55175.2031, Train: 90.18%, Valid: 83.01%, Test: 87.59%\n",
            "Epoch: 55, Loss: 52769.7969, Train: 90.25%, Valid: 83.60%, Test: 87.89%\n",
            "Epoch: 60, Loss: 50641.6523, Train: 90.47%, Valid: 83.31%, Test: 88.04%\n",
            "Epoch: 65, Loss: 48765.0586, Train: 90.55%, Valid: 83.31%, Test: 87.89%\n",
            "Epoch: 70, Loss: 47074.6602, Train: 90.99%, Valid: 83.01%, Test: 88.48%\n",
            "Epoch: 75, Loss: 45565.7266, Train: 90.99%, Valid: 83.60%, Test: 88.33%\n",
            "Epoch: 80, Loss: 44192.6680, Train: 91.14%, Valid: 83.60%, Test: 88.33%\n",
            "Epoch: 85, Loss: 42941.2812, Train: 91.14%, Valid: 83.60%, Test: 88.04%\n",
            "Epoch: 90, Loss: 41787.8008, Train: 91.29%, Valid: 83.90%, Test: 88.04%\n",
            "Epoch: 95, Loss: 40718.8789, Train: 91.21%, Valid: 84.05%, Test: 88.04%\n",
            "Epoch: 100, Loss: 39742.5430, Train: 91.29%, Valid: 84.05%, Test: 88.04%\n",
            "Epoch: 105, Loss: 38907.8164, Train: 91.29%, Valid: 84.05%, Test: 87.59%\n",
            "Epoch: 110, Loss: 38007.5039, Train: 91.21%, Valid: 83.75%, Test: 87.59%\n",
            "Epoch: 115, Loss: 37291.3008, Train: 91.14%, Valid: 83.75%, Test: 87.74%\n",
            "Epoch: 120, Loss: 36544.8555, Train: 91.14%, Valid: 83.75%, Test: 87.89%\n",
            "Epoch: 125, Loss: 35848.4336, Train: 91.21%, Valid: 83.75%, Test: 87.89%\n",
            "Epoch: 130, Loss: 35174.0000, Train: 91.29%, Valid: 83.60%, Test: 88.18%\n",
            "Epoch: 135, Loss: 34607.1016, Train: 91.29%, Valid: 83.75%, Test: 88.33%\n",
            "Epoch: 140, Loss: 33996.5664, Train: 91.36%, Valid: 83.90%, Test: 88.33%\n",
            "Epoch: 145, Loss: 33654.3398, Train: 91.21%, Valid: 83.60%, Test: 88.33%\n",
            "Epoch: 150, Loss: 32972.8047, Train: 91.21%, Valid: 83.46%, Test: 88.33%\n",
            "Epoch: 155, Loss: 32523.1602, Train: 90.99%, Valid: 83.60%, Test: 88.33%\n",
            "Epoch: 160, Loss: 32252.7500, Train: 91.14%, Valid: 83.60%, Test: 88.33%\n",
            "Epoch: 165, Loss: 31675.2656, Train: 91.06%, Valid: 83.60%, Test: 88.33%\n",
            "Epoch: 170, Loss: 31273.8164, Train: 91.14%, Valid: 83.60%, Test: 88.77%\n",
            "Epoch: 175, Loss: 30881.0977, Train: 91.29%, Valid: 83.60%, Test: 88.77%\n",
            "Epoch: 180, Loss: 30923.8125, Train: 91.43%, Valid: 83.75%, Test: 88.77%\n",
            "Epoch: 185, Loss: 30261.3809, Train: 91.43%, Valid: 83.75%, Test: 88.63%\n",
            "Epoch: 190, Loss: 30015.4727, Train: 91.36%, Valid: 83.60%, Test: 88.63%\n",
            "Epoch: 195, Loss: 29761.7637, Train: 91.43%, Valid: 83.60%, Test: 88.63%\n",
            "Run 02:\n",
            "Highest Train: 91.51\n",
            "Highest Valid: 84.05\n",
            "Highest Test: 88.92\n",
            "Chosen epoch: 92\n",
            "Final Train: 91.29\n",
            "Final Test: 88.04\n",
            "Epoch: 00, Loss: 577275.9375, Train: 9.60%, Valid: 6.35%, Test: 9.75%\n",
            "Epoch: 05, Loss: 148441.1875, Train: 31.39%, Valid: 24.22%, Test: 30.87%\n",
            "Epoch: 10, Loss: 115764.7344, Train: 42.61%, Valid: 33.68%, Test: 39.00%\n",
            "Epoch: 15, Loss: 99384.2500, Train: 46.45%, Valid: 39.00%, Test: 42.84%\n",
            "Epoch: 20, Loss: 89416.3516, Train: 61.08%, Valid: 55.54%, Test: 59.68%\n",
            "Epoch: 25, Loss: 81932.2812, Train: 75.70%, Valid: 70.46%, Test: 75.48%\n",
            "Epoch: 30, Loss: 75967.8672, Train: 81.24%, Valid: 75.04%, Test: 80.95%\n",
            "Epoch: 35, Loss: 71317.8125, Train: 82.72%, Valid: 77.25%, Test: 82.72%\n",
            "Epoch: 40, Loss: 67432.6250, Train: 85.16%, Valid: 79.32%, Test: 83.46%\n",
            "Epoch: 45, Loss: 64139.3047, Train: 86.71%, Valid: 80.95%, Test: 85.52%\n",
            "Epoch: 50, Loss: 61313.1523, Train: 87.59%, Valid: 82.27%, Test: 86.12%\n",
            "Epoch: 55, Loss: 58871.7539, Train: 87.74%, Valid: 82.42%, Test: 86.71%\n",
            "Epoch: 60, Loss: 56725.2422, Train: 87.96%, Valid: 81.83%, Test: 86.56%\n",
            "Epoch: 65, Loss: 54818.1367, Train: 88.11%, Valid: 81.68%, Test: 87.00%\n",
            "Epoch: 70, Loss: 53092.1914, Train: 88.18%, Valid: 81.83%, Test: 86.85%\n",
            "Epoch: 75, Loss: 51507.2695, Train: 88.40%, Valid: 82.27%, Test: 87.15%\n",
            "Epoch: 80, Loss: 50066.6836, Train: 88.63%, Valid: 82.57%, Test: 87.59%\n",
            "Epoch: 85, Loss: 48749.1797, Train: 88.85%, Valid: 82.42%, Test: 87.15%\n",
            "Epoch: 90, Loss: 47539.4062, Train: 89.07%, Valid: 82.57%, Test: 87.15%\n",
            "Epoch: 95, Loss: 46422.6016, Train: 89.07%, Valid: 82.57%, Test: 87.30%\n",
            "Epoch: 100, Loss: 45388.2461, Train: 89.22%, Valid: 82.13%, Test: 87.15%\n",
            "Epoch: 105, Loss: 44426.9297, Train: 89.07%, Valid: 82.13%, Test: 87.15%\n",
            "Epoch: 110, Loss: 43528.9648, Train: 89.22%, Valid: 81.83%, Test: 87.00%\n",
            "Epoch: 115, Loss: 42693.1172, Train: 89.29%, Valid: 82.13%, Test: 86.71%\n",
            "Epoch: 120, Loss: 41911.2969, Train: 89.44%, Valid: 82.13%, Test: 87.15%\n",
            "Epoch: 125, Loss: 41172.5586, Train: 89.51%, Valid: 82.13%, Test: 87.15%\n",
            "Epoch: 130, Loss: 40591.3047, Train: 89.59%, Valid: 82.13%, Test: 87.00%\n",
            "Epoch: 135, Loss: 39878.1055, Train: 89.51%, Valid: 82.13%, Test: 87.00%\n",
            "Epoch: 140, Loss: 39289.3164, Train: 89.51%, Valid: 82.27%, Test: 87.30%\n",
            "Epoch: 145, Loss: 38721.0117, Train: 89.44%, Valid: 82.42%, Test: 87.00%\n",
            "Epoch: 150, Loss: 38098.6055, Train: 89.44%, Valid: 82.13%, Test: 87.00%\n",
            "Epoch: 155, Loss: 37611.3984, Train: 89.51%, Valid: 82.13%, Test: 86.85%\n",
            "Epoch: 160, Loss: 37388.6172, Train: 89.59%, Valid: 82.27%, Test: 86.85%\n",
            "Epoch: 165, Loss: 36908.7070, Train: 89.59%, Valid: 82.27%, Test: 86.85%\n",
            "Epoch: 170, Loss: 36458.5195, Train: 89.59%, Valid: 82.42%, Test: 86.85%\n",
            "Epoch: 175, Loss: 36075.3945, Train: 89.44%, Valid: 82.57%, Test: 86.85%\n",
            "Epoch: 180, Loss: 35809.9766, Train: 89.51%, Valid: 82.42%, Test: 87.00%\n",
            "Epoch: 185, Loss: 36074.8750, Train: 89.51%, Valid: 82.42%, Test: 87.15%\n",
            "Epoch: 190, Loss: 35412.7188, Train: 89.59%, Valid: 82.13%, Test: 87.30%\n",
            "Epoch: 195, Loss: 35161.4883, Train: 89.44%, Valid: 82.27%, Test: 87.44%\n",
            "Run 03:\n",
            "Highest Train: 89.66\n",
            "Highest Valid: 82.72\n",
            "Highest Test: 87.59\n",
            "Chosen epoch: 193\n",
            "Final Train: 89.51\n",
            "Final Test: 87.30\n",
            "Epoch: 00, Loss: 580695.2500, Train: 9.90%, Valid: 7.68%, Test: 8.27%\n",
            "Epoch: 05, Loss: 154034.0312, Train: 19.57%, Valid: 19.20%, Test: 17.43%\n",
            "Epoch: 10, Loss: 118971.6328, Train: 36.93%, Valid: 34.86%, Test: 32.94%\n",
            "Epoch: 15, Loss: 101694.6094, Train: 60.93%, Valid: 55.54%, Test: 55.54%\n",
            "Epoch: 20, Loss: 90536.9375, Train: 72.82%, Valid: 66.03%, Test: 68.24%\n",
            "Epoch: 25, Loss: 82340.7891, Train: 78.43%, Valid: 71.20%, Test: 74.00%\n",
            "Epoch: 30, Loss: 76058.8516, Train: 82.13%, Valid: 74.15%, Test: 78.43%\n",
            "Epoch: 35, Loss: 71044.7891, Train: 83.53%, Valid: 75.63%, Test: 80.65%\n",
            "Epoch: 40, Loss: 66849.1641, Train: 85.60%, Valid: 77.55%, Test: 82.13%\n",
            "Epoch: 45, Loss: 63313.5938, Train: 87.74%, Valid: 80.35%, Test: 84.79%\n",
            "Epoch: 50, Loss: 60281.3828, Train: 88.48%, Valid: 81.68%, Test: 85.67%\n",
            "Epoch: 55, Loss: 57661.9297, Train: 89.00%, Valid: 81.83%, Test: 86.71%\n",
            "Epoch: 60, Loss: 55383.8477, Train: 89.59%, Valid: 82.27%, Test: 87.15%\n",
            "Epoch: 65, Loss: 53369.9062, Train: 89.96%, Valid: 82.57%, Test: 87.15%\n",
            "Epoch: 70, Loss: 51558.3945, Train: 90.25%, Valid: 82.87%, Test: 87.30%\n",
            "Epoch: 75, Loss: 49931.1172, Train: 90.40%, Valid: 82.72%, Test: 88.04%\n",
            "Epoch: 80, Loss: 48473.6602, Train: 90.32%, Valid: 82.72%, Test: 88.04%\n",
            "Epoch: 85, Loss: 47139.8867, Train: 90.40%, Valid: 82.72%, Test: 88.04%\n",
            "Epoch: 90, Loss: 45924.3867, Train: 90.62%, Valid: 82.57%, Test: 87.89%\n",
            "Epoch: 95, Loss: 44809.4180, Train: 90.77%, Valid: 82.72%, Test: 87.89%\n",
            "Epoch: 100, Loss: 43777.9727, Train: 91.06%, Valid: 82.72%, Test: 87.89%\n",
            "Epoch: 105, Loss: 42814.8477, Train: 91.06%, Valid: 82.87%, Test: 87.89%\n",
            "Epoch: 110, Loss: 41924.7188, Train: 91.06%, Valid: 82.87%, Test: 88.04%\n",
            "Epoch: 115, Loss: 41096.3125, Train: 90.92%, Valid: 82.87%, Test: 88.04%\n",
            "Epoch: 120, Loss: 40320.1133, Train: 90.99%, Valid: 83.01%, Test: 87.89%\n",
            "Epoch: 125, Loss: 39591.4844, Train: 91.21%, Valid: 83.31%, Test: 87.89%\n",
            "Epoch: 130, Loss: 38911.3789, Train: 91.29%, Valid: 83.60%, Test: 88.04%\n",
            "Epoch: 135, Loss: 38282.6172, Train: 91.43%, Valid: 83.46%, Test: 88.04%\n",
            "Epoch: 140, Loss: 37700.7344, Train: 91.21%, Valid: 83.46%, Test: 88.04%\n",
            "Epoch: 145, Loss: 37234.0391, Train: 91.21%, Valid: 83.31%, Test: 88.18%\n",
            "Epoch: 150, Loss: 36599.2500, Train: 91.29%, Valid: 83.46%, Test: 88.18%\n",
            "Epoch: 155, Loss: 36286.8242, Train: 91.43%, Valid: 83.46%, Test: 88.18%\n",
            "Epoch: 160, Loss: 35842.8477, Train: 91.36%, Valid: 83.31%, Test: 88.18%\n",
            "Epoch: 165, Loss: 35447.2617, Train: 91.43%, Valid: 83.16%, Test: 88.18%\n",
            "Epoch: 170, Loss: 34947.9023, Train: 91.43%, Valid: 83.01%, Test: 88.18%\n",
            "Epoch: 175, Loss: 34462.0508, Train: 91.36%, Valid: 82.87%, Test: 88.04%\n",
            "Epoch: 180, Loss: 34423.1016, Train: 91.29%, Valid: 82.72%, Test: 87.74%\n",
            "Epoch: 185, Loss: 33788.5000, Train: 91.51%, Valid: 82.72%, Test: 88.04%\n",
            "Epoch: 190, Loss: 33394.1250, Train: 91.36%, Valid: 83.01%, Test: 88.04%\n",
            "Epoch: 195, Loss: 33179.0469, Train: 91.29%, Valid: 82.72%, Test: 88.04%\n",
            "Run 04:\n",
            "Highest Train: 91.65\n",
            "Highest Valid: 83.60\n",
            "Highest Test: 88.33\n",
            "Chosen epoch: 130\n",
            "Final Train: 91.21\n",
            "Final Test: 88.04\n",
            "Epoch: 00, Loss: 579095.8125, Train: 22.38%, Valid: 22.90%, Test: 21.86%\n",
            "Epoch: 05, Loss: 167397.9531, Train: 29.17%, Valid: 32.79%, Test: 29.69%\n",
            "Epoch: 10, Loss: 127774.9844, Train: 41.29%, Valid: 40.92%, Test: 39.29%\n",
            "Epoch: 15, Loss: 108167.0391, Train: 60.78%, Valid: 56.28%, Test: 57.02%\n",
            "Epoch: 20, Loss: 95727.7969, Train: 71.20%, Valid: 67.95%, Test: 69.42%\n",
            "Epoch: 25, Loss: 86452.3594, Train: 78.14%, Valid: 71.20%, Test: 76.51%\n",
            "Epoch: 30, Loss: 79332.0078, Train: 83.09%, Valid: 76.37%, Test: 80.95%\n",
            "Epoch: 35, Loss: 73537.8750, Train: 84.79%, Valid: 77.84%, Test: 82.42%\n",
            "Epoch: 40, Loss: 68735.4453, Train: 87.52%, Valid: 79.47%, Test: 85.38%\n",
            "Epoch: 45, Loss: 64773.0820, Train: 89.29%, Valid: 81.24%, Test: 87.44%\n",
            "Epoch: 50, Loss: 61321.5742, Train: 89.88%, Valid: 82.57%, Test: 88.33%\n",
            "Epoch: 55, Loss: 58367.6094, Train: 90.92%, Valid: 83.60%, Test: 88.63%\n",
            "Epoch: 60, Loss: 55807.7344, Train: 91.21%, Valid: 83.90%, Test: 89.07%\n",
            "Epoch: 65, Loss: 53586.8672, Train: 91.29%, Valid: 84.19%, Test: 89.36%\n",
            "Epoch: 70, Loss: 51617.4375, Train: 91.36%, Valid: 84.19%, Test: 89.07%\n",
            "Epoch: 75, Loss: 49838.1328, Train: 91.36%, Valid: 84.19%, Test: 89.36%\n",
            "Epoch: 80, Loss: 48275.7461, Train: 91.73%, Valid: 84.05%, Test: 89.22%\n",
            "Epoch: 85, Loss: 46886.7422, Train: 91.80%, Valid: 84.05%, Test: 89.22%\n",
            "Epoch: 90, Loss: 45613.2031, Train: 91.73%, Valid: 83.75%, Test: 89.22%\n",
            "Epoch: 95, Loss: 44471.2852, Train: 91.73%, Valid: 83.90%, Test: 89.36%\n",
            "Epoch: 100, Loss: 43661.3008, Train: 91.88%, Valid: 83.75%, Test: 89.51%\n",
            "Epoch: 105, Loss: 42656.8633, Train: 92.10%, Valid: 83.75%, Test: 89.22%\n",
            "Epoch: 110, Loss: 41699.4883, Train: 92.02%, Valid: 83.60%, Test: 89.22%\n",
            "Epoch: 115, Loss: 40825.7891, Train: 92.17%, Valid: 83.75%, Test: 89.22%\n",
            "Epoch: 120, Loss: 40109.0352, Train: 92.25%, Valid: 83.75%, Test: 89.07%\n",
            "Epoch: 125, Loss: 39302.2539, Train: 92.02%, Valid: 83.75%, Test: 89.07%\n",
            "Epoch: 130, Loss: 38680.4102, Train: 92.10%, Valid: 83.90%, Test: 89.07%\n",
            "Epoch: 135, Loss: 37947.6914, Train: 92.39%, Valid: 83.90%, Test: 89.07%\n",
            "Epoch: 140, Loss: 37601.6914, Train: 92.39%, Valid: 83.46%, Test: 89.07%\n",
            "Epoch: 145, Loss: 36997.8047, Train: 92.54%, Valid: 83.60%, Test: 89.51%\n",
            "Epoch: 150, Loss: 36601.8672, Train: 92.54%, Valid: 83.46%, Test: 89.36%\n",
            "Epoch: 155, Loss: 36190.8867, Train: 92.39%, Valid: 83.46%, Test: 89.07%\n",
            "Epoch: 160, Loss: 35562.1875, Train: 92.47%, Valid: 83.60%, Test: 89.07%\n",
            "Epoch: 165, Loss: 35513.2266, Train: 92.54%, Valid: 83.46%, Test: 89.07%\n",
            "Epoch: 170, Loss: 34726.8047, Train: 92.17%, Valid: 83.46%, Test: 89.22%\n",
            "Epoch: 175, Loss: 34847.8320, Train: 92.17%, Valid: 83.75%, Test: 89.07%\n",
            "Epoch: 180, Loss: 34151.6836, Train: 92.25%, Valid: 83.31%, Test: 89.22%\n",
            "Epoch: 185, Loss: 33771.0703, Train: 92.39%, Valid: 83.46%, Test: 89.07%\n",
            "Epoch: 190, Loss: 33783.8516, Train: 92.47%, Valid: 83.16%, Test: 89.22%\n",
            "Epoch: 195, Loss: 33089.6055, Train: 92.54%, Valid: 83.31%, Test: 89.22%\n",
            "Run 05:\n",
            "Highest Train: 92.69\n",
            "Highest Valid: 84.34\n",
            "Highest Test: 89.51\n",
            "Chosen epoch: 72\n",
            "Final Train: 91.29\n",
            "Final Test: 89.07\n",
            "All runs:\n",
            "Highest Train: 91.39 ± 1.09\n",
            "Highest Test: 88.63 ± 0.72\n",
            "Highest Valid: 83.78 ± 0.66\n",
            "  Final Train: 90.86 ± 0.76\n",
            "   Final Test: 88.01 ± 0.67\n",
            "Saving results to logs/cora_edge.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 GKD/main.py --dataset cora --rand_split --use_bn --base_model gcn --mode train --priv_type edge --dist_mode gkd --use_kd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gd6-PdxIGm7o",
        "outputId": "1cd8e03a-f580-4230-bd1c-fa57db306f46"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(data_dir='data', dataset='cora', sub_dataset='', cpu=False, seed=42, train_prop=0.5, valid_prop=0.25, protocol='semi', rand_split=True, metric='acc', runs=5, epochs=200, hidden_channels=32, num_layers=3, gat_heads=8, out_heads=1, hops=1, lp_alpha=0.1, gpr_alpha=0.1, jk_type='max', directed=False, num_mlp_layers=1, display_step=5, cached=False, print_prop=False, priv_type='edge', priv_ratio=0.5, save_model=False, save_name='gcn', log_name='none', base_model='gcn', not_load_teacher=False, mode='train', dist_mode='gkd', weight_decay=0.05, dropout=0.0, lr=0.01, use_bn=True, use_batch=False, batch_size=2048, oracle=False, device=0, alpha=0.5, delta=0.1, use_kd=True, beta=0.0, tau=1.0, kernel='sigmoid', t=1.0, include_last=False, s=2, m=1, lr2=0.001, sim='l2', ker_norm=False)\n",
            "cuda:0\n",
            "cora\n",
            "Num nodes: 2708\n",
            "torch.Size([2708, 1])\n",
            "num nodes 2708 | num classes 7 | num node feats 1433\n",
            "MODEL: GeoDist(\n",
            "  (k): Kernel(\n",
            "    (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  )\n",
            "  (teacher_gnn): ModuleList(\n",
            "    (0): Linear(in_features=1433, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (student_gnn): ModuleList(\n",
            "    (0): Linear(in_features=1433, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  (bns2d): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            ")\n",
            "Epoch: 00, Loss: 580697.3750, Train: 32.57%, Valid: 29.84%, Test: 26.88%\n",
            "Epoch: 05, Loss: 145588.3125, Train: 38.63%, Valid: 34.27%, Test: 38.55%\n",
            "Epoch: 10, Loss: 112488.3047, Train: 56.13%, Valid: 51.99%, Test: 54.80%\n",
            "Epoch: 15, Loss: 94836.8984, Train: 64.03%, Valid: 60.12%, Test: 64.70%\n",
            "Epoch: 20, Loss: 84084.3594, Train: 69.94%, Valid: 66.17%, Test: 71.20%\n",
            "Epoch: 25, Loss: 76261.1719, Train: 78.29%, Valid: 74.30%, Test: 78.43%\n",
            "Epoch: 30, Loss: 70379.8750, Train: 84.79%, Valid: 80.50%, Test: 84.49%\n",
            "Epoch: 35, Loss: 65676.4609, Train: 87.15%, Valid: 82.13%, Test: 87.15%\n",
            "Epoch: 40, Loss: 61899.3359, Train: 88.55%, Valid: 82.13%, Test: 88.04%\n",
            "Epoch: 45, Loss: 58711.6914, Train: 88.55%, Valid: 83.01%, Test: 87.74%\n",
            "Epoch: 50, Loss: 55978.4609, Train: 89.44%, Valid: 83.46%, Test: 87.59%\n",
            "Epoch: 55, Loss: 53563.4023, Train: 89.73%, Valid: 83.75%, Test: 87.74%\n",
            "Epoch: 60, Loss: 51456.7031, Train: 90.03%, Valid: 83.90%, Test: 87.59%\n",
            "Epoch: 65, Loss: 49592.6836, Train: 90.18%, Valid: 83.60%, Test: 87.59%\n",
            "Epoch: 70, Loss: 47910.6406, Train: 90.62%, Valid: 83.31%, Test: 87.30%\n",
            "Epoch: 75, Loss: 46398.8984, Train: 90.84%, Valid: 83.46%, Test: 87.59%\n",
            "Epoch: 80, Loss: 45012.3906, Train: 90.62%, Valid: 83.60%, Test: 87.59%\n",
            "Epoch: 85, Loss: 43766.2500, Train: 90.77%, Valid: 83.90%, Test: 87.59%\n",
            "Epoch: 90, Loss: 42619.4023, Train: 90.99%, Valid: 84.05%, Test: 87.59%\n",
            "Epoch: 95, Loss: 41674.6094, Train: 91.21%, Valid: 84.05%, Test: 87.44%\n",
            "Epoch: 100, Loss: 40720.0977, Train: 91.14%, Valid: 83.90%, Test: 87.74%\n",
            "Epoch: 105, Loss: 39744.1797, Train: 91.14%, Valid: 83.60%, Test: 87.89%\n",
            "Epoch: 110, Loss: 38823.6211, Train: 91.14%, Valid: 83.01%, Test: 87.74%\n",
            "Epoch: 115, Loss: 38052.3281, Train: 91.14%, Valid: 83.16%, Test: 87.59%\n",
            "Epoch: 120, Loss: 37303.5352, Train: 91.21%, Valid: 83.01%, Test: 87.59%\n",
            "Epoch: 125, Loss: 36582.9102, Train: 91.29%, Valid: 82.87%, Test: 88.04%\n",
            "Epoch: 130, Loss: 35987.6992, Train: 91.14%, Valid: 82.87%, Test: 88.04%\n",
            "Epoch: 135, Loss: 35332.1484, Train: 91.29%, Valid: 83.01%, Test: 88.04%\n",
            "Epoch: 140, Loss: 34752.5273, Train: 91.36%, Valid: 82.42%, Test: 88.04%\n",
            "Epoch: 145, Loss: 34483.3945, Train: 91.36%, Valid: 83.01%, Test: 88.04%\n",
            "Epoch: 150, Loss: 33923.4023, Train: 91.14%, Valid: 82.87%, Test: 88.18%\n",
            "Epoch: 155, Loss: 33368.4922, Train: 91.21%, Valid: 83.16%, Test: 88.18%\n",
            "Epoch: 160, Loss: 32881.4180, Train: 91.21%, Valid: 83.16%, Test: 88.18%\n",
            "Epoch: 165, Loss: 32462.6621, Train: 91.21%, Valid: 83.46%, Test: 88.18%\n",
            "Epoch: 170, Loss: 32102.4004, Train: 91.06%, Valid: 83.16%, Test: 88.33%\n",
            "Epoch: 175, Loss: 31716.2852, Train: 91.14%, Valid: 83.16%, Test: 88.18%\n",
            "Epoch: 180, Loss: 31776.4375, Train: 90.99%, Valid: 82.87%, Test: 88.33%\n",
            "Epoch: 185, Loss: 31181.0312, Train: 91.06%, Valid: 82.87%, Test: 88.33%\n",
            "Epoch: 190, Loss: 30771.5801, Train: 91.14%, Valid: 82.57%, Test: 88.33%\n",
            "Epoch: 195, Loss: 30439.3652, Train: 91.36%, Valid: 82.72%, Test: 88.48%\n",
            "Run 01:\n",
            "Highest Train: 91.43\n",
            "Highest Valid: 84.19\n",
            "Highest Test: 88.77\n",
            "Chosen epoch: 93\n",
            "Final Train: 90.99\n",
            "Final Test: 87.59\n",
            "Epoch: 00, Loss: 581394.8750, Train: 17.28%, Valid: 14.77%, Test: 15.07%\n",
            "Epoch: 05, Loss: 139934.3281, Train: 29.84%, Valid: 24.08%, Test: 25.85%\n",
            "Epoch: 10, Loss: 107692.4297, Train: 43.35%, Valid: 38.11%, Test: 38.40%\n",
            "Epoch: 15, Loss: 92026.6484, Train: 56.79%, Valid: 49.63%, Test: 51.70%\n",
            "Epoch: 20, Loss: 82127.8203, Train: 74.30%, Valid: 68.24%, Test: 71.05%\n",
            "Epoch: 25, Loss: 75027.1875, Train: 84.71%, Valid: 79.91%, Test: 83.46%\n",
            "Epoch: 30, Loss: 69429.9766, Train: 88.85%, Valid: 82.13%, Test: 86.56%\n",
            "Epoch: 35, Loss: 64889.2305, Train: 89.44%, Valid: 82.72%, Test: 87.30%\n",
            "Epoch: 40, Loss: 61174.9102, Train: 89.73%, Valid: 82.57%, Test: 87.30%\n",
            "Epoch: 45, Loss: 57917.3672, Train: 89.96%, Valid: 82.87%, Test: 87.30%\n",
            "Epoch: 50, Loss: 55175.2031, Train: 90.18%, Valid: 83.01%, Test: 87.59%\n",
            "Epoch: 55, Loss: 52769.7969, Train: 90.25%, Valid: 83.60%, Test: 87.89%\n",
            "Epoch: 60, Loss: 50641.6523, Train: 90.47%, Valid: 83.31%, Test: 88.04%\n",
            "Epoch: 65, Loss: 48765.0625, Train: 90.55%, Valid: 83.31%, Test: 87.89%\n",
            "Epoch: 70, Loss: 47074.6602, Train: 90.99%, Valid: 83.01%, Test: 88.48%\n",
            "Epoch: 75, Loss: 45565.7266, Train: 90.99%, Valid: 83.60%, Test: 88.33%\n",
            "Epoch: 80, Loss: 44192.6680, Train: 91.14%, Valid: 83.60%, Test: 88.33%\n",
            "Epoch: 85, Loss: 42941.2812, Train: 91.14%, Valid: 83.60%, Test: 88.04%\n",
            "Epoch: 90, Loss: 41787.8008, Train: 91.29%, Valid: 83.90%, Test: 88.04%\n",
            "Epoch: 95, Loss: 40718.8789, Train: 91.21%, Valid: 84.05%, Test: 88.04%\n",
            "Epoch: 100, Loss: 39742.4961, Train: 91.29%, Valid: 84.05%, Test: 88.04%\n",
            "Epoch: 105, Loss: 38908.3086, Train: 91.29%, Valid: 84.05%, Test: 87.59%\n",
            "Epoch: 110, Loss: 38007.4102, Train: 91.21%, Valid: 83.75%, Test: 87.59%\n",
            "Epoch: 115, Loss: 37291.2734, Train: 91.14%, Valid: 83.75%, Test: 87.74%\n",
            "Epoch: 120, Loss: 36544.9453, Train: 91.14%, Valid: 83.75%, Test: 87.89%\n",
            "Epoch: 125, Loss: 35849.8086, Train: 91.21%, Valid: 83.75%, Test: 87.89%\n",
            "Epoch: 130, Loss: 35173.3125, Train: 91.29%, Valid: 83.60%, Test: 88.18%\n",
            "Epoch: 135, Loss: 34630.1797, Train: 91.29%, Valid: 83.75%, Test: 88.33%\n",
            "Epoch: 140, Loss: 33994.9961, Train: 91.36%, Valid: 83.75%, Test: 88.33%\n",
            "Epoch: 145, Loss: 33491.3711, Train: 91.21%, Valid: 83.90%, Test: 88.48%\n",
            "Epoch: 150, Loss: 33384.8086, Train: 91.21%, Valid: 83.46%, Test: 88.33%\n",
            "Epoch: 155, Loss: 32646.9199, Train: 90.99%, Valid: 83.60%, Test: 88.48%\n",
            "Epoch: 160, Loss: 32167.5625, Train: 91.06%, Valid: 83.90%, Test: 88.48%\n",
            "Epoch: 165, Loss: 31829.2793, Train: 91.06%, Valid: 84.05%, Test: 88.33%\n",
            "Epoch: 170, Loss: 31415.6719, Train: 91.21%, Valid: 83.75%, Test: 88.77%\n",
            "Epoch: 175, Loss: 31944.3789, Train: 91.36%, Valid: 84.05%, Test: 88.92%\n",
            "Epoch: 180, Loss: 31203.8359, Train: 91.36%, Valid: 83.60%, Test: 88.77%\n",
            "Epoch: 185, Loss: 30530.8750, Train: 91.36%, Valid: 83.60%, Test: 88.77%\n",
            "Epoch: 190, Loss: 30109.2148, Train: 91.36%, Valid: 83.75%, Test: 88.63%\n",
            "Epoch: 195, Loss: 29820.3281, Train: 91.43%, Valid: 83.60%, Test: 88.63%\n",
            "Run 02:\n",
            "Highest Train: 91.43\n",
            "Highest Valid: 84.05\n",
            "Highest Test: 88.92\n",
            "Chosen epoch: 92\n",
            "Final Train: 91.29\n",
            "Final Test: 88.04\n",
            "Epoch: 00, Loss: 577275.9375, Train: 9.60%, Valid: 6.35%, Test: 9.75%\n",
            "Epoch: 05, Loss: 148441.1875, Train: 31.39%, Valid: 24.22%, Test: 30.87%\n",
            "Epoch: 10, Loss: 115764.7344, Train: 42.61%, Valid: 33.68%, Test: 39.00%\n",
            "Epoch: 15, Loss: 99384.2500, Train: 46.45%, Valid: 39.00%, Test: 42.84%\n",
            "Epoch: 20, Loss: 89416.3594, Train: 61.08%, Valid: 55.54%, Test: 59.68%\n",
            "Epoch: 25, Loss: 81932.2812, Train: 75.70%, Valid: 70.46%, Test: 75.48%\n",
            "Epoch: 30, Loss: 75967.8672, Train: 81.24%, Valid: 75.04%, Test: 80.95%\n",
            "Epoch: 35, Loss: 71317.8125, Train: 82.72%, Valid: 77.25%, Test: 82.72%\n",
            "Epoch: 40, Loss: 67432.6250, Train: 85.16%, Valid: 79.32%, Test: 83.46%\n",
            "Epoch: 45, Loss: 64139.3008, Train: 86.71%, Valid: 80.95%, Test: 85.52%\n",
            "Epoch: 50, Loss: 61313.1523, Train: 87.59%, Valid: 82.27%, Test: 86.12%\n",
            "Epoch: 55, Loss: 58871.7539, Train: 87.74%, Valid: 82.42%, Test: 86.71%\n",
            "Epoch: 60, Loss: 56725.2422, Train: 87.96%, Valid: 81.83%, Test: 86.56%\n",
            "Epoch: 65, Loss: 54818.1367, Train: 88.11%, Valid: 81.68%, Test: 87.00%\n",
            "Epoch: 70, Loss: 53092.1875, Train: 88.18%, Valid: 81.83%, Test: 86.85%\n",
            "Epoch: 75, Loss: 51507.2695, Train: 88.40%, Valid: 82.27%, Test: 87.15%\n",
            "Epoch: 80, Loss: 50066.6836, Train: 88.63%, Valid: 82.57%, Test: 87.59%\n",
            "Epoch: 85, Loss: 48749.1836, Train: 88.85%, Valid: 82.42%, Test: 87.15%\n",
            "Epoch: 90, Loss: 47539.4062, Train: 89.07%, Valid: 82.57%, Test: 87.15%\n",
            "Epoch: 95, Loss: 46422.5938, Train: 89.07%, Valid: 82.57%, Test: 87.30%\n",
            "Epoch: 100, Loss: 45388.2383, Train: 89.22%, Valid: 82.13%, Test: 87.15%\n",
            "Epoch: 105, Loss: 44426.9180, Train: 89.07%, Valid: 82.13%, Test: 87.15%\n",
            "Epoch: 110, Loss: 43528.9766, Train: 89.22%, Valid: 81.83%, Test: 87.00%\n",
            "Epoch: 115, Loss: 42693.2461, Train: 89.29%, Valid: 82.13%, Test: 86.71%\n",
            "Epoch: 120, Loss: 41911.3125, Train: 89.44%, Valid: 82.13%, Test: 87.15%\n",
            "Epoch: 125, Loss: 41172.6875, Train: 89.51%, Valid: 82.13%, Test: 87.15%\n",
            "Epoch: 130, Loss: 40596.7070, Train: 89.59%, Valid: 82.13%, Test: 87.00%\n",
            "Epoch: 135, Loss: 39880.5742, Train: 89.51%, Valid: 82.13%, Test: 87.00%\n",
            "Epoch: 140, Loss: 39297.1641, Train: 89.51%, Valid: 82.27%, Test: 87.30%\n",
            "Epoch: 145, Loss: 38731.5508, Train: 89.44%, Valid: 82.42%, Test: 87.00%\n",
            "Epoch: 150, Loss: 38102.4727, Train: 89.51%, Valid: 82.13%, Test: 87.00%\n",
            "Epoch: 155, Loss: 37615.5664, Train: 89.51%, Valid: 82.27%, Test: 86.85%\n",
            "Epoch: 160, Loss: 37644.0195, Train: 89.59%, Valid: 82.27%, Test: 86.85%\n",
            "Epoch: 165, Loss: 37014.8359, Train: 89.59%, Valid: 82.27%, Test: 86.85%\n",
            "Epoch: 170, Loss: 36620.8125, Train: 89.44%, Valid: 82.42%, Test: 86.85%\n",
            "Epoch: 175, Loss: 36100.0273, Train: 89.51%, Valid: 82.42%, Test: 86.85%\n",
            "Epoch: 180, Loss: 35969.6641, Train: 89.51%, Valid: 82.42%, Test: 86.85%\n",
            "Epoch: 185, Loss: 35481.8945, Train: 89.44%, Valid: 82.27%, Test: 87.30%\n",
            "Epoch: 190, Loss: 35215.9297, Train: 89.59%, Valid: 82.27%, Test: 87.30%\n",
            "Epoch: 195, Loss: 34728.4570, Train: 89.59%, Valid: 82.42%, Test: 87.44%\n",
            "Run 03:\n",
            "Highest Train: 89.66\n",
            "Highest Valid: 82.87\n",
            "Highest Test: 87.59\n",
            "Chosen epoch: 197\n",
            "Final Train: 89.51\n",
            "Final Test: 87.44\n",
            "Epoch: 00, Loss: 580695.2500, Train: 9.90%, Valid: 7.68%, Test: 8.27%\n",
            "Epoch: 05, Loss: 154034.0312, Train: 19.57%, Valid: 19.20%, Test: 17.43%\n",
            "Epoch: 10, Loss: 118971.6328, Train: 36.93%, Valid: 34.86%, Test: 32.94%\n",
            "Epoch: 15, Loss: 101694.6094, Train: 60.93%, Valid: 55.54%, Test: 55.54%\n",
            "Epoch: 20, Loss: 90536.9375, Train: 72.82%, Valid: 66.03%, Test: 68.24%\n",
            "Epoch: 25, Loss: 82340.7891, Train: 78.43%, Valid: 71.20%, Test: 74.00%\n",
            "Epoch: 30, Loss: 76058.8516, Train: 82.13%, Valid: 74.15%, Test: 78.43%\n",
            "Epoch: 35, Loss: 71044.7891, Train: 83.53%, Valid: 75.63%, Test: 80.65%\n",
            "Epoch: 40, Loss: 66849.1641, Train: 85.60%, Valid: 77.55%, Test: 82.13%\n",
            "Epoch: 45, Loss: 63313.5938, Train: 87.74%, Valid: 80.35%, Test: 84.79%\n",
            "Epoch: 50, Loss: 60281.3867, Train: 88.48%, Valid: 81.68%, Test: 85.67%\n",
            "Epoch: 55, Loss: 57661.9297, Train: 89.00%, Valid: 81.83%, Test: 86.71%\n",
            "Epoch: 60, Loss: 55383.8477, Train: 89.59%, Valid: 82.27%, Test: 87.15%\n",
            "Epoch: 65, Loss: 53369.9062, Train: 89.96%, Valid: 82.57%, Test: 87.15%\n",
            "Epoch: 70, Loss: 51558.3945, Train: 90.25%, Valid: 82.87%, Test: 87.30%\n",
            "Epoch: 75, Loss: 49931.1172, Train: 90.40%, Valid: 82.72%, Test: 88.04%\n",
            "Epoch: 80, Loss: 48473.6602, Train: 90.32%, Valid: 82.72%, Test: 88.04%\n",
            "Epoch: 85, Loss: 47139.8867, Train: 90.40%, Valid: 82.72%, Test: 88.04%\n",
            "Epoch: 90, Loss: 45924.3867, Train: 90.62%, Valid: 82.57%, Test: 87.89%\n",
            "Epoch: 95, Loss: 44809.4180, Train: 90.77%, Valid: 82.72%, Test: 87.89%\n",
            "Epoch: 100, Loss: 43778.0273, Train: 91.06%, Valid: 82.72%, Test: 87.89%\n",
            "Epoch: 105, Loss: 42814.9297, Train: 91.06%, Valid: 82.87%, Test: 87.89%\n",
            "Epoch: 110, Loss: 41924.7070, Train: 91.06%, Valid: 82.87%, Test: 88.04%\n",
            "Epoch: 115, Loss: 41096.3867, Train: 90.92%, Valid: 82.87%, Test: 88.04%\n",
            "Epoch: 120, Loss: 40320.0273, Train: 90.99%, Valid: 83.01%, Test: 87.89%\n",
            "Epoch: 125, Loss: 39591.5352, Train: 91.21%, Valid: 83.31%, Test: 87.89%\n",
            "Epoch: 130, Loss: 38912.2539, Train: 91.36%, Valid: 83.60%, Test: 88.04%\n",
            "Epoch: 135, Loss: 38270.5312, Train: 91.43%, Valid: 83.46%, Test: 88.04%\n",
            "Epoch: 140, Loss: 37702.0703, Train: 91.21%, Valid: 83.31%, Test: 88.04%\n",
            "Epoch: 145, Loss: 37258.8672, Train: 91.21%, Valid: 83.31%, Test: 87.89%\n",
            "Epoch: 150, Loss: 36639.3359, Train: 91.21%, Valid: 83.31%, Test: 88.04%\n",
            "Epoch: 155, Loss: 36187.0000, Train: 91.43%, Valid: 83.46%, Test: 88.18%\n",
            "Epoch: 160, Loss: 35676.6445, Train: 91.43%, Valid: 83.31%, Test: 88.18%\n",
            "Epoch: 165, Loss: 35466.1445, Train: 91.51%, Valid: 83.01%, Test: 88.33%\n",
            "Epoch: 170, Loss: 35069.6914, Train: 91.36%, Valid: 83.01%, Test: 88.18%\n",
            "Epoch: 175, Loss: 34826.9727, Train: 91.51%, Valid: 82.72%, Test: 88.18%\n",
            "Epoch: 180, Loss: 34217.8555, Train: 91.43%, Valid: 82.87%, Test: 88.18%\n",
            "Epoch: 185, Loss: 33911.6250, Train: 91.43%, Valid: 82.57%, Test: 88.04%\n",
            "Epoch: 190, Loss: 33619.9766, Train: 91.36%, Valid: 82.87%, Test: 88.04%\n",
            "Epoch: 195, Loss: 33176.8203, Train: 91.36%, Valid: 82.87%, Test: 88.04%\n",
            "Run 04:\n",
            "Highest Train: 91.65\n",
            "Highest Valid: 83.60\n",
            "Highest Test: 88.33\n",
            "Chosen epoch: 130\n",
            "Final Train: 91.21\n",
            "Final Test: 88.04\n",
            "Epoch: 00, Loss: 579095.8125, Train: 22.38%, Valid: 22.90%, Test: 21.86%\n",
            "Epoch: 05, Loss: 167397.9531, Train: 29.17%, Valid: 32.79%, Test: 29.69%\n",
            "Epoch: 10, Loss: 127774.9844, Train: 41.29%, Valid: 40.92%, Test: 39.29%\n",
            "Epoch: 15, Loss: 108167.0391, Train: 60.78%, Valid: 56.28%, Test: 57.02%\n",
            "Epoch: 20, Loss: 95727.8047, Train: 71.20%, Valid: 67.95%, Test: 69.42%\n",
            "Epoch: 25, Loss: 86452.3594, Train: 78.14%, Valid: 71.20%, Test: 76.51%\n",
            "Epoch: 30, Loss: 79332.0078, Train: 83.09%, Valid: 76.37%, Test: 80.95%\n",
            "Epoch: 35, Loss: 73537.8750, Train: 84.79%, Valid: 77.84%, Test: 82.42%\n",
            "Epoch: 40, Loss: 68735.4375, Train: 87.52%, Valid: 79.47%, Test: 85.38%\n",
            "Epoch: 45, Loss: 64773.0859, Train: 89.29%, Valid: 81.24%, Test: 87.44%\n",
            "Epoch: 50, Loss: 61321.5742, Train: 89.88%, Valid: 82.57%, Test: 88.33%\n",
            "Epoch: 55, Loss: 58367.6094, Train: 90.92%, Valid: 83.60%, Test: 88.63%\n",
            "Epoch: 60, Loss: 55807.7266, Train: 91.21%, Valid: 83.90%, Test: 89.07%\n",
            "Epoch: 65, Loss: 53586.8594, Train: 91.29%, Valid: 84.19%, Test: 89.36%\n",
            "Epoch: 70, Loss: 51617.3984, Train: 91.36%, Valid: 84.19%, Test: 89.07%\n",
            "Epoch: 75, Loss: 49838.2461, Train: 91.36%, Valid: 84.19%, Test: 89.36%\n",
            "Epoch: 80, Loss: 48275.7695, Train: 91.73%, Valid: 84.05%, Test: 89.36%\n",
            "Epoch: 85, Loss: 46887.2852, Train: 91.80%, Valid: 84.05%, Test: 89.22%\n",
            "Epoch: 90, Loss: 45613.4961, Train: 91.73%, Valid: 83.75%, Test: 89.22%\n",
            "Epoch: 95, Loss: 44471.3945, Train: 91.73%, Valid: 83.90%, Test: 89.36%\n",
            "Epoch: 100, Loss: 43670.0508, Train: 91.88%, Valid: 83.75%, Test: 89.51%\n",
            "Epoch: 105, Loss: 42647.8633, Train: 92.02%, Valid: 83.75%, Test: 89.22%\n",
            "Epoch: 110, Loss: 41685.2695, Train: 92.02%, Valid: 83.60%, Test: 89.22%\n",
            "Epoch: 115, Loss: 40835.5039, Train: 92.17%, Valid: 83.75%, Test: 89.22%\n",
            "Epoch: 120, Loss: 40080.4336, Train: 92.17%, Valid: 83.75%, Test: 89.07%\n",
            "Epoch: 125, Loss: 39279.0469, Train: 91.95%, Valid: 83.90%, Test: 89.07%\n",
            "Epoch: 130, Loss: 38714.9375, Train: 92.02%, Valid: 83.90%, Test: 89.07%\n",
            "Epoch: 135, Loss: 37929.4688, Train: 92.39%, Valid: 83.90%, Test: 89.07%\n",
            "Epoch: 140, Loss: 37781.6914, Train: 92.39%, Valid: 83.46%, Test: 89.07%\n",
            "Epoch: 145, Loss: 37115.3359, Train: 92.47%, Valid: 83.60%, Test: 89.51%\n",
            "Epoch: 150, Loss: 36452.9766, Train: 92.32%, Valid: 83.60%, Test: 89.36%\n",
            "Epoch: 155, Loss: 35947.9141, Train: 92.39%, Valid: 83.46%, Test: 89.22%\n",
            "Epoch: 160, Loss: 35318.8047, Train: 92.39%, Valid: 83.46%, Test: 89.22%\n",
            "Epoch: 165, Loss: 35372.1719, Train: 92.25%, Valid: 83.75%, Test: 89.22%\n",
            "Epoch: 170, Loss: 34777.0547, Train: 92.10%, Valid: 83.46%, Test: 89.07%\n",
            "Epoch: 175, Loss: 34376.5859, Train: 92.17%, Valid: 83.46%, Test: 89.36%\n",
            "Epoch: 180, Loss: 33943.8945, Train: 92.25%, Valid: 83.60%, Test: 89.07%\n",
            "Epoch: 185, Loss: 33611.4375, Train: 92.47%, Valid: 83.46%, Test: 89.07%\n",
            "Epoch: 190, Loss: 33213.6797, Train: 92.47%, Valid: 83.16%, Test: 89.22%\n",
            "Epoch: 195, Loss: 33238.4102, Train: 92.25%, Valid: 83.01%, Test: 88.92%\n",
            "Run 05:\n",
            "Highest Train: 92.61\n",
            "Highest Valid: 84.34\n",
            "Highest Test: 89.51\n",
            "Chosen epoch: 72\n",
            "Final Train: 91.29\n",
            "Final Test: 89.07\n",
            "All runs:\n",
            "Highest Train: 91.36 ± 1.07\n",
            "Highest Test: 88.63 ± 0.72\n",
            "Highest Valid: 83.81 ± 0.60\n",
            "  Final Train: 90.86 ± 0.76\n",
            "   Final Test: 88.04 ± 0.64\n",
            "Saving results to logs/cora_edge.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 GKD/main.py --dataset cora --rand_split --use_bn --base_model gcn --mode train  --dist_mode gkd --use_kd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3k6t88xYGsAr",
        "outputId": "36eccf1e-3cce-4173-e735-d4c0b2bba543"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(data_dir='data', dataset='cora', sub_dataset='', cpu=False, seed=42, train_prop=0.5, valid_prop=0.25, protocol='semi', rand_split=True, metric='acc', runs=5, epochs=200, hidden_channels=32, num_layers=3, gat_heads=8, out_heads=1, hops=1, lp_alpha=0.1, gpr_alpha=0.1, jk_type='max', directed=False, num_mlp_layers=1, display_step=5, cached=False, print_prop=False, priv_type='edge', priv_ratio=0.5, save_model=False, save_name='gcn', log_name='none', base_model='gcn', not_load_teacher=False, mode='train', dist_mode='gkd', weight_decay=0.05, dropout=0.0, lr=0.01, use_bn=True, use_batch=False, batch_size=2048, oracle=False, device=0, alpha=0.5, delta=0.1, use_kd=True, beta=0.0, tau=1.0, kernel='sigmoid', t=1.0, include_last=False, s=2, m=1, lr2=0.001, sim='l2', ker_norm=False)\n",
            "cuda:0\n",
            "cora\n",
            "Num nodes: 2708\n",
            "torch.Size([2708, 1])\n",
            "num nodes 2708 | num classes 7 | num node feats 1433\n",
            "MODEL: GeoDist(\n",
            "  (k): Kernel(\n",
            "    (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  )\n",
            "  (teacher_gnn): ModuleList(\n",
            "    (0): Linear(in_features=1433, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (student_gnn): ModuleList(\n",
            "    (0): Linear(in_features=1433, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  (bns2d): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            ")\n",
            "Epoch: 00, Loss: 580697.3750, Train: 32.57%, Valid: 29.84%, Test: 26.88%\n",
            "Epoch: 05, Loss: 145588.3125, Train: 38.63%, Valid: 34.27%, Test: 38.55%\n",
            "Epoch: 10, Loss: 112488.2969, Train: 56.13%, Valid: 51.99%, Test: 54.80%\n",
            "Epoch: 15, Loss: 94836.8984, Train: 64.03%, Valid: 60.12%, Test: 64.70%\n",
            "Epoch: 20, Loss: 84084.3594, Train: 69.94%, Valid: 66.17%, Test: 71.20%\n",
            "Epoch: 25, Loss: 76261.1719, Train: 78.29%, Valid: 74.30%, Test: 78.43%\n",
            "Epoch: 30, Loss: 70379.8750, Train: 84.79%, Valid: 80.50%, Test: 84.49%\n",
            "Epoch: 35, Loss: 65676.4609, Train: 87.15%, Valid: 82.13%, Test: 87.15%\n",
            "Epoch: 40, Loss: 61899.3359, Train: 88.55%, Valid: 82.13%, Test: 88.04%\n",
            "Epoch: 45, Loss: 58711.6953, Train: 88.55%, Valid: 83.01%, Test: 87.74%\n",
            "Epoch: 50, Loss: 55978.4570, Train: 89.44%, Valid: 83.46%, Test: 87.59%\n",
            "Epoch: 55, Loss: 53563.4023, Train: 89.73%, Valid: 83.75%, Test: 87.74%\n",
            "Epoch: 60, Loss: 51456.7109, Train: 90.03%, Valid: 83.90%, Test: 87.59%\n",
            "Epoch: 65, Loss: 49592.6836, Train: 90.18%, Valid: 83.60%, Test: 87.59%\n",
            "Epoch: 70, Loss: 47910.6406, Train: 90.62%, Valid: 83.31%, Test: 87.30%\n",
            "Epoch: 75, Loss: 46398.8984, Train: 90.84%, Valid: 83.46%, Test: 87.59%\n",
            "Epoch: 80, Loss: 45012.3906, Train: 90.62%, Valid: 83.60%, Test: 87.59%\n",
            "Epoch: 85, Loss: 43766.2500, Train: 90.77%, Valid: 83.90%, Test: 87.59%\n",
            "Epoch: 90, Loss: 42619.4023, Train: 90.99%, Valid: 84.05%, Test: 87.59%\n",
            "Epoch: 95, Loss: 41674.7422, Train: 91.21%, Valid: 84.05%, Test: 87.44%\n",
            "Epoch: 100, Loss: 40720.1992, Train: 91.14%, Valid: 83.90%, Test: 87.74%\n",
            "Epoch: 105, Loss: 39744.0898, Train: 91.14%, Valid: 83.60%, Test: 87.89%\n",
            "Epoch: 110, Loss: 38823.6211, Train: 91.14%, Valid: 83.01%, Test: 87.74%\n",
            "Epoch: 115, Loss: 38052.3086, Train: 91.14%, Valid: 83.16%, Test: 87.59%\n",
            "Epoch: 120, Loss: 37303.4258, Train: 91.21%, Valid: 83.01%, Test: 87.59%\n",
            "Epoch: 125, Loss: 36582.8828, Train: 91.29%, Valid: 82.87%, Test: 88.04%\n",
            "Epoch: 130, Loss: 35987.6758, Train: 91.14%, Valid: 82.87%, Test: 88.04%\n",
            "Epoch: 135, Loss: 35330.2695, Train: 91.29%, Valid: 83.01%, Test: 88.04%\n",
            "Epoch: 140, Loss: 34761.7852, Train: 91.29%, Valid: 82.42%, Test: 88.04%\n",
            "Epoch: 145, Loss: 34434.3945, Train: 91.36%, Valid: 83.01%, Test: 88.04%\n",
            "Epoch: 150, Loss: 33907.7070, Train: 91.14%, Valid: 82.87%, Test: 88.18%\n",
            "Epoch: 155, Loss: 33340.6680, Train: 91.21%, Valid: 83.16%, Test: 88.18%\n",
            "Epoch: 160, Loss: 32843.1367, Train: 91.21%, Valid: 83.31%, Test: 88.18%\n",
            "Epoch: 165, Loss: 32520.8418, Train: 91.29%, Valid: 83.31%, Test: 88.33%\n",
            "Epoch: 170, Loss: 32112.4082, Train: 91.14%, Valid: 83.16%, Test: 88.33%\n",
            "Epoch: 175, Loss: 31804.3340, Train: 91.06%, Valid: 83.01%, Test: 88.33%\n",
            "Epoch: 180, Loss: 31839.5488, Train: 90.99%, Valid: 83.01%, Test: 88.48%\n",
            "Epoch: 185, Loss: 31133.8496, Train: 91.06%, Valid: 82.87%, Test: 88.33%\n",
            "Epoch: 190, Loss: 30604.9785, Train: 91.14%, Valid: 82.72%, Test: 88.33%\n",
            "Epoch: 195, Loss: 30234.1875, Train: 91.21%, Valid: 82.72%, Test: 88.33%\n",
            "Run 01:\n",
            "Highest Train: 91.43\n",
            "Highest Valid: 84.19\n",
            "Highest Test: 88.77\n",
            "Chosen epoch: 93\n",
            "Final Train: 90.99\n",
            "Final Test: 87.59\n",
            "Epoch: 00, Loss: 581394.8750, Train: 17.28%, Valid: 14.77%, Test: 15.07%\n",
            "Epoch: 05, Loss: 139934.3281, Train: 29.84%, Valid: 24.08%, Test: 25.85%\n",
            "Epoch: 10, Loss: 107692.4297, Train: 43.35%, Valid: 38.11%, Test: 38.40%\n",
            "Epoch: 15, Loss: 92026.6484, Train: 56.79%, Valid: 49.63%, Test: 51.70%\n",
            "Epoch: 20, Loss: 82127.8203, Train: 74.30%, Valid: 68.24%, Test: 71.05%\n",
            "Epoch: 25, Loss: 75027.1875, Train: 84.71%, Valid: 79.91%, Test: 83.46%\n",
            "Epoch: 30, Loss: 69429.9766, Train: 88.85%, Valid: 82.13%, Test: 86.56%\n",
            "Epoch: 35, Loss: 64889.2305, Train: 89.44%, Valid: 82.72%, Test: 87.30%\n",
            "Epoch: 40, Loss: 61174.9102, Train: 89.73%, Valid: 82.57%, Test: 87.30%\n",
            "Epoch: 45, Loss: 57917.3672, Train: 89.96%, Valid: 82.87%, Test: 87.30%\n",
            "Epoch: 50, Loss: 55175.2031, Train: 90.18%, Valid: 83.01%, Test: 87.59%\n",
            "Epoch: 55, Loss: 52769.7969, Train: 90.25%, Valid: 83.60%, Test: 87.89%\n",
            "Epoch: 60, Loss: 50641.6523, Train: 90.47%, Valid: 83.31%, Test: 88.04%\n",
            "Epoch: 65, Loss: 48765.0625, Train: 90.55%, Valid: 83.31%, Test: 87.89%\n",
            "Epoch: 70, Loss: 47074.6641, Train: 90.99%, Valid: 83.01%, Test: 88.48%\n",
            "Epoch: 75, Loss: 45565.7266, Train: 90.99%, Valid: 83.60%, Test: 88.33%\n",
            "Epoch: 80, Loss: 44192.6680, Train: 91.14%, Valid: 83.60%, Test: 88.33%\n",
            "Epoch: 85, Loss: 42941.2812, Train: 91.14%, Valid: 83.60%, Test: 88.04%\n",
            "Epoch: 90, Loss: 41787.8008, Train: 91.29%, Valid: 83.90%, Test: 88.04%\n",
            "Epoch: 95, Loss: 40718.8789, Train: 91.21%, Valid: 84.05%, Test: 88.04%\n",
            "Epoch: 100, Loss: 39742.4922, Train: 91.29%, Valid: 84.05%, Test: 88.04%\n",
            "Epoch: 105, Loss: 38908.3594, Train: 91.29%, Valid: 84.05%, Test: 87.59%\n",
            "Epoch: 110, Loss: 38007.3945, Train: 91.21%, Valid: 83.75%, Test: 87.59%\n",
            "Epoch: 115, Loss: 37291.2617, Train: 91.14%, Valid: 83.75%, Test: 87.74%\n",
            "Epoch: 120, Loss: 36544.9609, Train: 91.14%, Valid: 83.75%, Test: 87.89%\n",
            "Epoch: 125, Loss: 35849.9258, Train: 91.21%, Valid: 83.75%, Test: 87.89%\n",
            "Epoch: 130, Loss: 35173.2422, Train: 91.29%, Valid: 83.60%, Test: 88.18%\n",
            "Epoch: 135, Loss: 34630.4688, Train: 91.29%, Valid: 83.75%, Test: 88.33%\n",
            "Epoch: 140, Loss: 33994.2422, Train: 91.36%, Valid: 83.75%, Test: 88.33%\n",
            "Epoch: 145, Loss: 33489.6602, Train: 91.21%, Valid: 83.90%, Test: 88.48%\n",
            "Epoch: 150, Loss: 33395.8008, Train: 91.21%, Valid: 83.46%, Test: 88.48%\n",
            "Epoch: 155, Loss: 32686.8906, Train: 90.99%, Valid: 83.60%, Test: 88.33%\n",
            "Epoch: 160, Loss: 32151.5059, Train: 91.06%, Valid: 84.05%, Test: 88.33%\n",
            "Epoch: 165, Loss: 31778.6621, Train: 91.06%, Valid: 84.05%, Test: 88.33%\n",
            "Epoch: 170, Loss: 31501.1016, Train: 91.21%, Valid: 84.19%, Test: 88.77%\n",
            "Epoch: 175, Loss: 31185.8691, Train: 91.29%, Valid: 83.75%, Test: 88.77%\n",
            "Epoch: 180, Loss: 31032.8848, Train: 91.43%, Valid: 83.75%, Test: 88.77%\n",
            "Epoch: 185, Loss: 30523.0938, Train: 91.43%, Valid: 83.75%, Test: 88.63%\n",
            "Epoch: 190, Loss: 30116.5078, Train: 91.43%, Valid: 83.46%, Test: 88.77%\n",
            "Epoch: 195, Loss: 29587.4883, Train: 91.43%, Valid: 83.90%, Test: 88.63%\n",
            "Run 02:\n",
            "Highest Train: 91.51\n",
            "Highest Valid: 84.19\n",
            "Highest Test: 88.92\n",
            "Chosen epoch: 150\n",
            "Final Train: 91.21\n",
            "Final Test: 88.48\n",
            "Epoch: 00, Loss: 577275.8125, Train: 9.60%, Valid: 6.35%, Test: 9.75%\n",
            "Epoch: 05, Loss: 148441.1875, Train: 31.39%, Valid: 24.22%, Test: 30.87%\n",
            "Epoch: 10, Loss: 115764.7344, Train: 42.61%, Valid: 33.68%, Test: 39.00%\n",
            "Epoch: 15, Loss: 99384.2500, Train: 46.45%, Valid: 39.00%, Test: 42.84%\n",
            "Epoch: 20, Loss: 89416.3594, Train: 61.08%, Valid: 55.54%, Test: 59.68%\n",
            "Epoch: 25, Loss: 81932.2812, Train: 75.70%, Valid: 70.46%, Test: 75.48%\n",
            "Epoch: 30, Loss: 75967.8672, Train: 81.24%, Valid: 75.04%, Test: 80.95%\n",
            "Epoch: 35, Loss: 71317.8125, Train: 82.72%, Valid: 77.25%, Test: 82.72%\n",
            "Epoch: 40, Loss: 67432.6250, Train: 85.16%, Valid: 79.32%, Test: 83.46%\n",
            "Epoch: 45, Loss: 64139.3086, Train: 86.71%, Valid: 80.95%, Test: 85.52%\n",
            "Epoch: 50, Loss: 61313.1562, Train: 87.59%, Valid: 82.27%, Test: 86.12%\n",
            "Epoch: 55, Loss: 58871.7539, Train: 87.74%, Valid: 82.42%, Test: 86.71%\n",
            "Epoch: 60, Loss: 56725.2422, Train: 87.96%, Valid: 81.83%, Test: 86.56%\n",
            "Epoch: 65, Loss: 54818.1367, Train: 88.11%, Valid: 81.68%, Test: 87.00%\n",
            "Epoch: 70, Loss: 53092.1914, Train: 88.18%, Valid: 81.83%, Test: 86.85%\n",
            "Epoch: 75, Loss: 51507.2695, Train: 88.40%, Valid: 82.27%, Test: 87.15%\n",
            "Epoch: 80, Loss: 50066.6875, Train: 88.63%, Valid: 82.57%, Test: 87.59%\n",
            "Epoch: 85, Loss: 48749.1797, Train: 88.85%, Valid: 82.42%, Test: 87.15%\n",
            "Epoch: 90, Loss: 47539.4062, Train: 89.07%, Valid: 82.57%, Test: 87.15%\n",
            "Epoch: 95, Loss: 46422.6016, Train: 89.07%, Valid: 82.57%, Test: 87.30%\n",
            "Epoch: 100, Loss: 45388.2461, Train: 89.22%, Valid: 82.13%, Test: 87.15%\n",
            "Epoch: 105, Loss: 44426.9297, Train: 89.07%, Valid: 82.13%, Test: 87.15%\n",
            "Epoch: 110, Loss: 43528.9648, Train: 89.22%, Valid: 81.83%, Test: 87.00%\n",
            "Epoch: 115, Loss: 42693.1289, Train: 89.29%, Valid: 82.13%, Test: 86.71%\n",
            "Epoch: 120, Loss: 41911.2891, Train: 89.44%, Valid: 82.13%, Test: 87.15%\n",
            "Epoch: 125, Loss: 41172.4062, Train: 89.51%, Valid: 82.13%, Test: 87.15%\n",
            "Epoch: 130, Loss: 40572.1055, Train: 89.59%, Valid: 82.13%, Test: 87.00%\n",
            "Epoch: 135, Loss: 39877.9336, Train: 89.51%, Valid: 82.13%, Test: 87.00%\n",
            "Epoch: 140, Loss: 39285.2070, Train: 89.51%, Valid: 82.27%, Test: 87.30%\n",
            "Epoch: 145, Loss: 38720.0898, Train: 89.51%, Valid: 82.42%, Test: 87.00%\n",
            "Epoch: 150, Loss: 38097.5117, Train: 89.36%, Valid: 82.13%, Test: 87.00%\n",
            "Epoch: 155, Loss: 37621.0742, Train: 89.51%, Valid: 82.13%, Test: 86.85%\n",
            "Epoch: 160, Loss: 37488.2617, Train: 89.59%, Valid: 82.27%, Test: 86.85%\n",
            "Epoch: 165, Loss: 36865.7070, Train: 89.59%, Valid: 82.27%, Test: 86.85%\n",
            "Epoch: 170, Loss: 36462.8555, Train: 89.59%, Valid: 82.57%, Test: 86.85%\n",
            "Epoch: 175, Loss: 35934.3516, Train: 89.51%, Valid: 82.42%, Test: 86.85%\n",
            "Epoch: 180, Loss: 35774.7812, Train: 89.51%, Valid: 82.42%, Test: 87.15%\n",
            "Epoch: 185, Loss: 35320.1836, Train: 89.44%, Valid: 82.27%, Test: 87.30%\n",
            "Epoch: 190, Loss: 35116.4375, Train: 89.59%, Valid: 82.27%, Test: 87.44%\n",
            "Epoch: 195, Loss: 34748.6445, Train: 89.44%, Valid: 82.72%, Test: 87.44%\n",
            "Run 03:\n",
            "Highest Train: 89.66\n",
            "Highest Valid: 82.72\n",
            "Highest Test: 87.59\n",
            "Chosen epoch: 182\n",
            "Final Train: 89.36\n",
            "Final Test: 87.00\n",
            "Epoch: 00, Loss: 580695.2500, Train: 9.90%, Valid: 7.68%, Test: 8.27%\n",
            "Epoch: 05, Loss: 154034.0312, Train: 19.57%, Valid: 19.20%, Test: 17.43%\n",
            "Epoch: 10, Loss: 118971.6328, Train: 36.93%, Valid: 34.86%, Test: 32.94%\n",
            "Epoch: 15, Loss: 101694.6094, Train: 60.93%, Valid: 55.54%, Test: 55.54%\n",
            "Epoch: 20, Loss: 90536.9375, Train: 72.82%, Valid: 66.03%, Test: 68.24%\n",
            "Epoch: 25, Loss: 82340.7891, Train: 78.43%, Valid: 71.20%, Test: 74.00%\n",
            "Epoch: 30, Loss: 76058.8516, Train: 82.13%, Valid: 74.15%, Test: 78.43%\n",
            "Epoch: 35, Loss: 71044.7891, Train: 83.53%, Valid: 75.63%, Test: 80.65%\n",
            "Epoch: 40, Loss: 66849.1641, Train: 85.60%, Valid: 77.55%, Test: 82.13%\n",
            "Epoch: 45, Loss: 63313.5977, Train: 87.74%, Valid: 80.35%, Test: 84.79%\n",
            "Epoch: 50, Loss: 60281.3867, Train: 88.48%, Valid: 81.68%, Test: 85.67%\n",
            "Epoch: 55, Loss: 57661.9297, Train: 89.00%, Valid: 81.83%, Test: 86.71%\n",
            "Epoch: 60, Loss: 55383.8477, Train: 89.59%, Valid: 82.27%, Test: 87.15%\n",
            "Epoch: 65, Loss: 53369.9062, Train: 89.96%, Valid: 82.57%, Test: 87.15%\n",
            "Epoch: 70, Loss: 51558.3945, Train: 90.25%, Valid: 82.87%, Test: 87.30%\n",
            "Epoch: 75, Loss: 49931.1172, Train: 90.40%, Valid: 82.72%, Test: 88.04%\n",
            "Epoch: 80, Loss: 48473.6602, Train: 90.32%, Valid: 82.72%, Test: 88.04%\n",
            "Epoch: 85, Loss: 47139.8867, Train: 90.40%, Valid: 82.72%, Test: 88.04%\n",
            "Epoch: 90, Loss: 45924.3867, Train: 90.62%, Valid: 82.57%, Test: 87.89%\n",
            "Epoch: 95, Loss: 44809.4180, Train: 90.77%, Valid: 82.72%, Test: 87.89%\n",
            "Epoch: 100, Loss: 43777.9883, Train: 91.06%, Valid: 82.72%, Test: 87.89%\n",
            "Epoch: 105, Loss: 42814.8672, Train: 91.06%, Valid: 82.87%, Test: 87.89%\n",
            "Epoch: 110, Loss: 41924.7188, Train: 91.06%, Valid: 82.87%, Test: 88.04%\n",
            "Epoch: 115, Loss: 41096.3281, Train: 90.92%, Valid: 82.87%, Test: 88.04%\n",
            "Epoch: 120, Loss: 40320.0781, Train: 90.99%, Valid: 83.01%, Test: 87.89%\n",
            "Epoch: 125, Loss: 39591.4180, Train: 91.21%, Valid: 83.31%, Test: 87.89%\n",
            "Epoch: 130, Loss: 38908.5703, Train: 91.36%, Valid: 83.60%, Test: 88.04%\n",
            "Epoch: 135, Loss: 38267.0859, Train: 91.43%, Valid: 83.46%, Test: 88.04%\n",
            "Epoch: 140, Loss: 37717.0664, Train: 91.21%, Valid: 83.31%, Test: 88.04%\n",
            "Epoch: 145, Loss: 37214.4180, Train: 91.14%, Valid: 83.31%, Test: 88.04%\n",
            "Epoch: 150, Loss: 36712.8906, Train: 91.36%, Valid: 83.31%, Test: 88.18%\n",
            "Epoch: 155, Loss: 36126.3320, Train: 91.36%, Valid: 83.46%, Test: 88.04%\n",
            "Epoch: 160, Loss: 35724.6914, Train: 91.43%, Valid: 83.31%, Test: 88.18%\n",
            "Epoch: 165, Loss: 35367.8555, Train: 91.51%, Valid: 82.87%, Test: 88.18%\n",
            "Epoch: 170, Loss: 35097.2109, Train: 91.51%, Valid: 82.72%, Test: 88.04%\n",
            "Epoch: 175, Loss: 34633.5195, Train: 91.36%, Valid: 82.72%, Test: 88.04%\n",
            "Epoch: 180, Loss: 34246.4062, Train: 91.43%, Valid: 82.72%, Test: 88.18%\n",
            "Epoch: 185, Loss: 33896.0469, Train: 91.43%, Valid: 82.72%, Test: 87.89%\n",
            "Epoch: 190, Loss: 33594.8867, Train: 91.51%, Valid: 83.01%, Test: 88.04%\n",
            "Epoch: 195, Loss: 33397.7578, Train: 91.51%, Valid: 82.87%, Test: 88.18%\n",
            "Run 04:\n",
            "Highest Train: 91.58\n",
            "Highest Valid: 83.60\n",
            "Highest Test: 88.33\n",
            "Chosen epoch: 129\n",
            "Final Train: 91.21\n",
            "Final Test: 88.04\n",
            "Epoch: 00, Loss: 579095.8125, Train: 22.38%, Valid: 22.90%, Test: 21.86%\n",
            "Epoch: 05, Loss: 167397.9531, Train: 29.17%, Valid: 32.79%, Test: 29.69%\n",
            "Epoch: 10, Loss: 127774.9922, Train: 41.29%, Valid: 40.92%, Test: 39.29%\n",
            "Epoch: 15, Loss: 108167.0391, Train: 60.78%, Valid: 56.28%, Test: 57.02%\n",
            "Epoch: 20, Loss: 95727.8047, Train: 71.20%, Valid: 67.95%, Test: 69.42%\n",
            "Epoch: 25, Loss: 86452.3594, Train: 78.14%, Valid: 71.20%, Test: 76.51%\n",
            "Epoch: 30, Loss: 79332.0078, Train: 83.09%, Valid: 76.37%, Test: 80.95%\n",
            "Epoch: 35, Loss: 73537.8750, Train: 84.79%, Valid: 77.84%, Test: 82.42%\n",
            "Epoch: 40, Loss: 68735.4453, Train: 87.52%, Valid: 79.47%, Test: 85.38%\n",
            "Epoch: 45, Loss: 64773.0820, Train: 89.29%, Valid: 81.24%, Test: 87.44%\n",
            "Epoch: 50, Loss: 61321.5742, Train: 89.88%, Valid: 82.57%, Test: 88.33%\n",
            "Epoch: 55, Loss: 58367.6094, Train: 90.92%, Valid: 83.60%, Test: 88.63%\n",
            "Epoch: 60, Loss: 55807.7227, Train: 91.21%, Valid: 83.90%, Test: 89.07%\n",
            "Epoch: 65, Loss: 53586.8555, Train: 91.29%, Valid: 84.19%, Test: 89.36%\n",
            "Epoch: 70, Loss: 51617.3906, Train: 91.36%, Valid: 84.19%, Test: 89.07%\n",
            "Epoch: 75, Loss: 49838.2305, Train: 91.36%, Valid: 84.19%, Test: 89.36%\n",
            "Epoch: 80, Loss: 48275.8086, Train: 91.73%, Valid: 84.05%, Test: 89.36%\n",
            "Epoch: 85, Loss: 46887.2344, Train: 91.80%, Valid: 84.05%, Test: 89.22%\n",
            "Epoch: 90, Loss: 45613.5000, Train: 91.73%, Valid: 83.75%, Test: 89.22%\n",
            "Epoch: 95, Loss: 44480.9414, Train: 91.65%, Valid: 83.90%, Test: 89.36%\n",
            "Epoch: 100, Loss: 43672.4336, Train: 91.88%, Valid: 83.75%, Test: 89.51%\n",
            "Epoch: 105, Loss: 42636.4648, Train: 92.02%, Valid: 83.75%, Test: 89.22%\n",
            "Epoch: 110, Loss: 41682.5820, Train: 92.02%, Valid: 83.60%, Test: 89.22%\n",
            "Epoch: 115, Loss: 40844.5898, Train: 92.25%, Valid: 83.75%, Test: 89.22%\n",
            "Epoch: 120, Loss: 40076.4062, Train: 92.17%, Valid: 83.75%, Test: 89.07%\n",
            "Epoch: 125, Loss: 39288.8711, Train: 92.02%, Valid: 83.90%, Test: 89.07%\n",
            "Epoch: 130, Loss: 38758.7227, Train: 92.10%, Valid: 83.90%, Test: 89.07%\n",
            "Epoch: 135, Loss: 37923.0742, Train: 92.39%, Valid: 83.90%, Test: 89.22%\n",
            "Epoch: 140, Loss: 37767.5781, Train: 92.47%, Valid: 83.46%, Test: 89.07%\n",
            "Epoch: 145, Loss: 37038.3242, Train: 92.61%, Valid: 83.75%, Test: 89.51%\n",
            "Epoch: 150, Loss: 36349.0234, Train: 92.47%, Valid: 83.60%, Test: 89.22%\n",
            "Epoch: 155, Loss: 35816.1562, Train: 92.39%, Valid: 83.60%, Test: 89.07%\n",
            "Epoch: 160, Loss: 35883.2344, Train: 92.47%, Valid: 83.46%, Test: 88.92%\n",
            "Epoch: 165, Loss: 35308.8516, Train: 92.54%, Valid: 83.46%, Test: 89.07%\n",
            "Epoch: 170, Loss: 34759.9805, Train: 92.25%, Valid: 83.46%, Test: 89.36%\n",
            "Epoch: 175, Loss: 34457.1445, Train: 92.39%, Valid: 83.46%, Test: 89.07%\n",
            "Epoch: 180, Loss: 34162.2266, Train: 92.47%, Valid: 83.60%, Test: 88.92%\n",
            "Epoch: 185, Loss: 33863.4727, Train: 92.47%, Valid: 83.31%, Test: 88.77%\n",
            "Epoch: 190, Loss: 33698.6406, Train: 92.47%, Valid: 83.01%, Test: 89.07%\n",
            "Epoch: 195, Loss: 33146.6758, Train: 92.47%, Valid: 83.01%, Test: 88.92%\n",
            "Run 05:\n",
            "Highest Train: 92.61\n",
            "Highest Valid: 84.34\n",
            "Highest Test: 89.51\n",
            "Chosen epoch: 72\n",
            "Final Train: 91.29\n",
            "Final Test: 89.07\n",
            "All runs:\n",
            "Highest Train: 91.36 ± 1.07\n",
            "Highest Test: 88.63 ± 0.72\n",
            "Highest Valid: 83.81 ± 0.67\n",
            "  Final Train: 90.81 ± 0.82\n",
            "   Final Test: 88.04 ± 0.80\n",
            "Saving results to logs/cora_edge.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 GKD/main.py --dataset cora --rand_split --use_bn --base_model gcn --mode train  --dist_mode pgkd --use_kd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlWbFDTUGuSC",
        "outputId": "a1cfb16d-e8be-4f78-cc70-0363b20bdb2f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(data_dir='data', dataset='cora', sub_dataset='', cpu=False, seed=42, train_prop=0.5, valid_prop=0.25, protocol='semi', rand_split=True, metric='acc', runs=5, epochs=200, hidden_channels=32, num_layers=3, gat_heads=8, out_heads=1, hops=1, lp_alpha=0.1, gpr_alpha=0.1, jk_type='max', directed=False, num_mlp_layers=1, display_step=5, cached=False, print_prop=False, priv_type='edge', priv_ratio=0.5, save_model=False, save_name='gcn', log_name='none', base_model='gcn', not_load_teacher=False, mode='train', dist_mode='pgkd', weight_decay=0.05, dropout=0.0, lr=0.01, use_bn=True, use_batch=False, batch_size=2048, oracle=False, device=0, alpha=0.5, delta=0.1, use_kd=True, beta=0.0, tau=1.0, kernel='sigmoid', t=1.0, include_last=False, s=2, m=1, lr2=0.001, sim='l2', ker_norm=False)\n",
            "cuda:0\n",
            "cora\n",
            "Num nodes: 2708\n",
            "torch.Size([2708, 1])\n",
            "num nodes 2708 | num classes 7 | num node feats 1433\n",
            "MODEL: GeoDist(\n",
            "  (k): Kernel(\n",
            "    (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  )\n",
            "  (teacher_gnn): ModuleList(\n",
            "    (0): Linear(in_features=1433, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (student_gnn): ModuleList(\n",
            "    (0): Linear(in_features=1433, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  (bns2d): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            ")\n",
            "Epoch: 00, Loss: 69602560.0000, Train: 29.69%, Valid: 26.44%, Test: 25.70%\n",
            "Epoch: 05, Loss: 16549491.0000, Train: 34.93%, Valid: 33.53%, Test: 30.72%\n",
            "Epoch: 10, Loss: 11642521.0000, Train: 48.52%, Valid: 44.46%, Test: 44.46%\n",
            "Epoch: 15, Loss: 9567567.0000, Train: 61.45%, Valid: 57.16%, Test: 60.27%\n",
            "Epoch: 20, Loss: 8263297.5000, Train: 72.53%, Valid: 68.24%, Test: 71.49%\n",
            "Epoch: 25, Loss: 7349686.5000, Train: 81.68%, Valid: 76.51%, Test: 80.80%\n",
            "Epoch: 30, Loss: 6697714.5000, Train: 83.83%, Valid: 77.55%, Test: 83.31%\n",
            "Epoch: 35, Loss: 6189754.0000, Train: 84.93%, Valid: 78.73%, Test: 82.87%\n",
            "Epoch: 40, Loss: 5772580.5000, Train: 87.67%, Valid: 80.50%, Test: 86.26%\n",
            "Epoch: 45, Loss: 5443417.5000, Train: 88.77%, Valid: 81.83%, Test: 86.26%\n",
            "Epoch: 50, Loss: 5175602.0000, Train: 89.36%, Valid: 82.13%, Test: 87.30%\n",
            "Epoch: 55, Loss: 4948820.5000, Train: 89.88%, Valid: 82.87%, Test: 87.15%\n",
            "Epoch: 60, Loss: 4754053.5000, Train: 90.10%, Valid: 82.87%, Test: 87.89%\n",
            "Epoch: 65, Loss: 4586355.5000, Train: 89.96%, Valid: 83.16%, Test: 87.59%\n",
            "Epoch: 70, Loss: 4435254.5000, Train: 90.10%, Valid: 83.16%, Test: 87.59%\n",
            "Epoch: 75, Loss: 4297774.0000, Train: 90.32%, Valid: 83.60%, Test: 87.74%\n",
            "Epoch: 80, Loss: 4168890.7500, Train: 90.69%, Valid: 83.60%, Test: 87.59%\n",
            "Epoch: 85, Loss: 4052017.2500, Train: 90.84%, Valid: 83.31%, Test: 87.74%\n",
            "Epoch: 90, Loss: 3944887.0000, Train: 90.99%, Valid: 83.01%, Test: 87.59%\n",
            "Epoch: 95, Loss: 3846370.2500, Train: 91.06%, Valid: 83.01%, Test: 87.89%\n",
            "Epoch: 100, Loss: 3758346.7500, Train: 91.29%, Valid: 83.46%, Test: 87.74%\n",
            "Epoch: 105, Loss: 3672884.2500, Train: 91.36%, Valid: 82.87%, Test: 87.44%\n",
            "Epoch: 110, Loss: 3591151.7500, Train: 91.21%, Valid: 82.42%, Test: 87.44%\n",
            "Epoch: 115, Loss: 3511161.2500, Train: 91.14%, Valid: 82.72%, Test: 87.44%\n",
            "Epoch: 120, Loss: 3432124.2500, Train: 91.06%, Valid: 83.01%, Test: 87.59%\n",
            "Epoch: 125, Loss: 3364009.2500, Train: 91.06%, Valid: 82.72%, Test: 87.89%\n",
            "Epoch: 130, Loss: 3299491.7500, Train: 90.99%, Valid: 82.72%, Test: 87.74%\n",
            "Epoch: 135, Loss: 3238406.2500, Train: 91.06%, Valid: 82.57%, Test: 87.59%\n",
            "Epoch: 140, Loss: 3177475.2500, Train: 91.14%, Valid: 82.87%, Test: 87.74%\n",
            "Epoch: 145, Loss: 3118166.7500, Train: 91.21%, Valid: 82.72%, Test: 87.59%\n",
            "Epoch: 150, Loss: 3059469.5000, Train: 91.06%, Valid: 82.87%, Test: 87.74%\n",
            "Epoch: 155, Loss: 3003649.0000, Train: 90.92%, Valid: 83.01%, Test: 87.74%\n",
            "Epoch: 160, Loss: 2949408.7500, Train: 90.92%, Valid: 82.87%, Test: 87.89%\n",
            "Epoch: 165, Loss: 2894185.7500, Train: 90.77%, Valid: 83.01%, Test: 87.59%\n",
            "Epoch: 170, Loss: 2836666.0000, Train: 90.62%, Valid: 82.87%, Test: 87.59%\n",
            "Epoch: 175, Loss: 2784315.0000, Train: 90.55%, Valid: 82.87%, Test: 87.74%\n",
            "Epoch: 180, Loss: 2734402.7500, Train: 90.55%, Valid: 83.01%, Test: 87.59%\n",
            "Epoch: 185, Loss: 2685494.0000, Train: 90.32%, Valid: 83.01%, Test: 87.59%\n",
            "Epoch: 190, Loss: 2639151.0000, Train: 90.40%, Valid: 83.01%, Test: 87.59%\n",
            "Epoch: 195, Loss: 2595559.0000, Train: 90.25%, Valid: 83.46%, Test: 87.59%\n",
            "Run 01:\n",
            "Highest Train: 91.36\n",
            "Highest Valid: 83.75\n",
            "Highest Test: 88.04\n",
            "Chosen epoch: 84\n",
            "Final Train: 90.77\n",
            "Final Test: 87.74\n",
            "Epoch: 00, Loss: 59527816.0000, Train: 22.01%, Valid: 18.46%, Test: 21.27%\n",
            "Epoch: 05, Loss: 17722226.0000, Train: 28.58%, Valid: 23.93%, Test: 26.74%\n",
            "Epoch: 10, Loss: 12376076.0000, Train: 38.55%, Valid: 33.68%, Test: 36.93%\n",
            "Epoch: 15, Loss: 10112444.0000, Train: 53.10%, Valid: 49.48%, Test: 51.99%\n",
            "Epoch: 20, Loss: 8757269.0000, Train: 61.15%, Valid: 58.64%, Test: 60.27%\n",
            "Epoch: 25, Loss: 7858195.5000, Train: 72.01%, Valid: 70.16%, Test: 70.46%\n",
            "Epoch: 30, Loss: 7244116.5000, Train: 78.21%, Valid: 75.92%, Test: 77.10%\n",
            "Epoch: 35, Loss: 6817967.5000, Train: 80.87%, Valid: 78.88%, Test: 79.47%\n",
            "Epoch: 40, Loss: 6461590.5000, Train: 83.23%, Valid: 80.21%, Test: 81.54%\n",
            "Epoch: 45, Loss: 6172785.5000, Train: 84.49%, Valid: 80.95%, Test: 83.75%\n",
            "Epoch: 50, Loss: 5924936.0000, Train: 85.01%, Valid: 81.54%, Test: 84.79%\n",
            "Epoch: 55, Loss: 5721082.5000, Train: 85.30%, Valid: 81.39%, Test: 85.08%\n",
            "Epoch: 60, Loss: 5545254.5000, Train: 86.04%, Valid: 81.54%, Test: 84.64%\n",
            "Epoch: 65, Loss: 5380010.0000, Train: 86.04%, Valid: 81.83%, Test: 84.64%\n",
            "Epoch: 70, Loss: 5223174.5000, Train: 86.41%, Valid: 81.68%, Test: 84.93%\n",
            "Epoch: 75, Loss: 5058434.0000, Train: 87.15%, Valid: 81.83%, Test: 85.23%\n",
            "Epoch: 80, Loss: 4897352.5000, Train: 87.00%, Valid: 81.98%, Test: 85.38%\n",
            "Epoch: 85, Loss: 4749609.0000, Train: 86.85%, Valid: 82.13%, Test: 85.38%\n",
            "Epoch: 90, Loss: 4622789.0000, Train: 87.30%, Valid: 81.68%, Test: 86.12%\n",
            "Epoch: 95, Loss: 4508619.5000, Train: 87.67%, Valid: 81.98%, Test: 86.41%\n",
            "Epoch: 100, Loss: 4410498.5000, Train: 87.81%, Valid: 82.27%, Test: 86.26%\n",
            "Epoch: 105, Loss: 4327128.5000, Train: 88.04%, Valid: 82.42%, Test: 86.26%\n",
            "Epoch: 110, Loss: 4242484.5000, Train: 88.18%, Valid: 82.72%, Test: 86.41%\n",
            "Epoch: 115, Loss: 4166006.7500, Train: 88.11%, Valid: 83.01%, Test: 86.85%\n",
            "Epoch: 120, Loss: 4093237.7500, Train: 88.11%, Valid: 83.01%, Test: 87.00%\n",
            "Epoch: 125, Loss: 4015303.7500, Train: 88.18%, Valid: 82.87%, Test: 86.85%\n",
            "Epoch: 130, Loss: 3939249.2500, Train: 88.40%, Valid: 82.87%, Test: 87.59%\n",
            "Epoch: 135, Loss: 3866318.2500, Train: 88.40%, Valid: 83.16%, Test: 87.59%\n",
            "Epoch: 140, Loss: 3795918.2500, Train: 88.70%, Valid: 83.31%, Test: 87.30%\n",
            "Epoch: 145, Loss: 3730017.2500, Train: 88.33%, Valid: 83.75%, Test: 87.74%\n",
            "Epoch: 150, Loss: 3669704.5000, Train: 88.40%, Valid: 83.90%, Test: 87.30%\n",
            "Epoch: 155, Loss: 3605878.2500, Train: 88.11%, Valid: 83.90%, Test: 87.30%\n",
            "Epoch: 160, Loss: 3545437.0000, Train: 88.18%, Valid: 83.60%, Test: 87.30%\n",
            "Epoch: 165, Loss: 3489286.7500, Train: 88.33%, Valid: 83.16%, Test: 87.15%\n",
            "Epoch: 170, Loss: 3430839.7500, Train: 88.40%, Valid: 83.01%, Test: 87.15%\n",
            "Epoch: 175, Loss: 3365303.2500, Train: 88.77%, Valid: 82.87%, Test: 87.15%\n",
            "Epoch: 180, Loss: 3298706.7500, Train: 88.85%, Valid: 83.01%, Test: 87.00%\n",
            "Epoch: 185, Loss: 3227791.2500, Train: 88.77%, Valid: 83.31%, Test: 87.00%\n",
            "Epoch: 190, Loss: 3161212.2500, Train: 89.00%, Valid: 83.31%, Test: 86.85%\n",
            "Epoch: 195, Loss: 3096534.5000, Train: 89.22%, Valid: 83.01%, Test: 86.71%\n",
            "Run 02:\n",
            "Highest Train: 89.22\n",
            "Highest Valid: 84.05\n",
            "Highest Test: 87.74\n",
            "Chosen epoch: 149\n",
            "Final Train: 88.33\n",
            "Final Test: 87.30\n",
            "Epoch: 00, Loss: 63096984.0000, Train: 13.52%, Valid: 13.74%, Test: 14.03%\n",
            "Epoch: 05, Loss: 19040486.0000, Train: 25.04%, Valid: 26.29%, Test: 25.26%\n",
            "Epoch: 10, Loss: 13310918.0000, Train: 33.75%, Valid: 32.94%, Test: 31.46%\n",
            "Epoch: 15, Loss: 10867713.0000, Train: 41.29%, Valid: 41.80%, Test: 39.44%\n",
            "Epoch: 20, Loss: 9358963.0000, Train: 54.87%, Valid: 53.77%, Test: 53.47%\n",
            "Epoch: 25, Loss: 8314889.5000, Train: 64.33%, Valid: 63.22%, Test: 60.71%\n",
            "Epoch: 30, Loss: 7560132.5000, Train: 72.60%, Valid: 70.90%, Test: 72.23%\n",
            "Epoch: 35, Loss: 6947406.5000, Train: 78.80%, Valid: 76.51%, Test: 78.29%\n",
            "Epoch: 40, Loss: 6457272.5000, Train: 81.09%, Valid: 77.70%, Test: 79.76%\n",
            "Epoch: 45, Loss: 6049979.5000, Train: 81.46%, Valid: 78.58%, Test: 80.65%\n",
            "Epoch: 50, Loss: 5722023.5000, Train: 82.05%, Valid: 78.58%, Test: 80.50%\n",
            "Epoch: 55, Loss: 5439070.0000, Train: 83.31%, Valid: 79.32%, Test: 81.54%\n",
            "Epoch: 60, Loss: 5203558.5000, Train: 84.42%, Valid: 80.50%, Test: 82.87%\n",
            "Epoch: 65, Loss: 4980131.5000, Train: 85.45%, Valid: 81.39%, Test: 84.34%\n",
            "Epoch: 70, Loss: 4787434.5000, Train: 86.12%, Valid: 81.98%, Test: 84.49%\n",
            "Epoch: 75, Loss: 4619600.0000, Train: 86.63%, Valid: 82.42%, Test: 85.23%\n",
            "Epoch: 80, Loss: 4469835.5000, Train: 86.71%, Valid: 82.57%, Test: 85.38%\n",
            "Epoch: 85, Loss: 4332695.5000, Train: 86.78%, Valid: 82.57%, Test: 85.67%\n",
            "Epoch: 90, Loss: 4210191.0000, Train: 87.15%, Valid: 82.87%, Test: 85.82%\n",
            "Epoch: 95, Loss: 4101333.0000, Train: 87.00%, Valid: 83.16%, Test: 86.26%\n",
            "Epoch: 100, Loss: 4001191.7500, Train: 87.52%, Valid: 83.16%, Test: 86.41%\n",
            "Epoch: 105, Loss: 3904664.0000, Train: 87.59%, Valid: 83.46%, Test: 86.41%\n",
            "Epoch: 110, Loss: 3816941.2500, Train: 87.67%, Valid: 83.01%, Test: 86.41%\n",
            "Epoch: 115, Loss: 3733518.7500, Train: 87.74%, Valid: 83.16%, Test: 86.41%\n",
            "Epoch: 120, Loss: 3655924.7500, Train: 87.74%, Valid: 83.16%, Test: 86.12%\n",
            "Epoch: 125, Loss: 3587285.2500, Train: 87.59%, Valid: 82.72%, Test: 86.26%\n",
            "Epoch: 130, Loss: 3522754.7500, Train: 87.59%, Valid: 82.87%, Test: 86.12%\n",
            "Epoch: 135, Loss: 3464878.7500, Train: 87.74%, Valid: 82.87%, Test: 85.82%\n",
            "Epoch: 140, Loss: 3409664.5000, Train: 87.81%, Valid: 82.57%, Test: 86.12%\n",
            "Epoch: 145, Loss: 3352602.2500, Train: 87.74%, Valid: 82.57%, Test: 85.97%\n",
            "Epoch: 150, Loss: 3299301.2500, Train: 87.52%, Valid: 82.42%, Test: 86.26%\n",
            "Epoch: 155, Loss: 3246990.5000, Train: 87.67%, Valid: 82.57%, Test: 86.41%\n",
            "Epoch: 160, Loss: 3191939.7500, Train: 87.67%, Valid: 82.57%, Test: 86.41%\n",
            "Epoch: 165, Loss: 3140996.7500, Train: 87.74%, Valid: 82.72%, Test: 86.26%\n",
            "Epoch: 170, Loss: 3088136.2500, Train: 87.81%, Valid: 82.72%, Test: 86.26%\n",
            "Epoch: 175, Loss: 3041525.7500, Train: 87.96%, Valid: 83.01%, Test: 86.56%\n",
            "Epoch: 180, Loss: 2994065.7500, Train: 88.04%, Valid: 83.31%, Test: 86.56%\n",
            "Epoch: 185, Loss: 2948761.7500, Train: 87.89%, Valid: 83.31%, Test: 86.56%\n",
            "Epoch: 190, Loss: 2901252.7500, Train: 87.81%, Valid: 83.46%, Test: 86.71%\n",
            "Epoch: 195, Loss: 2857287.2500, Train: 87.52%, Valid: 83.31%, Test: 87.00%\n",
            "Run 03:\n",
            "Highest Train: 88.04\n",
            "Highest Valid: 83.60\n",
            "Highest Test: 87.00\n",
            "Chosen epoch: 107\n",
            "Final Train: 87.59\n",
            "Final Test: 86.41\n",
            "Epoch: 00, Loss: 79086000.0000, Train: 10.78%, Valid: 10.78%, Test: 13.29%\n",
            "Epoch: 05, Loss: 17585932.0000, Train: 12.92%, Valid: 10.93%, Test: 12.26%\n",
            "Epoch: 10, Loss: 11949999.0000, Train: 32.64%, Valid: 28.51%, Test: 27.18%\n",
            "Epoch: 15, Loss: 9526243.0000, Train: 55.32%, Valid: 52.73%, Test: 52.14%\n",
            "Epoch: 20, Loss: 8245832.5000, Train: 68.17%, Valid: 66.17%, Test: 64.99%\n",
            "Epoch: 25, Loss: 7313653.0000, Train: 74.08%, Valid: 71.20%, Test: 71.20%\n",
            "Epoch: 30, Loss: 6630336.0000, Train: 78.95%, Valid: 75.18%, Test: 75.63%\n",
            "Epoch: 35, Loss: 6111134.5000, Train: 81.68%, Valid: 77.84%, Test: 79.17%\n",
            "Epoch: 40, Loss: 5700221.5000, Train: 83.31%, Valid: 79.47%, Test: 80.35%\n",
            "Epoch: 45, Loss: 5368300.0000, Train: 85.67%, Valid: 81.54%, Test: 83.16%\n",
            "Epoch: 50, Loss: 5099905.0000, Train: 88.33%, Valid: 83.16%, Test: 84.34%\n",
            "Epoch: 55, Loss: 4882595.0000, Train: 89.36%, Valid: 83.60%, Test: 86.26%\n",
            "Epoch: 60, Loss: 4694307.5000, Train: 90.32%, Valid: 84.49%, Test: 86.56%\n",
            "Epoch: 65, Loss: 4525358.5000, Train: 90.99%, Valid: 84.79%, Test: 87.15%\n",
            "Epoch: 70, Loss: 4372422.0000, Train: 91.06%, Valid: 85.67%, Test: 87.00%\n",
            "Epoch: 75, Loss: 4243647.5000, Train: 91.21%, Valid: 85.67%, Test: 87.30%\n",
            "Epoch: 80, Loss: 4125625.2500, Train: 91.51%, Valid: 85.82%, Test: 87.44%\n",
            "Epoch: 85, Loss: 4021860.7500, Train: 91.80%, Valid: 85.82%, Test: 87.30%\n",
            "Epoch: 90, Loss: 3935535.7500, Train: 91.88%, Valid: 86.12%, Test: 87.30%\n",
            "Epoch: 95, Loss: 3860585.7500, Train: 91.95%, Valid: 85.97%, Test: 87.30%\n",
            "Epoch: 100, Loss: 3799140.2500, Train: 92.02%, Valid: 86.12%, Test: 87.00%\n",
            "Epoch: 105, Loss: 3747455.7500, Train: 92.02%, Valid: 86.12%, Test: 86.71%\n",
            "Epoch: 110, Loss: 3696927.2500, Train: 91.95%, Valid: 86.26%, Test: 86.71%\n",
            "Epoch: 115, Loss: 3652287.5000, Train: 92.02%, Valid: 86.12%, Test: 86.85%\n",
            "Epoch: 120, Loss: 3604821.0000, Train: 91.80%, Valid: 86.71%, Test: 87.00%\n",
            "Epoch: 125, Loss: 3544617.7500, Train: 91.95%, Valid: 86.85%, Test: 87.15%\n",
            "Epoch: 130, Loss: 3495526.5000, Train: 92.17%, Valid: 87.30%, Test: 87.15%\n",
            "Epoch: 135, Loss: 3446212.7500, Train: 91.95%, Valid: 87.15%, Test: 87.15%\n",
            "Epoch: 140, Loss: 3403135.2500, Train: 91.88%, Valid: 87.00%, Test: 87.30%\n",
            "Epoch: 145, Loss: 3364473.7500, Train: 91.80%, Valid: 86.85%, Test: 87.44%\n",
            "Epoch: 150, Loss: 3327804.0000, Train: 91.65%, Valid: 86.71%, Test: 87.44%\n",
            "Epoch: 155, Loss: 3290214.2500, Train: 91.80%, Valid: 86.41%, Test: 87.59%\n",
            "Epoch: 160, Loss: 3253512.7500, Train: 91.88%, Valid: 85.97%, Test: 87.89%\n",
            "Epoch: 165, Loss: 3212135.5000, Train: 92.02%, Valid: 86.12%, Test: 87.74%\n",
            "Epoch: 170, Loss: 3173671.7500, Train: 92.02%, Valid: 85.97%, Test: 87.74%\n",
            "Epoch: 175, Loss: 3137601.7500, Train: 92.02%, Valid: 86.12%, Test: 87.74%\n",
            "Epoch: 180, Loss: 3100776.5000, Train: 92.25%, Valid: 85.97%, Test: 87.74%\n",
            "Epoch: 185, Loss: 3056192.7500, Train: 92.25%, Valid: 86.26%, Test: 87.30%\n",
            "Epoch: 190, Loss: 3010824.7500, Train: 92.17%, Valid: 86.12%, Test: 87.44%\n",
            "Epoch: 195, Loss: 2965871.7500, Train: 92.17%, Valid: 86.12%, Test: 87.00%\n",
            "Run 04:\n",
            "Highest Train: 92.32\n",
            "Highest Valid: 87.30\n",
            "Highest Test: 87.89\n",
            "Chosen epoch: 129\n",
            "Final Train: 92.10\n",
            "Final Test: 87.15\n",
            "Epoch: 00, Loss: 60304040.0000, Train: 18.39%, Valid: 20.38%, Test: 17.87%\n",
            "Epoch: 05, Loss: 17339368.0000, Train: 22.90%, Valid: 24.96%, Test: 22.90%\n",
            "Epoch: 10, Loss: 11729724.0000, Train: 38.92%, Valid: 38.40%, Test: 37.22%\n",
            "Epoch: 15, Loss: 9355609.0000, Train: 58.64%, Valid: 58.64%, Test: 56.13%\n",
            "Epoch: 20, Loss: 7928104.5000, Train: 68.83%, Valid: 65.58%, Test: 66.77%\n",
            "Epoch: 25, Loss: 6940356.0000, Train: 74.15%, Valid: 70.61%, Test: 72.23%\n",
            "Epoch: 30, Loss: 6281284.5000, Train: 80.13%, Valid: 75.92%, Test: 78.73%\n",
            "Epoch: 35, Loss: 5777745.5000, Train: 83.09%, Valid: 78.29%, Test: 81.98%\n",
            "Epoch: 40, Loss: 5368543.5000, Train: 84.19%, Valid: 79.03%, Test: 83.60%\n",
            "Epoch: 45, Loss: 5022412.0000, Train: 84.93%, Valid: 79.17%, Test: 83.60%\n",
            "Epoch: 50, Loss: 4745811.5000, Train: 85.60%, Valid: 79.76%, Test: 83.75%\n",
            "Epoch: 55, Loss: 4513954.5000, Train: 86.19%, Valid: 79.62%, Test: 84.34%\n",
            "Epoch: 60, Loss: 4316930.5000, Train: 86.48%, Valid: 79.62%, Test: 84.64%\n",
            "Epoch: 65, Loss: 4141307.2500, Train: 86.63%, Valid: 80.06%, Test: 84.93%\n",
            "Epoch: 70, Loss: 4002407.7500, Train: 86.93%, Valid: 80.35%, Test: 84.93%\n",
            "Epoch: 75, Loss: 3882058.0000, Train: 86.93%, Valid: 80.65%, Test: 84.93%\n",
            "Epoch: 80, Loss: 3772003.7500, Train: 87.22%, Valid: 80.65%, Test: 85.52%\n",
            "Epoch: 85, Loss: 3674762.7500, Train: 87.37%, Valid: 80.95%, Test: 85.38%\n",
            "Epoch: 90, Loss: 3587499.2500, Train: 87.67%, Valid: 81.24%, Test: 85.23%\n",
            "Epoch: 95, Loss: 3505283.7500, Train: 87.81%, Valid: 81.24%, Test: 85.23%\n",
            "Epoch: 100, Loss: 3431566.7500, Train: 88.18%, Valid: 81.39%, Test: 85.38%\n",
            "Epoch: 105, Loss: 3364838.2500, Train: 88.26%, Valid: 81.24%, Test: 85.67%\n",
            "Epoch: 110, Loss: 3303076.2500, Train: 88.33%, Valid: 81.39%, Test: 85.67%\n",
            "Epoch: 115, Loss: 3241376.2500, Train: 88.48%, Valid: 81.39%, Test: 85.52%\n",
            "Epoch: 120, Loss: 3182181.0000, Train: 88.48%, Valid: 81.54%, Test: 85.23%\n",
            "Epoch: 125, Loss: 3123789.2500, Train: 88.48%, Valid: 81.39%, Test: 85.67%\n",
            "Epoch: 130, Loss: 3070199.7500, Train: 88.70%, Valid: 81.39%, Test: 86.12%\n",
            "Epoch: 135, Loss: 3024083.2500, Train: 88.92%, Valid: 81.24%, Test: 86.12%\n",
            "Epoch: 140, Loss: 2978584.7500, Train: 88.48%, Valid: 80.95%, Test: 85.82%\n",
            "Epoch: 145, Loss: 2937632.5000, Train: 88.40%, Valid: 80.80%, Test: 85.82%\n",
            "Epoch: 150, Loss: 2897409.0000, Train: 88.33%, Valid: 80.65%, Test: 85.67%\n",
            "Epoch: 155, Loss: 2857298.7500, Train: 88.48%, Valid: 80.65%, Test: 85.52%\n",
            "Epoch: 160, Loss: 2815637.7500, Train: 88.70%, Valid: 80.21%, Test: 85.52%\n",
            "Epoch: 165, Loss: 2779157.2500, Train: 88.48%, Valid: 80.06%, Test: 85.67%\n",
            "Epoch: 170, Loss: 2749357.2500, Train: 88.33%, Valid: 80.06%, Test: 85.23%\n",
            "Epoch: 175, Loss: 2723085.5000, Train: 88.33%, Valid: 80.06%, Test: 85.23%\n",
            "Epoch: 180, Loss: 2698676.7500, Train: 88.33%, Valid: 79.76%, Test: 85.52%\n",
            "Epoch: 185, Loss: 2674828.0000, Train: 88.11%, Valid: 80.06%, Test: 85.52%\n",
            "Epoch: 190, Loss: 2649996.0000, Train: 88.26%, Valid: 80.06%, Test: 85.23%\n",
            "Epoch: 195, Loss: 2620282.7500, Train: 88.18%, Valid: 80.35%, Test: 85.23%\n",
            "Run 05:\n",
            "Highest Train: 88.92\n",
            "Highest Valid: 81.68\n",
            "Highest Test: 86.26\n",
            "Chosen epoch: 120\n",
            "Final Train: 88.48\n",
            "Final Test: 85.23\n",
            "All runs:\n",
            "Highest Train: 89.97 ± 1.79\n",
            "Highest Test: 87.39 ± 0.74\n",
            "Highest Valid: 84.08 ± 2.03\n",
            "  Final Train: 89.45 ± 1.90\n",
            "   Final Test: 86.77 ± 0.98\n",
            "Saving results to logs/cora_edge.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##CiteSeerX\n"
      ],
      "metadata": {
        "id": "aF4JpACxJTZX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Pre-train Setting"
      ],
      "metadata": {
        "id": "Ln24p1NLJYa5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 GKD/main.py --dataset citeseer --rand_split --use_bn --base_model gcn --mode pretrain --dist_mode no --save_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRfENtuFJfF7",
        "outputId": "0a08e384-da55-455c-ddd8-2ce39ae2a4a1"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(data_dir='data', dataset='citeseer', sub_dataset='', cpu=False, seed=42, train_prop=0.5, valid_prop=0.25, protocol='semi', rand_split=True, metric='acc', runs=5, epochs=200, hidden_channels=32, num_layers=3, gat_heads=8, out_heads=1, hops=1, lp_alpha=0.1, gpr_alpha=0.1, jk_type='max', directed=False, num_mlp_layers=1, display_step=5, cached=False, print_prop=False, priv_type='edge', priv_ratio=0.5, save_model=True, save_name='gcn', log_name='none', base_model='gcn', not_load_teacher=False, mode='pretrain', dist_mode='no', weight_decay=0.05, dropout=0.0, lr=0.01, use_bn=True, use_batch=False, batch_size=2048, oracle=False, device=0, alpha=0.5, delta=0.1, use_kd=False, beta=0.0, tau=1.0, kernel='sigmoid', t=1.0, include_last=False, s=2, m=1, lr2=0.001, sim='l2', ker_norm=False)\n",
            "cuda:0\n",
            "citeseer\n",
            "Num nodes: 3327\n",
            "torch.Size([3327, 1])\n",
            "num nodes 3327 | num classes 6 | num node feats 3703\n",
            "MODEL: GeoDist(\n",
            "  (k): Kernel(\n",
            "    (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  )\n",
            "  (teacher_gnn): ModuleList(\n",
            "    (0): Linear(in_features=3703, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (student_gnn): ModuleList(\n",
            "    (0): Linear(in_features=3703, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  (bns2d): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            ")\n",
            "Epoch: 00, Loss: 2.3262, Train: 76.13%, Valid: 64.86%, Test: 62.18%\n",
            "Epoch: 05, Loss: 0.4767, Train: 87.61%, Valid: 74.13%, Test: 71.43%\n",
            "Epoch: 10, Loss: 0.4219, Train: 88.09%, Valid: 74.73%, Test: 71.31%\n",
            "Epoch: 15, Loss: 0.4016, Train: 88.88%, Valid: 75.45%, Test: 71.91%\n",
            "Epoch: 20, Loss: 0.3628, Train: 89.84%, Valid: 74.49%, Test: 71.07%\n",
            "Epoch: 25, Loss: 0.3074, Train: 92.30%, Valid: 73.16%, Test: 69.15%\n",
            "Epoch: 30, Loss: 0.2521, Train: 94.41%, Valid: 72.08%, Test: 68.07%\n",
            "Epoch: 35, Loss: 0.2274, Train: 94.65%, Valid: 69.68%, Test: 64.11%\n",
            "Epoch: 40, Loss: 0.2007, Train: 95.37%, Valid: 71.24%, Test: 63.87%\n",
            "Epoch: 45, Loss: 0.1839, Train: 95.31%, Valid: 69.31%, Test: 62.91%\n",
            "Epoch: 50, Loss: 0.1983, Train: 95.25%, Valid: 69.92%, Test: 63.39%\n",
            "Epoch: 55, Loss: 0.1763, Train: 96.03%, Valid: 69.07%, Test: 62.30%\n",
            "Epoch: 60, Loss: 0.1892, Train: 95.61%, Valid: 70.16%, Test: 62.42%\n",
            "Epoch: 65, Loss: 0.2164, Train: 95.13%, Valid: 69.55%, Test: 63.27%\n",
            "Epoch: 70, Loss: 0.1794, Train: 96.09%, Valid: 71.24%, Test: 63.27%\n",
            "Epoch: 75, Loss: 0.1633, Train: 95.79%, Valid: 67.27%, Test: 58.46%\n",
            "Epoch: 80, Loss: 0.1932, Train: 95.61%, Valid: 71.00%, Test: 61.82%\n",
            "Epoch: 85, Loss: 0.1731, Train: 95.79%, Valid: 69.19%, Test: 61.34%\n",
            "Epoch: 90, Loss: 0.1556, Train: 96.45%, Valid: 69.92%, Test: 61.46%\n",
            "Epoch: 95, Loss: 0.1728, Train: 96.33%, Valid: 67.27%, Test: 60.86%\n",
            "Epoch: 100, Loss: 0.1781, Train: 95.91%, Valid: 70.40%, Test: 61.46%\n",
            "Epoch: 105, Loss: 0.1554, Train: 96.03%, Valid: 70.40%, Test: 62.18%\n",
            "Epoch: 110, Loss: 0.1684, Train: 95.79%, Valid: 67.87%, Test: 60.26%\n",
            "Epoch: 115, Loss: 0.1754, Train: 96.45%, Valid: 70.04%, Test: 62.18%\n",
            "Epoch: 120, Loss: 0.1599, Train: 96.03%, Valid: 68.59%, Test: 60.74%\n",
            "Epoch: 125, Loss: 0.1588, Train: 96.09%, Valid: 67.03%, Test: 59.30%\n",
            "Epoch: 130, Loss: 0.1541, Train: 97.17%, Valid: 70.04%, Test: 61.34%\n",
            "Epoch: 135, Loss: 0.1928, Train: 95.61%, Valid: 69.55%, Test: 61.34%\n",
            "Epoch: 140, Loss: 0.1641, Train: 96.27%, Valid: 70.04%, Test: 61.34%\n",
            "Epoch: 145, Loss: 0.1451, Train: 97.47%, Valid: 67.99%, Test: 60.86%\n",
            "Epoch: 150, Loss: 0.1648, Train: 94.77%, Valid: 66.79%, Test: 59.30%\n",
            "Epoch: 155, Loss: 0.1590, Train: 95.97%, Valid: 68.95%, Test: 61.46%\n",
            "Epoch: 160, Loss: 0.1446, Train: 96.99%, Valid: 67.99%, Test: 57.50%\n",
            "Epoch: 165, Loss: 0.1664, Train: 95.73%, Valid: 68.47%, Test: 59.30%\n",
            "Epoch: 170, Loss: 0.1726, Train: 96.51%, Valid: 69.43%, Test: 60.74%\n",
            "Epoch: 175, Loss: 0.1586, Train: 96.51%, Valid: 66.79%, Test: 60.62%\n",
            "Epoch: 180, Loss: 0.1577, Train: 96.21%, Valid: 68.47%, Test: 58.10%\n",
            "Epoch: 185, Loss: 0.1548, Train: 96.69%, Valid: 67.75%, Test: 59.18%\n",
            "Epoch: 190, Loss: 0.1600, Train: 96.75%, Valid: 68.35%, Test: 60.14%\n",
            "Epoch: 195, Loss: 0.1520, Train: 96.33%, Valid: 67.39%, Test: 59.18%\n",
            "Run 01:\n",
            "Highest Train: 97.47\n",
            "Highest Valid: 75.45\n",
            "Highest Test: 72.27\n",
            "Chosen epoch: 16\n",
            "Final Train: 88.88\n",
            "Final Test: 71.91\n",
            "Epoch: 00, Loss: 2.3765, Train: 76.49%, Valid: 66.19%, Test: 61.46%\n",
            "Epoch: 05, Loss: 0.4886, Train: 87.67%, Valid: 73.04%, Test: 70.35%\n",
            "Epoch: 10, Loss: 0.4243, Train: 89.06%, Valid: 72.68%, Test: 70.59%\n",
            "Epoch: 15, Loss: 0.3985, Train: 89.54%, Valid: 73.41%, Test: 70.95%\n",
            "Epoch: 20, Loss: 0.3521, Train: 90.86%, Valid: 73.41%, Test: 70.11%\n",
            "Epoch: 25, Loss: 0.2895, Train: 93.02%, Valid: 72.68%, Test: 69.27%\n",
            "Epoch: 30, Loss: 0.2308, Train: 95.01%, Valid: 71.84%, Test: 66.51%\n",
            "Epoch: 35, Loss: 0.2189, Train: 94.59%, Valid: 71.36%, Test: 65.79%\n",
            "Epoch: 40, Loss: 0.1826, Train: 95.91%, Valid: 70.52%, Test: 63.15%\n",
            "Epoch: 45, Loss: 0.1804, Train: 94.89%, Valid: 68.59%, Test: 61.58%\n",
            "Epoch: 50, Loss: 0.2097, Train: 95.43%, Valid: 69.92%, Test: 65.19%\n",
            "Epoch: 55, Loss: 0.1789, Train: 96.03%, Valid: 69.68%, Test: 63.75%\n",
            "Epoch: 60, Loss: 0.1874, Train: 96.03%, Valid: 69.80%, Test: 62.67%\n",
            "Epoch: 65, Loss: 0.1962, Train: 94.17%, Valid: 69.55%, Test: 64.11%\n",
            "Epoch: 70, Loss: 0.1670, Train: 96.21%, Valid: 68.35%, Test: 63.15%\n",
            "Epoch: 75, Loss: 0.1701, Train: 96.03%, Valid: 67.87%, Test: 60.98%\n",
            "Epoch: 80, Loss: 0.1817, Train: 95.85%, Valid: 69.68%, Test: 62.67%\n",
            "Epoch: 85, Loss: 0.1607, Train: 96.51%, Valid: 67.03%, Test: 61.58%\n",
            "Epoch: 90, Loss: 0.1643, Train: 95.55%, Valid: 69.19%, Test: 60.98%\n",
            "Epoch: 95, Loss: 0.1818, Train: 95.91%, Valid: 70.88%, Test: 62.18%\n",
            "Epoch: 100, Loss: 0.1601, Train: 96.57%, Valid: 69.31%, Test: 60.86%\n",
            "Epoch: 105, Loss: 0.1667, Train: 94.77%, Valid: 69.19%, Test: 62.18%\n",
            "Epoch: 110, Loss: 0.1777, Train: 96.03%, Valid: 69.43%, Test: 63.75%\n",
            "Epoch: 115, Loss: 0.1535, Train: 96.33%, Valid: 68.35%, Test: 62.30%\n",
            "Epoch: 120, Loss: 0.1732, Train: 94.77%, Valid: 68.11%, Test: 60.74%\n",
            "Epoch: 125, Loss: 0.1935, Train: 95.07%, Valid: 69.19%, Test: 63.63%\n",
            "Epoch: 130, Loss: 0.1578, Train: 96.33%, Valid: 67.99%, Test: 61.10%\n",
            "Epoch: 135, Loss: 0.1723, Train: 95.85%, Valid: 69.92%, Test: 61.10%\n",
            "Epoch: 140, Loss: 0.1861, Train: 96.09%, Valid: 69.55%, Test: 64.23%\n",
            "Epoch: 145, Loss: 0.1618, Train: 95.97%, Valid: 69.92%, Test: 63.03%\n",
            "Epoch: 150, Loss: 0.1652, Train: 96.69%, Valid: 67.75%, Test: 60.74%\n",
            "Epoch: 155, Loss: 0.1860, Train: 95.13%, Valid: 68.47%, Test: 62.55%\n",
            "Epoch: 160, Loss: 0.1665, Train: 96.27%, Valid: 69.43%, Test: 61.10%\n",
            "Epoch: 165, Loss: 0.1570, Train: 95.91%, Valid: 67.39%, Test: 59.54%\n",
            "Epoch: 170, Loss: 0.1578, Train: 96.51%, Valid: 67.75%, Test: 62.18%\n",
            "Epoch: 175, Loss: 0.1913, Train: 95.61%, Valid: 68.11%, Test: 63.27%\n",
            "Epoch: 180, Loss: 0.1576, Train: 96.45%, Valid: 67.15%, Test: 60.38%\n",
            "Epoch: 185, Loss: 0.1698, Train: 95.37%, Valid: 68.35%, Test: 62.06%\n",
            "Epoch: 190, Loss: 0.1696, Train: 96.33%, Valid: 69.19%, Test: 61.58%\n",
            "Epoch: 195, Loss: 0.1726, Train: 95.49%, Valid: 70.16%, Test: 63.87%\n",
            "Run 02:\n",
            "Highest Train: 97.11\n",
            "Highest Valid: 73.89\n",
            "Highest Test: 71.07\n",
            "Chosen epoch: 18\n",
            "Final Train: 89.90\n",
            "Final Test: 70.71\n",
            "Epoch: 00, Loss: 2.3769, Train: 69.81%, Valid: 58.84%, Test: 56.54%\n",
            "Epoch: 05, Loss: 0.5322, Train: 87.31%, Valid: 71.48%, Test: 69.51%\n",
            "Epoch: 10, Loss: 0.4440, Train: 88.33%, Valid: 73.29%, Test: 71.19%\n",
            "Epoch: 15, Loss: 0.4040, Train: 89.54%, Valid: 72.92%, Test: 69.51%\n",
            "Epoch: 20, Loss: 0.3508, Train: 91.22%, Valid: 72.80%, Test: 70.35%\n",
            "Epoch: 25, Loss: 0.2905, Train: 93.39%, Valid: 71.96%, Test: 68.79%\n",
            "Epoch: 30, Loss: 0.2334, Train: 94.89%, Valid: 70.76%, Test: 66.99%\n",
            "Epoch: 35, Loss: 0.2368, Train: 94.47%, Valid: 70.28%, Test: 64.11%\n",
            "Epoch: 40, Loss: 0.1938, Train: 95.37%, Valid: 70.64%, Test: 65.07%\n",
            "Epoch: 45, Loss: 0.1819, Train: 95.79%, Valid: 68.83%, Test: 63.03%\n",
            "Epoch: 50, Loss: 0.2049, Train: 94.95%, Valid: 68.95%, Test: 63.27%\n",
            "Epoch: 55, Loss: 0.1808, Train: 96.21%, Valid: 67.99%, Test: 61.58%\n",
            "Epoch: 60, Loss: 0.1829, Train: 93.99%, Valid: 70.16%, Test: 62.55%\n",
            "Epoch: 65, Loss: 0.1875, Train: 95.85%, Valid: 68.59%, Test: 62.06%\n",
            "Epoch: 70, Loss: 0.1671, Train: 96.21%, Valid: 67.63%, Test: 62.67%\n",
            "Epoch: 75, Loss: 0.1603, Train: 96.21%, Valid: 67.87%, Test: 61.70%\n",
            "Epoch: 80, Loss: 0.2329, Train: 94.95%, Valid: 70.16%, Test: 65.19%\n",
            "Epoch: 85, Loss: 0.1840, Train: 95.67%, Valid: 69.68%, Test: 63.27%\n",
            "Epoch: 90, Loss: 0.1581, Train: 96.09%, Valid: 67.87%, Test: 60.74%\n",
            "Epoch: 95, Loss: 0.1827, Train: 95.67%, Valid: 69.07%, Test: 61.82%\n",
            "Epoch: 100, Loss: 0.1694, Train: 95.55%, Valid: 69.68%, Test: 61.46%\n",
            "Epoch: 105, Loss: 0.1687, Train: 96.39%, Valid: 69.19%, Test: 60.98%\n",
            "Epoch: 110, Loss: 0.1618, Train: 96.39%, Valid: 67.51%, Test: 60.14%\n",
            "Epoch: 115, Loss: 0.1908, Train: 95.13%, Valid: 68.95%, Test: 62.06%\n",
            "Epoch: 120, Loss: 0.1670, Train: 96.45%, Valid: 69.07%, Test: 60.98%\n",
            "Epoch: 125, Loss: 0.1567, Train: 96.39%, Valid: 68.11%, Test: 60.50%\n",
            "Epoch: 130, Loss: 0.2355, Train: 94.47%, Valid: 69.80%, Test: 63.63%\n",
            "Epoch: 135, Loss: 0.1764, Train: 96.27%, Valid: 67.99%, Test: 62.42%\n",
            "Epoch: 140, Loss: 0.1545, Train: 96.51%, Valid: 68.59%, Test: 60.86%\n",
            "Epoch: 145, Loss: 0.1882, Train: 95.91%, Valid: 70.64%, Test: 61.82%\n",
            "Epoch: 150, Loss: 0.1564, Train: 95.67%, Valid: 68.11%, Test: 59.90%\n",
            "Epoch: 155, Loss: 0.1959, Train: 95.61%, Valid: 67.99%, Test: 61.22%\n",
            "Epoch: 160, Loss: 0.1616, Train: 96.33%, Valid: 67.51%, Test: 59.78%\n",
            "Epoch: 165, Loss: 0.1569, Train: 96.63%, Valid: 67.63%, Test: 59.66%\n",
            "Epoch: 170, Loss: 0.1590, Train: 96.21%, Valid: 67.39%, Test: 58.34%\n",
            "Epoch: 175, Loss: 0.1914, Train: 94.95%, Valid: 67.39%, Test: 60.38%\n",
            "Epoch: 180, Loss: 0.1726, Train: 96.09%, Valid: 67.51%, Test: 60.38%\n",
            "Epoch: 185, Loss: 0.1530, Train: 96.93%, Valid: 68.35%, Test: 59.30%\n",
            "Epoch: 190, Loss: 0.1910, Train: 94.65%, Valid: 67.63%, Test: 58.70%\n",
            "Epoch: 195, Loss: 0.1696, Train: 96.15%, Valid: 67.99%, Test: 60.26%\n",
            "Run 03:\n",
            "Highest Train: 96.93\n",
            "Highest Valid: 73.41\n",
            "Highest Test: 71.19\n",
            "Chosen epoch: 12\n",
            "Final Train: 88.70\n",
            "Final Test: 71.19\n",
            "Epoch: 00, Loss: 2.2760, Train: 69.15%, Valid: 58.60%, Test: 55.58%\n",
            "Epoch: 05, Loss: 0.5372, Train: 86.23%, Valid: 71.48%, Test: 69.99%\n",
            "Epoch: 10, Loss: 0.4554, Train: 87.79%, Valid: 72.20%, Test: 70.71%\n",
            "Epoch: 15, Loss: 0.4115, Train: 89.24%, Valid: 72.32%, Test: 71.31%\n",
            "Epoch: 20, Loss: 0.3519, Train: 91.10%, Valid: 72.56%, Test: 68.67%\n",
            "Epoch: 25, Loss: 0.2814, Train: 93.75%, Valid: 72.08%, Test: 69.39%\n",
            "Epoch: 30, Loss: 0.2252, Train: 95.01%, Valid: 69.68%, Test: 64.35%\n",
            "Epoch: 35, Loss: 0.2002, Train: 95.31%, Valid: 70.16%, Test: 65.55%\n",
            "Epoch: 40, Loss: 0.1782, Train: 94.35%, Valid: 69.31%, Test: 62.91%\n",
            "Epoch: 45, Loss: 0.1813, Train: 95.79%, Valid: 70.04%, Test: 63.75%\n",
            "Epoch: 50, Loss: 0.1669, Train: 95.55%, Valid: 68.59%, Test: 62.30%\n",
            "Epoch: 55, Loss: 0.1870, Train: 95.19%, Valid: 70.40%, Test: 61.94%\n",
            "Epoch: 60, Loss: 0.1745, Train: 95.85%, Valid: 69.31%, Test: 61.22%\n",
            "Epoch: 65, Loss: 0.1760, Train: 95.73%, Valid: 68.83%, Test: 63.27%\n",
            "Epoch: 70, Loss: 0.1781, Train: 95.91%, Valid: 68.95%, Test: 62.55%\n",
            "Epoch: 75, Loss: 0.1568, Train: 96.81%, Valid: 68.71%, Test: 59.42%\n",
            "Epoch: 80, Loss: 0.1819, Train: 95.19%, Valid: 69.80%, Test: 63.27%\n",
            "Epoch: 85, Loss: 0.1785, Train: 95.73%, Valid: 68.95%, Test: 60.86%\n",
            "Epoch: 90, Loss: 0.1576, Train: 96.57%, Valid: 68.47%, Test: 59.30%\n",
            "Epoch: 95, Loss: 0.1812, Train: 94.77%, Valid: 70.88%, Test: 60.50%\n",
            "Epoch: 100, Loss: 0.1729, Train: 96.27%, Valid: 70.04%, Test: 63.75%\n",
            "Epoch: 105, Loss: 0.1521, Train: 96.99%, Valid: 67.63%, Test: 60.38%\n",
            "Epoch: 110, Loss: 0.1887, Train: 96.03%, Valid: 68.23%, Test: 62.06%\n",
            "Epoch: 115, Loss: 0.1645, Train: 96.39%, Valid: 70.04%, Test: 59.78%\n",
            "Epoch: 120, Loss: 0.1522, Train: 96.15%, Valid: 66.79%, Test: 57.74%\n",
            "Epoch: 125, Loss: 0.1995, Train: 95.73%, Valid: 69.07%, Test: 62.67%\n",
            "Epoch: 130, Loss: 0.1632, Train: 96.27%, Valid: 69.07%, Test: 61.70%\n",
            "Epoch: 135, Loss: 0.1524, Train: 95.01%, Valid: 67.99%, Test: 59.18%\n",
            "Epoch: 140, Loss: 0.1744, Train: 96.21%, Valid: 67.87%, Test: 62.55%\n",
            "Epoch: 145, Loss: 0.1534, Train: 96.51%, Valid: 67.87%, Test: 60.38%\n",
            "Epoch: 150, Loss: 0.1696, Train: 95.43%, Valid: 70.28%, Test: 59.54%\n",
            "Epoch: 155, Loss: 0.1828, Train: 95.25%, Valid: 69.19%, Test: 59.42%\n",
            "Epoch: 160, Loss: 0.1702, Train: 96.15%, Valid: 71.36%, Test: 63.03%\n",
            "Epoch: 165, Loss: 0.1461, Train: 96.81%, Valid: 68.83%, Test: 58.94%\n",
            "Epoch: 170, Loss: 0.1929, Train: 95.01%, Valid: 68.95%, Test: 59.54%\n",
            "Epoch: 175, Loss: 0.1687, Train: 96.15%, Valid: 69.19%, Test: 62.55%\n",
            "Epoch: 180, Loss: 0.1447, Train: 96.75%, Valid: 67.39%, Test: 56.42%\n",
            "Epoch: 185, Loss: 0.1549, Train: 96.09%, Valid: 68.59%, Test: 57.74%\n",
            "Epoch: 190, Loss: 0.1838, Train: 95.67%, Valid: 68.35%, Test: 62.55%\n",
            "Epoch: 195, Loss: 0.1574, Train: 96.81%, Valid: 68.11%, Test: 59.42%\n",
            "Run 04:\n",
            "Highest Train: 97.41\n",
            "Highest Valid: 72.80\n",
            "Highest Test: 71.31\n",
            "Chosen epoch: 18\n",
            "Final Train: 89.72\n",
            "Final Test: 69.75\n",
            "Epoch: 00, Loss: 2.1209, Train: 77.63%, Valid: 67.87%, Test: 65.31%\n",
            "Epoch: 05, Loss: 0.4720, Train: 87.97%, Valid: 72.80%, Test: 69.63%\n",
            "Epoch: 10, Loss: 0.4217, Train: 88.51%, Valid: 72.44%, Test: 69.99%\n",
            "Epoch: 15, Loss: 0.3933, Train: 89.36%, Valid: 73.65%, Test: 69.63%\n",
            "Epoch: 20, Loss: 0.3389, Train: 90.74%, Valid: 73.89%, Test: 70.47%\n",
            "Epoch: 25, Loss: 0.2777, Train: 93.14%, Valid: 72.80%, Test: 69.39%\n",
            "Epoch: 30, Loss: 0.2388, Train: 93.33%, Valid: 72.32%, Test: 66.99%\n",
            "Epoch: 35, Loss: 0.2050, Train: 94.95%, Valid: 70.64%, Test: 66.39%\n",
            "Epoch: 40, Loss: 0.1800, Train: 95.91%, Valid: 70.52%, Test: 63.75%\n",
            "Epoch: 45, Loss: 0.2075, Train: 94.77%, Valid: 70.28%, Test: 63.75%\n",
            "Epoch: 50, Loss: 0.1764, Train: 96.09%, Valid: 68.23%, Test: 61.10%\n",
            "Epoch: 55, Loss: 0.1693, Train: 95.91%, Valid: 70.04%, Test: 60.86%\n",
            "Epoch: 60, Loss: 0.2039, Train: 95.25%, Valid: 70.76%, Test: 62.67%\n",
            "Epoch: 65, Loss: 0.1694, Train: 96.27%, Valid: 68.83%, Test: 60.62%\n",
            "Epoch: 70, Loss: 0.1584, Train: 96.09%, Valid: 68.35%, Test: 60.02%\n",
            "Epoch: 75, Loss: 0.2129, Train: 95.07%, Valid: 71.00%, Test: 63.03%\n",
            "Epoch: 80, Loss: 0.1726, Train: 96.45%, Valid: 69.07%, Test: 61.10%\n",
            "Epoch: 85, Loss: 0.1663, Train: 95.97%, Valid: 68.83%, Test: 58.94%\n",
            "Epoch: 90, Loss: 0.1851, Train: 95.55%, Valid: 68.11%, Test: 61.46%\n",
            "Epoch: 95, Loss: 0.1635, Train: 96.33%, Valid: 68.11%, Test: 60.86%\n",
            "Epoch: 100, Loss: 0.1594, Train: 95.91%, Valid: 67.63%, Test: 60.98%\n",
            "Epoch: 105, Loss: 0.1947, Train: 95.37%, Valid: 69.19%, Test: 63.51%\n",
            "Epoch: 110, Loss: 0.1610, Train: 96.39%, Valid: 69.55%, Test: 61.34%\n",
            "Epoch: 115, Loss: 0.1484, Train: 96.09%, Valid: 67.27%, Test: 60.50%\n",
            "Epoch: 120, Loss: 0.1917, Train: 95.19%, Valid: 69.80%, Test: 63.63%\n",
            "Epoch: 125, Loss: 0.1615, Train: 96.81%, Valid: 68.35%, Test: 60.26%\n",
            "Epoch: 130, Loss: 0.1511, Train: 96.15%, Valid: 68.59%, Test: 58.46%\n",
            "Epoch: 135, Loss: 0.1845, Train: 95.19%, Valid: 68.47%, Test: 60.38%\n",
            "Epoch: 140, Loss: 0.1631, Train: 96.45%, Valid: 68.23%, Test: 60.38%\n",
            "Epoch: 145, Loss: 0.1488, Train: 96.63%, Valid: 68.47%, Test: 59.78%\n",
            "Epoch: 150, Loss: 0.1844, Train: 95.55%, Valid: 68.35%, Test: 61.22%\n",
            "Epoch: 155, Loss: 0.1698, Train: 96.69%, Valid: 68.11%, Test: 59.90%\n",
            "Epoch: 160, Loss: 0.1630, Train: 96.93%, Valid: 67.27%, Test: 59.54%\n",
            "Epoch: 165, Loss: 0.1797, Train: 95.79%, Valid: 68.83%, Test: 60.98%\n",
            "Epoch: 170, Loss: 0.1634, Train: 96.57%, Valid: 67.63%, Test: 59.18%\n",
            "Epoch: 175, Loss: 0.1643, Train: 96.63%, Valid: 69.68%, Test: 59.66%\n",
            "Epoch: 180, Loss: 0.1658, Train: 96.03%, Valid: 69.19%, Test: 60.38%\n",
            "Epoch: 185, Loss: 0.1690, Train: 96.51%, Valid: 68.11%, Test: 58.94%\n",
            "Epoch: 190, Loss: 0.1644, Train: 96.27%, Valid: 68.71%, Test: 58.22%\n",
            "Epoch: 195, Loss: 0.1550, Train: 96.75%, Valid: 66.79%, Test: 57.74%\n",
            "Run 05:\n",
            "Highest Train: 97.41\n",
            "Highest Valid: 74.13\n",
            "Highest Test: 70.95\n",
            "Chosen epoch: 20\n",
            "Final Train: 90.26\n",
            "Final Test: 70.11\n",
            "All runs:\n",
            "Highest Train: 97.27 ± 0.24\n",
            "Highest Test: 71.36 ± 0.53\n",
            "Highest Valid: 73.94 ± 0.99\n",
            "  Final Train: 89.49 ± 0.67\n",
            "   Final Test: 70.73 ± 0.86\n",
            "Saving results to logs/citeseer_edge.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Edge Aware Setting\n"
      ],
      "metadata": {
        "id": "vVDMfALiJhgb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 GKD/main.py --dataset citeseer --rand_split --use_bn --base_model gcn --mode train --priv_type edge --dist_mode gkd --kernel sigmoid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4mbQ7NtJma5",
        "outputId": "6fee37b6-f3a2-4d97-edee-0125a03cbe6e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(data_dir='data', dataset='citeseer', sub_dataset='', cpu=False, seed=42, train_prop=0.5, valid_prop=0.25, protocol='semi', rand_split=True, metric='acc', runs=5, epochs=200, hidden_channels=32, num_layers=3, gat_heads=8, out_heads=1, hops=1, lp_alpha=0.1, gpr_alpha=0.1, jk_type='max', directed=False, num_mlp_layers=1, display_step=5, cached=False, print_prop=False, priv_type='edge', priv_ratio=0.5, save_model=False, save_name='gcn', log_name='none', base_model='gcn', not_load_teacher=False, mode='train', dist_mode='gkd', weight_decay=0.05, dropout=0.0, lr=0.01, use_bn=True, use_batch=False, batch_size=2048, oracle=False, device=0, alpha=0.5, delta=0.1, use_kd=False, beta=0.0, tau=1.0, kernel='sigmoid', t=1.0, include_last=False, s=2, m=1, lr2=0.001, sim='l2', ker_norm=False)\n",
            "cuda:0\n",
            "citeseer\n",
            "Num nodes: 3327\n",
            "torch.Size([3327, 1])\n",
            "num nodes 3327 | num classes 6 | num node feats 3703\n",
            "MODEL: GeoDist(\n",
            "  (k): Kernel(\n",
            "    (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  )\n",
            "  (teacher_gnn): ModuleList(\n",
            "    (0): Linear(in_features=3703, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (student_gnn): ModuleList(\n",
            "    (0): Linear(in_features=3703, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  (bns2d): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            ")\n",
            "Epoch: 00, Loss: 918465.8125, Train: 14.07%, Valid: 14.92%, Test: 17.89%\n",
            "Epoch: 05, Loss: 192346.2500, Train: 25.98%, Valid: 24.55%, Test: 24.85%\n",
            "Epoch: 10, Loss: 150587.6719, Train: 43.42%, Valid: 38.99%, Test: 40.10%\n",
            "Epoch: 15, Loss: 129515.5938, Train: 58.75%, Valid: 51.02%, Test: 52.10%\n",
            "Epoch: 20, Loss: 115140.5391, Train: 73.18%, Valid: 63.66%, Test: 62.55%\n",
            "Epoch: 25, Loss: 104605.9609, Train: 80.10%, Valid: 70.28%, Test: 69.15%\n",
            "Epoch: 30, Loss: 96229.8047, Train: 81.36%, Valid: 70.76%, Test: 70.23%\n",
            "Epoch: 35, Loss: 89171.5078, Train: 82.38%, Valid: 71.84%, Test: 71.55%\n",
            "Epoch: 40, Loss: 83274.9688, Train: 82.38%, Valid: 72.20%, Test: 72.15%\n",
            "Epoch: 45, Loss: 78249.5547, Train: 82.56%, Valid: 72.44%, Test: 72.51%\n",
            "Epoch: 50, Loss: 73839.0000, Train: 82.74%, Valid: 72.32%, Test: 72.51%\n",
            "Epoch: 55, Loss: 69927.6094, Train: 82.86%, Valid: 72.80%, Test: 72.87%\n",
            "Epoch: 60, Loss: 66394.8516, Train: 82.86%, Valid: 73.29%, Test: 72.39%\n",
            "Epoch: 65, Loss: 63214.9180, Train: 82.98%, Valid: 73.29%, Test: 72.51%\n",
            "Epoch: 70, Loss: 60377.9180, Train: 83.28%, Valid: 73.16%, Test: 72.51%\n",
            "Epoch: 75, Loss: 57769.5664, Train: 83.46%, Valid: 73.53%, Test: 72.87%\n",
            "Epoch: 80, Loss: 55337.6133, Train: 83.52%, Valid: 73.77%, Test: 73.11%\n",
            "Epoch: 85, Loss: 53117.1875, Train: 83.64%, Valid: 73.89%, Test: 73.11%\n",
            "Epoch: 90, Loss: 51170.5312, Train: 83.52%, Valid: 73.77%, Test: 72.99%\n",
            "Epoch: 95, Loss: 49269.4531, Train: 83.76%, Valid: 73.53%, Test: 72.75%\n",
            "Epoch: 100, Loss: 47393.0156, Train: 83.70%, Valid: 73.29%, Test: 72.63%\n",
            "Epoch: 105, Loss: 45623.3750, Train: 83.82%, Valid: 73.41%, Test: 72.87%\n",
            "Epoch: 110, Loss: 44123.8398, Train: 83.88%, Valid: 73.16%, Test: 72.99%\n",
            "Epoch: 115, Loss: 42667.4531, Train: 83.88%, Valid: 73.04%, Test: 72.75%\n",
            "Epoch: 120, Loss: 41248.3281, Train: 83.94%, Valid: 72.92%, Test: 72.63%\n",
            "Epoch: 125, Loss: 39946.9062, Train: 84.00%, Valid: 73.29%, Test: 72.75%\n",
            "Epoch: 130, Loss: 38709.5781, Train: 84.06%, Valid: 72.92%, Test: 72.87%\n",
            "Epoch: 135, Loss: 37601.8281, Train: 84.13%, Valid: 73.04%, Test: 72.75%\n",
            "Epoch: 140, Loss: 36557.2344, Train: 84.25%, Valid: 73.29%, Test: 72.99%\n",
            "Epoch: 145, Loss: 35573.8203, Train: 84.19%, Valid: 72.92%, Test: 73.11%\n",
            "Epoch: 150, Loss: 35029.3047, Train: 84.00%, Valid: 72.80%, Test: 73.23%\n",
            "Epoch: 155, Loss: 34006.7188, Train: 84.13%, Valid: 72.80%, Test: 73.11%\n",
            "Epoch: 160, Loss: 33288.4219, Train: 84.19%, Valid: 72.68%, Test: 73.11%\n",
            "Epoch: 165, Loss: 32585.2207, Train: 84.06%, Valid: 72.56%, Test: 73.11%\n",
            "Epoch: 170, Loss: 32018.5586, Train: 84.06%, Valid: 72.44%, Test: 73.23%\n",
            "Epoch: 175, Loss: 31138.8457, Train: 84.00%, Valid: 72.56%, Test: 72.87%\n",
            "Epoch: 180, Loss: 30441.9492, Train: 83.94%, Valid: 72.56%, Test: 72.87%\n",
            "Epoch: 185, Loss: 29873.7090, Train: 83.94%, Valid: 72.56%, Test: 72.75%\n",
            "Epoch: 190, Loss: 29753.5098, Train: 84.00%, Valid: 72.68%, Test: 72.87%\n",
            "Epoch: 195, Loss: 28867.0996, Train: 84.13%, Valid: 72.56%, Test: 72.75%\n",
            "Run 01:\n",
            "Highest Train: 84.25\n",
            "Highest Valid: 74.01\n",
            "Highest Test: 73.23\n",
            "Chosen epoch: 88\n",
            "Final Train: 83.58\n",
            "Final Test: 73.23\n",
            "Epoch: 00, Loss: 912336.3125, Train: 11.85%, Valid: 13.12%, Test: 13.93%\n",
            "Epoch: 05, Loss: 217768.6094, Train: 31.99%, Valid: 28.88%, Test: 31.81%\n",
            "Epoch: 10, Loss: 166158.5156, Train: 46.18%, Valid: 41.16%, Test: 45.50%\n",
            "Epoch: 15, Loss: 142163.2500, Train: 62.00%, Valid: 52.83%, Test: 57.26%\n",
            "Epoch: 20, Loss: 125413.7266, Train: 72.10%, Valid: 63.42%, Test: 64.95%\n",
            "Epoch: 25, Loss: 113063.6406, Train: 79.92%, Valid: 71.00%, Test: 71.55%\n",
            "Epoch: 30, Loss: 103589.8125, Train: 82.08%, Valid: 71.48%, Test: 72.27%\n",
            "Epoch: 35, Loss: 95780.2266, Train: 83.04%, Valid: 71.48%, Test: 72.99%\n",
            "Epoch: 40, Loss: 89332.3203, Train: 83.70%, Valid: 71.84%, Test: 73.47%\n",
            "Epoch: 45, Loss: 83824.5781, Train: 84.55%, Valid: 72.20%, Test: 73.23%\n",
            "Epoch: 50, Loss: 79165.3203, Train: 84.91%, Valid: 73.16%, Test: 73.35%\n",
            "Epoch: 55, Loss: 75137.4609, Train: 85.63%, Valid: 73.41%, Test: 73.59%\n",
            "Epoch: 60, Loss: 71583.1641, Train: 85.93%, Valid: 73.29%, Test: 73.71%\n",
            "Epoch: 65, Loss: 68416.4297, Train: 86.53%, Valid: 73.65%, Test: 74.43%\n",
            "Epoch: 70, Loss: 65548.1641, Train: 86.65%, Valid: 73.29%, Test: 73.83%\n",
            "Epoch: 75, Loss: 62932.5781, Train: 86.71%, Valid: 73.41%, Test: 73.83%\n",
            "Epoch: 80, Loss: 60529.3359, Train: 86.77%, Valid: 73.04%, Test: 74.07%\n",
            "Epoch: 85, Loss: 58305.8672, Train: 86.65%, Valid: 73.41%, Test: 74.31%\n",
            "Epoch: 90, Loss: 56247.2188, Train: 86.77%, Valid: 72.92%, Test: 74.07%\n",
            "Epoch: 95, Loss: 54328.6875, Train: 86.83%, Valid: 73.04%, Test: 74.19%\n",
            "Epoch: 100, Loss: 52547.6719, Train: 86.77%, Valid: 73.16%, Test: 74.07%\n",
            "Epoch: 105, Loss: 50875.5156, Train: 86.77%, Valid: 73.29%, Test: 74.07%\n",
            "Epoch: 110, Loss: 49309.0117, Train: 86.71%, Valid: 73.29%, Test: 74.55%\n",
            "Epoch: 115, Loss: 47856.8203, Train: 86.77%, Valid: 73.29%, Test: 74.55%\n",
            "Epoch: 120, Loss: 46492.8438, Train: 86.77%, Valid: 73.29%, Test: 74.67%\n",
            "Epoch: 125, Loss: 45201.7031, Train: 86.65%, Valid: 73.53%, Test: 74.91%\n",
            "Epoch: 130, Loss: 43978.8359, Train: 86.65%, Valid: 73.65%, Test: 74.79%\n",
            "Epoch: 135, Loss: 42816.0273, Train: 86.77%, Valid: 73.65%, Test: 74.91%\n",
            "Epoch: 140, Loss: 41713.6055, Train: 86.77%, Valid: 73.41%, Test: 74.79%\n",
            "Epoch: 145, Loss: 40673.9453, Train: 86.77%, Valid: 73.41%, Test: 74.91%\n",
            "Epoch: 150, Loss: 39694.1797, Train: 86.71%, Valid: 73.16%, Test: 74.91%\n",
            "Epoch: 155, Loss: 38808.1602, Train: 86.65%, Valid: 73.16%, Test: 74.91%\n",
            "Epoch: 160, Loss: 38044.9375, Train: 86.71%, Valid: 73.16%, Test: 74.79%\n",
            "Epoch: 165, Loss: 37144.5664, Train: 86.71%, Valid: 73.16%, Test: 74.67%\n",
            "Epoch: 170, Loss: 36519.3867, Train: 86.83%, Valid: 73.29%, Test: 74.67%\n",
            "Epoch: 175, Loss: 35705.1797, Train: 86.83%, Valid: 73.16%, Test: 74.91%\n",
            "Epoch: 180, Loss: 34961.9648, Train: 86.77%, Valid: 73.29%, Test: 74.67%\n",
            "Epoch: 185, Loss: 34306.1406, Train: 86.83%, Valid: 73.41%, Test: 74.79%\n",
            "Epoch: 190, Loss: 33676.5703, Train: 86.71%, Valid: 73.16%, Test: 74.79%\n",
            "Epoch: 195, Loss: 33080.5156, Train: 86.71%, Valid: 73.29%, Test: 74.91%\n",
            "Run 02:\n",
            "Highest Train: 86.95\n",
            "Highest Valid: 73.65\n",
            "Highest Test: 75.03\n",
            "Chosen epoch: 65\n",
            "Final Train: 86.23\n",
            "Final Test: 74.43\n",
            "Epoch: 00, Loss: 913669.8750, Train: 18.64%, Valid: 19.13%, Test: 18.25%\n",
            "Epoch: 05, Loss: 221028.2031, Train: 27.66%, Valid: 27.68%, Test: 24.61%\n",
            "Epoch: 10, Loss: 171788.2344, Train: 54.90%, Valid: 47.41%, Test: 48.38%\n",
            "Epoch: 15, Loss: 146493.2500, Train: 62.00%, Valid: 53.67%, Test: 54.62%\n",
            "Epoch: 20, Loss: 130246.0547, Train: 73.90%, Valid: 66.19%, Test: 66.15%\n",
            "Epoch: 25, Loss: 118031.3516, Train: 78.59%, Valid: 69.68%, Test: 70.11%\n",
            "Epoch: 30, Loss: 108068.4609, Train: 79.68%, Valid: 70.76%, Test: 71.31%\n",
            "Epoch: 35, Loss: 99642.1094, Train: 80.28%, Valid: 71.12%, Test: 70.83%\n",
            "Epoch: 40, Loss: 92393.7812, Train: 80.34%, Valid: 71.24%, Test: 70.47%\n",
            "Epoch: 45, Loss: 85987.9375, Train: 80.58%, Valid: 71.60%, Test: 70.59%\n",
            "Epoch: 50, Loss: 80231.9688, Train: 81.00%, Valid: 71.72%, Test: 70.71%\n",
            "Epoch: 55, Loss: 75231.4844, Train: 81.00%, Valid: 71.96%, Test: 70.95%\n",
            "Epoch: 60, Loss: 70769.7969, Train: 81.24%, Valid: 71.84%, Test: 70.95%\n",
            "Epoch: 65, Loss: 66745.7344, Train: 81.24%, Valid: 71.84%, Test: 71.31%\n",
            "Epoch: 70, Loss: 63121.2539, Train: 81.30%, Valid: 71.96%, Test: 71.43%\n",
            "Epoch: 75, Loss: 59912.0469, Train: 81.54%, Valid: 71.72%, Test: 71.91%\n",
            "Epoch: 80, Loss: 57044.7500, Train: 81.60%, Valid: 71.36%, Test: 72.27%\n",
            "Epoch: 85, Loss: 54450.6914, Train: 81.72%, Valid: 71.24%, Test: 72.15%\n",
            "Epoch: 90, Loss: 52087.5273, Train: 81.84%, Valid: 71.48%, Test: 72.27%\n",
            "Epoch: 95, Loss: 49943.9648, Train: 81.60%, Valid: 71.60%, Test: 71.91%\n",
            "Epoch: 100, Loss: 47998.9883, Train: 81.72%, Valid: 71.48%, Test: 71.67%\n",
            "Epoch: 105, Loss: 46214.8320, Train: 81.54%, Valid: 71.48%, Test: 72.03%\n",
            "Epoch: 110, Loss: 44587.5547, Train: 81.54%, Valid: 71.84%, Test: 72.03%\n",
            "Epoch: 115, Loss: 43089.8086, Train: 81.66%, Valid: 71.96%, Test: 72.03%\n",
            "Epoch: 120, Loss: 41733.7461, Train: 81.84%, Valid: 72.08%, Test: 72.51%\n",
            "Epoch: 125, Loss: 40446.5625, Train: 81.90%, Valid: 72.32%, Test: 72.63%\n",
            "Epoch: 130, Loss: 39470.2852, Train: 81.90%, Valid: 72.44%, Test: 72.51%\n",
            "Epoch: 135, Loss: 38201.9688, Train: 82.08%, Valid: 72.68%, Test: 72.63%\n",
            "Epoch: 140, Loss: 37271.3281, Train: 82.14%, Valid: 72.56%, Test: 72.51%\n",
            "Epoch: 145, Loss: 36265.7539, Train: 82.20%, Valid: 72.44%, Test: 72.51%\n",
            "Epoch: 150, Loss: 35416.8633, Train: 82.14%, Valid: 72.44%, Test: 72.51%\n",
            "Epoch: 155, Loss: 34605.4102, Train: 82.02%, Valid: 71.96%, Test: 72.39%\n",
            "Epoch: 160, Loss: 33850.0000, Train: 82.20%, Valid: 71.84%, Test: 72.27%\n",
            "Epoch: 165, Loss: 33414.8789, Train: 82.38%, Valid: 71.84%, Test: 71.91%\n",
            "Epoch: 170, Loss: 32622.7930, Train: 82.32%, Valid: 71.96%, Test: 72.15%\n",
            "Epoch: 175, Loss: 31968.2734, Train: 82.32%, Valid: 71.96%, Test: 72.15%\n",
            "Epoch: 180, Loss: 31352.2676, Train: 82.26%, Valid: 71.96%, Test: 72.03%\n",
            "Epoch: 185, Loss: 30759.9551, Train: 82.38%, Valid: 71.96%, Test: 72.27%\n",
            "Epoch: 190, Loss: 30294.6094, Train: 82.50%, Valid: 71.84%, Test: 72.39%\n",
            "Epoch: 195, Loss: 29803.9219, Train: 82.68%, Valid: 71.84%, Test: 72.27%\n",
            "Run 03:\n",
            "Highest Train: 82.80\n",
            "Highest Valid: 72.68\n",
            "Highest Test: 72.75\n",
            "Chosen epoch: 136\n",
            "Final Train: 82.08\n",
            "Final Test: 72.63\n",
            "Epoch: 00, Loss: 925642.4375, Train: 10.40%, Valid: 10.35%, Test: 11.40%\n",
            "Epoch: 05, Loss: 196733.6250, Train: 31.81%, Valid: 31.65%, Test: 30.37%\n",
            "Epoch: 10, Loss: 156195.6562, Train: 41.25%, Valid: 39.47%, Test: 38.18%\n",
            "Epoch: 15, Loss: 135959.8750, Train: 53.22%, Valid: 49.10%, Test: 48.02%\n",
            "Epoch: 20, Loss: 122006.3359, Train: 65.66%, Valid: 60.53%, Test: 58.58%\n",
            "Epoch: 25, Loss: 111750.1484, Train: 72.04%, Valid: 66.06%, Test: 65.19%\n",
            "Epoch: 30, Loss: 103344.2891, Train: 78.11%, Valid: 69.19%, Test: 69.39%\n",
            "Epoch: 35, Loss: 96205.2266, Train: 80.40%, Valid: 71.72%, Test: 71.67%\n",
            "Epoch: 40, Loss: 90044.5156, Train: 81.42%, Valid: 71.72%, Test: 72.75%\n",
            "Epoch: 45, Loss: 84602.2109, Train: 82.02%, Valid: 71.60%, Test: 72.39%\n",
            "Epoch: 50, Loss: 79720.5547, Train: 82.08%, Valid: 71.84%, Test: 72.39%\n",
            "Epoch: 55, Loss: 75382.2812, Train: 82.32%, Valid: 72.08%, Test: 72.15%\n",
            "Epoch: 60, Loss: 71452.8203, Train: 82.26%, Valid: 71.96%, Test: 72.51%\n",
            "Epoch: 65, Loss: 67860.4688, Train: 82.56%, Valid: 71.96%, Test: 72.87%\n",
            "Epoch: 70, Loss: 64547.2422, Train: 82.92%, Valid: 71.96%, Test: 72.75%\n",
            "Epoch: 75, Loss: 61536.3008, Train: 83.04%, Valid: 72.20%, Test: 73.11%\n",
            "Epoch: 80, Loss: 58811.6172, Train: 83.46%, Valid: 72.08%, Test: 73.23%\n",
            "Epoch: 85, Loss: 56362.7305, Train: 83.58%, Valid: 71.84%, Test: 73.59%\n",
            "Epoch: 90, Loss: 54131.2617, Train: 83.82%, Valid: 72.32%, Test: 73.47%\n",
            "Epoch: 95, Loss: 52097.6797, Train: 83.88%, Valid: 72.44%, Test: 73.35%\n",
            "Epoch: 100, Loss: 50229.5977, Train: 83.88%, Valid: 72.56%, Test: 73.23%\n",
            "Epoch: 105, Loss: 48509.9180, Train: 84.19%, Valid: 72.56%, Test: 73.11%\n",
            "Epoch: 110, Loss: 46935.1211, Train: 84.06%, Valid: 72.44%, Test: 72.87%\n",
            "Epoch: 115, Loss: 45484.0039, Train: 84.25%, Valid: 72.56%, Test: 72.99%\n",
            "Epoch: 120, Loss: 44138.2656, Train: 84.43%, Valid: 72.56%, Test: 72.75%\n",
            "Epoch: 125, Loss: 42891.8945, Train: 84.43%, Valid: 72.56%, Test: 72.63%\n",
            "Epoch: 130, Loss: 41738.5508, Train: 84.43%, Valid: 72.56%, Test: 72.15%\n",
            "Epoch: 135, Loss: 40667.5625, Train: 84.37%, Valid: 72.56%, Test: 72.03%\n",
            "Epoch: 140, Loss: 39848.3906, Train: 84.61%, Valid: 72.68%, Test: 71.91%\n",
            "Epoch: 145, Loss: 39042.8359, Train: 84.61%, Valid: 72.68%, Test: 71.91%\n",
            "Epoch: 150, Loss: 38154.8125, Train: 84.55%, Valid: 72.68%, Test: 71.91%\n",
            "Epoch: 155, Loss: 37203.9688, Train: 84.73%, Valid: 72.80%, Test: 72.15%\n",
            "Epoch: 160, Loss: 36475.6289, Train: 84.85%, Valid: 72.80%, Test: 72.03%\n",
            "Epoch: 165, Loss: 35833.0156, Train: 84.91%, Valid: 72.56%, Test: 71.79%\n",
            "Epoch: 170, Loss: 35274.4648, Train: 84.79%, Valid: 72.80%, Test: 71.67%\n",
            "Epoch: 175, Loss: 34499.1836, Train: 84.85%, Valid: 72.80%, Test: 72.03%\n",
            "Epoch: 180, Loss: 33964.3047, Train: 85.09%, Valid: 72.56%, Test: 72.15%\n",
            "Epoch: 185, Loss: 33458.3594, Train: 85.09%, Valid: 72.68%, Test: 72.15%\n",
            "Epoch: 190, Loss: 33007.1914, Train: 85.03%, Valid: 72.56%, Test: 71.91%\n",
            "Epoch: 195, Loss: 32417.7305, Train: 85.15%, Valid: 72.44%, Test: 72.15%\n",
            "Run 04:\n",
            "Highest Train: 85.15\n",
            "Highest Valid: 72.80\n",
            "Highest Test: 73.59\n",
            "Chosen epoch: 154\n",
            "Final Train: 84.85\n",
            "Final Test: 72.15\n",
            "Epoch: 00, Loss: 910929.8750, Train: 18.64%, Valid: 20.94%, Test: 20.77%\n",
            "Epoch: 05, Loss: 208556.9375, Train: 35.54%, Valid: 29.96%, Test: 33.73%\n",
            "Epoch: 10, Loss: 164174.3281, Train: 47.50%, Valid: 42.84%, Test: 42.50%\n",
            "Epoch: 15, Loss: 142287.7656, Train: 64.64%, Valid: 56.08%, Test: 57.86%\n",
            "Epoch: 20, Loss: 127461.6797, Train: 71.62%, Valid: 63.42%, Test: 63.87%\n",
            "Epoch: 25, Loss: 115889.9297, Train: 78.89%, Valid: 70.04%, Test: 68.67%\n",
            "Epoch: 30, Loss: 106529.0625, Train: 82.68%, Valid: 71.96%, Test: 70.71%\n",
            "Epoch: 35, Loss: 98777.6094, Train: 84.37%, Valid: 73.53%, Test: 71.19%\n",
            "Epoch: 40, Loss: 92226.5938, Train: 85.45%, Valid: 73.89%, Test: 72.27%\n",
            "Epoch: 45, Loss: 86556.8828, Train: 85.99%, Valid: 74.13%, Test: 72.75%\n",
            "Epoch: 50, Loss: 81630.6562, Train: 86.11%, Valid: 74.01%, Test: 73.11%\n",
            "Epoch: 55, Loss: 77228.0781, Train: 86.71%, Valid: 74.01%, Test: 73.11%\n",
            "Epoch: 60, Loss: 73238.2969, Train: 86.83%, Valid: 74.25%, Test: 72.99%\n",
            "Epoch: 65, Loss: 69639.2656, Train: 86.89%, Valid: 74.13%, Test: 73.23%\n",
            "Epoch: 70, Loss: 66355.9922, Train: 87.13%, Valid: 74.13%, Test: 72.99%\n",
            "Epoch: 75, Loss: 63410.0625, Train: 87.55%, Valid: 74.13%, Test: 72.99%\n",
            "Epoch: 80, Loss: 60741.7305, Train: 87.55%, Valid: 74.13%, Test: 73.23%\n",
            "Epoch: 85, Loss: 58285.6953, Train: 87.49%, Valid: 74.01%, Test: 73.11%\n",
            "Epoch: 90, Loss: 56007.1992, Train: 87.67%, Valid: 73.77%, Test: 72.99%\n",
            "Epoch: 95, Loss: 53880.0234, Train: 87.85%, Valid: 73.53%, Test: 73.11%\n",
            "Epoch: 100, Loss: 51887.6562, Train: 88.03%, Valid: 73.41%, Test: 73.23%\n",
            "Epoch: 105, Loss: 50022.9688, Train: 87.91%, Valid: 73.53%, Test: 73.23%\n",
            "Epoch: 110, Loss: 48298.5312, Train: 88.03%, Valid: 73.89%, Test: 73.23%\n",
            "Epoch: 115, Loss: 46709.2734, Train: 87.97%, Valid: 73.89%, Test: 73.35%\n",
            "Epoch: 120, Loss: 45238.3047, Train: 88.09%, Valid: 74.01%, Test: 73.47%\n",
            "Epoch: 125, Loss: 43882.7734, Train: 88.15%, Valid: 74.13%, Test: 73.11%\n",
            "Epoch: 130, Loss: 42639.4766, Train: 88.21%, Valid: 74.13%, Test: 72.75%\n",
            "Epoch: 135, Loss: 41493.8828, Train: 88.21%, Valid: 74.25%, Test: 72.63%\n",
            "Epoch: 140, Loss: 40433.2188, Train: 88.15%, Valid: 74.13%, Test: 72.63%\n",
            "Epoch: 145, Loss: 39457.6016, Train: 88.21%, Valid: 74.25%, Test: 72.63%\n",
            "Epoch: 150, Loss: 39070.5391, Train: 88.21%, Valid: 74.25%, Test: 72.75%\n",
            "Epoch: 155, Loss: 37745.9688, Train: 88.39%, Valid: 74.37%, Test: 72.63%\n",
            "Epoch: 160, Loss: 37030.5703, Train: 88.39%, Valid: 74.25%, Test: 72.75%\n",
            "Epoch: 165, Loss: 36253.8789, Train: 88.39%, Valid: 74.25%, Test: 72.63%\n",
            "Epoch: 170, Loss: 35480.8477, Train: 88.33%, Valid: 74.37%, Test: 72.63%\n",
            "Epoch: 175, Loss: 34836.4492, Train: 88.39%, Valid: 74.49%, Test: 72.63%\n",
            "Epoch: 180, Loss: 34228.1289, Train: 88.39%, Valid: 74.49%, Test: 72.75%\n",
            "Epoch: 185, Loss: 33897.1172, Train: 88.39%, Valid: 74.37%, Test: 72.39%\n",
            "Epoch: 190, Loss: 33098.6250, Train: 88.39%, Valid: 74.25%, Test: 72.51%\n",
            "Epoch: 195, Loss: 32661.3105, Train: 88.45%, Valid: 74.13%, Test: 72.63%\n",
            "Run 05:\n",
            "Highest Train: 88.51\n",
            "Highest Valid: 74.49\n",
            "Highest Test: 73.47\n",
            "Chosen epoch: 176\n",
            "Final Train: 88.39\n",
            "Final Test: 72.63\n",
            "All runs:\n",
            "Highest Train: 85.53 ± 2.25\n",
            "Highest Test: 73.61 ± 0.85\n",
            "Highest Valid: 73.53 ± 0.78\n",
            "  Final Train: 85.03 ± 2.43\n",
            "   Final Test: 73.01 ± 0.88\n",
            "Saving results to logs/citeseer_edge.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 GKD/main.py --dataset citeseer --rand_split --use_bn --base_model gcn --mode train --priv_type edge --dist_mode gkd --kernel gaussian"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvyIQFmlJrZw",
        "outputId": "ccf6326a-4fb9-4632-b384-81b5a6183916"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(data_dir='data', dataset='citeseer', sub_dataset='', cpu=False, seed=42, train_prop=0.5, valid_prop=0.25, protocol='semi', rand_split=True, metric='acc', runs=5, epochs=200, hidden_channels=32, num_layers=3, gat_heads=8, out_heads=1, hops=1, lp_alpha=0.1, gpr_alpha=0.1, jk_type='max', directed=False, num_mlp_layers=1, display_step=5, cached=False, print_prop=False, priv_type='edge', priv_ratio=0.5, save_model=False, save_name='gcn', log_name='none', base_model='gcn', not_load_teacher=False, mode='train', dist_mode='gkd', weight_decay=0.05, dropout=0.0, lr=0.01, use_bn=True, use_batch=False, batch_size=2048, oracle=False, device=0, alpha=0.5, delta=0.1, use_kd=False, beta=0.0, tau=1.0, kernel='gaussian', t=1.0, include_last=False, s=2, m=1, lr2=0.001, sim='l2', ker_norm=False)\n",
            "cuda:0\n",
            "citeseer\n",
            "Num nodes: 3327\n",
            "torch.Size([3327, 1])\n",
            "num nodes 3327 | num classes 6 | num node feats 3703\n",
            "MODEL: GeoDist(\n",
            "  (k): Kernel(\n",
            "    (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  )\n",
            "  (teacher_gnn): ModuleList(\n",
            "    (0): Linear(in_features=3703, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (student_gnn): ModuleList(\n",
            "    (0): Linear(in_features=3703, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  (bns2d): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            ")\n",
            "Epoch: 00, Loss: 297.0674, Train: 18.58%, Valid: 16.85%, Test: 20.77%\n",
            "Epoch: 05, Loss: 230.0417, Train: 24.59%, Valid: 24.91%, Test: 25.09%\n",
            "Epoch: 10, Loss: 206.0706, Train: 38.24%, Valid: 34.78%, Test: 37.45%\n",
            "Epoch: 15, Loss: 193.3878, Train: 48.05%, Valid: 42.60%, Test: 44.78%\n",
            "Epoch: 20, Loss: 184.5990, Train: 57.43%, Valid: 52.23%, Test: 54.26%\n",
            "Epoch: 25, Loss: 177.6695, Train: 66.63%, Valid: 62.82%, Test: 62.18%\n",
            "Epoch: 30, Loss: 172.1166, Train: 71.38%, Valid: 67.99%, Test: 65.67%\n",
            "Epoch: 35, Loss: 167.5031, Train: 73.84%, Valid: 69.19%, Test: 66.99%\n",
            "Epoch: 40, Loss: 163.4838, Train: 75.23%, Valid: 70.16%, Test: 68.07%\n",
            "Epoch: 45, Loss: 159.8640, Train: 75.83%, Valid: 71.00%, Test: 69.27%\n",
            "Epoch: 50, Loss: 156.6029, Train: 76.91%, Valid: 71.36%, Test: 70.23%\n",
            "Epoch: 55, Loss: 153.5797, Train: 77.45%, Valid: 71.48%, Test: 70.59%\n",
            "Epoch: 60, Loss: 150.6667, Train: 77.81%, Valid: 71.72%, Test: 70.59%\n",
            "Epoch: 65, Loss: 147.8901, Train: 78.11%, Valid: 71.60%, Test: 70.59%\n",
            "Epoch: 70, Loss: 145.3533, Train: 78.47%, Valid: 71.24%, Test: 70.59%\n",
            "Epoch: 75, Loss: 143.0335, Train: 78.53%, Valid: 71.60%, Test: 70.71%\n",
            "Epoch: 80, Loss: 140.6751, Train: 78.95%, Valid: 71.60%, Test: 70.83%\n",
            "Epoch: 85, Loss: 138.6687, Train: 79.07%, Valid: 71.84%, Test: 70.95%\n",
            "Epoch: 90, Loss: 136.6409, Train: 79.37%, Valid: 71.60%, Test: 71.31%\n",
            "Epoch: 95, Loss: 134.7635, Train: 79.56%, Valid: 71.72%, Test: 71.07%\n",
            "Epoch: 100, Loss: 133.1041, Train: 79.86%, Valid: 71.96%, Test: 71.07%\n",
            "Epoch: 105, Loss: 131.4175, Train: 79.92%, Valid: 72.08%, Test: 70.95%\n",
            "Epoch: 110, Loss: 130.3081, Train: 80.16%, Valid: 71.96%, Test: 71.07%\n",
            "Epoch: 115, Loss: 129.2841, Train: 80.52%, Valid: 71.84%, Test: 71.07%\n",
            "Epoch: 120, Loss: 128.3080, Train: 80.88%, Valid: 72.56%, Test: 70.83%\n",
            "Epoch: 125, Loss: 127.4789, Train: 81.12%, Valid: 72.80%, Test: 70.95%\n",
            "Epoch: 130, Loss: 126.4346, Train: 81.18%, Valid: 72.80%, Test: 71.55%\n",
            "Epoch: 135, Loss: 125.6001, Train: 81.36%, Valid: 73.41%, Test: 71.43%\n",
            "Epoch: 140, Loss: 125.9457, Train: 81.42%, Valid: 72.92%, Test: 70.95%\n",
            "Epoch: 145, Loss: 124.9266, Train: 81.72%, Valid: 73.41%, Test: 71.19%\n",
            "Epoch: 150, Loss: 123.8406, Train: 81.90%, Valid: 73.77%, Test: 71.55%\n",
            "Epoch: 155, Loss: 123.2083, Train: 82.32%, Valid: 73.16%, Test: 71.43%\n",
            "Epoch: 160, Loss: 123.3148, Train: 82.80%, Valid: 73.41%, Test: 71.91%\n",
            "Epoch: 165, Loss: 122.7679, Train: 82.80%, Valid: 72.92%, Test: 72.51%\n",
            "Epoch: 170, Loss: 122.3284, Train: 82.80%, Valid: 73.41%, Test: 72.27%\n",
            "Epoch: 175, Loss: 122.0430, Train: 82.80%, Valid: 73.29%, Test: 72.99%\n",
            "Epoch: 180, Loss: 121.8163, Train: 82.98%, Valid: 73.04%, Test: 72.63%\n",
            "Epoch: 185, Loss: 121.3827, Train: 83.34%, Valid: 72.92%, Test: 72.87%\n",
            "Epoch: 190, Loss: 120.7354, Train: 83.40%, Valid: 72.92%, Test: 72.87%\n",
            "Epoch: 195, Loss: 120.0698, Train: 83.76%, Valid: 73.65%, Test: 72.39%\n",
            "Run 01:\n",
            "Highest Train: 83.82\n",
            "Highest Valid: 73.77\n",
            "Highest Test: 72.99\n",
            "Chosen epoch: 151\n",
            "Final Train: 81.90\n",
            "Final Test: 71.55\n",
            "Epoch: 00, Loss: 276.0960, Train: 12.81%, Valid: 11.43%, Test: 15.01%\n",
            "Epoch: 05, Loss: 235.9523, Train: 16.60%, Valid: 16.73%, Test: 18.85%\n",
            "Epoch: 10, Loss: 219.8944, Train: 25.98%, Valid: 22.50%, Test: 26.29%\n",
            "Epoch: 15, Loss: 209.5354, Train: 38.60%, Valid: 34.30%, Test: 36.37%\n",
            "Epoch: 20, Loss: 201.6429, Train: 54.84%, Valid: 50.54%, Test: 49.10%\n",
            "Epoch: 25, Loss: 195.7002, Train: 65.36%, Valid: 62.33%, Test: 60.02%\n",
            "Epoch: 30, Loss: 190.6803, Train: 69.93%, Valid: 65.70%, Test: 63.39%\n",
            "Epoch: 35, Loss: 186.1783, Train: 72.34%, Valid: 68.23%, Test: 64.23%\n",
            "Epoch: 40, Loss: 182.3698, Train: 72.76%, Valid: 68.23%, Test: 64.47%\n",
            "Epoch: 45, Loss: 179.0862, Train: 73.12%, Valid: 68.83%, Test: 65.19%\n",
            "Epoch: 50, Loss: 176.1092, Train: 73.66%, Valid: 68.59%, Test: 65.55%\n",
            "Epoch: 55, Loss: 173.3165, Train: 74.14%, Valid: 69.31%, Test: 66.03%\n",
            "Epoch: 60, Loss: 170.6600, Train: 74.80%, Valid: 69.19%, Test: 66.75%\n",
            "Epoch: 65, Loss: 168.3234, Train: 75.83%, Valid: 69.80%, Test: 67.11%\n",
            "Epoch: 70, Loss: 165.9980, Train: 75.95%, Valid: 69.80%, Test: 67.71%\n",
            "Epoch: 75, Loss: 163.8689, Train: 76.25%, Valid: 69.80%, Test: 68.19%\n",
            "Epoch: 80, Loss: 161.9489, Train: 76.43%, Valid: 69.92%, Test: 67.95%\n",
            "Epoch: 85, Loss: 160.1992, Train: 76.85%, Valid: 69.92%, Test: 68.19%\n",
            "Epoch: 90, Loss: 158.5112, Train: 77.51%, Valid: 70.28%, Test: 68.19%\n",
            "Epoch: 95, Loss: 156.7621, Train: 78.35%, Valid: 70.88%, Test: 68.43%\n",
            "Epoch: 100, Loss: 154.8649, Train: 78.89%, Valid: 70.88%, Test: 68.31%\n",
            "Epoch: 105, Loss: 153.3082, Train: 79.19%, Valid: 70.76%, Test: 69.03%\n",
            "Epoch: 110, Loss: 151.8726, Train: 79.31%, Valid: 70.76%, Test: 69.15%\n",
            "Epoch: 115, Loss: 150.3769, Train: 79.68%, Valid: 70.52%, Test: 69.39%\n",
            "Epoch: 120, Loss: 149.0920, Train: 79.74%, Valid: 70.40%, Test: 69.15%\n",
            "Epoch: 125, Loss: 147.9223, Train: 80.16%, Valid: 70.52%, Test: 69.63%\n",
            "Epoch: 130, Loss: 146.9167, Train: 80.40%, Valid: 70.88%, Test: 70.23%\n",
            "Epoch: 135, Loss: 145.8391, Train: 80.82%, Valid: 71.12%, Test: 70.23%\n",
            "Epoch: 140, Loss: 144.6753, Train: 81.36%, Valid: 71.36%, Test: 69.87%\n",
            "Epoch: 145, Loss: 143.7611, Train: 81.36%, Valid: 71.60%, Test: 70.71%\n",
            "Epoch: 150, Loss: 143.2831, Train: 82.08%, Valid: 71.72%, Test: 71.19%\n",
            "Epoch: 155, Loss: 142.3750, Train: 82.32%, Valid: 72.08%, Test: 71.43%\n",
            "Epoch: 160, Loss: 141.5512, Train: 82.56%, Valid: 71.84%, Test: 71.31%\n",
            "Epoch: 165, Loss: 140.7039, Train: 82.74%, Valid: 71.84%, Test: 71.31%\n",
            "Epoch: 170, Loss: 140.2301, Train: 82.74%, Valid: 72.08%, Test: 71.31%\n",
            "Epoch: 175, Loss: 139.9444, Train: 83.28%, Valid: 72.08%, Test: 71.67%\n",
            "Epoch: 180, Loss: 139.2349, Train: 83.58%, Valid: 71.84%, Test: 72.03%\n",
            "Epoch: 185, Loss: 138.9346, Train: 83.70%, Valid: 71.96%, Test: 72.39%\n",
            "Epoch: 190, Loss: 138.4722, Train: 83.94%, Valid: 71.96%, Test: 72.87%\n",
            "Epoch: 195, Loss: 137.9406, Train: 84.06%, Valid: 72.08%, Test: 72.87%\n",
            "Run 02:\n",
            "Highest Train: 84.49\n",
            "Highest Valid: 72.56\n",
            "Highest Test: 72.99\n",
            "Chosen epoch: 200\n",
            "Final Train: 84.49\n",
            "Final Test: 72.39\n",
            "Epoch: 00, Loss: 296.5146, Train: 16.18%, Valid: 16.49%, Test: 16.93%\n",
            "Epoch: 05, Loss: 246.2336, Train: 22.61%, Valid: 24.55%, Test: 23.17%\n",
            "Epoch: 10, Loss: 225.5750, Train: 29.04%, Valid: 28.64%, Test: 27.73%\n",
            "Epoch: 15, Loss: 212.6366, Train: 39.39%, Valid: 36.22%, Test: 35.89%\n",
            "Epoch: 20, Loss: 203.5083, Train: 53.16%, Valid: 50.78%, Test: 47.42%\n",
            "Epoch: 25, Loss: 196.3570, Train: 61.82%, Valid: 59.69%, Test: 57.98%\n",
            "Epoch: 30, Loss: 190.4406, Train: 65.66%, Valid: 63.42%, Test: 61.46%\n",
            "Epoch: 35, Loss: 185.4918, Train: 69.15%, Valid: 64.26%, Test: 63.99%\n",
            "Epoch: 40, Loss: 181.3080, Train: 70.72%, Valid: 66.43%, Test: 64.83%\n",
            "Epoch: 45, Loss: 177.6945, Train: 71.80%, Valid: 67.75%, Test: 65.79%\n",
            "Epoch: 50, Loss: 174.4215, Train: 73.30%, Valid: 68.47%, Test: 66.39%\n",
            "Epoch: 55, Loss: 171.4966, Train: 73.72%, Valid: 69.19%, Test: 67.35%\n",
            "Epoch: 60, Loss: 168.6232, Train: 74.56%, Valid: 69.43%, Test: 68.55%\n",
            "Epoch: 65, Loss: 165.9193, Train: 75.29%, Valid: 69.55%, Test: 68.79%\n",
            "Epoch: 70, Loss: 163.2565, Train: 75.77%, Valid: 70.88%, Test: 68.91%\n",
            "Epoch: 75, Loss: 160.5844, Train: 76.13%, Valid: 71.00%, Test: 68.79%\n",
            "Epoch: 80, Loss: 157.9687, Train: 76.01%, Valid: 70.52%, Test: 68.91%\n",
            "Epoch: 85, Loss: 155.4926, Train: 76.37%, Valid: 70.52%, Test: 68.79%\n",
            "Epoch: 90, Loss: 153.3646, Train: 77.21%, Valid: 70.88%, Test: 69.03%\n",
            "Epoch: 95, Loss: 151.2482, Train: 77.39%, Valid: 71.12%, Test: 69.39%\n",
            "Epoch: 100, Loss: 149.3594, Train: 77.93%, Valid: 71.00%, Test: 69.99%\n",
            "Epoch: 105, Loss: 147.4825, Train: 78.11%, Valid: 70.52%, Test: 70.11%\n",
            "Epoch: 110, Loss: 145.6219, Train: 78.65%, Valid: 70.76%, Test: 69.87%\n",
            "Epoch: 115, Loss: 143.8607, Train: 78.95%, Valid: 70.64%, Test: 69.87%\n",
            "Epoch: 120, Loss: 142.2257, Train: 79.07%, Valid: 70.28%, Test: 70.11%\n",
            "Epoch: 125, Loss: 140.7669, Train: 78.89%, Valid: 70.28%, Test: 70.47%\n",
            "Epoch: 130, Loss: 139.4917, Train: 78.95%, Valid: 70.16%, Test: 70.23%\n",
            "Epoch: 135, Loss: 138.2817, Train: 79.25%, Valid: 70.52%, Test: 70.23%\n",
            "Epoch: 140, Loss: 137.3141, Train: 79.31%, Valid: 70.52%, Test: 69.63%\n",
            "Epoch: 145, Loss: 136.2576, Train: 79.80%, Valid: 71.00%, Test: 69.51%\n",
            "Epoch: 150, Loss: 135.3602, Train: 79.74%, Valid: 71.00%, Test: 69.27%\n",
            "Epoch: 155, Loss: 134.4502, Train: 80.22%, Valid: 71.60%, Test: 69.87%\n",
            "Epoch: 160, Loss: 134.0313, Train: 80.22%, Valid: 71.48%, Test: 69.87%\n",
            "Epoch: 165, Loss: 133.5520, Train: 80.76%, Valid: 71.00%, Test: 70.71%\n",
            "Epoch: 170, Loss: 132.6821, Train: 81.00%, Valid: 71.48%, Test: 70.59%\n",
            "Epoch: 175, Loss: 132.6932, Train: 81.24%, Valid: 71.60%, Test: 70.95%\n",
            "Epoch: 180, Loss: 132.4501, Train: 81.18%, Valid: 71.24%, Test: 70.59%\n",
            "Epoch: 185, Loss: 131.7111, Train: 81.36%, Valid: 71.24%, Test: 70.59%\n",
            "Epoch: 190, Loss: 131.1979, Train: 81.00%, Valid: 71.24%, Test: 70.95%\n",
            "Epoch: 195, Loss: 130.7853, Train: 81.72%, Valid: 71.84%, Test: 71.31%\n",
            "Run 03:\n",
            "Highest Train: 81.96\n",
            "Highest Valid: 71.84\n",
            "Highest Test: 71.79\n",
            "Chosen epoch: 196\n",
            "Final Train: 81.72\n",
            "Final Test: 71.31\n",
            "Epoch: 00, Loss: 276.7237, Train: 17.68%, Valid: 17.21%, Test: 17.53%\n",
            "Epoch: 05, Loss: 247.1706, Train: 16.96%, Valid: 19.25%, Test: 18.01%\n",
            "Epoch: 10, Loss: 228.3811, Train: 23.93%, Valid: 24.07%, Test: 23.65%\n",
            "Epoch: 15, Loss: 217.3747, Train: 30.01%, Valid: 30.20%, Test: 29.17%\n",
            "Epoch: 20, Loss: 209.5638, Train: 35.84%, Valid: 34.78%, Test: 35.41%\n",
            "Epoch: 25, Loss: 203.2607, Train: 44.56%, Valid: 43.32%, Test: 43.46%\n",
            "Epoch: 30, Loss: 198.1262, Train: 57.37%, Valid: 54.15%, Test: 56.30%\n",
            "Epoch: 35, Loss: 193.7978, Train: 64.64%, Valid: 60.89%, Test: 61.82%\n",
            "Epoch: 40, Loss: 190.0833, Train: 68.13%, Valid: 63.78%, Test: 65.67%\n",
            "Epoch: 45, Loss: 186.6073, Train: 69.99%, Valid: 66.19%, Test: 66.63%\n",
            "Epoch: 50, Loss: 183.4335, Train: 70.78%, Valid: 67.99%, Test: 66.87%\n",
            "Epoch: 55, Loss: 180.4573, Train: 71.80%, Valid: 67.51%, Test: 66.87%\n",
            "Epoch: 60, Loss: 177.5602, Train: 72.22%, Valid: 67.75%, Test: 67.11%\n",
            "Epoch: 65, Loss: 174.8032, Train: 73.00%, Valid: 67.87%, Test: 67.11%\n",
            "Epoch: 70, Loss: 172.1620, Train: 73.78%, Valid: 68.35%, Test: 67.35%\n",
            "Epoch: 75, Loss: 169.7288, Train: 74.08%, Valid: 67.75%, Test: 67.35%\n",
            "Epoch: 80, Loss: 167.3586, Train: 74.50%, Valid: 67.99%, Test: 67.47%\n",
            "Epoch: 85, Loss: 165.1068, Train: 74.62%, Valid: 68.35%, Test: 68.19%\n",
            "Epoch: 90, Loss: 162.9803, Train: 74.98%, Valid: 68.11%, Test: 68.31%\n",
            "Epoch: 95, Loss: 160.9205, Train: 75.47%, Valid: 68.23%, Test: 68.91%\n",
            "Epoch: 100, Loss: 159.0644, Train: 75.35%, Valid: 68.35%, Test: 69.75%\n",
            "Epoch: 105, Loss: 157.2093, Train: 75.83%, Valid: 68.35%, Test: 69.87%\n",
            "Epoch: 110, Loss: 155.5342, Train: 76.25%, Valid: 68.47%, Test: 70.35%\n",
            "Epoch: 115, Loss: 153.8652, Train: 76.67%, Valid: 68.83%, Test: 70.35%\n",
            "Epoch: 120, Loss: 152.3465, Train: 76.73%, Valid: 68.71%, Test: 70.23%\n",
            "Epoch: 125, Loss: 150.8298, Train: 77.15%, Valid: 68.83%, Test: 69.39%\n",
            "Epoch: 130, Loss: 149.2827, Train: 77.69%, Valid: 68.71%, Test: 69.75%\n",
            "Epoch: 135, Loss: 147.8260, Train: 77.99%, Valid: 68.47%, Test: 69.27%\n",
            "Epoch: 140, Loss: 146.4628, Train: 78.05%, Valid: 68.71%, Test: 69.63%\n",
            "Epoch: 145, Loss: 145.0743, Train: 78.41%, Valid: 69.31%, Test: 69.99%\n",
            "Epoch: 150, Loss: 143.7857, Train: 77.99%, Valid: 69.19%, Test: 70.47%\n",
            "Epoch: 155, Loss: 142.6734, Train: 78.11%, Valid: 69.31%, Test: 70.71%\n",
            "Epoch: 160, Loss: 141.5960, Train: 78.29%, Valid: 69.31%, Test: 70.47%\n",
            "Epoch: 165, Loss: 140.4907, Train: 78.53%, Valid: 69.31%, Test: 70.83%\n",
            "Epoch: 170, Loss: 139.5457, Train: 78.47%, Valid: 68.83%, Test: 71.07%\n",
            "Epoch: 175, Loss: 138.5300, Train: 78.83%, Valid: 69.31%, Test: 71.55%\n",
            "Epoch: 180, Loss: 137.4972, Train: 78.95%, Valid: 69.07%, Test: 71.07%\n",
            "Epoch: 185, Loss: 136.7192, Train: 79.25%, Valid: 69.19%, Test: 71.07%\n",
            "Epoch: 190, Loss: 135.8819, Train: 79.49%, Valid: 69.55%, Test: 70.83%\n",
            "Epoch: 195, Loss: 135.2533, Train: 79.98%, Valid: 69.55%, Test: 70.95%\n",
            "Run 04:\n",
            "Highest Train: 79.98\n",
            "Highest Valid: 69.80\n",
            "Highest Test: 71.55\n",
            "Chosen epoch: 189\n",
            "Final Train: 79.49\n",
            "Final Test: 71.31\n",
            "Epoch: 00, Loss: 252.9951, Train: 16.42%, Valid: 17.69%, Test: 17.17%\n",
            "Epoch: 05, Loss: 218.0372, Train: 28.38%, Valid: 25.75%, Test: 26.77%\n",
            "Epoch: 10, Loss: 199.8691, Train: 30.79%, Valid: 27.68%, Test: 29.65%\n",
            "Epoch: 15, Loss: 188.9225, Train: 36.08%, Valid: 32.13%, Test: 35.17%\n",
            "Epoch: 20, Loss: 181.2838, Train: 47.44%, Valid: 41.16%, Test: 41.90%\n",
            "Epoch: 25, Loss: 175.2214, Train: 59.29%, Valid: 51.62%, Test: 52.22%\n",
            "Epoch: 30, Loss: 170.1852, Train: 66.33%, Valid: 57.52%, Test: 58.82%\n",
            "Epoch: 35, Loss: 166.1162, Train: 68.49%, Valid: 60.41%, Test: 61.22%\n",
            "Epoch: 40, Loss: 162.5667, Train: 69.99%, Valid: 62.09%, Test: 62.67%\n",
            "Epoch: 45, Loss: 159.3302, Train: 70.90%, Valid: 63.18%, Test: 64.23%\n",
            "Epoch: 50, Loss: 156.4281, Train: 71.80%, Valid: 64.02%, Test: 65.91%\n",
            "Epoch: 55, Loss: 153.4675, Train: 72.34%, Valid: 64.74%, Test: 66.87%\n",
            "Epoch: 60, Loss: 150.7123, Train: 73.30%, Valid: 64.62%, Test: 67.71%\n",
            "Epoch: 65, Loss: 148.2978, Train: 73.72%, Valid: 65.34%, Test: 67.83%\n",
            "Epoch: 70, Loss: 146.0269, Train: 74.80%, Valid: 65.94%, Test: 68.55%\n",
            "Epoch: 75, Loss: 143.8498, Train: 75.53%, Valid: 66.06%, Test: 68.19%\n",
            "Epoch: 80, Loss: 141.7569, Train: 75.89%, Valid: 66.31%, Test: 67.95%\n",
            "Epoch: 85, Loss: 139.8035, Train: 76.01%, Valid: 66.67%, Test: 68.31%\n",
            "Epoch: 90, Loss: 137.8903, Train: 76.43%, Valid: 66.19%, Test: 68.55%\n",
            "Epoch: 95, Loss: 136.0831, Train: 76.85%, Valid: 66.91%, Test: 68.07%\n",
            "Epoch: 100, Loss: 134.4380, Train: 77.45%, Valid: 68.11%, Test: 68.55%\n",
            "Epoch: 105, Loss: 132.9700, Train: 77.63%, Valid: 68.35%, Test: 68.79%\n",
            "Epoch: 110, Loss: 131.5575, Train: 78.35%, Valid: 68.59%, Test: 68.43%\n",
            "Epoch: 115, Loss: 130.1893, Train: 78.95%, Valid: 68.71%, Test: 68.67%\n",
            "Epoch: 120, Loss: 128.8025, Train: 79.25%, Valid: 69.31%, Test: 69.51%\n",
            "Epoch: 125, Loss: 127.5061, Train: 79.43%, Valid: 70.04%, Test: 69.51%\n",
            "Epoch: 130, Loss: 126.2279, Train: 79.86%, Valid: 69.55%, Test: 69.75%\n",
            "Epoch: 135, Loss: 125.2103, Train: 80.70%, Valid: 69.31%, Test: 69.75%\n",
            "Epoch: 140, Loss: 124.1981, Train: 81.06%, Valid: 70.16%, Test: 69.87%\n",
            "Epoch: 145, Loss: 123.1602, Train: 81.30%, Valid: 70.04%, Test: 69.63%\n",
            "Epoch: 150, Loss: 122.4488, Train: 81.54%, Valid: 70.52%, Test: 70.23%\n",
            "Epoch: 155, Loss: 121.7616, Train: 81.84%, Valid: 70.52%, Test: 70.11%\n",
            "Epoch: 160, Loss: 121.3900, Train: 82.26%, Valid: 70.76%, Test: 70.23%\n",
            "Epoch: 165, Loss: 120.5804, Train: 82.32%, Valid: 70.76%, Test: 70.11%\n",
            "Epoch: 170, Loss: 120.0168, Train: 82.56%, Valid: 71.60%, Test: 70.47%\n",
            "Epoch: 175, Loss: 119.7618, Train: 82.68%, Valid: 71.00%, Test: 70.23%\n",
            "Epoch: 180, Loss: 119.0833, Train: 83.04%, Valid: 71.24%, Test: 70.11%\n",
            "Epoch: 185, Loss: 118.4761, Train: 83.28%, Valid: 71.72%, Test: 70.47%\n",
            "Epoch: 190, Loss: 117.9380, Train: 83.88%, Valid: 71.48%, Test: 70.35%\n",
            "Epoch: 195, Loss: 118.3630, Train: 83.88%, Valid: 71.72%, Test: 70.35%\n",
            "Run 05:\n",
            "Highest Train: 84.06\n",
            "Highest Valid: 71.84\n",
            "Highest Test: 70.71\n",
            "Chosen epoch: 190\n",
            "Final Train: 83.70\n",
            "Final Test: 70.59\n",
            "All runs:\n",
            "Highest Train: 82.86 ± 1.88\n",
            "Highest Test: 72.00 ± 0.98\n",
            "Highest Valid: 71.96 ± 1.44\n",
            "  Final Train: 82.26 ± 1.94\n",
            "   Final Test: 71.43 ± 0.65\n",
            "Saving results to logs/citeseer_edge.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 GKD/main.py --dataset citeseer--rand_split --use_bn --base_model gcn --mode train --priv_type edge --dist_mode gkd --use_kd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ui31fRB3Jtpq",
        "outputId": "1ca6b7bc-dd1d-4a22-df83-b59905531cbd"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(data_dir='data', dataset='citeseer--rand_split', sub_dataset='', cpu=False, seed=42, train_prop=0.5, valid_prop=0.25, protocol='semi', rand_split=False, metric='acc', runs=5, epochs=200, hidden_channels=32, num_layers=3, gat_heads=8, out_heads=1, hops=1, lp_alpha=0.1, gpr_alpha=0.1, jk_type='max', directed=False, num_mlp_layers=1, display_step=5, cached=False, print_prop=False, priv_type='edge', priv_ratio=0.5, save_model=False, save_name='gcn', log_name='none', base_model='gcn', not_load_teacher=False, mode='train', dist_mode='gkd', weight_decay=0.05, dropout=0.0, lr=0.01, use_bn=True, use_batch=False, batch_size=2048, oracle=False, device=0, alpha=0.5, delta=0.1, use_kd=True, beta=0.0, tau=1.0, kernel='sigmoid', t=1.0, include_last=False, s=2, m=1, lr2=0.001, sim='l2', ker_norm=False)\n",
            "cuda:0\n",
            "citeseer--rand_split\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/GKD/main.py\", line 47, in <module>\n",
            "    dataset = load_nc_dataset(args.dataset, args.sub_dataset, args.data_dir)\n",
            "  File \"/content/GKD/dataset.py\", line 123, in load_nc_dataset\n",
            "    raise ValueError('Invalid dataname')\n",
            "ValueError: Invalid dataname\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 GKD/main.py --dataset citeseer --rand_split --use_bn --base_model gcn --mode train --priv_type edge --dist_mode gkd --use_kd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGqKYsv2JwPt",
        "outputId": "ede18ce1-48de-402d-d824-00c2e9b9be86"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(data_dir='data', dataset='citeseer', sub_dataset='', cpu=False, seed=42, train_prop=0.5, valid_prop=0.25, protocol='semi', rand_split=True, metric='acc', runs=5, epochs=200, hidden_channels=32, num_layers=3, gat_heads=8, out_heads=1, hops=1, lp_alpha=0.1, gpr_alpha=0.1, jk_type='max', directed=False, num_mlp_layers=1, display_step=5, cached=False, print_prop=False, priv_type='edge', priv_ratio=0.5, save_model=False, save_name='gcn', log_name='none', base_model='gcn', not_load_teacher=False, mode='train', dist_mode='gkd', weight_decay=0.05, dropout=0.0, lr=0.01, use_bn=True, use_batch=False, batch_size=2048, oracle=False, device=0, alpha=0.5, delta=0.1, use_kd=True, beta=0.0, tau=1.0, kernel='sigmoid', t=1.0, include_last=False, s=2, m=1, lr2=0.001, sim='l2', ker_norm=False)\n",
            "cuda:0\n",
            "citeseer\n",
            "Num nodes: 3327\n",
            "torch.Size([3327, 1])\n",
            "num nodes 3327 | num classes 6 | num node feats 3703\n",
            "MODEL: GeoDist(\n",
            "  (k): Kernel(\n",
            "    (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  )\n",
            "  (teacher_gnn): ModuleList(\n",
            "    (0): Linear(in_features=3703, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (student_gnn): ModuleList(\n",
            "    (0): Linear(in_features=3703, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  (bns2d): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            ")\n",
            "Epoch: 00, Loss: 918465.8125, Train: 14.07%, Valid: 14.92%, Test: 17.89%\n",
            "Epoch: 05, Loss: 192346.2500, Train: 25.98%, Valid: 24.55%, Test: 24.85%\n",
            "Epoch: 10, Loss: 150587.6719, Train: 43.42%, Valid: 38.99%, Test: 40.10%\n",
            "Epoch: 15, Loss: 129515.5938, Train: 58.75%, Valid: 51.02%, Test: 52.10%\n",
            "Epoch: 20, Loss: 115140.5391, Train: 73.18%, Valid: 63.66%, Test: 62.55%\n",
            "Epoch: 25, Loss: 104605.9609, Train: 80.10%, Valid: 70.28%, Test: 69.15%\n",
            "Epoch: 30, Loss: 96229.8047, Train: 81.36%, Valid: 70.76%, Test: 70.23%\n",
            "Epoch: 35, Loss: 89171.5000, Train: 82.38%, Valid: 71.84%, Test: 71.55%\n",
            "Epoch: 40, Loss: 83274.9688, Train: 82.38%, Valid: 72.20%, Test: 72.15%\n",
            "Epoch: 45, Loss: 78249.5547, Train: 82.56%, Valid: 72.44%, Test: 72.51%\n",
            "Epoch: 50, Loss: 73839.0000, Train: 82.74%, Valid: 72.32%, Test: 72.51%\n",
            "Epoch: 55, Loss: 69927.6094, Train: 82.86%, Valid: 72.80%, Test: 72.87%\n",
            "Epoch: 60, Loss: 66394.8516, Train: 82.86%, Valid: 73.29%, Test: 72.39%\n",
            "Epoch: 65, Loss: 63214.9141, Train: 82.98%, Valid: 73.29%, Test: 72.51%\n",
            "Epoch: 70, Loss: 60377.9141, Train: 83.28%, Valid: 73.16%, Test: 72.51%\n",
            "Epoch: 75, Loss: 57769.5664, Train: 83.46%, Valid: 73.53%, Test: 72.87%\n",
            "Epoch: 80, Loss: 55337.6133, Train: 83.52%, Valid: 73.77%, Test: 73.11%\n",
            "Epoch: 85, Loss: 53117.1875, Train: 83.64%, Valid: 73.89%, Test: 73.11%\n",
            "Epoch: 90, Loss: 51170.5039, Train: 83.52%, Valid: 73.77%, Test: 72.99%\n",
            "Epoch: 95, Loss: 49269.4336, Train: 83.76%, Valid: 73.53%, Test: 72.75%\n",
            "Epoch: 100, Loss: 47393.0195, Train: 83.70%, Valid: 73.29%, Test: 72.63%\n",
            "Epoch: 105, Loss: 45623.3828, Train: 83.82%, Valid: 73.41%, Test: 72.87%\n",
            "Epoch: 110, Loss: 44123.7812, Train: 83.88%, Valid: 73.16%, Test: 72.99%\n",
            "Epoch: 115, Loss: 42667.7227, Train: 83.88%, Valid: 73.04%, Test: 72.75%\n",
            "Epoch: 120, Loss: 41248.4180, Train: 83.94%, Valid: 72.92%, Test: 72.63%\n",
            "Epoch: 125, Loss: 39946.9922, Train: 84.00%, Valid: 73.29%, Test: 72.75%\n",
            "Epoch: 130, Loss: 38709.7109, Train: 84.06%, Valid: 72.92%, Test: 72.87%\n",
            "Epoch: 135, Loss: 37601.6094, Train: 84.13%, Valid: 73.04%, Test: 72.75%\n",
            "Epoch: 140, Loss: 36556.7891, Train: 84.25%, Valid: 73.29%, Test: 72.99%\n",
            "Epoch: 145, Loss: 35573.5156, Train: 84.19%, Valid: 72.92%, Test: 73.11%\n",
            "Epoch: 150, Loss: 35026.1016, Train: 84.00%, Valid: 72.80%, Test: 73.23%\n",
            "Epoch: 155, Loss: 34004.7812, Train: 84.13%, Valid: 72.80%, Test: 73.11%\n",
            "Epoch: 160, Loss: 33286.6211, Train: 84.19%, Valid: 72.68%, Test: 73.11%\n",
            "Epoch: 165, Loss: 32580.8848, Train: 84.13%, Valid: 72.56%, Test: 73.11%\n",
            "Epoch: 170, Loss: 32015.1602, Train: 84.00%, Valid: 72.44%, Test: 73.23%\n",
            "Epoch: 175, Loss: 31140.6543, Train: 84.00%, Valid: 72.56%, Test: 72.99%\n",
            "Epoch: 180, Loss: 30464.4141, Train: 83.94%, Valid: 72.56%, Test: 72.87%\n",
            "Epoch: 185, Loss: 29876.4199, Train: 84.00%, Valid: 72.56%, Test: 72.87%\n",
            "Epoch: 190, Loss: 29640.2520, Train: 84.06%, Valid: 72.68%, Test: 72.75%\n",
            "Epoch: 195, Loss: 28831.4258, Train: 84.06%, Valid: 72.68%, Test: 72.87%\n",
            "Run 01:\n",
            "Highest Train: 84.25\n",
            "Highest Valid: 74.01\n",
            "Highest Test: 73.23\n",
            "Chosen epoch: 88\n",
            "Final Train: 83.58\n",
            "Final Test: 73.23\n",
            "Epoch: 00, Loss: 912336.3125, Train: 11.85%, Valid: 13.12%, Test: 13.93%\n",
            "Epoch: 05, Loss: 217768.6094, Train: 31.99%, Valid: 28.88%, Test: 31.81%\n",
            "Epoch: 10, Loss: 166158.5156, Train: 46.18%, Valid: 41.16%, Test: 45.50%\n",
            "Epoch: 15, Loss: 142163.2500, Train: 62.00%, Valid: 52.83%, Test: 57.26%\n",
            "Epoch: 20, Loss: 125413.7188, Train: 72.10%, Valid: 63.42%, Test: 64.95%\n",
            "Epoch: 25, Loss: 113063.6406, Train: 79.92%, Valid: 71.00%, Test: 71.55%\n",
            "Epoch: 30, Loss: 103589.8203, Train: 82.08%, Valid: 71.48%, Test: 72.27%\n",
            "Epoch: 35, Loss: 95780.2266, Train: 83.04%, Valid: 71.48%, Test: 72.99%\n",
            "Epoch: 40, Loss: 89332.3203, Train: 83.70%, Valid: 71.84%, Test: 73.47%\n",
            "Epoch: 45, Loss: 83824.5781, Train: 84.55%, Valid: 72.20%, Test: 73.23%\n",
            "Epoch: 50, Loss: 79165.3203, Train: 84.91%, Valid: 73.16%, Test: 73.35%\n",
            "Epoch: 55, Loss: 75137.4609, Train: 85.63%, Valid: 73.41%, Test: 73.59%\n",
            "Epoch: 60, Loss: 71583.1641, Train: 85.93%, Valid: 73.29%, Test: 73.71%\n",
            "Epoch: 65, Loss: 68416.4297, Train: 86.53%, Valid: 73.65%, Test: 74.43%\n",
            "Epoch: 70, Loss: 65548.1641, Train: 86.65%, Valid: 73.29%, Test: 73.83%\n",
            "Epoch: 75, Loss: 62932.5781, Train: 86.71%, Valid: 73.41%, Test: 73.83%\n",
            "Epoch: 80, Loss: 60529.3359, Train: 86.77%, Valid: 73.04%, Test: 74.07%\n",
            "Epoch: 85, Loss: 58305.8672, Train: 86.65%, Valid: 73.41%, Test: 74.31%\n",
            "Epoch: 90, Loss: 56247.2188, Train: 86.77%, Valid: 72.92%, Test: 74.07%\n",
            "Epoch: 95, Loss: 54328.6875, Train: 86.83%, Valid: 73.04%, Test: 74.19%\n",
            "Epoch: 100, Loss: 52547.6719, Train: 86.77%, Valid: 73.16%, Test: 74.07%\n",
            "Epoch: 105, Loss: 50875.5195, Train: 86.77%, Valid: 73.29%, Test: 74.07%\n",
            "Epoch: 110, Loss: 49309.0117, Train: 86.71%, Valid: 73.29%, Test: 74.55%\n",
            "Epoch: 115, Loss: 47856.8203, Train: 86.77%, Valid: 73.29%, Test: 74.55%\n",
            "Epoch: 120, Loss: 46492.8438, Train: 86.77%, Valid: 73.29%, Test: 74.67%\n",
            "Epoch: 125, Loss: 45201.7031, Train: 86.65%, Valid: 73.53%, Test: 74.91%\n",
            "Epoch: 130, Loss: 43978.8320, Train: 86.65%, Valid: 73.65%, Test: 74.79%\n",
            "Epoch: 135, Loss: 42816.0273, Train: 86.77%, Valid: 73.65%, Test: 74.91%\n",
            "Epoch: 140, Loss: 41713.6055, Train: 86.77%, Valid: 73.41%, Test: 74.79%\n",
            "Epoch: 145, Loss: 40673.9453, Train: 86.77%, Valid: 73.41%, Test: 74.91%\n",
            "Epoch: 150, Loss: 39694.1562, Train: 86.71%, Valid: 73.16%, Test: 74.91%\n",
            "Epoch: 155, Loss: 38809.0234, Train: 86.65%, Valid: 73.16%, Test: 74.91%\n",
            "Epoch: 160, Loss: 38043.5156, Train: 86.71%, Valid: 73.16%, Test: 74.79%\n",
            "Epoch: 165, Loss: 37156.7969, Train: 86.71%, Valid: 73.16%, Test: 74.67%\n",
            "Epoch: 170, Loss: 36470.1875, Train: 86.83%, Valid: 73.16%, Test: 74.67%\n",
            "Epoch: 175, Loss: 35717.8750, Train: 86.83%, Valid: 73.16%, Test: 74.79%\n",
            "Epoch: 180, Loss: 34966.5352, Train: 86.83%, Valid: 73.41%, Test: 74.79%\n",
            "Epoch: 185, Loss: 34300.3555, Train: 86.83%, Valid: 73.41%, Test: 74.79%\n",
            "Epoch: 190, Loss: 33662.3555, Train: 86.71%, Valid: 73.29%, Test: 74.79%\n",
            "Epoch: 195, Loss: 33102.2305, Train: 86.71%, Valid: 73.29%, Test: 74.79%\n",
            "Run 02:\n",
            "Highest Train: 86.89\n",
            "Highest Valid: 73.65\n",
            "Highest Test: 75.03\n",
            "Chosen epoch: 65\n",
            "Final Train: 86.23\n",
            "Final Test: 74.43\n",
            "Epoch: 00, Loss: 913669.8750, Train: 18.64%, Valid: 19.13%, Test: 18.25%\n",
            "Epoch: 05, Loss: 221028.2031, Train: 27.66%, Valid: 27.68%, Test: 24.61%\n",
            "Epoch: 10, Loss: 171788.2344, Train: 54.90%, Valid: 47.41%, Test: 48.38%\n",
            "Epoch: 15, Loss: 146493.2500, Train: 62.00%, Valid: 53.67%, Test: 54.62%\n",
            "Epoch: 20, Loss: 130246.0547, Train: 73.90%, Valid: 66.19%, Test: 66.15%\n",
            "Epoch: 25, Loss: 118031.3516, Train: 78.59%, Valid: 69.68%, Test: 70.11%\n",
            "Epoch: 30, Loss: 108068.4609, Train: 79.68%, Valid: 70.76%, Test: 71.31%\n",
            "Epoch: 35, Loss: 99642.1172, Train: 80.28%, Valid: 71.12%, Test: 70.83%\n",
            "Epoch: 40, Loss: 92393.7812, Train: 80.34%, Valid: 71.24%, Test: 70.47%\n",
            "Epoch: 45, Loss: 85987.9375, Train: 80.58%, Valid: 71.60%, Test: 70.59%\n",
            "Epoch: 50, Loss: 80231.9688, Train: 81.00%, Valid: 71.72%, Test: 70.71%\n",
            "Epoch: 55, Loss: 75231.4844, Train: 81.00%, Valid: 71.96%, Test: 70.95%\n",
            "Epoch: 60, Loss: 70769.8047, Train: 81.24%, Valid: 71.84%, Test: 70.95%\n",
            "Epoch: 65, Loss: 66745.7422, Train: 81.24%, Valid: 71.84%, Test: 71.31%\n",
            "Epoch: 70, Loss: 63121.2617, Train: 81.30%, Valid: 71.96%, Test: 71.43%\n",
            "Epoch: 75, Loss: 59912.0469, Train: 81.54%, Valid: 71.72%, Test: 71.91%\n",
            "Epoch: 80, Loss: 57044.7500, Train: 81.60%, Valid: 71.36%, Test: 72.27%\n",
            "Epoch: 85, Loss: 54450.6914, Train: 81.72%, Valid: 71.24%, Test: 72.15%\n",
            "Epoch: 90, Loss: 52087.5273, Train: 81.84%, Valid: 71.48%, Test: 72.27%\n",
            "Epoch: 95, Loss: 49943.9648, Train: 81.60%, Valid: 71.60%, Test: 71.91%\n",
            "Epoch: 100, Loss: 47998.9883, Train: 81.72%, Valid: 71.48%, Test: 71.67%\n",
            "Epoch: 105, Loss: 46214.8320, Train: 81.54%, Valid: 71.48%, Test: 72.03%\n",
            "Epoch: 110, Loss: 44587.5547, Train: 81.54%, Valid: 71.84%, Test: 72.03%\n",
            "Epoch: 115, Loss: 43089.8086, Train: 81.66%, Valid: 71.96%, Test: 72.03%\n",
            "Epoch: 120, Loss: 41733.8672, Train: 81.84%, Valid: 72.08%, Test: 72.51%\n",
            "Epoch: 125, Loss: 40446.3242, Train: 81.90%, Valid: 72.32%, Test: 72.63%\n",
            "Epoch: 130, Loss: 39470.3359, Train: 81.90%, Valid: 72.44%, Test: 72.51%\n",
            "Epoch: 135, Loss: 38201.9961, Train: 82.08%, Valid: 72.68%, Test: 72.75%\n",
            "Epoch: 140, Loss: 37271.1680, Train: 82.14%, Valid: 72.56%, Test: 72.63%\n",
            "Epoch: 145, Loss: 36266.5430, Train: 82.20%, Valid: 72.44%, Test: 72.51%\n",
            "Epoch: 150, Loss: 35415.8828, Train: 82.14%, Valid: 72.44%, Test: 72.51%\n",
            "Epoch: 155, Loss: 34603.6211, Train: 82.02%, Valid: 71.96%, Test: 72.39%\n",
            "Epoch: 160, Loss: 33848.6641, Train: 82.20%, Valid: 71.96%, Test: 72.27%\n",
            "Epoch: 165, Loss: 33414.5781, Train: 82.32%, Valid: 71.84%, Test: 71.91%\n",
            "Epoch: 170, Loss: 32624.6895, Train: 82.32%, Valid: 71.96%, Test: 72.03%\n",
            "Epoch: 175, Loss: 31977.9277, Train: 82.32%, Valid: 71.96%, Test: 72.15%\n",
            "Epoch: 180, Loss: 31358.7109, Train: 82.26%, Valid: 71.96%, Test: 72.27%\n",
            "Epoch: 185, Loss: 30762.4824, Train: 82.38%, Valid: 71.96%, Test: 72.27%\n",
            "Epoch: 190, Loss: 30275.8281, Train: 82.50%, Valid: 71.84%, Test: 72.39%\n",
            "Epoch: 195, Loss: 29795.5039, Train: 82.68%, Valid: 71.84%, Test: 72.27%\n",
            "Run 03:\n",
            "Highest Train: 82.74\n",
            "Highest Valid: 72.68\n",
            "Highest Test: 72.75\n",
            "Chosen epoch: 136\n",
            "Final Train: 82.08\n",
            "Final Test: 72.75\n",
            "Epoch: 00, Loss: 925642.4375, Train: 10.40%, Valid: 10.35%, Test: 11.40%\n",
            "Epoch: 05, Loss: 196733.6406, Train: 31.81%, Valid: 31.65%, Test: 30.37%\n",
            "Epoch: 10, Loss: 156195.6562, Train: 41.25%, Valid: 39.47%, Test: 38.18%\n",
            "Epoch: 15, Loss: 135959.8750, Train: 53.22%, Valid: 49.10%, Test: 48.02%\n",
            "Epoch: 20, Loss: 122006.3359, Train: 65.66%, Valid: 60.53%, Test: 58.58%\n",
            "Epoch: 25, Loss: 111750.1484, Train: 72.04%, Valid: 66.06%, Test: 65.19%\n",
            "Epoch: 30, Loss: 103344.2891, Train: 78.11%, Valid: 69.19%, Test: 69.39%\n",
            "Epoch: 35, Loss: 96205.2266, Train: 80.40%, Valid: 71.72%, Test: 71.67%\n",
            "Epoch: 40, Loss: 90044.5156, Train: 81.42%, Valid: 71.72%, Test: 72.75%\n",
            "Epoch: 45, Loss: 84602.2188, Train: 82.02%, Valid: 71.60%, Test: 72.39%\n",
            "Epoch: 50, Loss: 79720.5625, Train: 82.08%, Valid: 71.84%, Test: 72.39%\n",
            "Epoch: 55, Loss: 75382.2812, Train: 82.32%, Valid: 72.08%, Test: 72.15%\n",
            "Epoch: 60, Loss: 71452.8203, Train: 82.26%, Valid: 71.96%, Test: 72.51%\n",
            "Epoch: 65, Loss: 67860.4688, Train: 82.56%, Valid: 71.96%, Test: 72.87%\n",
            "Epoch: 70, Loss: 64547.2422, Train: 82.92%, Valid: 71.96%, Test: 72.75%\n",
            "Epoch: 75, Loss: 61536.3008, Train: 83.04%, Valid: 72.20%, Test: 73.11%\n",
            "Epoch: 80, Loss: 58811.6211, Train: 83.46%, Valid: 72.08%, Test: 73.23%\n",
            "Epoch: 85, Loss: 56362.7305, Train: 83.58%, Valid: 71.84%, Test: 73.59%\n",
            "Epoch: 90, Loss: 54131.2617, Train: 83.82%, Valid: 72.32%, Test: 73.47%\n",
            "Epoch: 95, Loss: 52097.6797, Train: 83.88%, Valid: 72.44%, Test: 73.35%\n",
            "Epoch: 100, Loss: 50229.5977, Train: 83.88%, Valid: 72.56%, Test: 73.23%\n",
            "Epoch: 105, Loss: 48509.9180, Train: 84.19%, Valid: 72.56%, Test: 73.11%\n",
            "Epoch: 110, Loss: 46935.1172, Train: 84.06%, Valid: 72.44%, Test: 72.87%\n",
            "Epoch: 115, Loss: 45484.0039, Train: 84.25%, Valid: 72.56%, Test: 72.99%\n",
            "Epoch: 120, Loss: 44138.2656, Train: 84.43%, Valid: 72.56%, Test: 72.75%\n",
            "Epoch: 125, Loss: 42891.8945, Train: 84.43%, Valid: 72.56%, Test: 72.63%\n",
            "Epoch: 130, Loss: 41738.5547, Train: 84.43%, Valid: 72.56%, Test: 72.15%\n",
            "Epoch: 135, Loss: 40667.5703, Train: 84.37%, Valid: 72.56%, Test: 72.03%\n",
            "Epoch: 140, Loss: 39850.5664, Train: 84.61%, Valid: 72.68%, Test: 71.91%\n",
            "Epoch: 145, Loss: 39045.8438, Train: 84.61%, Valid: 72.68%, Test: 71.91%\n",
            "Epoch: 150, Loss: 38153.3672, Train: 84.55%, Valid: 72.68%, Test: 71.91%\n",
            "Epoch: 155, Loss: 37203.1953, Train: 84.73%, Valid: 72.80%, Test: 72.15%\n",
            "Epoch: 160, Loss: 36475.0156, Train: 84.79%, Valid: 72.68%, Test: 72.03%\n",
            "Epoch: 165, Loss: 35817.9219, Train: 84.85%, Valid: 72.68%, Test: 71.79%\n",
            "Epoch: 170, Loss: 35454.3125, Train: 84.79%, Valid: 72.80%, Test: 71.79%\n",
            "Epoch: 175, Loss: 34532.4727, Train: 84.79%, Valid: 72.80%, Test: 72.15%\n",
            "Epoch: 180, Loss: 33955.9180, Train: 85.15%, Valid: 72.68%, Test: 72.03%\n",
            "Epoch: 185, Loss: 33478.2344, Train: 85.09%, Valid: 72.80%, Test: 72.27%\n",
            "Epoch: 190, Loss: 32944.5820, Train: 85.03%, Valid: 72.80%, Test: 72.27%\n",
            "Epoch: 195, Loss: 32832.6172, Train: 85.21%, Valid: 72.56%, Test: 72.27%\n",
            "Run 04:\n",
            "Highest Train: 85.21\n",
            "Highest Valid: 73.04\n",
            "Highest Test: 73.59\n",
            "Chosen epoch: 193\n",
            "Final Train: 85.03\n",
            "Final Test: 72.15\n",
            "Epoch: 00, Loss: 910929.8750, Train: 18.64%, Valid: 20.94%, Test: 20.77%\n",
            "Epoch: 05, Loss: 208556.9375, Train: 35.54%, Valid: 29.96%, Test: 33.73%\n",
            "Epoch: 10, Loss: 164174.3281, Train: 47.50%, Valid: 42.84%, Test: 42.50%\n",
            "Epoch: 15, Loss: 142287.7656, Train: 64.64%, Valid: 56.08%, Test: 57.86%\n",
            "Epoch: 20, Loss: 127461.6797, Train: 71.62%, Valid: 63.42%, Test: 63.87%\n",
            "Epoch: 25, Loss: 115889.9297, Train: 78.89%, Valid: 70.04%, Test: 68.67%\n",
            "Epoch: 30, Loss: 106529.0625, Train: 82.68%, Valid: 71.96%, Test: 70.71%\n",
            "Epoch: 35, Loss: 98777.6094, Train: 84.37%, Valid: 73.53%, Test: 71.19%\n",
            "Epoch: 40, Loss: 92226.5938, Train: 85.45%, Valid: 73.89%, Test: 72.27%\n",
            "Epoch: 45, Loss: 86556.8828, Train: 85.99%, Valid: 74.13%, Test: 72.75%\n",
            "Epoch: 50, Loss: 81630.6641, Train: 86.11%, Valid: 74.01%, Test: 73.11%\n",
            "Epoch: 55, Loss: 77228.0781, Train: 86.71%, Valid: 74.01%, Test: 73.11%\n",
            "Epoch: 60, Loss: 73238.2969, Train: 86.83%, Valid: 74.25%, Test: 72.99%\n",
            "Epoch: 65, Loss: 69639.2656, Train: 86.89%, Valid: 74.13%, Test: 73.23%\n",
            "Epoch: 70, Loss: 66356.0000, Train: 87.13%, Valid: 74.13%, Test: 72.99%\n",
            "Epoch: 75, Loss: 63410.0625, Train: 87.55%, Valid: 74.13%, Test: 72.99%\n",
            "Epoch: 80, Loss: 60741.7344, Train: 87.55%, Valid: 74.13%, Test: 73.23%\n",
            "Epoch: 85, Loss: 58285.6914, Train: 87.49%, Valid: 74.01%, Test: 73.11%\n",
            "Epoch: 90, Loss: 56007.1992, Train: 87.67%, Valid: 73.77%, Test: 72.99%\n",
            "Epoch: 95, Loss: 53880.0234, Train: 87.85%, Valid: 73.53%, Test: 73.11%\n",
            "Epoch: 100, Loss: 51887.6562, Train: 88.03%, Valid: 73.41%, Test: 73.23%\n",
            "Epoch: 105, Loss: 50022.9688, Train: 87.91%, Valid: 73.53%, Test: 73.23%\n",
            "Epoch: 110, Loss: 48298.5312, Train: 88.03%, Valid: 73.89%, Test: 73.23%\n",
            "Epoch: 115, Loss: 46709.2734, Train: 87.97%, Valid: 73.89%, Test: 73.35%\n",
            "Epoch: 120, Loss: 45238.3047, Train: 88.09%, Valid: 74.01%, Test: 73.47%\n",
            "Epoch: 125, Loss: 43882.7734, Train: 88.15%, Valid: 74.13%, Test: 73.11%\n",
            "Epoch: 130, Loss: 42639.4766, Train: 88.21%, Valid: 74.13%, Test: 72.75%\n",
            "Epoch: 135, Loss: 41493.8828, Train: 88.21%, Valid: 74.25%, Test: 72.63%\n",
            "Epoch: 140, Loss: 40433.2188, Train: 88.15%, Valid: 74.13%, Test: 72.63%\n",
            "Epoch: 145, Loss: 39457.6992, Train: 88.21%, Valid: 74.25%, Test: 72.63%\n",
            "Epoch: 150, Loss: 39068.0820, Train: 88.21%, Valid: 74.25%, Test: 72.75%\n",
            "Epoch: 155, Loss: 37744.8359, Train: 88.39%, Valid: 74.37%, Test: 72.63%\n",
            "Epoch: 160, Loss: 37030.6406, Train: 88.39%, Valid: 74.25%, Test: 72.75%\n",
            "Epoch: 165, Loss: 36252.2266, Train: 88.39%, Valid: 74.25%, Test: 72.63%\n",
            "Epoch: 170, Loss: 35480.8633, Train: 88.33%, Valid: 74.37%, Test: 72.63%\n",
            "Epoch: 175, Loss: 34833.6055, Train: 88.39%, Valid: 74.49%, Test: 72.63%\n",
            "Epoch: 180, Loss: 34222.1797, Train: 88.39%, Valid: 74.49%, Test: 72.75%\n",
            "Epoch: 185, Loss: 33867.6367, Train: 88.39%, Valid: 74.37%, Test: 72.39%\n",
            "Epoch: 190, Loss: 33099.1445, Train: 88.39%, Valid: 74.25%, Test: 72.51%\n",
            "Epoch: 195, Loss: 32657.8750, Train: 88.45%, Valid: 74.13%, Test: 72.63%\n",
            "Run 05:\n",
            "Highest Train: 88.51\n",
            "Highest Valid: 74.49\n",
            "Highest Test: 73.47\n",
            "Chosen epoch: 176\n",
            "Final Train: 88.39\n",
            "Final Test: 72.63\n",
            "All runs:\n",
            "Highest Train: 85.52 ± 2.25\n",
            "Highest Test: 73.61 ± 0.85\n",
            "Highest Valid: 73.57 ± 0.73\n",
            "  Final Train: 85.06 ± 2.43\n",
            "   Final Test: 73.04 ± 0.87\n",
            "Saving results to logs/citeseer_edge.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 GKD/main.py --dataset citeseer --rand_split --use_bn --base_model gcn --mode train --priv_type edge --dist_mode pgkd --use_kd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FA1_6fQJzkr",
        "outputId": "c965c403-461e-4e0f-ef78-9a90cde1927b"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(data_dir='data', dataset='citeseer', sub_dataset='', cpu=False, seed=42, train_prop=0.5, valid_prop=0.25, protocol='semi', rand_split=True, metric='acc', runs=5, epochs=200, hidden_channels=32, num_layers=3, gat_heads=8, out_heads=1, hops=1, lp_alpha=0.1, gpr_alpha=0.1, jk_type='max', directed=False, num_mlp_layers=1, display_step=5, cached=False, print_prop=False, priv_type='edge', priv_ratio=0.5, save_model=False, save_name='gcn', log_name='none', base_model='gcn', not_load_teacher=False, mode='train', dist_mode='pgkd', weight_decay=0.05, dropout=0.0, lr=0.01, use_bn=True, use_batch=False, batch_size=2048, oracle=False, device=0, alpha=0.5, delta=0.1, use_kd=True, beta=0.0, tau=1.0, kernel='sigmoid', t=1.0, include_last=False, s=2, m=1, lr2=0.001, sim='l2', ker_norm=False)\n",
            "cuda:0\n",
            "citeseer\n",
            "Num nodes: 3327\n",
            "torch.Size([3327, 1])\n",
            "num nodes 3327 | num classes 6 | num node feats 3703\n",
            "MODEL: GeoDist(\n",
            "  (k): Kernel(\n",
            "    (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  )\n",
            "  (teacher_gnn): ModuleList(\n",
            "    (0): Linear(in_features=3703, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (student_gnn): ModuleList(\n",
            "    (0): Linear(in_features=3703, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  (bns2d): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            ")\n",
            "Epoch: 00, Loss: 92568176.0000, Train: 15.27%, Valid: 15.52%, Test: 14.65%\n",
            "Epoch: 05, Loss: 26452406.0000, Train: 20.38%, Valid: 18.41%, Test: 19.69%\n",
            "Epoch: 10, Loss: 19788926.0000, Train: 38.91%, Valid: 34.06%, Test: 36.73%\n",
            "Epoch: 15, Loss: 16795580.0000, Train: 54.12%, Valid: 47.41%, Test: 51.26%\n",
            "Epoch: 20, Loss: 14939689.0000, Train: 65.18%, Valid: 58.48%, Test: 61.70%\n",
            "Epoch: 25, Loss: 13587812.0000, Train: 74.20%, Valid: 65.10%, Test: 67.35%\n",
            "Epoch: 30, Loss: 12537314.0000, Train: 77.33%, Valid: 67.63%, Test: 69.03%\n",
            "Epoch: 35, Loss: 11703909.0000, Train: 78.77%, Valid: 68.95%, Test: 70.23%\n",
            "Epoch: 40, Loss: 11034073.0000, Train: 79.19%, Valid: 70.76%, Test: 70.59%\n",
            "Epoch: 45, Loss: 10477247.0000, Train: 79.49%, Valid: 71.24%, Test: 70.83%\n",
            "Epoch: 50, Loss: 9996098.0000, Train: 80.10%, Valid: 71.60%, Test: 70.59%\n",
            "Epoch: 55, Loss: 9569719.0000, Train: 80.04%, Valid: 71.48%, Test: 70.71%\n",
            "Epoch: 60, Loss: 9206944.0000, Train: 80.10%, Valid: 71.72%, Test: 71.19%\n",
            "Epoch: 65, Loss: 8896931.0000, Train: 80.52%, Valid: 71.96%, Test: 71.19%\n",
            "Epoch: 70, Loss: 8615560.0000, Train: 80.70%, Valid: 72.08%, Test: 71.43%\n",
            "Epoch: 75, Loss: 8360631.5000, Train: 81.12%, Valid: 72.20%, Test: 71.55%\n",
            "Epoch: 80, Loss: 8126420.5000, Train: 81.18%, Valid: 71.72%, Test: 71.43%\n",
            "Epoch: 85, Loss: 7907774.5000, Train: 81.36%, Valid: 71.84%, Test: 71.55%\n",
            "Epoch: 90, Loss: 7703680.5000, Train: 81.72%, Valid: 71.72%, Test: 71.43%\n",
            "Epoch: 95, Loss: 7496459.0000, Train: 81.72%, Valid: 71.72%, Test: 71.31%\n",
            "Epoch: 100, Loss: 7320125.5000, Train: 81.66%, Valid: 71.60%, Test: 71.31%\n",
            "Epoch: 105, Loss: 7159265.0000, Train: 81.72%, Valid: 71.84%, Test: 71.31%\n",
            "Epoch: 110, Loss: 6995605.5000, Train: 81.72%, Valid: 71.84%, Test: 71.19%\n",
            "Epoch: 115, Loss: 6834177.5000, Train: 81.72%, Valid: 72.08%, Test: 71.19%\n",
            "Epoch: 120, Loss: 6688330.5000, Train: 81.60%, Valid: 72.20%, Test: 70.95%\n",
            "Epoch: 125, Loss: 6551060.0000, Train: 81.72%, Valid: 72.08%, Test: 71.07%\n",
            "Epoch: 130, Loss: 6420153.5000, Train: 81.72%, Valid: 71.96%, Test: 71.31%\n",
            "Epoch: 135, Loss: 6292528.0000, Train: 81.96%, Valid: 71.96%, Test: 71.07%\n",
            "Epoch: 140, Loss: 6177096.5000, Train: 81.90%, Valid: 71.96%, Test: 71.07%\n",
            "Epoch: 145, Loss: 6065720.5000, Train: 81.84%, Valid: 72.56%, Test: 70.83%\n",
            "Epoch: 150, Loss: 5952115.0000, Train: 81.90%, Valid: 72.92%, Test: 70.59%\n",
            "Epoch: 155, Loss: 5841636.0000, Train: 81.96%, Valid: 72.92%, Test: 70.47%\n",
            "Epoch: 160, Loss: 5729835.5000, Train: 81.96%, Valid: 72.80%, Test: 70.59%\n",
            "Epoch: 165, Loss: 5625915.0000, Train: 81.84%, Valid: 72.92%, Test: 70.47%\n",
            "Epoch: 170, Loss: 5531954.5000, Train: 81.72%, Valid: 72.92%, Test: 70.59%\n",
            "Epoch: 175, Loss: 5443006.5000, Train: 81.60%, Valid: 73.04%, Test: 70.71%\n",
            "Epoch: 180, Loss: 5354464.5000, Train: 81.60%, Valid: 73.16%, Test: 70.71%\n",
            "Epoch: 185, Loss: 5269400.5000, Train: 81.30%, Valid: 72.92%, Test: 70.83%\n",
            "Epoch: 190, Loss: 5174198.5000, Train: 81.30%, Valid: 72.68%, Test: 70.95%\n",
            "Epoch: 195, Loss: 5083254.5000, Train: 81.24%, Valid: 72.56%, Test: 70.71%\n",
            "Run 01:\n",
            "Highest Train: 82.02\n",
            "Highest Valid: 73.16\n",
            "Highest Test: 71.67\n",
            "Chosen epoch: 179\n",
            "Final Train: 81.54\n",
            "Final Test: 70.47\n",
            "Epoch: 00, Loss: 124333600.0000, Train: 14.91%, Valid: 16.61%, Test: 17.41%\n",
            "Epoch: 05, Loss: 34372048.0000, Train: 26.10%, Valid: 25.51%, Test: 24.61%\n",
            "Epoch: 10, Loss: 24280208.0000, Train: 36.56%, Valid: 34.06%, Test: 33.61%\n",
            "Epoch: 15, Loss: 19734074.0000, Train: 47.93%, Valid: 42.60%, Test: 43.10%\n",
            "Epoch: 20, Loss: 17033196.0000, Train: 62.90%, Valid: 56.56%, Test: 58.34%\n",
            "Epoch: 25, Loss: 15081047.0000, Train: 75.17%, Valid: 66.55%, Test: 65.91%\n",
            "Epoch: 30, Loss: 13638991.0000, Train: 78.77%, Valid: 68.59%, Test: 68.91%\n",
            "Epoch: 35, Loss: 12501362.0000, Train: 80.22%, Valid: 69.92%, Test: 70.71%\n",
            "Epoch: 40, Loss: 11595986.0000, Train: 81.12%, Valid: 69.68%, Test: 71.55%\n",
            "Epoch: 45, Loss: 10865376.0000, Train: 81.78%, Valid: 69.92%, Test: 72.03%\n",
            "Epoch: 50, Loss: 10245702.0000, Train: 81.78%, Valid: 70.40%, Test: 71.67%\n",
            "Epoch: 55, Loss: 9715140.0000, Train: 81.90%, Valid: 70.52%, Test: 71.31%\n",
            "Epoch: 60, Loss: 9258081.0000, Train: 81.96%, Valid: 70.28%, Test: 72.15%\n",
            "Epoch: 65, Loss: 8867178.0000, Train: 82.02%, Valid: 70.64%, Test: 72.15%\n",
            "Epoch: 70, Loss: 8528022.0000, Train: 82.08%, Valid: 70.76%, Test: 71.79%\n",
            "Epoch: 75, Loss: 8221086.5000, Train: 82.32%, Valid: 70.64%, Test: 71.55%\n",
            "Epoch: 80, Loss: 7941662.5000, Train: 81.96%, Valid: 70.52%, Test: 71.55%\n",
            "Epoch: 85, Loss: 7688917.5000, Train: 81.96%, Valid: 70.52%, Test: 71.55%\n",
            "Epoch: 90, Loss: 7462751.0000, Train: 82.02%, Valid: 70.64%, Test: 71.55%\n",
            "Epoch: 95, Loss: 7269455.5000, Train: 81.90%, Valid: 70.76%, Test: 71.55%\n",
            "Epoch: 100, Loss: 7096845.5000, Train: 81.84%, Valid: 70.88%, Test: 71.67%\n",
            "Epoch: 105, Loss: 6934685.0000, Train: 81.72%, Valid: 70.88%, Test: 71.67%\n",
            "Epoch: 110, Loss: 6788576.5000, Train: 81.78%, Valid: 70.76%, Test: 71.43%\n",
            "Epoch: 115, Loss: 6654663.0000, Train: 81.84%, Valid: 70.64%, Test: 71.43%\n",
            "Epoch: 120, Loss: 6527001.5000, Train: 81.84%, Valid: 70.52%, Test: 71.31%\n",
            "Epoch: 125, Loss: 6404277.5000, Train: 81.96%, Valid: 70.64%, Test: 71.31%\n",
            "Epoch: 130, Loss: 6285783.5000, Train: 81.96%, Valid: 70.52%, Test: 71.19%\n",
            "Epoch: 135, Loss: 6182278.5000, Train: 82.14%, Valid: 70.64%, Test: 71.31%\n",
            "Epoch: 140, Loss: 6092505.5000, Train: 81.96%, Valid: 70.52%, Test: 71.31%\n",
            "Epoch: 145, Loss: 6014052.5000, Train: 81.84%, Valid: 70.76%, Test: 71.19%\n",
            "Epoch: 150, Loss: 5939747.5000, Train: 81.84%, Valid: 70.64%, Test: 71.07%\n",
            "Epoch: 155, Loss: 5867295.5000, Train: 81.90%, Valid: 70.76%, Test: 71.31%\n",
            "Epoch: 160, Loss: 5797265.5000, Train: 81.84%, Valid: 70.88%, Test: 71.07%\n",
            "Epoch: 165, Loss: 5733097.5000, Train: 81.66%, Valid: 70.88%, Test: 70.95%\n",
            "Epoch: 170, Loss: 5675484.5000, Train: 81.66%, Valid: 70.88%, Test: 70.95%\n",
            "Epoch: 175, Loss: 5623219.0000, Train: 81.72%, Valid: 71.00%, Test: 70.95%\n",
            "Epoch: 180, Loss: 5575288.0000, Train: 81.72%, Valid: 71.12%, Test: 70.71%\n",
            "Epoch: 185, Loss: 5529354.5000, Train: 81.66%, Valid: 70.88%, Test: 70.71%\n",
            "Epoch: 190, Loss: 5487213.5000, Train: 81.66%, Valid: 70.88%, Test: 70.83%\n",
            "Epoch: 195, Loss: 5446916.5000, Train: 81.60%, Valid: 70.52%, Test: 70.83%\n",
            "Run 02:\n",
            "Highest Train: 82.32\n",
            "Highest Valid: 71.12\n",
            "Highest Test: 72.39\n",
            "Chosen epoch: 180\n",
            "Final Train: 81.72\n",
            "Final Test: 70.95\n",
            "Epoch: 00, Loss: 106087616.0000, Train: 24.17%, Valid: 23.95%, Test: 21.85%\n",
            "Epoch: 05, Loss: 33691968.0000, Train: 28.26%, Valid: 27.92%, Test: 25.81%\n",
            "Epoch: 10, Loss: 23573142.0000, Train: 38.91%, Valid: 37.42%, Test: 34.93%\n",
            "Epoch: 15, Loss: 18844816.0000, Train: 52.19%, Valid: 50.78%, Test: 50.30%\n",
            "Epoch: 20, Loss: 16081223.0000, Train: 64.16%, Valid: 62.09%, Test: 60.62%\n",
            "Epoch: 25, Loss: 14207663.0000, Train: 72.16%, Valid: 66.43%, Test: 66.15%\n",
            "Epoch: 30, Loss: 12927068.0000, Train: 74.32%, Valid: 67.87%, Test: 68.55%\n",
            "Epoch: 35, Loss: 11932296.0000, Train: 76.43%, Valid: 68.35%, Test: 69.27%\n",
            "Epoch: 40, Loss: 11100087.0000, Train: 77.75%, Valid: 68.95%, Test: 69.99%\n",
            "Epoch: 45, Loss: 10427352.0000, Train: 78.83%, Valid: 69.31%, Test: 70.83%\n",
            "Epoch: 50, Loss: 9865024.0000, Train: 79.07%, Valid: 68.95%, Test: 70.47%\n",
            "Epoch: 55, Loss: 9413499.0000, Train: 79.31%, Valid: 69.07%, Test: 70.23%\n",
            "Epoch: 60, Loss: 9031864.0000, Train: 79.31%, Valid: 69.68%, Test: 70.59%\n",
            "Epoch: 65, Loss: 8697383.0000, Train: 79.43%, Valid: 69.68%, Test: 70.83%\n",
            "Epoch: 70, Loss: 8400020.0000, Train: 79.74%, Valid: 69.92%, Test: 70.71%\n",
            "Epoch: 75, Loss: 8135390.0000, Train: 79.92%, Valid: 69.92%, Test: 70.59%\n",
            "Epoch: 80, Loss: 7904712.5000, Train: 80.04%, Valid: 70.04%, Test: 70.59%\n",
            "Epoch: 85, Loss: 7710478.5000, Train: 80.22%, Valid: 70.28%, Test: 70.35%\n",
            "Epoch: 90, Loss: 7533640.5000, Train: 80.28%, Valid: 70.28%, Test: 70.35%\n",
            "Epoch: 95, Loss: 7356419.5000, Train: 80.22%, Valid: 70.16%, Test: 70.59%\n",
            "Epoch: 100, Loss: 7186660.5000, Train: 80.28%, Valid: 70.16%, Test: 70.83%\n",
            "Epoch: 105, Loss: 7027930.5000, Train: 80.46%, Valid: 70.04%, Test: 70.71%\n",
            "Epoch: 110, Loss: 6881338.5000, Train: 80.40%, Valid: 70.16%, Test: 70.95%\n",
            "Epoch: 115, Loss: 6741317.0000, Train: 80.22%, Valid: 70.04%, Test: 71.19%\n",
            "Epoch: 120, Loss: 6613764.5000, Train: 80.52%, Valid: 69.92%, Test: 71.19%\n",
            "Epoch: 125, Loss: 6496239.5000, Train: 80.70%, Valid: 70.04%, Test: 70.83%\n",
            "Epoch: 130, Loss: 6383587.5000, Train: 80.46%, Valid: 70.04%, Test: 70.83%\n",
            "Epoch: 135, Loss: 6277451.5000, Train: 80.76%, Valid: 70.28%, Test: 70.35%\n",
            "Epoch: 140, Loss: 6173260.0000, Train: 80.82%, Valid: 70.16%, Test: 70.47%\n",
            "Epoch: 145, Loss: 6076539.0000, Train: 80.70%, Valid: 70.28%, Test: 70.47%\n",
            "Epoch: 150, Loss: 5983774.0000, Train: 80.70%, Valid: 70.52%, Test: 70.47%\n",
            "Epoch: 155, Loss: 5894313.5000, Train: 80.88%, Valid: 70.40%, Test: 70.59%\n",
            "Epoch: 160, Loss: 5807452.0000, Train: 80.88%, Valid: 70.64%, Test: 70.47%\n",
            "Epoch: 165, Loss: 5727462.0000, Train: 80.88%, Valid: 70.76%, Test: 70.35%\n",
            "Epoch: 170, Loss: 5658911.5000, Train: 80.88%, Valid: 71.00%, Test: 70.35%\n",
            "Epoch: 175, Loss: 5590244.5000, Train: 81.06%, Valid: 70.88%, Test: 70.35%\n",
            "Epoch: 180, Loss: 5524384.5000, Train: 81.06%, Valid: 70.88%, Test: 70.35%\n",
            "Epoch: 185, Loss: 5461469.0000, Train: 81.00%, Valid: 71.00%, Test: 70.47%\n",
            "Epoch: 190, Loss: 5399959.5000, Train: 80.94%, Valid: 70.64%, Test: 70.59%\n",
            "Epoch: 195, Loss: 5342476.5000, Train: 80.94%, Valid: 70.76%, Test: 70.71%\n",
            "Run 03:\n",
            "Highest Train: 81.12\n",
            "Highest Valid: 71.00\n",
            "Highest Test: 71.19\n",
            "Chosen epoch: 171\n",
            "Final Train: 80.88\n",
            "Final Test: 70.35\n",
            "Epoch: 00, Loss: 85706672.0000, Train: 13.23%, Valid: 14.08%, Test: 14.89%\n",
            "Epoch: 05, Loss: 27762694.0000, Train: 27.96%, Valid: 27.08%, Test: 26.53%\n",
            "Epoch: 10, Loss: 20535288.0000, Train: 37.40%, Valid: 35.74%, Test: 35.41%\n",
            "Epoch: 15, Loss: 17153756.0000, Train: 45.46%, Valid: 42.24%, Test: 42.50%\n",
            "Epoch: 20, Loss: 15088239.0000, Train: 60.01%, Valid: 54.15%, Test: 56.78%\n",
            "Epoch: 25, Loss: 13681209.0000, Train: 74.02%, Valid: 65.58%, Test: 65.91%\n",
            "Epoch: 30, Loss: 12636732.0000, Train: 78.05%, Valid: 68.59%, Test: 68.67%\n",
            "Epoch: 35, Loss: 11800378.0000, Train: 79.37%, Valid: 69.31%, Test: 69.51%\n",
            "Epoch: 40, Loss: 11117717.0000, Train: 80.58%, Valid: 69.80%, Test: 70.35%\n",
            "Epoch: 45, Loss: 10559064.0000, Train: 81.00%, Valid: 70.28%, Test: 70.71%\n",
            "Epoch: 50, Loss: 10075394.0000, Train: 81.12%, Valid: 70.52%, Test: 71.07%\n",
            "Epoch: 55, Loss: 9669868.0000, Train: 81.54%, Valid: 70.40%, Test: 71.07%\n",
            "Epoch: 60, Loss: 9320118.0000, Train: 81.54%, Valid: 70.76%, Test: 71.67%\n",
            "Epoch: 65, Loss: 9025180.0000, Train: 81.96%, Valid: 71.00%, Test: 71.43%\n",
            "Epoch: 70, Loss: 8758564.0000, Train: 81.78%, Valid: 70.88%, Test: 71.19%\n",
            "Epoch: 75, Loss: 8498549.0000, Train: 82.02%, Valid: 71.12%, Test: 71.79%\n",
            "Epoch: 80, Loss: 8248001.5000, Train: 82.26%, Valid: 71.48%, Test: 72.03%\n",
            "Epoch: 85, Loss: 8032385.0000, Train: 82.14%, Valid: 71.60%, Test: 72.15%\n",
            "Epoch: 90, Loss: 7841815.5000, Train: 82.38%, Valid: 71.00%, Test: 72.03%\n",
            "Epoch: 95, Loss: 7679593.0000, Train: 82.56%, Valid: 71.12%, Test: 72.03%\n",
            "Epoch: 100, Loss: 7542121.0000, Train: 82.62%, Valid: 71.24%, Test: 71.91%\n",
            "Epoch: 105, Loss: 7415624.5000, Train: 82.68%, Valid: 71.12%, Test: 71.91%\n",
            "Epoch: 110, Loss: 7311022.5000, Train: 82.86%, Valid: 71.36%, Test: 71.67%\n",
            "Epoch: 115, Loss: 7230965.5000, Train: 82.86%, Valid: 71.36%, Test: 71.55%\n",
            "Epoch: 120, Loss: 7172397.5000, Train: 82.92%, Valid: 71.72%, Test: 71.55%\n",
            "Epoch: 125, Loss: 7130797.5000, Train: 83.10%, Valid: 71.72%, Test: 71.43%\n",
            "Epoch: 130, Loss: 7085228.5000, Train: 83.04%, Valid: 71.72%, Test: 71.67%\n",
            "Epoch: 135, Loss: 7033341.5000, Train: 83.16%, Valid: 71.84%, Test: 71.67%\n",
            "Epoch: 140, Loss: 6969531.5000, Train: 83.22%, Valid: 72.08%, Test: 71.31%\n",
            "Epoch: 145, Loss: 6918290.5000, Train: 83.28%, Valid: 72.08%, Test: 71.67%\n",
            "Epoch: 150, Loss: 6862503.5000, Train: 83.40%, Valid: 71.96%, Test: 71.91%\n",
            "Epoch: 155, Loss: 6817519.5000, Train: 83.34%, Valid: 71.72%, Test: 72.27%\n",
            "Epoch: 160, Loss: 6787026.5000, Train: 83.28%, Valid: 71.72%, Test: 72.15%\n",
            "Epoch: 165, Loss: 6764863.0000, Train: 83.28%, Valid: 71.96%, Test: 72.15%\n",
            "Epoch: 170, Loss: 6738579.5000, Train: 83.46%, Valid: 71.84%, Test: 71.91%\n",
            "Epoch: 175, Loss: 6714444.0000, Train: 83.58%, Valid: 71.84%, Test: 72.03%\n",
            "Epoch: 180, Loss: 6695970.5000, Train: 83.70%, Valid: 72.08%, Test: 71.91%\n",
            "Epoch: 185, Loss: 6674988.5000, Train: 83.76%, Valid: 72.08%, Test: 71.79%\n",
            "Epoch: 190, Loss: 6648160.5000, Train: 83.82%, Valid: 72.44%, Test: 71.79%\n",
            "Epoch: 195, Loss: 6614486.5000, Train: 83.94%, Valid: 72.56%, Test: 71.67%\n",
            "Run 04:\n",
            "Highest Train: 83.94\n",
            "Highest Valid: 72.56\n",
            "Highest Test: 72.27\n",
            "Chosen epoch: 196\n",
            "Final Train: 83.94\n",
            "Final Test: 71.67\n",
            "Epoch: 00, Loss: 108466368.0000, Train: 20.08%, Valid: 22.38%, Test: 21.97%\n",
            "Epoch: 05, Loss: 33370044.0000, Train: 20.32%, Valid: 19.25%, Test: 18.85%\n",
            "Epoch: 10, Loss: 24414916.0000, Train: 27.54%, Valid: 24.31%, Test: 25.69%\n",
            "Epoch: 15, Loss: 20189474.0000, Train: 40.35%, Valid: 36.70%, Test: 37.45%\n",
            "Epoch: 20, Loss: 17430444.0000, Train: 60.61%, Valid: 52.47%, Test: 52.22%\n",
            "Epoch: 25, Loss: 15425792.0000, Train: 73.24%, Valid: 62.33%, Test: 61.82%\n",
            "Epoch: 30, Loss: 14038866.0000, Train: 76.91%, Valid: 65.10%, Test: 65.31%\n",
            "Epoch: 35, Loss: 12950792.0000, Train: 79.80%, Valid: 67.99%, Test: 66.87%\n",
            "Epoch: 40, Loss: 12051143.0000, Train: 81.24%, Valid: 69.80%, Test: 68.31%\n",
            "Epoch: 45, Loss: 11299038.0000, Train: 83.28%, Valid: 71.24%, Test: 69.03%\n",
            "Epoch: 50, Loss: 10659906.0000, Train: 84.25%, Valid: 72.32%, Test: 69.87%\n",
            "Epoch: 55, Loss: 10093816.0000, Train: 85.15%, Valid: 72.68%, Test: 70.71%\n",
            "Epoch: 60, Loss: 9614078.0000, Train: 85.15%, Valid: 73.04%, Test: 70.83%\n",
            "Epoch: 65, Loss: 9186888.0000, Train: 86.05%, Valid: 73.65%, Test: 71.19%\n",
            "Epoch: 70, Loss: 8817918.0000, Train: 86.35%, Valid: 73.77%, Test: 70.83%\n",
            "Epoch: 75, Loss: 8494908.0000, Train: 86.53%, Valid: 74.25%, Test: 71.31%\n",
            "Epoch: 80, Loss: 8202614.5000, Train: 86.23%, Valid: 74.13%, Test: 71.55%\n",
            "Epoch: 85, Loss: 7950606.0000, Train: 86.41%, Valid: 74.25%, Test: 71.67%\n",
            "Epoch: 90, Loss: 7727864.5000, Train: 86.47%, Valid: 74.13%, Test: 71.43%\n",
            "Epoch: 95, Loss: 7525749.5000, Train: 86.65%, Valid: 74.37%, Test: 71.67%\n",
            "Epoch: 100, Loss: 7332261.5000, Train: 86.47%, Valid: 74.25%, Test: 72.03%\n",
            "Epoch: 105, Loss: 7160630.5000, Train: 86.35%, Valid: 74.49%, Test: 71.91%\n",
            "Epoch: 110, Loss: 7001127.5000, Train: 86.71%, Valid: 74.49%, Test: 72.03%\n",
            "Epoch: 115, Loss: 6856624.0000, Train: 86.71%, Valid: 74.25%, Test: 71.79%\n",
            "Epoch: 120, Loss: 6714683.5000, Train: 86.77%, Valid: 74.49%, Test: 71.55%\n",
            "Epoch: 125, Loss: 6576628.5000, Train: 86.77%, Valid: 74.13%, Test: 71.55%\n",
            "Epoch: 130, Loss: 6450269.0000, Train: 86.77%, Valid: 73.89%, Test: 71.91%\n",
            "Epoch: 135, Loss: 6327442.5000, Train: 86.77%, Valid: 73.53%, Test: 71.91%\n",
            "Epoch: 140, Loss: 6214711.5000, Train: 86.89%, Valid: 73.53%, Test: 72.15%\n",
            "Epoch: 145, Loss: 6108735.5000, Train: 86.95%, Valid: 73.53%, Test: 72.51%\n",
            "Epoch: 150, Loss: 6006675.0000, Train: 86.89%, Valid: 73.41%, Test: 72.51%\n",
            "Epoch: 155, Loss: 5911078.0000, Train: 87.07%, Valid: 73.41%, Test: 72.75%\n",
            "Epoch: 160, Loss: 5821865.0000, Train: 87.31%, Valid: 73.77%, Test: 73.11%\n",
            "Epoch: 165, Loss: 5740440.0000, Train: 87.19%, Valid: 73.89%, Test: 72.99%\n",
            "Epoch: 170, Loss: 5663807.5000, Train: 87.13%, Valid: 73.41%, Test: 72.75%\n",
            "Epoch: 175, Loss: 5592586.5000, Train: 87.13%, Valid: 73.29%, Test: 72.63%\n",
            "Epoch: 180, Loss: 5529005.5000, Train: 87.25%, Valid: 73.04%, Test: 72.51%\n",
            "Epoch: 185, Loss: 5472765.5000, Train: 87.25%, Valid: 73.04%, Test: 72.63%\n",
            "Epoch: 190, Loss: 5420729.5000, Train: 87.25%, Valid: 72.92%, Test: 72.63%\n",
            "Epoch: 195, Loss: 5368497.5000, Train: 87.25%, Valid: 72.80%, Test: 72.99%\n",
            "Run 05:\n",
            "Highest Train: 87.31\n",
            "Highest Valid: 74.49\n",
            "Highest Test: 73.11\n",
            "Chosen epoch: 77\n",
            "Final Train: 86.41\n",
            "Final Test: 71.31\n",
            "All runs:\n",
            "Highest Train: 83.34 ± 2.44\n",
            "Highest Test: 72.12 ± 0.73\n",
            "Highest Valid: 72.47 ± 1.46\n",
            "  Final Train: 82.90 ± 2.28\n",
            "   Final Test: 70.95 ± 0.56\n",
            "Saving results to logs/citeseer_edge.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Node Aware Setting\n"
      ],
      "metadata": {
        "id": "tiP6vNzqJ2fs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 GKD/main.py --dataset citeseer --rand_split --use_bn --base_model gcn --mode train --dist_mode no --save_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EduU9bP6J4vP",
        "outputId": "1550eac4-d553-45e8-8f74-df27477856d8"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(data_dir='data', dataset='citeseer', sub_dataset='', cpu=False, seed=42, train_prop=0.5, valid_prop=0.25, protocol='semi', rand_split=True, metric='acc', runs=5, epochs=200, hidden_channels=32, num_layers=3, gat_heads=8, out_heads=1, hops=1, lp_alpha=0.1, gpr_alpha=0.1, jk_type='max', directed=False, num_mlp_layers=1, display_step=5, cached=False, print_prop=False, priv_type='edge', priv_ratio=0.5, save_model=True, save_name='gcn', log_name='none', base_model='gcn', not_load_teacher=False, mode='train', dist_mode='no', weight_decay=0.05, dropout=0.0, lr=0.01, use_bn=True, use_batch=False, batch_size=2048, oracle=False, device=0, alpha=0.5, delta=0.1, use_kd=False, beta=0.0, tau=1.0, kernel='sigmoid', t=1.0, include_last=False, s=2, m=1, lr2=0.001, sim='l2', ker_norm=False)\n",
            "cuda:0\n",
            "citeseer\n",
            "Num nodes: 3327\n",
            "torch.Size([3327, 1])\n",
            "num nodes 3327 | num classes 6 | num node feats 3703\n",
            "MODEL: GeoDist(\n",
            "  (k): Kernel(\n",
            "    (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  )\n",
            "  (teacher_gnn): ModuleList(\n",
            "    (0): Linear(in_features=3703, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (student_gnn): ModuleList(\n",
            "    (0): Linear(in_features=3703, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  (bns2d): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            ")\n",
            "Epoch: 00, Loss: 2.2075, Train: 74.02%, Valid: 57.76%, Test: 58.58%\n",
            "Epoch: 05, Loss: 0.4033, Train: 91.46%, Valid: 69.68%, Test: 67.71%\n",
            "Epoch: 10, Loss: 0.3388, Train: 92.00%, Valid: 69.80%, Test: 69.15%\n",
            "Epoch: 15, Loss: 0.3107, Train: 92.66%, Valid: 70.28%, Test: 69.51%\n",
            "Epoch: 20, Loss: 0.2644, Train: 94.05%, Valid: 69.68%, Test: 67.83%\n",
            "Epoch: 25, Loss: 0.2083, Train: 95.13%, Valid: 67.87%, Test: 66.99%\n",
            "Epoch: 30, Loss: 0.1575, Train: 97.17%, Valid: 65.58%, Test: 67.11%\n",
            "Epoch: 35, Loss: 0.1585, Train: 96.27%, Valid: 62.94%, Test: 65.43%\n",
            "Epoch: 40, Loss: 0.1346, Train: 96.69%, Valid: 63.30%, Test: 63.15%\n",
            "Epoch: 45, Loss: 0.1320, Train: 96.87%, Valid: 61.49%, Test: 61.94%\n",
            "Epoch: 50, Loss: 0.1682, Train: 96.21%, Valid: 61.85%, Test: 62.91%\n",
            "Epoch: 55, Loss: 0.1322, Train: 97.29%, Valid: 58.84%, Test: 61.22%\n",
            "Epoch: 60, Loss: 0.1434, Train: 96.21%, Valid: 62.45%, Test: 61.94%\n",
            "Epoch: 65, Loss: 0.1432, Train: 96.81%, Valid: 63.90%, Test: 64.11%\n",
            "Epoch: 70, Loss: 0.1189, Train: 97.11%, Valid: 61.01%, Test: 60.86%\n",
            "Epoch: 75, Loss: 0.1271, Train: 97.17%, Valid: 59.69%, Test: 60.74%\n",
            "Epoch: 80, Loss: 0.1210, Train: 97.41%, Valid: 58.72%, Test: 59.42%\n",
            "Epoch: 85, Loss: 0.1316, Train: 96.15%, Valid: 60.65%, Test: 61.34%\n",
            "Epoch: 90, Loss: 0.1253, Train: 97.17%, Valid: 58.84%, Test: 61.34%\n",
            "Epoch: 95, Loss: 0.1111, Train: 97.23%, Valid: 57.52%, Test: 56.06%\n",
            "Epoch: 100, Loss: 0.1400, Train: 96.45%, Valid: 58.60%, Test: 60.50%\n",
            "Epoch: 105, Loss: 0.1257, Train: 97.71%, Valid: 60.29%, Test: 59.42%\n",
            "Epoch: 110, Loss: 0.1069, Train: 97.41%, Valid: 57.40%, Test: 57.86%\n",
            "Epoch: 115, Loss: 0.1639, Train: 95.79%, Valid: 61.97%, Test: 60.38%\n",
            "Epoch: 120, Loss: 0.1295, Train: 97.41%, Valid: 59.69%, Test: 60.14%\n",
            "Epoch: 125, Loss: 0.1128, Train: 97.90%, Valid: 57.88%, Test: 58.10%\n",
            "Epoch: 130, Loss: 0.1401, Train: 97.29%, Valid: 58.84%, Test: 58.46%\n",
            "Epoch: 135, Loss: 0.1204, Train: 97.59%, Valid: 57.16%, Test: 57.62%\n",
            "Epoch: 140, Loss: 0.1272, Train: 96.39%, Valid: 57.64%, Test: 59.66%\n",
            "Epoch: 145, Loss: 0.1256, Train: 97.59%, Valid: 59.09%, Test: 59.30%\n",
            "Epoch: 150, Loss: 0.1093, Train: 97.53%, Valid: 56.32%, Test: 57.98%\n",
            "Epoch: 155, Loss: 0.1457, Train: 97.05%, Valid: 58.00%, Test: 57.62%\n",
            "Epoch: 160, Loss: 0.1195, Train: 97.65%, Valid: 57.52%, Test: 58.22%\n",
            "Epoch: 165, Loss: 0.1072, Train: 97.47%, Valid: 58.72%, Test: 58.82%\n",
            "Epoch: 170, Loss: 0.1332, Train: 97.59%, Valid: 61.13%, Test: 59.30%\n",
            "Epoch: 175, Loss: 0.1136, Train: 97.65%, Valid: 54.27%, Test: 54.14%\n",
            "Epoch: 180, Loss: 0.1214, Train: 97.47%, Valid: 57.28%, Test: 57.50%\n",
            "Epoch: 185, Loss: 0.1141, Train: 97.65%, Valid: 58.72%, Test: 57.62%\n",
            "Epoch: 190, Loss: 0.1079, Train: 97.59%, Valid: 55.96%, Test: 54.86%\n",
            "Epoch: 195, Loss: 0.1386, Train: 97.47%, Valid: 59.45%, Test: 61.70%\n",
            "Run 01:\n",
            "Highest Train: 98.08\n",
            "Highest Valid: 70.40\n",
            "Highest Test: 69.75\n",
            "Chosen epoch: 20\n",
            "Final Train: 93.81\n",
            "Final Test: 68.67\n",
            "Epoch: 00, Loss: 2.2883, Train: 72.40%, Valid: 59.21%, Test: 57.14%\n",
            "Epoch: 05, Loss: 0.4173, Train: 91.64%, Valid: 71.72%, Test: 69.99%\n",
            "Epoch: 10, Loss: 0.3401, Train: 92.60%, Valid: 72.08%, Test: 69.75%\n",
            "Epoch: 15, Loss: 0.3020, Train: 93.21%, Valid: 71.12%, Test: 69.87%\n",
            "Epoch: 20, Loss: 0.2518, Train: 94.11%, Valid: 71.00%, Test: 69.75%\n",
            "Epoch: 25, Loss: 0.1992, Train: 95.85%, Valid: 70.16%, Test: 68.67%\n",
            "Epoch: 30, Loss: 0.1608, Train: 96.69%, Valid: 69.55%, Test: 66.75%\n",
            "Epoch: 35, Loss: 0.1559, Train: 96.51%, Valid: 65.70%, Test: 63.87%\n",
            "Epoch: 40, Loss: 0.1321, Train: 97.17%, Valid: 65.58%, Test: 64.35%\n",
            "Epoch: 45, Loss: 0.1412, Train: 96.27%, Valid: 63.78%, Test: 63.27%\n",
            "Epoch: 50, Loss: 0.1472, Train: 96.69%, Valid: 65.46%, Test: 63.87%\n",
            "Epoch: 55, Loss: 0.1263, Train: 97.35%, Valid: 62.33%, Test: 62.91%\n",
            "Epoch: 60, Loss: 0.1919, Train: 96.09%, Valid: 63.90%, Test: 62.91%\n",
            "Epoch: 65, Loss: 0.1460, Train: 96.99%, Valid: 65.94%, Test: 64.59%\n",
            "Epoch: 70, Loss: 0.1185, Train: 97.05%, Valid: 61.49%, Test: 60.98%\n",
            "Epoch: 75, Loss: 0.1361, Train: 96.39%, Valid: 62.70%, Test: 61.22%\n",
            "Epoch: 80, Loss: 0.1430, Train: 96.57%, Valid: 62.70%, Test: 62.42%\n",
            "Epoch: 85, Loss: 0.1191, Train: 97.35%, Valid: 61.37%, Test: 59.54%\n",
            "Epoch: 90, Loss: 0.1152, Train: 97.23%, Valid: 64.74%, Test: 63.39%\n",
            "Epoch: 95, Loss: 0.1522, Train: 96.63%, Valid: 63.42%, Test: 61.34%\n",
            "Epoch: 100, Loss: 0.1193, Train: 97.53%, Valid: 61.85%, Test: 59.90%\n",
            "Epoch: 105, Loss: 0.1097, Train: 97.47%, Valid: 61.13%, Test: 58.58%\n",
            "Epoch: 110, Loss: 0.1308, Train: 96.39%, Valid: 62.70%, Test: 61.46%\n",
            "Epoch: 115, Loss: 0.1274, Train: 96.87%, Valid: 62.21%, Test: 63.87%\n",
            "Epoch: 120, Loss: 0.1056, Train: 97.53%, Valid: 63.54%, Test: 60.26%\n",
            "Epoch: 125, Loss: 0.1216, Train: 97.41%, Valid: 61.49%, Test: 59.06%\n",
            "Epoch: 130, Loss: 0.1521, Train: 96.33%, Valid: 65.22%, Test: 63.87%\n",
            "Epoch: 135, Loss: 0.1167, Train: 97.35%, Valid: 63.78%, Test: 61.82%\n",
            "Epoch: 140, Loss: 0.1044, Train: 97.71%, Valid: 59.33%, Test: 59.18%\n",
            "Epoch: 145, Loss: 0.1521, Train: 95.85%, Valid: 62.21%, Test: 61.46%\n",
            "Epoch: 150, Loss: 0.1301, Train: 96.87%, Valid: 62.21%, Test: 62.06%\n",
            "Epoch: 155, Loss: 0.1095, Train: 97.47%, Valid: 57.52%, Test: 59.18%\n",
            "Epoch: 160, Loss: 0.1330, Train: 96.81%, Valid: 62.09%, Test: 61.22%\n",
            "Epoch: 165, Loss: 0.1295, Train: 97.53%, Valid: 61.85%, Test: 61.94%\n",
            "Epoch: 170, Loss: 0.1192, Train: 96.87%, Valid: 60.05%, Test: 58.22%\n",
            "Epoch: 175, Loss: 0.1278, Train: 96.87%, Valid: 60.89%, Test: 58.58%\n",
            "Epoch: 180, Loss: 0.1114, Train: 97.47%, Valid: 61.25%, Test: 59.78%\n",
            "Epoch: 185, Loss: 0.1107, Train: 97.53%, Valid: 58.72%, Test: 59.90%\n",
            "Epoch: 190, Loss: 0.1248, Train: 96.75%, Valid: 61.01%, Test: 59.06%\n",
            "Epoch: 195, Loss: 0.1153, Train: 97.23%, Valid: 63.42%, Test: 61.22%\n",
            "Run 02:\n",
            "Highest Train: 97.90\n",
            "Highest Valid: 72.68\n",
            "Highest Test: 70.59\n",
            "Chosen epoch: 13\n",
            "Final Train: 92.84\n",
            "Final Test: 69.63\n",
            "Epoch: 00, Loss: 2.2281, Train: 80.46%, Valid: 63.90%, Test: 62.18%\n",
            "Epoch: 05, Loss: 0.3848, Train: 92.30%, Valid: 69.80%, Test: 69.15%\n",
            "Epoch: 10, Loss: 0.3053, Train: 93.27%, Valid: 70.40%, Test: 69.15%\n",
            "Epoch: 15, Loss: 0.2720, Train: 93.81%, Valid: 69.19%, Test: 70.11%\n",
            "Epoch: 20, Loss: 0.2242, Train: 95.25%, Valid: 68.83%, Test: 68.67%\n",
            "Epoch: 25, Loss: 0.1798, Train: 96.87%, Valid: 68.23%, Test: 68.43%\n",
            "Epoch: 30, Loss: 0.1473, Train: 96.93%, Valid: 66.31%, Test: 67.71%\n",
            "Epoch: 35, Loss: 0.1444, Train: 96.39%, Valid: 64.50%, Test: 64.35%\n",
            "Epoch: 40, Loss: 0.1386, Train: 96.57%, Valid: 63.90%, Test: 61.46%\n",
            "Epoch: 45, Loss: 0.1366, Train: 97.23%, Valid: 62.09%, Test: 62.42%\n",
            "Epoch: 50, Loss: 0.1669, Train: 96.39%, Valid: 63.66%, Test: 63.51%\n",
            "Epoch: 55, Loss: 0.1387, Train: 97.05%, Valid: 61.13%, Test: 62.91%\n",
            "Epoch: 60, Loss: 0.1181, Train: 97.05%, Valid: 58.97%, Test: 59.42%\n",
            "Epoch: 65, Loss: 0.1330, Train: 96.69%, Valid: 63.06%, Test: 60.50%\n",
            "Epoch: 70, Loss: 0.1316, Train: 96.93%, Valid: 61.85%, Test: 62.42%\n",
            "Epoch: 75, Loss: 0.1156, Train: 97.41%, Valid: 60.41%, Test: 59.06%\n",
            "Epoch: 80, Loss: 0.1306, Train: 96.75%, Valid: 62.58%, Test: 61.94%\n",
            "Epoch: 85, Loss: 0.1210, Train: 96.93%, Valid: 59.69%, Test: 58.22%\n",
            "Epoch: 90, Loss: 0.1264, Train: 96.51%, Valid: 61.25%, Test: 60.26%\n",
            "Epoch: 95, Loss: 0.1190, Train: 97.35%, Valid: 61.25%, Test: 58.22%\n",
            "Epoch: 100, Loss: 0.1225, Train: 97.05%, Valid: 60.05%, Test: 57.14%\n",
            "Epoch: 105, Loss: 0.1231, Train: 97.11%, Valid: 59.81%, Test: 58.82%\n",
            "Epoch: 110, Loss: 0.1200, Train: 97.05%, Valid: 58.97%, Test: 59.90%\n",
            "Epoch: 115, Loss: 0.1275, Train: 97.17%, Valid: 59.69%, Test: 59.18%\n",
            "Epoch: 120, Loss: 0.1174, Train: 97.65%, Valid: 59.33%, Test: 60.38%\n",
            "Epoch: 125, Loss: 0.1211, Train: 96.81%, Valid: 61.73%, Test: 58.34%\n",
            "Epoch: 130, Loss: 0.1140, Train: 97.17%, Valid: 59.93%, Test: 60.26%\n",
            "Epoch: 135, Loss: 0.1070, Train: 97.35%, Valid: 57.88%, Test: 57.26%\n",
            "Epoch: 140, Loss: 0.1332, Train: 96.69%, Valid: 58.84%, Test: 60.62%\n",
            "Epoch: 145, Loss: 0.1107, Train: 97.53%, Valid: 56.08%, Test: 56.78%\n",
            "Epoch: 150, Loss: 0.1139, Train: 97.29%, Valid: 60.17%, Test: 57.98%\n",
            "Epoch: 155, Loss: 0.1379, Train: 96.75%, Valid: 59.93%, Test: 59.30%\n",
            "Epoch: 160, Loss: 0.1203, Train: 97.35%, Valid: 61.13%, Test: 61.10%\n",
            "Epoch: 165, Loss: 0.1140, Train: 97.35%, Valid: 57.40%, Test: 54.38%\n",
            "Epoch: 170, Loss: 0.1157, Train: 96.99%, Valid: 57.88%, Test: 56.90%\n",
            "Epoch: 175, Loss: 0.1242, Train: 97.35%, Valid: 58.97%, Test: 60.02%\n",
            "Epoch: 180, Loss: 0.1121, Train: 97.29%, Valid: 60.77%, Test: 59.66%\n",
            "Epoch: 185, Loss: 0.1174, Train: 96.93%, Valid: 59.57%, Test: 60.14%\n",
            "Epoch: 190, Loss: 0.1284, Train: 96.81%, Valid: 57.28%, Test: 55.94%\n",
            "Epoch: 195, Loss: 0.1143, Train: 97.53%, Valid: 57.76%, Test: 56.78%\n",
            "Run 03:\n",
            "Highest Train: 97.71\n",
            "Highest Valid: 70.52\n",
            "Highest Test: 70.11\n",
            "Chosen epoch: 7\n",
            "Final Train: 92.84\n",
            "Final Test: 69.03\n",
            "Epoch: 00, Loss: 2.3593, Train: 73.30%, Valid: 59.09%, Test: 56.06%\n",
            "Epoch: 05, Loss: 0.3836, Train: 92.30%, Valid: 71.00%, Test: 68.55%\n",
            "Epoch: 10, Loss: 0.3157, Train: 92.78%, Valid: 72.32%, Test: 68.79%\n",
            "Epoch: 15, Loss: 0.2942, Train: 93.45%, Valid: 71.96%, Test: 69.39%\n",
            "Epoch: 20, Loss: 0.2529, Train: 94.41%, Valid: 72.32%, Test: 68.55%\n",
            "Epoch: 25, Loss: 0.1999, Train: 96.09%, Valid: 69.55%, Test: 68.07%\n",
            "Epoch: 30, Loss: 0.1566, Train: 96.87%, Valid: 67.27%, Test: 64.95%\n",
            "Epoch: 35, Loss: 0.1447, Train: 96.21%, Valid: 66.43%, Test: 63.63%\n",
            "Epoch: 40, Loss: 0.1337, Train: 96.63%, Valid: 65.10%, Test: 63.03%\n",
            "Epoch: 45, Loss: 0.1453, Train: 96.09%, Valid: 63.42%, Test: 60.62%\n",
            "Epoch: 50, Loss: 0.1420, Train: 96.93%, Valid: 63.66%, Test: 62.79%\n",
            "Epoch: 55, Loss: 0.1323, Train: 97.35%, Valid: 61.01%, Test: 58.46%\n",
            "Epoch: 60, Loss: 0.1622, Train: 96.15%, Valid: 66.06%, Test: 62.67%\n",
            "Epoch: 65, Loss: 0.1271, Train: 97.11%, Valid: 62.09%, Test: 61.46%\n",
            "Epoch: 70, Loss: 0.1196, Train: 97.23%, Valid: 62.09%, Test: 60.86%\n",
            "Epoch: 75, Loss: 0.1733, Train: 96.09%, Valid: 62.82%, Test: 61.70%\n",
            "Epoch: 80, Loss: 0.1366, Train: 97.29%, Valid: 64.74%, Test: 61.46%\n",
            "Epoch: 85, Loss: 0.1191, Train: 97.23%, Valid: 60.29%, Test: 57.50%\n",
            "Epoch: 90, Loss: 0.1345, Train: 96.99%, Valid: 61.25%, Test: 59.30%\n",
            "Epoch: 95, Loss: 0.1460, Train: 96.81%, Valid: 64.62%, Test: 60.14%\n",
            "Epoch: 100, Loss: 0.1169, Train: 97.71%, Valid: 61.25%, Test: 57.74%\n",
            "Epoch: 105, Loss: 0.1357, Train: 96.09%, Valid: 62.70%, Test: 60.26%\n",
            "Epoch: 110, Loss: 0.1456, Train: 96.99%, Valid: 63.78%, Test: 60.02%\n",
            "Epoch: 115, Loss: 0.1225, Train: 97.29%, Valid: 63.30%, Test: 60.98%\n",
            "Epoch: 120, Loss: 0.1177, Train: 97.11%, Valid: 59.81%, Test: 57.62%\n",
            "Epoch: 125, Loss: 0.1443, Train: 96.69%, Valid: 61.61%, Test: 57.98%\n",
            "Epoch: 130, Loss: 0.1236, Train: 97.17%, Valid: 58.72%, Test: 59.54%\n",
            "Epoch: 135, Loss: 0.1180, Train: 97.71%, Valid: 59.21%, Test: 58.94%\n",
            "Epoch: 140, Loss: 0.1600, Train: 96.15%, Valid: 61.61%, Test: 58.10%\n",
            "Epoch: 145, Loss: 0.1362, Train: 97.11%, Valid: 63.66%, Test: 63.39%\n",
            "Epoch: 150, Loss: 0.1083, Train: 97.23%, Valid: 58.72%, Test: 58.94%\n",
            "Epoch: 155, Loss: 0.1204, Train: 96.69%, Valid: 57.76%, Test: 57.98%\n",
            "Epoch: 160, Loss: 0.1317, Train: 97.05%, Valid: 60.53%, Test: 57.86%\n",
            "Epoch: 165, Loss: 0.1148, Train: 97.17%, Valid: 59.45%, Test: 56.18%\n",
            "Epoch: 170, Loss: 0.1221, Train: 97.23%, Valid: 58.60%, Test: 57.98%\n",
            "Epoch: 175, Loss: 0.1197, Train: 97.35%, Valid: 60.17%, Test: 56.90%\n",
            "Epoch: 180, Loss: 0.1318, Train: 97.11%, Valid: 60.41%, Test: 59.54%\n",
            "Epoch: 185, Loss: 0.1181, Train: 97.11%, Valid: 59.33%, Test: 57.02%\n",
            "Epoch: 190, Loss: 0.1095, Train: 96.81%, Valid: 58.84%, Test: 56.06%\n",
            "Epoch: 195, Loss: 0.1282, Train: 96.63%, Valid: 60.05%, Test: 56.42%\n",
            "Run 04:\n",
            "Highest Train: 97.84\n",
            "Highest Valid: 72.80\n",
            "Highest Test: 69.75\n",
            "Chosen epoch: 13\n",
            "Final Train: 92.90\n",
            "Final Test: 69.03\n",
            "Epoch: 00, Loss: 2.4119, Train: 71.92%, Valid: 60.77%, Test: 58.34%\n",
            "Epoch: 05, Loss: 0.4267, Train: 90.26%, Valid: 70.76%, Test: 67.71%\n",
            "Epoch: 10, Loss: 0.3542, Train: 91.22%, Valid: 72.32%, Test: 68.91%\n",
            "Epoch: 15, Loss: 0.3246, Train: 92.42%, Valid: 73.04%, Test: 69.75%\n",
            "Epoch: 20, Loss: 0.2775, Train: 93.33%, Valid: 72.68%, Test: 70.71%\n",
            "Epoch: 25, Loss: 0.2214, Train: 94.41%, Valid: 71.60%, Test: 68.31%\n",
            "Epoch: 30, Loss: 0.1774, Train: 95.67%, Valid: 68.71%, Test: 66.03%\n",
            "Epoch: 35, Loss: 0.1663, Train: 95.37%, Valid: 69.31%, Test: 64.47%\n",
            "Epoch: 40, Loss: 0.1471, Train: 95.67%, Valid: 65.58%, Test: 64.47%\n",
            "Epoch: 45, Loss: 0.1350, Train: 96.33%, Valid: 64.50%, Test: 59.54%\n",
            "Epoch: 50, Loss: 0.1813, Train: 95.55%, Valid: 66.79%, Test: 65.55%\n",
            "Epoch: 55, Loss: 0.1485, Train: 96.87%, Valid: 64.38%, Test: 62.79%\n",
            "Epoch: 60, Loss: 0.1368, Train: 96.63%, Valid: 62.09%, Test: 58.82%\n",
            "Epoch: 65, Loss: 0.1581, Train: 96.15%, Valid: 65.46%, Test: 63.75%\n",
            "Epoch: 70, Loss: 0.1301, Train: 97.17%, Valid: 61.13%, Test: 58.94%\n",
            "Epoch: 75, Loss: 0.1399, Train: 96.45%, Valid: 62.45%, Test: 59.18%\n",
            "Epoch: 80, Loss: 0.1431, Train: 96.81%, Valid: 64.50%, Test: 62.06%\n",
            "Epoch: 85, Loss: 0.1288, Train: 96.99%, Valid: 61.49%, Test: 59.18%\n",
            "Epoch: 90, Loss: 0.1368, Train: 96.51%, Valid: 61.01%, Test: 58.82%\n",
            "Epoch: 95, Loss: 0.1306, Train: 96.57%, Valid: 61.73%, Test: 59.90%\n",
            "Epoch: 100, Loss: 0.1599, Train: 96.33%, Valid: 61.61%, Test: 60.74%\n",
            "Epoch: 105, Loss: 0.1297, Train: 97.23%, Valid: 63.30%, Test: 59.90%\n",
            "Epoch: 110, Loss: 0.1296, Train: 96.69%, Valid: 62.33%, Test: 57.50%\n",
            "Epoch: 115, Loss: 0.1307, Train: 95.79%, Valid: 58.97%, Test: 58.34%\n",
            "Epoch: 120, Loss: 0.1427, Train: 97.17%, Valid: 63.30%, Test: 61.46%\n",
            "Epoch: 125, Loss: 0.1199, Train: 97.11%, Valid: 58.12%, Test: 56.42%\n",
            "Epoch: 130, Loss: 0.1304, Train: 96.69%, Valid: 61.97%, Test: 58.22%\n",
            "Epoch: 135, Loss: 0.1458, Train: 96.27%, Valid: 63.30%, Test: 59.78%\n",
            "Epoch: 140, Loss: 0.1290, Train: 97.35%, Valid: 60.29%, Test: 60.50%\n",
            "Epoch: 145, Loss: 0.1293, Train: 97.23%, Valid: 60.17%, Test: 58.46%\n",
            "Epoch: 150, Loss: 0.1331, Train: 97.11%, Valid: 61.01%, Test: 58.22%\n",
            "Epoch: 155, Loss: 0.1497, Train: 96.45%, Valid: 62.58%, Test: 60.74%\n",
            "Epoch: 160, Loss: 0.1234, Train: 97.35%, Valid: 60.53%, Test: 55.46%\n",
            "Epoch: 165, Loss: 0.1240, Train: 96.93%, Valid: 62.09%, Test: 57.02%\n",
            "Epoch: 170, Loss: 0.1604, Train: 96.27%, Valid: 61.01%, Test: 59.78%\n",
            "Epoch: 175, Loss: 0.1260, Train: 97.71%, Valid: 60.29%, Test: 57.38%\n",
            "Epoch: 180, Loss: 0.1210, Train: 97.41%, Valid: 59.81%, Test: 55.34%\n",
            "Epoch: 185, Loss: 0.1235, Train: 96.21%, Valid: 57.64%, Test: 55.82%\n",
            "Epoch: 190, Loss: 0.1445, Train: 96.81%, Valid: 62.70%, Test: 63.03%\n",
            "Epoch: 195, Loss: 0.1172, Train: 97.53%, Valid: 58.97%, Test: 56.78%\n",
            "Run 05:\n",
            "Highest Train: 97.71\n",
            "Highest Valid: 73.29\n",
            "Highest Test: 70.83\n",
            "Chosen epoch: 18\n",
            "Final Train: 92.54\n",
            "Final Test: 70.35\n",
            "All runs:\n",
            "Highest Train: 97.85 ± 0.15\n",
            "Highest Test: 70.20 ± 0.49\n",
            "Highest Valid: 71.94 ± 1.37\n",
            "  Final Train: 92.99 ± 0.48\n",
            "   Final Test: 69.34 ± 0.66\n",
            "Saving results to logs/citeseer_edge.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 GKD/main.py --dataset citeseer --rand_split --use_bn --base_model gcn --mode train  --dist_mode gkd --kernel sigmoid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2TZXGHnJ7Ww",
        "outputId": "ed555992-a474-43bc-b475-8614f3854ad7"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(data_dir='data', dataset='citeseer', sub_dataset='', cpu=False, seed=42, train_prop=0.5, valid_prop=0.25, protocol='semi', rand_split=True, metric='acc', runs=5, epochs=200, hidden_channels=32, num_layers=3, gat_heads=8, out_heads=1, hops=1, lp_alpha=0.1, gpr_alpha=0.1, jk_type='max', directed=False, num_mlp_layers=1, display_step=5, cached=False, print_prop=False, priv_type='edge', priv_ratio=0.5, save_model=False, save_name='gcn', log_name='none', base_model='gcn', not_load_teacher=False, mode='train', dist_mode='gkd', weight_decay=0.05, dropout=0.0, lr=0.01, use_bn=True, use_batch=False, batch_size=2048, oracle=False, device=0, alpha=0.5, delta=0.1, use_kd=False, beta=0.0, tau=1.0, kernel='sigmoid', t=1.0, include_last=False, s=2, m=1, lr2=0.001, sim='l2', ker_norm=False)\n",
            "cuda:0\n",
            "citeseer\n",
            "Num nodes: 3327\n",
            "torch.Size([3327, 1])\n",
            "num nodes 3327 | num classes 6 | num node feats 3703\n",
            "MODEL: GeoDist(\n",
            "  (k): Kernel(\n",
            "    (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  )\n",
            "  (teacher_gnn): ModuleList(\n",
            "    (0): Linear(in_features=3703, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (student_gnn): ModuleList(\n",
            "    (0): Linear(in_features=3703, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  (bns2d): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            ")\n",
            "Epoch: 00, Loss: 918465.7500, Train: 14.07%, Valid: 14.92%, Test: 17.89%\n",
            "Epoch: 05, Loss: 192346.2500, Train: 25.98%, Valid: 24.55%, Test: 24.85%\n",
            "Epoch: 10, Loss: 150587.6719, Train: 43.42%, Valid: 38.99%, Test: 40.10%\n",
            "Epoch: 15, Loss: 129515.6016, Train: 58.75%, Valid: 51.02%, Test: 52.10%\n",
            "Epoch: 20, Loss: 115140.5391, Train: 73.18%, Valid: 63.66%, Test: 62.55%\n",
            "Epoch: 25, Loss: 104605.9609, Train: 80.10%, Valid: 70.28%, Test: 69.15%\n",
            "Epoch: 30, Loss: 96229.7969, Train: 81.36%, Valid: 70.76%, Test: 70.23%\n",
            "Epoch: 35, Loss: 89171.5078, Train: 82.38%, Valid: 71.84%, Test: 71.55%\n",
            "Epoch: 40, Loss: 83274.9688, Train: 82.38%, Valid: 72.20%, Test: 72.15%\n",
            "Epoch: 45, Loss: 78249.5547, Train: 82.56%, Valid: 72.44%, Test: 72.51%\n",
            "Epoch: 50, Loss: 73839.0000, Train: 82.74%, Valid: 72.32%, Test: 72.51%\n",
            "Epoch: 55, Loss: 69927.6094, Train: 82.86%, Valid: 72.80%, Test: 72.87%\n",
            "Epoch: 60, Loss: 66394.8516, Train: 82.86%, Valid: 73.29%, Test: 72.39%\n",
            "Epoch: 65, Loss: 63214.9180, Train: 82.98%, Valid: 73.29%, Test: 72.51%\n",
            "Epoch: 70, Loss: 60377.9180, Train: 83.28%, Valid: 73.16%, Test: 72.51%\n",
            "Epoch: 75, Loss: 57769.5664, Train: 83.46%, Valid: 73.53%, Test: 72.87%\n",
            "Epoch: 80, Loss: 55337.6133, Train: 83.52%, Valid: 73.77%, Test: 73.11%\n",
            "Epoch: 85, Loss: 53117.1875, Train: 83.64%, Valid: 73.89%, Test: 73.11%\n",
            "Epoch: 90, Loss: 51170.4648, Train: 83.52%, Valid: 73.77%, Test: 72.99%\n",
            "Epoch: 95, Loss: 49269.4023, Train: 83.76%, Valid: 73.53%, Test: 72.75%\n",
            "Epoch: 100, Loss: 47393.0508, Train: 83.70%, Valid: 73.29%, Test: 72.63%\n",
            "Epoch: 105, Loss: 45623.3828, Train: 83.82%, Valid: 73.41%, Test: 72.87%\n",
            "Epoch: 110, Loss: 44123.7773, Train: 83.88%, Valid: 73.16%, Test: 72.99%\n",
            "Epoch: 115, Loss: 42667.7422, Train: 83.88%, Valid: 73.04%, Test: 72.75%\n",
            "Epoch: 120, Loss: 41248.4375, Train: 83.94%, Valid: 72.92%, Test: 72.63%\n",
            "Epoch: 125, Loss: 39946.9922, Train: 84.00%, Valid: 73.29%, Test: 72.75%\n",
            "Epoch: 130, Loss: 38709.6953, Train: 84.06%, Valid: 72.92%, Test: 72.87%\n",
            "Epoch: 135, Loss: 37601.6406, Train: 84.13%, Valid: 73.04%, Test: 72.75%\n",
            "Epoch: 140, Loss: 36556.8203, Train: 84.25%, Valid: 73.29%, Test: 72.99%\n",
            "Epoch: 145, Loss: 35573.5781, Train: 84.19%, Valid: 72.92%, Test: 73.11%\n",
            "Epoch: 150, Loss: 35027.3242, Train: 84.00%, Valid: 72.80%, Test: 73.23%\n",
            "Epoch: 155, Loss: 34005.6289, Train: 84.13%, Valid: 72.80%, Test: 73.11%\n",
            "Epoch: 160, Loss: 33286.1016, Train: 84.19%, Valid: 72.68%, Test: 73.11%\n",
            "Epoch: 165, Loss: 32581.0469, Train: 84.13%, Valid: 72.56%, Test: 73.11%\n",
            "Epoch: 170, Loss: 32012.0059, Train: 84.00%, Valid: 72.44%, Test: 73.23%\n",
            "Epoch: 175, Loss: 31142.3984, Train: 84.00%, Valid: 72.56%, Test: 73.11%\n",
            "Epoch: 180, Loss: 30465.8926, Train: 83.94%, Valid: 72.56%, Test: 72.87%\n",
            "Epoch: 185, Loss: 29875.9980, Train: 83.94%, Valid: 72.56%, Test: 72.99%\n",
            "Epoch: 190, Loss: 29626.5332, Train: 84.06%, Valid: 72.68%, Test: 72.75%\n",
            "Epoch: 195, Loss: 28840.8418, Train: 84.06%, Valid: 72.68%, Test: 72.87%\n",
            "Run 01:\n",
            "Highest Train: 84.25\n",
            "Highest Valid: 74.01\n",
            "Highest Test: 73.23\n",
            "Chosen epoch: 88\n",
            "Final Train: 83.58\n",
            "Final Test: 73.23\n",
            "Epoch: 00, Loss: 912336.3125, Train: 11.85%, Valid: 13.12%, Test: 13.93%\n",
            "Epoch: 05, Loss: 217768.6094, Train: 31.99%, Valid: 28.88%, Test: 31.81%\n",
            "Epoch: 10, Loss: 166158.5156, Train: 46.18%, Valid: 41.16%, Test: 45.50%\n",
            "Epoch: 15, Loss: 142163.2500, Train: 62.00%, Valid: 52.83%, Test: 57.26%\n",
            "Epoch: 20, Loss: 125413.7266, Train: 72.10%, Valid: 63.42%, Test: 64.95%\n",
            "Epoch: 25, Loss: 113063.6406, Train: 79.92%, Valid: 71.00%, Test: 71.55%\n",
            "Epoch: 30, Loss: 103589.8125, Train: 82.08%, Valid: 71.48%, Test: 72.27%\n",
            "Epoch: 35, Loss: 95780.2266, Train: 83.04%, Valid: 71.48%, Test: 72.99%\n",
            "Epoch: 40, Loss: 89332.3203, Train: 83.70%, Valid: 71.84%, Test: 73.47%\n",
            "Epoch: 45, Loss: 83824.5781, Train: 84.55%, Valid: 72.20%, Test: 73.23%\n",
            "Epoch: 50, Loss: 79165.3203, Train: 84.91%, Valid: 73.16%, Test: 73.35%\n",
            "Epoch: 55, Loss: 75137.4609, Train: 85.63%, Valid: 73.41%, Test: 73.59%\n",
            "Epoch: 60, Loss: 71583.1641, Train: 85.93%, Valid: 73.29%, Test: 73.71%\n",
            "Epoch: 65, Loss: 68416.4297, Train: 86.53%, Valid: 73.65%, Test: 74.43%\n",
            "Epoch: 70, Loss: 65548.1641, Train: 86.65%, Valid: 73.29%, Test: 73.83%\n",
            "Epoch: 75, Loss: 62932.5781, Train: 86.71%, Valid: 73.41%, Test: 73.83%\n",
            "Epoch: 80, Loss: 60529.3359, Train: 86.77%, Valid: 73.04%, Test: 74.07%\n",
            "Epoch: 85, Loss: 58305.8672, Train: 86.65%, Valid: 73.41%, Test: 74.31%\n",
            "Epoch: 90, Loss: 56247.2188, Train: 86.77%, Valid: 72.92%, Test: 74.07%\n",
            "Epoch: 95, Loss: 54328.6875, Train: 86.83%, Valid: 73.04%, Test: 74.19%\n",
            "Epoch: 100, Loss: 52547.6719, Train: 86.77%, Valid: 73.16%, Test: 74.07%\n",
            "Epoch: 105, Loss: 50875.5156, Train: 86.77%, Valid: 73.29%, Test: 74.07%\n",
            "Epoch: 110, Loss: 49309.0117, Train: 86.71%, Valid: 73.29%, Test: 74.55%\n",
            "Epoch: 115, Loss: 47856.8203, Train: 86.77%, Valid: 73.29%, Test: 74.55%\n",
            "Epoch: 120, Loss: 46492.8438, Train: 86.77%, Valid: 73.29%, Test: 74.67%\n",
            "Epoch: 125, Loss: 45201.7031, Train: 86.65%, Valid: 73.53%, Test: 74.91%\n",
            "Epoch: 130, Loss: 43978.8359, Train: 86.65%, Valid: 73.65%, Test: 74.79%\n",
            "Epoch: 135, Loss: 42816.0273, Train: 86.77%, Valid: 73.65%, Test: 74.91%\n",
            "Epoch: 140, Loss: 41713.6094, Train: 86.77%, Valid: 73.41%, Test: 74.79%\n",
            "Epoch: 145, Loss: 40673.9453, Train: 86.77%, Valid: 73.41%, Test: 74.91%\n",
            "Epoch: 150, Loss: 39694.1641, Train: 86.71%, Valid: 73.16%, Test: 74.91%\n",
            "Epoch: 155, Loss: 38809.2148, Train: 86.65%, Valid: 73.16%, Test: 74.91%\n",
            "Epoch: 160, Loss: 38041.7539, Train: 86.71%, Valid: 73.16%, Test: 74.79%\n",
            "Epoch: 165, Loss: 37158.3125, Train: 86.71%, Valid: 73.16%, Test: 74.67%\n",
            "Epoch: 170, Loss: 36482.7812, Train: 86.83%, Valid: 73.29%, Test: 74.67%\n",
            "Epoch: 175, Loss: 35729.0469, Train: 86.83%, Valid: 73.29%, Test: 74.79%\n",
            "Epoch: 180, Loss: 34970.1211, Train: 86.83%, Valid: 73.29%, Test: 74.79%\n",
            "Epoch: 185, Loss: 34276.9062, Train: 86.83%, Valid: 73.41%, Test: 74.79%\n",
            "Epoch: 190, Loss: 33655.0977, Train: 86.71%, Valid: 73.16%, Test: 74.79%\n",
            "Epoch: 195, Loss: 33253.4844, Train: 86.71%, Valid: 73.16%, Test: 74.79%\n",
            "Run 02:\n",
            "Highest Train: 86.89\n",
            "Highest Valid: 73.65\n",
            "Highest Test: 75.03\n",
            "Chosen epoch: 65\n",
            "Final Train: 86.23\n",
            "Final Test: 74.43\n",
            "Epoch: 00, Loss: 913669.8750, Train: 18.64%, Valid: 19.13%, Test: 18.25%\n",
            "Epoch: 05, Loss: 221028.2031, Train: 27.66%, Valid: 27.68%, Test: 24.61%\n",
            "Epoch: 10, Loss: 171788.2344, Train: 54.90%, Valid: 47.41%, Test: 48.38%\n",
            "Epoch: 15, Loss: 146493.2500, Train: 62.00%, Valid: 53.67%, Test: 54.62%\n",
            "Epoch: 20, Loss: 130246.0547, Train: 73.90%, Valid: 66.19%, Test: 66.15%\n",
            "Epoch: 25, Loss: 118031.3438, Train: 78.59%, Valid: 69.68%, Test: 70.11%\n",
            "Epoch: 30, Loss: 108068.4609, Train: 79.68%, Valid: 70.76%, Test: 71.31%\n",
            "Epoch: 35, Loss: 99642.1172, Train: 80.28%, Valid: 71.12%, Test: 70.83%\n",
            "Epoch: 40, Loss: 92393.7812, Train: 80.34%, Valid: 71.24%, Test: 70.47%\n",
            "Epoch: 45, Loss: 85987.9375, Train: 80.58%, Valid: 71.60%, Test: 70.59%\n",
            "Epoch: 50, Loss: 80231.9688, Train: 81.00%, Valid: 71.72%, Test: 70.71%\n",
            "Epoch: 55, Loss: 75231.4844, Train: 81.00%, Valid: 71.96%, Test: 70.95%\n",
            "Epoch: 60, Loss: 70769.8047, Train: 81.24%, Valid: 71.84%, Test: 70.95%\n",
            "Epoch: 65, Loss: 66745.7422, Train: 81.24%, Valid: 71.84%, Test: 71.31%\n",
            "Epoch: 70, Loss: 63121.2617, Train: 81.30%, Valid: 71.96%, Test: 71.43%\n",
            "Epoch: 75, Loss: 59912.0430, Train: 81.54%, Valid: 71.72%, Test: 71.91%\n",
            "Epoch: 80, Loss: 57044.7500, Train: 81.60%, Valid: 71.36%, Test: 72.27%\n",
            "Epoch: 85, Loss: 54450.6836, Train: 81.72%, Valid: 71.24%, Test: 72.15%\n",
            "Epoch: 90, Loss: 52087.5273, Train: 81.84%, Valid: 71.48%, Test: 72.27%\n",
            "Epoch: 95, Loss: 49943.9492, Train: 81.60%, Valid: 71.60%, Test: 71.91%\n",
            "Epoch: 100, Loss: 47998.9766, Train: 81.72%, Valid: 71.48%, Test: 71.67%\n",
            "Epoch: 105, Loss: 46214.7188, Train: 81.54%, Valid: 71.48%, Test: 72.03%\n",
            "Epoch: 110, Loss: 44587.4336, Train: 81.54%, Valid: 71.84%, Test: 72.03%\n",
            "Epoch: 115, Loss: 43089.7422, Train: 81.66%, Valid: 71.96%, Test: 72.03%\n",
            "Epoch: 120, Loss: 41728.0273, Train: 81.84%, Valid: 72.08%, Test: 72.51%\n",
            "Epoch: 125, Loss: 40465.2852, Train: 81.90%, Valid: 72.32%, Test: 72.63%\n",
            "Epoch: 130, Loss: 39465.1602, Train: 81.90%, Valid: 72.44%, Test: 72.51%\n",
            "Epoch: 135, Loss: 38201.5078, Train: 82.08%, Valid: 72.68%, Test: 72.75%\n",
            "Epoch: 140, Loss: 37273.2148, Train: 82.14%, Valid: 72.56%, Test: 72.51%\n",
            "Epoch: 145, Loss: 36265.8086, Train: 82.20%, Valid: 72.44%, Test: 72.51%\n",
            "Epoch: 150, Loss: 35417.2227, Train: 82.14%, Valid: 72.44%, Test: 72.51%\n",
            "Epoch: 155, Loss: 34606.3633, Train: 82.02%, Valid: 71.96%, Test: 72.39%\n",
            "Epoch: 160, Loss: 33855.5859, Train: 82.20%, Valid: 71.84%, Test: 72.27%\n",
            "Epoch: 165, Loss: 33411.0547, Train: 82.38%, Valid: 71.84%, Test: 71.91%\n",
            "Epoch: 170, Loss: 32634.8242, Train: 82.32%, Valid: 71.96%, Test: 72.15%\n",
            "Epoch: 175, Loss: 31957.1758, Train: 82.32%, Valid: 71.96%, Test: 72.27%\n",
            "Epoch: 180, Loss: 31327.3945, Train: 82.32%, Valid: 71.96%, Test: 72.39%\n",
            "Epoch: 185, Loss: 30758.5371, Train: 82.38%, Valid: 71.96%, Test: 72.51%\n",
            "Epoch: 190, Loss: 30338.1621, Train: 82.50%, Valid: 71.84%, Test: 72.39%\n",
            "Epoch: 195, Loss: 29813.2441, Train: 82.74%, Valid: 71.84%, Test: 72.39%\n",
            "Run 03:\n",
            "Highest Train: 82.80\n",
            "Highest Valid: 72.68\n",
            "Highest Test: 72.75\n",
            "Chosen epoch: 136\n",
            "Final Train: 82.08\n",
            "Final Test: 72.75\n",
            "Epoch: 00, Loss: 925642.4375, Train: 10.40%, Valid: 10.35%, Test: 11.40%\n",
            "Epoch: 05, Loss: 196733.6250, Train: 31.81%, Valid: 31.65%, Test: 30.37%\n",
            "Epoch: 10, Loss: 156195.6562, Train: 41.25%, Valid: 39.47%, Test: 38.18%\n",
            "Epoch: 15, Loss: 135959.8750, Train: 53.22%, Valid: 49.10%, Test: 48.02%\n",
            "Epoch: 20, Loss: 122006.3359, Train: 65.66%, Valid: 60.53%, Test: 58.58%\n",
            "Epoch: 25, Loss: 111750.1484, Train: 72.04%, Valid: 66.06%, Test: 65.19%\n",
            "Epoch: 30, Loss: 103344.2969, Train: 78.11%, Valid: 69.19%, Test: 69.39%\n",
            "Epoch: 35, Loss: 96205.2266, Train: 80.40%, Valid: 71.72%, Test: 71.67%\n",
            "Epoch: 40, Loss: 90044.5156, Train: 81.42%, Valid: 71.72%, Test: 72.75%\n",
            "Epoch: 45, Loss: 84602.2109, Train: 82.02%, Valid: 71.60%, Test: 72.39%\n",
            "Epoch: 50, Loss: 79720.5625, Train: 82.08%, Valid: 71.84%, Test: 72.39%\n",
            "Epoch: 55, Loss: 75382.2812, Train: 82.32%, Valid: 72.08%, Test: 72.15%\n",
            "Epoch: 60, Loss: 71452.8203, Train: 82.26%, Valid: 71.96%, Test: 72.51%\n",
            "Epoch: 65, Loss: 67860.4688, Train: 82.56%, Valid: 71.96%, Test: 72.87%\n",
            "Epoch: 70, Loss: 64547.2422, Train: 82.92%, Valid: 71.96%, Test: 72.75%\n",
            "Epoch: 75, Loss: 61536.2969, Train: 83.04%, Valid: 72.20%, Test: 73.11%\n",
            "Epoch: 80, Loss: 58811.6211, Train: 83.46%, Valid: 72.08%, Test: 73.23%\n",
            "Epoch: 85, Loss: 56362.7305, Train: 83.58%, Valid: 71.84%, Test: 73.59%\n",
            "Epoch: 90, Loss: 54131.2617, Train: 83.82%, Valid: 72.32%, Test: 73.47%\n",
            "Epoch: 95, Loss: 52097.6797, Train: 83.88%, Valid: 72.44%, Test: 73.35%\n",
            "Epoch: 100, Loss: 50229.5977, Train: 83.88%, Valid: 72.56%, Test: 73.23%\n",
            "Epoch: 105, Loss: 48509.9258, Train: 84.19%, Valid: 72.56%, Test: 73.11%\n",
            "Epoch: 110, Loss: 46935.1211, Train: 84.06%, Valid: 72.44%, Test: 72.87%\n",
            "Epoch: 115, Loss: 45483.9961, Train: 84.25%, Valid: 72.56%, Test: 72.99%\n",
            "Epoch: 120, Loss: 44138.2734, Train: 84.43%, Valid: 72.56%, Test: 72.75%\n",
            "Epoch: 125, Loss: 42891.9297, Train: 84.43%, Valid: 72.56%, Test: 72.63%\n",
            "Epoch: 130, Loss: 41738.5234, Train: 84.43%, Valid: 72.56%, Test: 72.15%\n",
            "Epoch: 135, Loss: 40667.8125, Train: 84.37%, Valid: 72.56%, Test: 72.03%\n",
            "Epoch: 140, Loss: 39874.7031, Train: 84.61%, Valid: 72.68%, Test: 71.91%\n",
            "Epoch: 145, Loss: 39072.8125, Train: 84.61%, Valid: 72.68%, Test: 71.91%\n",
            "Epoch: 150, Loss: 38133.2969, Train: 84.55%, Valid: 72.68%, Test: 71.91%\n",
            "Epoch: 155, Loss: 37199.5508, Train: 84.73%, Valid: 72.80%, Test: 72.15%\n",
            "Epoch: 160, Loss: 36486.0234, Train: 84.79%, Valid: 72.68%, Test: 72.03%\n",
            "Epoch: 165, Loss: 35897.3008, Train: 84.91%, Valid: 72.56%, Test: 71.91%\n",
            "Epoch: 170, Loss: 35182.6758, Train: 84.79%, Valid: 72.80%, Test: 71.79%\n",
            "Epoch: 175, Loss: 34508.3008, Train: 84.91%, Valid: 72.68%, Test: 72.03%\n",
            "Epoch: 180, Loss: 33960.2812, Train: 85.03%, Valid: 72.56%, Test: 72.27%\n",
            "Epoch: 185, Loss: 33489.2266, Train: 85.15%, Valid: 72.56%, Test: 72.27%\n",
            "Epoch: 190, Loss: 33114.7578, Train: 85.03%, Valid: 72.56%, Test: 72.15%\n",
            "Epoch: 195, Loss: 32460.5234, Train: 85.09%, Valid: 72.68%, Test: 72.03%\n",
            "Run 04:\n",
            "Highest Train: 85.15\n",
            "Highest Valid: 72.80\n",
            "Highest Test: 73.59\n",
            "Chosen epoch: 154\n",
            "Final Train: 84.79\n",
            "Final Test: 72.15\n",
            "Epoch: 00, Loss: 910929.8750, Train: 18.64%, Valid: 20.94%, Test: 20.77%\n",
            "Epoch: 05, Loss: 208556.9375, Train: 35.54%, Valid: 29.96%, Test: 33.73%\n",
            "Epoch: 10, Loss: 164174.3281, Train: 47.50%, Valid: 42.84%, Test: 42.50%\n",
            "Epoch: 15, Loss: 142287.7656, Train: 64.64%, Valid: 56.08%, Test: 57.86%\n",
            "Epoch: 20, Loss: 127461.6797, Train: 71.62%, Valid: 63.42%, Test: 63.87%\n",
            "Epoch: 25, Loss: 115889.9297, Train: 78.89%, Valid: 70.04%, Test: 68.67%\n",
            "Epoch: 30, Loss: 106529.0625, Train: 82.68%, Valid: 71.96%, Test: 70.71%\n",
            "Epoch: 35, Loss: 98777.6094, Train: 84.37%, Valid: 73.53%, Test: 71.19%\n",
            "Epoch: 40, Loss: 92226.5938, Train: 85.45%, Valid: 73.89%, Test: 72.27%\n",
            "Epoch: 45, Loss: 86556.8828, Train: 85.99%, Valid: 74.13%, Test: 72.75%\n",
            "Epoch: 50, Loss: 81630.6562, Train: 86.11%, Valid: 74.01%, Test: 73.11%\n",
            "Epoch: 55, Loss: 77228.0781, Train: 86.71%, Valid: 74.01%, Test: 73.11%\n",
            "Epoch: 60, Loss: 73238.2969, Train: 86.83%, Valid: 74.25%, Test: 72.99%\n",
            "Epoch: 65, Loss: 69639.2656, Train: 86.89%, Valid: 74.13%, Test: 73.23%\n",
            "Epoch: 70, Loss: 66355.9922, Train: 87.13%, Valid: 74.13%, Test: 72.99%\n",
            "Epoch: 75, Loss: 63410.0625, Train: 87.55%, Valid: 74.13%, Test: 72.99%\n",
            "Epoch: 80, Loss: 60741.7344, Train: 87.55%, Valid: 74.13%, Test: 73.23%\n",
            "Epoch: 85, Loss: 58285.6953, Train: 87.49%, Valid: 74.01%, Test: 73.11%\n",
            "Epoch: 90, Loss: 56007.1992, Train: 87.67%, Valid: 73.77%, Test: 72.99%\n",
            "Epoch: 95, Loss: 53880.0234, Train: 87.85%, Valid: 73.53%, Test: 73.11%\n",
            "Epoch: 100, Loss: 51887.6562, Train: 88.03%, Valid: 73.41%, Test: 73.23%\n",
            "Epoch: 105, Loss: 50022.9688, Train: 87.91%, Valid: 73.53%, Test: 73.23%\n",
            "Epoch: 110, Loss: 48298.5312, Train: 88.03%, Valid: 73.89%, Test: 73.23%\n",
            "Epoch: 115, Loss: 46709.2734, Train: 87.97%, Valid: 73.89%, Test: 73.35%\n",
            "Epoch: 120, Loss: 45238.3047, Train: 88.09%, Valid: 74.01%, Test: 73.47%\n",
            "Epoch: 125, Loss: 43882.7734, Train: 88.15%, Valid: 74.13%, Test: 73.11%\n",
            "Epoch: 130, Loss: 42639.4766, Train: 88.21%, Valid: 74.13%, Test: 72.75%\n",
            "Epoch: 135, Loss: 41493.8828, Train: 88.21%, Valid: 74.25%, Test: 72.63%\n",
            "Epoch: 140, Loss: 40433.2227, Train: 88.15%, Valid: 74.13%, Test: 72.63%\n",
            "Epoch: 145, Loss: 39457.6484, Train: 88.21%, Valid: 74.25%, Test: 72.63%\n",
            "Epoch: 150, Loss: 39069.3086, Train: 88.21%, Valid: 74.25%, Test: 72.75%\n",
            "Epoch: 155, Loss: 37745.4297, Train: 88.39%, Valid: 74.37%, Test: 72.63%\n",
            "Epoch: 160, Loss: 37030.3555, Train: 88.39%, Valid: 74.25%, Test: 72.75%\n",
            "Epoch: 165, Loss: 36253.1172, Train: 88.39%, Valid: 74.25%, Test: 72.63%\n",
            "Epoch: 170, Loss: 35480.3008, Train: 88.33%, Valid: 74.37%, Test: 72.63%\n",
            "Epoch: 175, Loss: 34834.9297, Train: 88.39%, Valid: 74.49%, Test: 72.63%\n",
            "Epoch: 180, Loss: 34225.2031, Train: 88.39%, Valid: 74.49%, Test: 72.75%\n",
            "Epoch: 185, Loss: 33890.0352, Train: 88.39%, Valid: 74.37%, Test: 72.63%\n",
            "Epoch: 190, Loss: 33095.7969, Train: 88.39%, Valid: 74.25%, Test: 72.51%\n",
            "Epoch: 195, Loss: 32673.9004, Train: 88.45%, Valid: 74.13%, Test: 72.75%\n",
            "Run 05:\n",
            "Highest Train: 88.51\n",
            "Highest Valid: 74.49\n",
            "Highest Test: 73.47\n",
            "Chosen epoch: 176\n",
            "Final Train: 88.39\n",
            "Final Test: 72.63\n",
            "All runs:\n",
            "Highest Train: 85.52 ± 2.24\n",
            "Highest Test: 73.61 ± 0.85\n",
            "Highest Valid: 73.53 ± 0.78\n",
            "  Final Train: 85.02 ± 2.43\n",
            "   Final Test: 73.04 ± 0.87\n",
            "Saving results to logs/citeseer_edge.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 GKD/main.py --dataset citeseer --rand_split --use_bn --base_model gcn --mode train --priv_type edge --dist_mode gkd --use_kd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suftY3XmJ-y0",
        "outputId": "f396d374-13b4-475a-eb53-ac1f00d03018"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(data_dir='data', dataset='citeseer', sub_dataset='', cpu=False, seed=42, train_prop=0.5, valid_prop=0.25, protocol='semi', rand_split=True, metric='acc', runs=5, epochs=200, hidden_channels=32, num_layers=3, gat_heads=8, out_heads=1, hops=1, lp_alpha=0.1, gpr_alpha=0.1, jk_type='max', directed=False, num_mlp_layers=1, display_step=5, cached=False, print_prop=False, priv_type='edge', priv_ratio=0.5, save_model=False, save_name='gcn', log_name='none', base_model='gcn', not_load_teacher=False, mode='train', dist_mode='gkd', weight_decay=0.05, dropout=0.0, lr=0.01, use_bn=True, use_batch=False, batch_size=2048, oracle=False, device=0, alpha=0.5, delta=0.1, use_kd=True, beta=0.0, tau=1.0, kernel='sigmoid', t=1.0, include_last=False, s=2, m=1, lr2=0.001, sim='l2', ker_norm=False)\n",
            "cuda:0\n",
            "citeseer\n",
            "Num nodes: 3327\n",
            "torch.Size([3327, 1])\n",
            "num nodes 3327 | num classes 6 | num node feats 3703\n",
            "MODEL: GeoDist(\n",
            "  (k): Kernel(\n",
            "    (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  )\n",
            "  (teacher_gnn): ModuleList(\n",
            "    (0): Linear(in_features=3703, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (student_gnn): ModuleList(\n",
            "    (0): Linear(in_features=3703, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  (bns2d): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            ")\n",
            "Epoch: 00, Loss: 918465.7500, Train: 14.07%, Valid: 14.92%, Test: 17.89%\n",
            "Epoch: 05, Loss: 192346.2500, Train: 25.98%, Valid: 24.55%, Test: 24.85%\n",
            "Epoch: 10, Loss: 150587.6719, Train: 43.42%, Valid: 38.99%, Test: 40.10%\n",
            "Epoch: 15, Loss: 129515.5938, Train: 58.75%, Valid: 51.02%, Test: 52.10%\n",
            "Epoch: 20, Loss: 115140.5391, Train: 73.18%, Valid: 63.66%, Test: 62.55%\n",
            "Epoch: 25, Loss: 104605.9609, Train: 80.10%, Valid: 70.28%, Test: 69.15%\n",
            "Epoch: 30, Loss: 96229.7969, Train: 81.36%, Valid: 70.76%, Test: 70.23%\n",
            "Epoch: 35, Loss: 89171.5078, Train: 82.38%, Valid: 71.84%, Test: 71.55%\n",
            "Epoch: 40, Loss: 83274.9688, Train: 82.38%, Valid: 72.20%, Test: 72.15%\n",
            "Epoch: 45, Loss: 78249.5547, Train: 82.56%, Valid: 72.44%, Test: 72.51%\n",
            "Epoch: 50, Loss: 73839.0000, Train: 82.74%, Valid: 72.32%, Test: 72.51%\n",
            "Epoch: 55, Loss: 69927.6094, Train: 82.86%, Valid: 72.80%, Test: 72.87%\n",
            "Epoch: 60, Loss: 66394.8516, Train: 82.86%, Valid: 73.29%, Test: 72.39%\n",
            "Epoch: 65, Loss: 63214.9180, Train: 82.98%, Valid: 73.29%, Test: 72.51%\n",
            "Epoch: 70, Loss: 60377.9180, Train: 83.28%, Valid: 73.16%, Test: 72.51%\n",
            "Epoch: 75, Loss: 57769.5664, Train: 83.46%, Valid: 73.53%, Test: 72.87%\n",
            "Epoch: 80, Loss: 55337.6133, Train: 83.52%, Valid: 73.77%, Test: 73.11%\n",
            "Epoch: 85, Loss: 53117.1875, Train: 83.64%, Valid: 73.89%, Test: 73.11%\n",
            "Epoch: 90, Loss: 51170.4570, Train: 83.52%, Valid: 73.77%, Test: 72.99%\n",
            "Epoch: 95, Loss: 49269.3945, Train: 83.76%, Valid: 73.53%, Test: 72.75%\n",
            "Epoch: 100, Loss: 47393.0508, Train: 83.70%, Valid: 73.29%, Test: 72.63%\n",
            "Epoch: 105, Loss: 45623.3906, Train: 83.82%, Valid: 73.41%, Test: 72.87%\n",
            "Epoch: 110, Loss: 44123.8047, Train: 83.88%, Valid: 73.16%, Test: 72.99%\n",
            "Epoch: 115, Loss: 42667.6406, Train: 83.88%, Valid: 73.04%, Test: 72.75%\n",
            "Epoch: 120, Loss: 41248.4297, Train: 83.94%, Valid: 72.92%, Test: 72.63%\n",
            "Epoch: 125, Loss: 39946.9609, Train: 84.00%, Valid: 73.29%, Test: 72.75%\n",
            "Epoch: 130, Loss: 38709.6289, Train: 84.06%, Valid: 72.92%, Test: 72.87%\n",
            "Epoch: 135, Loss: 37601.7227, Train: 84.13%, Valid: 73.04%, Test: 72.75%\n",
            "Epoch: 140, Loss: 36556.9609, Train: 84.25%, Valid: 73.29%, Test: 72.99%\n",
            "Epoch: 145, Loss: 35573.6953, Train: 84.19%, Valid: 72.92%, Test: 73.11%\n",
            "Epoch: 150, Loss: 35029.0742, Train: 84.00%, Valid: 72.80%, Test: 73.23%\n",
            "Epoch: 155, Loss: 34006.5000, Train: 84.13%, Valid: 72.80%, Test: 73.11%\n",
            "Epoch: 160, Loss: 33284.7188, Train: 84.19%, Valid: 72.68%, Test: 73.11%\n",
            "Epoch: 165, Loss: 32579.8262, Train: 84.13%, Valid: 72.56%, Test: 73.11%\n",
            "Epoch: 170, Loss: 32020.0684, Train: 84.00%, Valid: 72.44%, Test: 73.23%\n",
            "Epoch: 175, Loss: 31144.2793, Train: 84.00%, Valid: 72.56%, Test: 73.11%\n",
            "Epoch: 180, Loss: 30473.5215, Train: 83.94%, Valid: 72.56%, Test: 72.87%\n",
            "Epoch: 185, Loss: 29912.9492, Train: 84.06%, Valid: 72.56%, Test: 72.99%\n",
            "Epoch: 190, Loss: 29695.4922, Train: 84.00%, Valid: 72.68%, Test: 72.75%\n",
            "Epoch: 195, Loss: 28856.0918, Train: 84.13%, Valid: 72.68%, Test: 72.75%\n",
            "Run 01:\n",
            "Highest Train: 84.25\n",
            "Highest Valid: 74.01\n",
            "Highest Test: 73.23\n",
            "Chosen epoch: 88\n",
            "Final Train: 83.58\n",
            "Final Test: 73.23\n",
            "Epoch: 00, Loss: 912336.3125, Train: 11.85%, Valid: 13.12%, Test: 13.93%\n",
            "Epoch: 05, Loss: 217768.6094, Train: 31.99%, Valid: 28.88%, Test: 31.81%\n",
            "Epoch: 10, Loss: 166158.5156, Train: 46.18%, Valid: 41.16%, Test: 45.50%\n",
            "Epoch: 15, Loss: 142163.2500, Train: 62.00%, Valid: 52.83%, Test: 57.26%\n",
            "Epoch: 20, Loss: 125413.7188, Train: 72.10%, Valid: 63.42%, Test: 64.95%\n",
            "Epoch: 25, Loss: 113063.6406, Train: 79.92%, Valid: 71.00%, Test: 71.55%\n",
            "Epoch: 30, Loss: 103589.8125, Train: 82.08%, Valid: 71.48%, Test: 72.27%\n",
            "Epoch: 35, Loss: 95780.2266, Train: 83.04%, Valid: 71.48%, Test: 72.99%\n",
            "Epoch: 40, Loss: 89332.3203, Train: 83.70%, Valid: 71.84%, Test: 73.47%\n",
            "Epoch: 45, Loss: 83824.5781, Train: 84.55%, Valid: 72.20%, Test: 73.23%\n",
            "Epoch: 50, Loss: 79165.3203, Train: 84.91%, Valid: 73.16%, Test: 73.35%\n",
            "Epoch: 55, Loss: 75137.4609, Train: 85.63%, Valid: 73.41%, Test: 73.59%\n",
            "Epoch: 60, Loss: 71583.1641, Train: 85.93%, Valid: 73.29%, Test: 73.71%\n",
            "Epoch: 65, Loss: 68416.4297, Train: 86.53%, Valid: 73.65%, Test: 74.43%\n",
            "Epoch: 70, Loss: 65548.1641, Train: 86.65%, Valid: 73.29%, Test: 73.83%\n",
            "Epoch: 75, Loss: 62932.5781, Train: 86.71%, Valid: 73.41%, Test: 73.83%\n",
            "Epoch: 80, Loss: 60529.3359, Train: 86.77%, Valid: 73.04%, Test: 74.07%\n",
            "Epoch: 85, Loss: 58305.8672, Train: 86.65%, Valid: 73.41%, Test: 74.31%\n",
            "Epoch: 90, Loss: 56247.2188, Train: 86.77%, Valid: 72.92%, Test: 74.07%\n",
            "Epoch: 95, Loss: 54328.6836, Train: 86.83%, Valid: 73.04%, Test: 74.19%\n",
            "Epoch: 100, Loss: 52547.6719, Train: 86.77%, Valid: 73.16%, Test: 74.07%\n",
            "Epoch: 105, Loss: 50875.5195, Train: 86.77%, Valid: 73.29%, Test: 74.07%\n",
            "Epoch: 110, Loss: 49309.0117, Train: 86.71%, Valid: 73.29%, Test: 74.55%\n",
            "Epoch: 115, Loss: 47856.8203, Train: 86.77%, Valid: 73.29%, Test: 74.55%\n",
            "Epoch: 120, Loss: 46492.8438, Train: 86.77%, Valid: 73.29%, Test: 74.67%\n",
            "Epoch: 125, Loss: 45201.7031, Train: 86.65%, Valid: 73.53%, Test: 74.91%\n",
            "Epoch: 130, Loss: 43978.8359, Train: 86.65%, Valid: 73.65%, Test: 74.79%\n",
            "Epoch: 135, Loss: 42816.0312, Train: 86.77%, Valid: 73.65%, Test: 74.91%\n",
            "Epoch: 140, Loss: 41713.6055, Train: 86.77%, Valid: 73.41%, Test: 74.79%\n",
            "Epoch: 145, Loss: 40673.9492, Train: 86.77%, Valid: 73.41%, Test: 74.91%\n",
            "Epoch: 150, Loss: 39694.2031, Train: 86.71%, Valid: 73.16%, Test: 74.91%\n",
            "Epoch: 155, Loss: 38808.8438, Train: 86.65%, Valid: 73.16%, Test: 74.91%\n",
            "Epoch: 160, Loss: 38040.0391, Train: 86.71%, Valid: 73.16%, Test: 74.79%\n",
            "Epoch: 165, Loss: 37146.4805, Train: 86.71%, Valid: 73.16%, Test: 74.67%\n",
            "Epoch: 170, Loss: 36455.5781, Train: 86.83%, Valid: 73.16%, Test: 74.67%\n",
            "Epoch: 175, Loss: 35678.5977, Train: 86.83%, Valid: 73.16%, Test: 74.79%\n",
            "Epoch: 180, Loss: 34974.3086, Train: 86.83%, Valid: 73.29%, Test: 74.67%\n",
            "Epoch: 185, Loss: 34292.3945, Train: 86.77%, Valid: 73.41%, Test: 74.79%\n",
            "Epoch: 190, Loss: 33693.9141, Train: 86.71%, Valid: 73.29%, Test: 74.79%\n",
            "Epoch: 195, Loss: 33348.7578, Train: 86.77%, Valid: 73.41%, Test: 74.91%\n",
            "Run 02:\n",
            "Highest Train: 86.89\n",
            "Highest Valid: 73.65\n",
            "Highest Test: 75.03\n",
            "Chosen epoch: 65\n",
            "Final Train: 86.23\n",
            "Final Test: 74.43\n",
            "Epoch: 00, Loss: 913669.8750, Train: 18.64%, Valid: 19.13%, Test: 18.25%\n",
            "Epoch: 05, Loss: 221028.2031, Train: 27.66%, Valid: 27.68%, Test: 24.61%\n",
            "Epoch: 10, Loss: 171788.2344, Train: 54.90%, Valid: 47.41%, Test: 48.38%\n",
            "Epoch: 15, Loss: 146493.2500, Train: 62.00%, Valid: 53.67%, Test: 54.62%\n",
            "Epoch: 20, Loss: 130246.0547, Train: 73.90%, Valid: 66.19%, Test: 66.15%\n",
            "Epoch: 25, Loss: 118031.3438, Train: 78.59%, Valid: 69.68%, Test: 70.11%\n",
            "Epoch: 30, Loss: 108068.4609, Train: 79.68%, Valid: 70.76%, Test: 71.31%\n",
            "Epoch: 35, Loss: 99642.1172, Train: 80.28%, Valid: 71.12%, Test: 70.83%\n",
            "Epoch: 40, Loss: 92393.7812, Train: 80.34%, Valid: 71.24%, Test: 70.47%\n",
            "Epoch: 45, Loss: 85987.9375, Train: 80.58%, Valid: 71.60%, Test: 70.59%\n",
            "Epoch: 50, Loss: 80231.9688, Train: 81.00%, Valid: 71.72%, Test: 70.71%\n",
            "Epoch: 55, Loss: 75231.4844, Train: 81.00%, Valid: 71.96%, Test: 70.95%\n",
            "Epoch: 60, Loss: 70769.8047, Train: 81.24%, Valid: 71.84%, Test: 70.95%\n",
            "Epoch: 65, Loss: 66745.7344, Train: 81.24%, Valid: 71.84%, Test: 71.31%\n",
            "Epoch: 70, Loss: 63121.2578, Train: 81.30%, Valid: 71.96%, Test: 71.43%\n",
            "Epoch: 75, Loss: 59912.0469, Train: 81.54%, Valid: 71.72%, Test: 71.91%\n",
            "Epoch: 80, Loss: 57044.7500, Train: 81.60%, Valid: 71.36%, Test: 72.27%\n",
            "Epoch: 85, Loss: 54450.6836, Train: 81.72%, Valid: 71.24%, Test: 72.15%\n",
            "Epoch: 90, Loss: 52087.5273, Train: 81.84%, Valid: 71.48%, Test: 72.27%\n",
            "Epoch: 95, Loss: 49943.9492, Train: 81.60%, Valid: 71.60%, Test: 71.91%\n",
            "Epoch: 100, Loss: 47998.9727, Train: 81.72%, Valid: 71.48%, Test: 71.67%\n",
            "Epoch: 105, Loss: 46214.7188, Train: 81.54%, Valid: 71.48%, Test: 72.03%\n",
            "Epoch: 110, Loss: 44587.4297, Train: 81.54%, Valid: 71.84%, Test: 72.03%\n",
            "Epoch: 115, Loss: 43089.7422, Train: 81.66%, Valid: 71.96%, Test: 72.03%\n",
            "Epoch: 120, Loss: 41728.7031, Train: 81.84%, Valid: 72.08%, Test: 72.51%\n",
            "Epoch: 125, Loss: 40462.2344, Train: 81.90%, Valid: 72.32%, Test: 72.63%\n",
            "Epoch: 130, Loss: 39466.3203, Train: 81.90%, Valid: 72.44%, Test: 72.51%\n",
            "Epoch: 135, Loss: 38201.4062, Train: 82.08%, Valid: 72.68%, Test: 72.75%\n",
            "Epoch: 140, Loss: 37272.9688, Train: 82.14%, Valid: 72.56%, Test: 72.51%\n",
            "Epoch: 145, Loss: 36265.6016, Train: 82.20%, Valid: 72.44%, Test: 72.51%\n",
            "Epoch: 150, Loss: 35417.1250, Train: 82.14%, Valid: 72.44%, Test: 72.51%\n",
            "Epoch: 155, Loss: 34607.0859, Train: 82.02%, Valid: 71.96%, Test: 72.39%\n",
            "Epoch: 160, Loss: 33856.3242, Train: 82.20%, Valid: 71.84%, Test: 72.15%\n",
            "Epoch: 165, Loss: 33412.7500, Train: 82.38%, Valid: 71.84%, Test: 71.91%\n",
            "Epoch: 170, Loss: 32640.6602, Train: 82.32%, Valid: 71.96%, Test: 72.27%\n",
            "Epoch: 175, Loss: 31965.3242, Train: 82.32%, Valid: 71.96%, Test: 72.15%\n",
            "Epoch: 180, Loss: 31330.3457, Train: 82.32%, Valid: 71.96%, Test: 72.39%\n",
            "Epoch: 185, Loss: 30756.5957, Train: 82.38%, Valid: 71.96%, Test: 72.51%\n",
            "Epoch: 190, Loss: 30348.1543, Train: 82.50%, Valid: 71.84%, Test: 72.27%\n",
            "Epoch: 195, Loss: 29812.4355, Train: 82.68%, Valid: 71.84%, Test: 72.39%\n",
            "Run 03:\n",
            "Highest Train: 82.80\n",
            "Highest Valid: 72.68\n",
            "Highest Test: 72.75\n",
            "Chosen epoch: 136\n",
            "Final Train: 82.08\n",
            "Final Test: 72.75\n",
            "Epoch: 00, Loss: 925642.4375, Train: 10.40%, Valid: 10.35%, Test: 11.40%\n",
            "Epoch: 05, Loss: 196733.6406, Train: 31.81%, Valid: 31.65%, Test: 30.37%\n",
            "Epoch: 10, Loss: 156195.6562, Train: 41.25%, Valid: 39.47%, Test: 38.18%\n",
            "Epoch: 15, Loss: 135959.8750, Train: 53.22%, Valid: 49.10%, Test: 48.02%\n",
            "Epoch: 20, Loss: 122006.3359, Train: 65.66%, Valid: 60.53%, Test: 58.58%\n",
            "Epoch: 25, Loss: 111750.1484, Train: 72.04%, Valid: 66.06%, Test: 65.19%\n",
            "Epoch: 30, Loss: 103344.2891, Train: 78.11%, Valid: 69.19%, Test: 69.39%\n",
            "Epoch: 35, Loss: 96205.2266, Train: 80.40%, Valid: 71.72%, Test: 71.67%\n",
            "Epoch: 40, Loss: 90044.5156, Train: 81.42%, Valid: 71.72%, Test: 72.75%\n",
            "Epoch: 45, Loss: 84602.2109, Train: 82.02%, Valid: 71.60%, Test: 72.39%\n",
            "Epoch: 50, Loss: 79720.5625, Train: 82.08%, Valid: 71.84%, Test: 72.39%\n",
            "Epoch: 55, Loss: 75382.2812, Train: 82.32%, Valid: 72.08%, Test: 72.15%\n",
            "Epoch: 60, Loss: 71452.8203, Train: 82.26%, Valid: 71.96%, Test: 72.51%\n",
            "Epoch: 65, Loss: 67860.4688, Train: 82.56%, Valid: 71.96%, Test: 72.87%\n",
            "Epoch: 70, Loss: 64547.2383, Train: 82.92%, Valid: 71.96%, Test: 72.75%\n",
            "Epoch: 75, Loss: 61536.3008, Train: 83.04%, Valid: 72.20%, Test: 73.11%\n",
            "Epoch: 80, Loss: 58811.6211, Train: 83.46%, Valid: 72.08%, Test: 73.23%\n",
            "Epoch: 85, Loss: 56362.7305, Train: 83.58%, Valid: 71.84%, Test: 73.59%\n",
            "Epoch: 90, Loss: 54131.2617, Train: 83.82%, Valid: 72.32%, Test: 73.47%\n",
            "Epoch: 95, Loss: 52097.6797, Train: 83.88%, Valid: 72.44%, Test: 73.35%\n",
            "Epoch: 100, Loss: 50229.5977, Train: 83.88%, Valid: 72.56%, Test: 73.23%\n",
            "Epoch: 105, Loss: 48509.9258, Train: 84.19%, Valid: 72.56%, Test: 73.11%\n",
            "Epoch: 110, Loss: 46935.1211, Train: 84.06%, Valid: 72.44%, Test: 72.87%\n",
            "Epoch: 115, Loss: 45483.9961, Train: 84.25%, Valid: 72.56%, Test: 72.99%\n",
            "Epoch: 120, Loss: 44138.2773, Train: 84.43%, Valid: 72.56%, Test: 72.75%\n",
            "Epoch: 125, Loss: 42891.9297, Train: 84.43%, Valid: 72.56%, Test: 72.63%\n",
            "Epoch: 130, Loss: 41738.5234, Train: 84.43%, Valid: 72.56%, Test: 72.15%\n",
            "Epoch: 135, Loss: 40667.8203, Train: 84.37%, Valid: 72.56%, Test: 72.03%\n",
            "Epoch: 140, Loss: 39877.0664, Train: 84.61%, Valid: 72.68%, Test: 71.91%\n",
            "Epoch: 145, Loss: 39075.1250, Train: 84.61%, Valid: 72.68%, Test: 71.91%\n",
            "Epoch: 150, Loss: 38131.2500, Train: 84.55%, Valid: 72.68%, Test: 71.91%\n",
            "Epoch: 155, Loss: 37199.8711, Train: 84.73%, Valid: 72.80%, Test: 72.15%\n",
            "Epoch: 160, Loss: 36487.2500, Train: 84.79%, Valid: 72.68%, Test: 72.03%\n",
            "Epoch: 165, Loss: 35901.5938, Train: 84.91%, Valid: 72.56%, Test: 71.91%\n",
            "Epoch: 170, Loss: 35196.2930, Train: 84.79%, Valid: 72.80%, Test: 71.79%\n",
            "Epoch: 175, Loss: 34531.4688, Train: 84.85%, Valid: 72.92%, Test: 72.15%\n",
            "Epoch: 180, Loss: 34008.8828, Train: 85.03%, Valid: 72.56%, Test: 72.15%\n",
            "Epoch: 185, Loss: 33467.2969, Train: 85.15%, Valid: 72.68%, Test: 72.15%\n",
            "Epoch: 190, Loss: 32917.3438, Train: 84.97%, Valid: 72.80%, Test: 72.15%\n",
            "Epoch: 195, Loss: 32674.8105, Train: 85.21%, Valid: 72.32%, Test: 72.15%\n",
            "Run 04:\n",
            "Highest Train: 85.21\n",
            "Highest Valid: 72.92\n",
            "Highest Test: 73.59\n",
            "Chosen epoch: 176\n",
            "Final Train: 84.85\n",
            "Final Test: 72.15\n",
            "Epoch: 00, Loss: 910929.8750, Train: 18.64%, Valid: 20.94%, Test: 20.77%\n",
            "Epoch: 05, Loss: 208556.9375, Train: 35.54%, Valid: 29.96%, Test: 33.73%\n",
            "Epoch: 10, Loss: 164174.3281, Train: 47.50%, Valid: 42.84%, Test: 42.50%\n",
            "Epoch: 15, Loss: 142287.7656, Train: 64.64%, Valid: 56.08%, Test: 57.86%\n",
            "Epoch: 20, Loss: 127461.6875, Train: 71.62%, Valid: 63.42%, Test: 63.87%\n",
            "Epoch: 25, Loss: 115889.9297, Train: 78.89%, Valid: 70.04%, Test: 68.67%\n",
            "Epoch: 30, Loss: 106529.0625, Train: 82.68%, Valid: 71.96%, Test: 70.71%\n",
            "Epoch: 35, Loss: 98777.6094, Train: 84.37%, Valid: 73.53%, Test: 71.19%\n",
            "Epoch: 40, Loss: 92226.5938, Train: 85.45%, Valid: 73.89%, Test: 72.27%\n",
            "Epoch: 45, Loss: 86556.8828, Train: 85.99%, Valid: 74.13%, Test: 72.75%\n",
            "Epoch: 50, Loss: 81630.6562, Train: 86.11%, Valid: 74.01%, Test: 73.11%\n",
            "Epoch: 55, Loss: 77228.0781, Train: 86.71%, Valid: 74.01%, Test: 73.11%\n",
            "Epoch: 60, Loss: 73238.2969, Train: 86.83%, Valid: 74.25%, Test: 72.99%\n",
            "Epoch: 65, Loss: 69639.2578, Train: 86.89%, Valid: 74.13%, Test: 73.23%\n",
            "Epoch: 70, Loss: 66355.9922, Train: 87.13%, Valid: 74.13%, Test: 72.99%\n",
            "Epoch: 75, Loss: 63410.0664, Train: 87.55%, Valid: 74.13%, Test: 72.99%\n",
            "Epoch: 80, Loss: 60741.7344, Train: 87.55%, Valid: 74.13%, Test: 73.23%\n",
            "Epoch: 85, Loss: 58285.6953, Train: 87.49%, Valid: 74.01%, Test: 73.11%\n",
            "Epoch: 90, Loss: 56007.2031, Train: 87.67%, Valid: 73.77%, Test: 72.99%\n",
            "Epoch: 95, Loss: 53880.0234, Train: 87.85%, Valid: 73.53%, Test: 73.11%\n",
            "Epoch: 100, Loss: 51887.6562, Train: 88.03%, Valid: 73.41%, Test: 73.23%\n",
            "Epoch: 105, Loss: 50022.9688, Train: 87.91%, Valid: 73.53%, Test: 73.23%\n",
            "Epoch: 110, Loss: 48298.5312, Train: 88.03%, Valid: 73.89%, Test: 73.23%\n",
            "Epoch: 115, Loss: 46709.2734, Train: 87.97%, Valid: 73.89%, Test: 73.35%\n",
            "Epoch: 120, Loss: 45238.3047, Train: 88.09%, Valid: 74.01%, Test: 73.47%\n",
            "Epoch: 125, Loss: 43882.7734, Train: 88.15%, Valid: 74.13%, Test: 73.11%\n",
            "Epoch: 130, Loss: 42639.4766, Train: 88.21%, Valid: 74.13%, Test: 72.75%\n",
            "Epoch: 135, Loss: 41493.8828, Train: 88.21%, Valid: 74.25%, Test: 72.63%\n",
            "Epoch: 140, Loss: 40433.2188, Train: 88.15%, Valid: 74.13%, Test: 72.63%\n",
            "Epoch: 145, Loss: 39457.7500, Train: 88.21%, Valid: 74.25%, Test: 72.63%\n",
            "Epoch: 150, Loss: 39066.8789, Train: 88.21%, Valid: 74.25%, Test: 72.75%\n",
            "Epoch: 155, Loss: 37744.3125, Train: 88.39%, Valid: 74.37%, Test: 72.63%\n",
            "Epoch: 160, Loss: 37030.4766, Train: 88.39%, Valid: 74.25%, Test: 72.75%\n",
            "Epoch: 165, Loss: 36253.6797, Train: 88.39%, Valid: 74.25%, Test: 72.63%\n",
            "Epoch: 170, Loss: 35480.4688, Train: 88.33%, Valid: 74.37%, Test: 72.63%\n",
            "Epoch: 175, Loss: 34834.9648, Train: 88.39%, Valid: 74.49%, Test: 72.63%\n",
            "Epoch: 180, Loss: 34225.1562, Train: 88.39%, Valid: 74.49%, Test: 72.75%\n",
            "Epoch: 185, Loss: 33889.0547, Train: 88.39%, Valid: 74.37%, Test: 72.51%\n",
            "Epoch: 190, Loss: 33098.2227, Train: 88.39%, Valid: 74.25%, Test: 72.63%\n",
            "Epoch: 195, Loss: 32663.6934, Train: 88.45%, Valid: 74.13%, Test: 72.51%\n",
            "Run 05:\n",
            "Highest Train: 88.51\n",
            "Highest Valid: 74.49\n",
            "Highest Test: 73.47\n",
            "Chosen epoch: 176\n",
            "Final Train: 88.39\n",
            "Final Test: 72.63\n",
            "All runs:\n",
            "Highest Train: 85.53 ± 2.23\n",
            "Highest Test: 73.61 ± 0.85\n",
            "Highest Valid: 73.55 ± 0.75\n",
            "  Final Train: 85.03 ± 2.43\n",
            "   Final Test: 73.04 ± 0.87\n",
            "Saving results to logs/citeseer_edge.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 GKD/main.py --dataset citeseer --rand_split --use_bn --base_model gcn --mode train  --dist_mode gkd --use_kd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3UDnTZFKB-T",
        "outputId": "e5944f98-6520-4710-9164-e3fcd69f6b4c"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(data_dir='data', dataset='citeseer', sub_dataset='', cpu=False, seed=42, train_prop=0.5, valid_prop=0.25, protocol='semi', rand_split=True, metric='acc', runs=5, epochs=200, hidden_channels=32, num_layers=3, gat_heads=8, out_heads=1, hops=1, lp_alpha=0.1, gpr_alpha=0.1, jk_type='max', directed=False, num_mlp_layers=1, display_step=5, cached=False, print_prop=False, priv_type='edge', priv_ratio=0.5, save_model=False, save_name='gcn', log_name='none', base_model='gcn', not_load_teacher=False, mode='train', dist_mode='gkd', weight_decay=0.05, dropout=0.0, lr=0.01, use_bn=True, use_batch=False, batch_size=2048, oracle=False, device=0, alpha=0.5, delta=0.1, use_kd=True, beta=0.0, tau=1.0, kernel='sigmoid', t=1.0, include_last=False, s=2, m=1, lr2=0.001, sim='l2', ker_norm=False)\n",
            "cuda:0\n",
            "citeseer\n",
            "Num nodes: 3327\n",
            "torch.Size([3327, 1])\n",
            "num nodes 3327 | num classes 6 | num node feats 3703\n",
            "MODEL: GeoDist(\n",
            "  (k): Kernel(\n",
            "    (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  )\n",
            "  (teacher_gnn): ModuleList(\n",
            "    (0): Linear(in_features=3703, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (student_gnn): ModuleList(\n",
            "    (0): Linear(in_features=3703, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  (bns2d): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            ")\n",
            "Epoch: 00, Loss: 918465.8125, Train: 14.07%, Valid: 14.92%, Test: 17.89%\n",
            "Epoch: 05, Loss: 192346.2500, Train: 25.98%, Valid: 24.55%, Test: 24.85%\n",
            "Epoch: 10, Loss: 150587.6719, Train: 43.42%, Valid: 38.99%, Test: 40.10%\n",
            "Epoch: 15, Loss: 129515.6016, Train: 58.75%, Valid: 51.02%, Test: 52.10%\n",
            "Epoch: 20, Loss: 115140.5391, Train: 73.18%, Valid: 63.66%, Test: 62.55%\n",
            "Epoch: 25, Loss: 104605.9609, Train: 80.10%, Valid: 70.28%, Test: 69.15%\n",
            "Epoch: 30, Loss: 96229.8047, Train: 81.36%, Valid: 70.76%, Test: 70.23%\n",
            "Epoch: 35, Loss: 89171.5000, Train: 82.38%, Valid: 71.84%, Test: 71.55%\n",
            "Epoch: 40, Loss: 83274.9688, Train: 82.38%, Valid: 72.20%, Test: 72.15%\n",
            "Epoch: 45, Loss: 78249.5547, Train: 82.56%, Valid: 72.44%, Test: 72.51%\n",
            "Epoch: 50, Loss: 73839.0000, Train: 82.74%, Valid: 72.32%, Test: 72.51%\n",
            "Epoch: 55, Loss: 69927.6094, Train: 82.86%, Valid: 72.80%, Test: 72.87%\n",
            "Epoch: 60, Loss: 66394.8516, Train: 82.86%, Valid: 73.29%, Test: 72.39%\n",
            "Epoch: 65, Loss: 63214.9141, Train: 82.98%, Valid: 73.29%, Test: 72.51%\n",
            "Epoch: 70, Loss: 60377.9180, Train: 83.28%, Valid: 73.16%, Test: 72.51%\n",
            "Epoch: 75, Loss: 57769.5664, Train: 83.46%, Valid: 73.53%, Test: 72.87%\n",
            "Epoch: 80, Loss: 55337.6133, Train: 83.52%, Valid: 73.77%, Test: 73.11%\n",
            "Epoch: 85, Loss: 53117.1875, Train: 83.64%, Valid: 73.89%, Test: 73.11%\n",
            "Epoch: 90, Loss: 51170.5000, Train: 83.52%, Valid: 73.77%, Test: 72.99%\n",
            "Epoch: 95, Loss: 49269.4258, Train: 83.76%, Valid: 73.53%, Test: 72.75%\n",
            "Epoch: 100, Loss: 47393.0352, Train: 83.70%, Valid: 73.29%, Test: 72.63%\n",
            "Epoch: 105, Loss: 45623.3789, Train: 83.82%, Valid: 73.41%, Test: 72.87%\n",
            "Epoch: 110, Loss: 44123.8672, Train: 83.88%, Valid: 73.16%, Test: 72.99%\n",
            "Epoch: 115, Loss: 42667.3359, Train: 83.88%, Valid: 73.04%, Test: 72.75%\n",
            "Epoch: 120, Loss: 41248.2891, Train: 83.94%, Valid: 72.92%, Test: 72.63%\n",
            "Epoch: 125, Loss: 39946.8125, Train: 84.00%, Valid: 73.29%, Test: 72.75%\n",
            "Epoch: 130, Loss: 38709.4883, Train: 84.06%, Valid: 72.92%, Test: 72.87%\n",
            "Epoch: 135, Loss: 37601.8828, Train: 84.13%, Valid: 73.04%, Test: 72.75%\n",
            "Epoch: 140, Loss: 36557.6172, Train: 84.25%, Valid: 73.29%, Test: 72.99%\n",
            "Epoch: 145, Loss: 35574.6055, Train: 84.19%, Valid: 72.92%, Test: 73.11%\n",
            "Epoch: 150, Loss: 35046.9062, Train: 84.00%, Valid: 72.80%, Test: 73.23%\n",
            "Epoch: 155, Loss: 34015.7305, Train: 84.13%, Valid: 72.80%, Test: 73.11%\n",
            "Epoch: 160, Loss: 33274.0586, Train: 84.19%, Valid: 72.68%, Test: 73.11%\n",
            "Epoch: 165, Loss: 32578.4922, Train: 84.13%, Valid: 72.56%, Test: 73.11%\n",
            "Epoch: 170, Loss: 32016.8730, Train: 84.00%, Valid: 72.56%, Test: 73.23%\n",
            "Epoch: 175, Loss: 31184.7305, Train: 84.00%, Valid: 72.56%, Test: 72.99%\n",
            "Epoch: 180, Loss: 30468.1621, Train: 83.94%, Valid: 72.56%, Test: 72.87%\n",
            "Epoch: 185, Loss: 29959.1172, Train: 83.94%, Valid: 72.56%, Test: 72.87%\n",
            "Epoch: 190, Loss: 29495.7852, Train: 84.13%, Valid: 72.68%, Test: 72.87%\n",
            "Epoch: 195, Loss: 28842.8379, Train: 84.00%, Valid: 72.68%, Test: 72.87%\n",
            "Run 01:\n",
            "Highest Train: 84.25\n",
            "Highest Valid: 74.01\n",
            "Highest Test: 73.23\n",
            "Chosen epoch: 88\n",
            "Final Train: 83.58\n",
            "Final Test: 73.23\n",
            "Epoch: 00, Loss: 912336.3125, Train: 11.85%, Valid: 13.12%, Test: 13.93%\n",
            "Epoch: 05, Loss: 217768.6094, Train: 31.99%, Valid: 28.88%, Test: 31.81%\n",
            "Epoch: 10, Loss: 166158.5156, Train: 46.18%, Valid: 41.16%, Test: 45.50%\n",
            "Epoch: 15, Loss: 142163.2500, Train: 62.00%, Valid: 52.83%, Test: 57.26%\n",
            "Epoch: 20, Loss: 125413.7266, Train: 72.10%, Valid: 63.42%, Test: 64.95%\n",
            "Epoch: 25, Loss: 113063.6406, Train: 79.92%, Valid: 71.00%, Test: 71.55%\n",
            "Epoch: 30, Loss: 103589.8125, Train: 82.08%, Valid: 71.48%, Test: 72.27%\n",
            "Epoch: 35, Loss: 95780.2344, Train: 83.04%, Valid: 71.48%, Test: 72.99%\n",
            "Epoch: 40, Loss: 89332.3203, Train: 83.70%, Valid: 71.84%, Test: 73.47%\n",
            "Epoch: 45, Loss: 83824.5781, Train: 84.55%, Valid: 72.20%, Test: 73.23%\n",
            "Epoch: 50, Loss: 79165.3203, Train: 84.91%, Valid: 73.16%, Test: 73.35%\n",
            "Epoch: 55, Loss: 75137.4609, Train: 85.63%, Valid: 73.41%, Test: 73.59%\n",
            "Epoch: 60, Loss: 71583.1641, Train: 85.93%, Valid: 73.29%, Test: 73.71%\n",
            "Epoch: 65, Loss: 68416.4297, Train: 86.53%, Valid: 73.65%, Test: 74.43%\n",
            "Epoch: 70, Loss: 65548.1641, Train: 86.65%, Valid: 73.29%, Test: 73.83%\n",
            "Epoch: 75, Loss: 62932.5781, Train: 86.71%, Valid: 73.41%, Test: 73.83%\n",
            "Epoch: 80, Loss: 60529.3359, Train: 86.77%, Valid: 73.04%, Test: 74.07%\n",
            "Epoch: 85, Loss: 58305.8672, Train: 86.65%, Valid: 73.41%, Test: 74.31%\n",
            "Epoch: 90, Loss: 56247.2188, Train: 86.77%, Valid: 72.92%, Test: 74.07%\n",
            "Epoch: 95, Loss: 54328.6875, Train: 86.83%, Valid: 73.04%, Test: 74.19%\n",
            "Epoch: 100, Loss: 52547.6719, Train: 86.77%, Valid: 73.16%, Test: 74.07%\n",
            "Epoch: 105, Loss: 50875.5195, Train: 86.77%, Valid: 73.29%, Test: 74.07%\n",
            "Epoch: 110, Loss: 49309.0117, Train: 86.71%, Valid: 73.29%, Test: 74.55%\n",
            "Epoch: 115, Loss: 47856.8203, Train: 86.77%, Valid: 73.29%, Test: 74.55%\n",
            "Epoch: 120, Loss: 46492.8438, Train: 86.77%, Valid: 73.29%, Test: 74.67%\n",
            "Epoch: 125, Loss: 45201.7031, Train: 86.65%, Valid: 73.53%, Test: 74.91%\n",
            "Epoch: 130, Loss: 43978.8359, Train: 86.65%, Valid: 73.65%, Test: 74.79%\n",
            "Epoch: 135, Loss: 42816.0312, Train: 86.77%, Valid: 73.65%, Test: 74.91%\n",
            "Epoch: 140, Loss: 41713.6094, Train: 86.77%, Valid: 73.41%, Test: 74.79%\n",
            "Epoch: 145, Loss: 40673.9453, Train: 86.77%, Valid: 73.41%, Test: 74.91%\n",
            "Epoch: 150, Loss: 39694.1484, Train: 86.71%, Valid: 73.16%, Test: 74.91%\n",
            "Epoch: 155, Loss: 38808.6367, Train: 86.65%, Valid: 73.16%, Test: 74.91%\n",
            "Epoch: 160, Loss: 38045.7578, Train: 86.71%, Valid: 73.16%, Test: 74.79%\n",
            "Epoch: 165, Loss: 37156.3984, Train: 86.71%, Valid: 73.16%, Test: 74.67%\n",
            "Epoch: 170, Loss: 36474.3359, Train: 86.83%, Valid: 73.29%, Test: 74.67%\n",
            "Epoch: 175, Loss: 35691.0078, Train: 86.83%, Valid: 73.16%, Test: 74.79%\n",
            "Epoch: 180, Loss: 34942.2383, Train: 86.83%, Valid: 73.41%, Test: 74.79%\n",
            "Epoch: 185, Loss: 34274.3711, Train: 86.83%, Valid: 73.41%, Test: 74.79%\n",
            "Epoch: 190, Loss: 33651.1055, Train: 86.71%, Valid: 73.16%, Test: 74.79%\n",
            "Epoch: 195, Loss: 33103.6992, Train: 86.71%, Valid: 73.29%, Test: 74.79%\n",
            "Run 02:\n",
            "Highest Train: 86.89\n",
            "Highest Valid: 73.65\n",
            "Highest Test: 75.03\n",
            "Chosen epoch: 65\n",
            "Final Train: 86.23\n",
            "Final Test: 74.43\n",
            "Epoch: 00, Loss: 913669.8750, Train: 18.64%, Valid: 19.13%, Test: 18.25%\n",
            "Epoch: 05, Loss: 221028.2031, Train: 27.66%, Valid: 27.68%, Test: 24.61%\n",
            "Epoch: 10, Loss: 171788.2344, Train: 54.90%, Valid: 47.41%, Test: 48.38%\n",
            "Epoch: 15, Loss: 146493.2500, Train: 62.00%, Valid: 53.67%, Test: 54.62%\n",
            "Epoch: 20, Loss: 130246.0547, Train: 73.90%, Valid: 66.19%, Test: 66.15%\n",
            "Epoch: 25, Loss: 118031.3438, Train: 78.59%, Valid: 69.68%, Test: 70.11%\n",
            "Epoch: 30, Loss: 108068.4609, Train: 79.68%, Valid: 70.76%, Test: 71.31%\n",
            "Epoch: 35, Loss: 99642.1172, Train: 80.28%, Valid: 71.12%, Test: 70.83%\n",
            "Epoch: 40, Loss: 92393.7812, Train: 80.34%, Valid: 71.24%, Test: 70.47%\n",
            "Epoch: 45, Loss: 85987.9375, Train: 80.58%, Valid: 71.60%, Test: 70.59%\n",
            "Epoch: 50, Loss: 80231.9688, Train: 81.00%, Valid: 71.72%, Test: 70.71%\n",
            "Epoch: 55, Loss: 75231.4844, Train: 81.00%, Valid: 71.96%, Test: 70.95%\n",
            "Epoch: 60, Loss: 70769.7969, Train: 81.24%, Valid: 71.84%, Test: 70.95%\n",
            "Epoch: 65, Loss: 66745.7422, Train: 81.24%, Valid: 71.84%, Test: 71.31%\n",
            "Epoch: 70, Loss: 63121.2617, Train: 81.30%, Valid: 71.96%, Test: 71.43%\n",
            "Epoch: 75, Loss: 59912.0430, Train: 81.54%, Valid: 71.72%, Test: 71.91%\n",
            "Epoch: 80, Loss: 57044.7500, Train: 81.60%, Valid: 71.36%, Test: 72.27%\n",
            "Epoch: 85, Loss: 54450.6836, Train: 81.72%, Valid: 71.24%, Test: 72.15%\n",
            "Epoch: 90, Loss: 52087.5273, Train: 81.84%, Valid: 71.48%, Test: 72.27%\n",
            "Epoch: 95, Loss: 49943.9570, Train: 81.60%, Valid: 71.60%, Test: 71.91%\n",
            "Epoch: 100, Loss: 47998.9766, Train: 81.72%, Valid: 71.48%, Test: 71.67%\n",
            "Epoch: 105, Loss: 46214.7188, Train: 81.54%, Valid: 71.48%, Test: 72.03%\n",
            "Epoch: 110, Loss: 44587.4336, Train: 81.54%, Valid: 71.84%, Test: 72.03%\n",
            "Epoch: 115, Loss: 43089.7383, Train: 81.66%, Valid: 71.96%, Test: 72.03%\n",
            "Epoch: 120, Loss: 41728.0586, Train: 81.84%, Valid: 72.08%, Test: 72.51%\n",
            "Epoch: 125, Loss: 40465.1289, Train: 81.90%, Valid: 72.32%, Test: 72.63%\n",
            "Epoch: 130, Loss: 39465.2188, Train: 81.90%, Valid: 72.44%, Test: 72.51%\n",
            "Epoch: 135, Loss: 38201.5078, Train: 82.08%, Valid: 72.68%, Test: 72.75%\n",
            "Epoch: 140, Loss: 37273.1953, Train: 82.14%, Valid: 72.56%, Test: 72.51%\n",
            "Epoch: 145, Loss: 36265.8047, Train: 82.20%, Valid: 72.44%, Test: 72.51%\n",
            "Epoch: 150, Loss: 35417.2227, Train: 82.14%, Valid: 72.44%, Test: 72.51%\n",
            "Epoch: 155, Loss: 34606.3477, Train: 82.02%, Valid: 71.96%, Test: 72.39%\n",
            "Epoch: 160, Loss: 33855.6016, Train: 82.20%, Valid: 71.84%, Test: 72.27%\n",
            "Epoch: 165, Loss: 33411.0352, Train: 82.38%, Valid: 71.84%, Test: 71.91%\n",
            "Epoch: 170, Loss: 32634.6562, Train: 82.32%, Valid: 71.96%, Test: 72.15%\n",
            "Epoch: 175, Loss: 31957.3379, Train: 82.32%, Valid: 71.96%, Test: 72.27%\n",
            "Epoch: 180, Loss: 31327.5742, Train: 82.32%, Valid: 71.96%, Test: 72.39%\n",
            "Epoch: 185, Loss: 30758.2773, Train: 82.38%, Valid: 71.96%, Test: 72.51%\n",
            "Epoch: 190, Loss: 30338.5977, Train: 82.50%, Valid: 71.84%, Test: 72.27%\n",
            "Epoch: 195, Loss: 29811.8164, Train: 82.68%, Valid: 71.84%, Test: 72.27%\n",
            "Run 03:\n",
            "Highest Train: 82.80\n",
            "Highest Valid: 72.68\n",
            "Highest Test: 72.75\n",
            "Chosen epoch: 136\n",
            "Final Train: 82.08\n",
            "Final Test: 72.75\n",
            "Epoch: 00, Loss: 925642.4375, Train: 10.40%, Valid: 10.35%, Test: 11.40%\n",
            "Epoch: 05, Loss: 196733.6406, Train: 31.81%, Valid: 31.65%, Test: 30.37%\n",
            "Epoch: 10, Loss: 156195.6562, Train: 41.25%, Valid: 39.47%, Test: 38.18%\n",
            "Epoch: 15, Loss: 135959.8750, Train: 53.22%, Valid: 49.10%, Test: 48.02%\n",
            "Epoch: 20, Loss: 122006.3359, Train: 65.66%, Valid: 60.53%, Test: 58.58%\n",
            "Epoch: 25, Loss: 111750.1484, Train: 72.04%, Valid: 66.06%, Test: 65.19%\n",
            "Epoch: 30, Loss: 103344.2891, Train: 78.11%, Valid: 69.19%, Test: 69.39%\n",
            "Epoch: 35, Loss: 96205.2266, Train: 80.40%, Valid: 71.72%, Test: 71.67%\n",
            "Epoch: 40, Loss: 90044.5234, Train: 81.42%, Valid: 71.72%, Test: 72.75%\n",
            "Epoch: 45, Loss: 84602.2109, Train: 82.02%, Valid: 71.60%, Test: 72.39%\n",
            "Epoch: 50, Loss: 79720.5469, Train: 82.08%, Valid: 71.84%, Test: 72.39%\n",
            "Epoch: 55, Loss: 75382.2812, Train: 82.32%, Valid: 72.08%, Test: 72.15%\n",
            "Epoch: 60, Loss: 71452.8203, Train: 82.26%, Valid: 71.96%, Test: 72.51%\n",
            "Epoch: 65, Loss: 67860.4688, Train: 82.56%, Valid: 71.96%, Test: 72.87%\n",
            "Epoch: 70, Loss: 64547.2383, Train: 82.92%, Valid: 71.96%, Test: 72.75%\n",
            "Epoch: 75, Loss: 61536.3008, Train: 83.04%, Valid: 72.20%, Test: 73.11%\n",
            "Epoch: 80, Loss: 58811.6211, Train: 83.46%, Valid: 72.08%, Test: 73.23%\n",
            "Epoch: 85, Loss: 56362.7305, Train: 83.58%, Valid: 71.84%, Test: 73.59%\n",
            "Epoch: 90, Loss: 54131.2617, Train: 83.82%, Valid: 72.32%, Test: 73.47%\n",
            "Epoch: 95, Loss: 52097.6797, Train: 83.88%, Valid: 72.44%, Test: 73.35%\n",
            "Epoch: 100, Loss: 50229.5977, Train: 83.88%, Valid: 72.56%, Test: 73.23%\n",
            "Epoch: 105, Loss: 48509.9258, Train: 84.19%, Valid: 72.56%, Test: 73.11%\n",
            "Epoch: 110, Loss: 46935.1211, Train: 84.06%, Valid: 72.44%, Test: 72.87%\n",
            "Epoch: 115, Loss: 45483.9961, Train: 84.25%, Valid: 72.56%, Test: 72.99%\n",
            "Epoch: 120, Loss: 44138.2773, Train: 84.43%, Valid: 72.56%, Test: 72.75%\n",
            "Epoch: 125, Loss: 42891.9297, Train: 84.43%, Valid: 72.56%, Test: 72.63%\n",
            "Epoch: 130, Loss: 41738.5234, Train: 84.43%, Valid: 72.56%, Test: 72.15%\n",
            "Epoch: 135, Loss: 40667.8203, Train: 84.37%, Valid: 72.56%, Test: 72.03%\n",
            "Epoch: 140, Loss: 39876.8320, Train: 84.61%, Valid: 72.68%, Test: 71.91%\n",
            "Epoch: 145, Loss: 39074.8594, Train: 84.61%, Valid: 72.68%, Test: 71.91%\n",
            "Epoch: 150, Loss: 38131.6797, Train: 84.55%, Valid: 72.68%, Test: 71.91%\n",
            "Epoch: 155, Loss: 37199.8047, Train: 84.73%, Valid: 72.80%, Test: 72.15%\n",
            "Epoch: 160, Loss: 36486.9531, Train: 84.79%, Valid: 72.68%, Test: 72.03%\n",
            "Epoch: 165, Loss: 35902.6250, Train: 84.91%, Valid: 72.56%, Test: 71.91%\n",
            "Epoch: 170, Loss: 35193.7461, Train: 84.79%, Valid: 72.80%, Test: 71.79%\n",
            "Epoch: 175, Loss: 34526.6719, Train: 84.85%, Valid: 72.92%, Test: 72.03%\n",
            "Epoch: 180, Loss: 33999.8516, Train: 84.97%, Valid: 72.56%, Test: 72.15%\n",
            "Epoch: 185, Loss: 33489.0703, Train: 85.15%, Valid: 72.68%, Test: 72.15%\n",
            "Epoch: 190, Loss: 32976.4570, Train: 85.03%, Valid: 72.56%, Test: 72.03%\n",
            "Epoch: 195, Loss: 32491.0703, Train: 85.15%, Valid: 72.32%, Test: 72.15%\n",
            "Run 04:\n",
            "Highest Train: 85.27\n",
            "Highest Valid: 72.92\n",
            "Highest Test: 73.59\n",
            "Chosen epoch: 176\n",
            "Final Train: 84.85\n",
            "Final Test: 72.03\n",
            "Epoch: 00, Loss: 910929.8750, Train: 18.64%, Valid: 20.94%, Test: 20.77%\n",
            "Epoch: 05, Loss: 208556.9375, Train: 35.54%, Valid: 29.96%, Test: 33.73%\n",
            "Epoch: 10, Loss: 164174.3281, Train: 47.50%, Valid: 42.84%, Test: 42.50%\n",
            "Epoch: 15, Loss: 142287.7656, Train: 64.64%, Valid: 56.08%, Test: 57.86%\n",
            "Epoch: 20, Loss: 127461.6875, Train: 71.62%, Valid: 63.42%, Test: 63.87%\n",
            "Epoch: 25, Loss: 115889.9297, Train: 78.89%, Valid: 70.04%, Test: 68.67%\n",
            "Epoch: 30, Loss: 106529.0625, Train: 82.68%, Valid: 71.96%, Test: 70.71%\n",
            "Epoch: 35, Loss: 98777.6094, Train: 84.37%, Valid: 73.53%, Test: 71.19%\n",
            "Epoch: 40, Loss: 92226.5938, Train: 85.45%, Valid: 73.89%, Test: 72.27%\n",
            "Epoch: 45, Loss: 86556.8828, Train: 85.99%, Valid: 74.13%, Test: 72.75%\n",
            "Epoch: 50, Loss: 81630.6562, Train: 86.11%, Valid: 74.01%, Test: 73.11%\n",
            "Epoch: 55, Loss: 77228.0781, Train: 86.71%, Valid: 74.01%, Test: 73.11%\n",
            "Epoch: 60, Loss: 73238.2969, Train: 86.83%, Valid: 74.25%, Test: 72.99%\n",
            "Epoch: 65, Loss: 69639.2578, Train: 86.89%, Valid: 74.13%, Test: 73.23%\n",
            "Epoch: 70, Loss: 66355.9922, Train: 87.13%, Valid: 74.13%, Test: 72.99%\n",
            "Epoch: 75, Loss: 63410.0625, Train: 87.55%, Valid: 74.13%, Test: 72.99%\n",
            "Epoch: 80, Loss: 60741.7305, Train: 87.55%, Valid: 74.13%, Test: 73.23%\n",
            "Epoch: 85, Loss: 58285.6953, Train: 87.49%, Valid: 74.01%, Test: 73.11%\n",
            "Epoch: 90, Loss: 56007.1992, Train: 87.67%, Valid: 73.77%, Test: 72.99%\n",
            "Epoch: 95, Loss: 53880.0234, Train: 87.85%, Valid: 73.53%, Test: 73.11%\n",
            "Epoch: 100, Loss: 51887.6562, Train: 88.03%, Valid: 73.41%, Test: 73.23%\n",
            "Epoch: 105, Loss: 50022.9688, Train: 87.91%, Valid: 73.53%, Test: 73.23%\n",
            "Epoch: 110, Loss: 48298.5312, Train: 88.03%, Valid: 73.89%, Test: 73.23%\n",
            "Epoch: 115, Loss: 46709.2734, Train: 87.97%, Valid: 73.89%, Test: 73.35%\n",
            "Epoch: 120, Loss: 45238.3047, Train: 88.09%, Valid: 74.01%, Test: 73.47%\n",
            "Epoch: 125, Loss: 43882.7734, Train: 88.15%, Valid: 74.13%, Test: 73.11%\n",
            "Epoch: 130, Loss: 42639.4766, Train: 88.21%, Valid: 74.13%, Test: 72.75%\n",
            "Epoch: 135, Loss: 41493.8828, Train: 88.21%, Valid: 74.25%, Test: 72.63%\n",
            "Epoch: 140, Loss: 40433.2188, Train: 88.15%, Valid: 74.13%, Test: 72.63%\n",
            "Epoch: 145, Loss: 39457.7031, Train: 88.21%, Valid: 74.25%, Test: 72.63%\n",
            "Epoch: 150, Loss: 39067.9062, Train: 88.21%, Valid: 74.25%, Test: 72.75%\n",
            "Epoch: 155, Loss: 37744.7344, Train: 88.39%, Valid: 74.37%, Test: 72.63%\n",
            "Epoch: 160, Loss: 37030.6406, Train: 88.39%, Valid: 74.25%, Test: 72.75%\n",
            "Epoch: 165, Loss: 36253.4453, Train: 88.39%, Valid: 74.25%, Test: 72.63%\n",
            "Epoch: 170, Loss: 35480.7344, Train: 88.33%, Valid: 74.37%, Test: 72.63%\n",
            "Epoch: 175, Loss: 34834.4766, Train: 88.45%, Valid: 74.49%, Test: 72.63%\n",
            "Epoch: 180, Loss: 34225.6172, Train: 88.39%, Valid: 74.49%, Test: 72.75%\n",
            "Epoch: 185, Loss: 33884.7969, Train: 88.39%, Valid: 74.37%, Test: 72.51%\n",
            "Epoch: 190, Loss: 33097.7930, Train: 88.39%, Valid: 74.25%, Test: 72.63%\n",
            "Epoch: 195, Loss: 32664.9121, Train: 88.45%, Valid: 74.13%, Test: 72.75%\n",
            "Run 05:\n",
            "Highest Train: 88.51\n",
            "Highest Valid: 74.49\n",
            "Highest Test: 73.47\n",
            "Chosen epoch: 176\n",
            "Final Train: 88.45\n",
            "Final Test: 72.63\n",
            "All runs:\n",
            "Highest Train: 85.54 ± 2.23\n",
            "Highest Test: 73.61 ± 0.85\n",
            "Highest Valid: 73.55 ± 0.75\n",
            "  Final Train: 85.04 ± 2.45\n",
            "   Final Test: 73.01 ± 0.90\n",
            "Saving results to logs/citeseer_edge.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 GKD/main.py --dataset citeseer --rand_split --use_bn --base_model gcn --mode train  --dist_mode pgkd --use_kd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ru-LOVtRKDIm",
        "outputId": "d923aeaf-5b7a-4ee8-e3b9-3ff349ff70f3"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(data_dir='data', dataset='citeseer', sub_dataset='', cpu=False, seed=42, train_prop=0.5, valid_prop=0.25, protocol='semi', rand_split=True, metric='acc', runs=5, epochs=200, hidden_channels=32, num_layers=3, gat_heads=8, out_heads=1, hops=1, lp_alpha=0.1, gpr_alpha=0.1, jk_type='max', directed=False, num_mlp_layers=1, display_step=5, cached=False, print_prop=False, priv_type='edge', priv_ratio=0.5, save_model=False, save_name='gcn', log_name='none', base_model='gcn', not_load_teacher=False, mode='train', dist_mode='pgkd', weight_decay=0.05, dropout=0.0, lr=0.01, use_bn=True, use_batch=False, batch_size=2048, oracle=False, device=0, alpha=0.5, delta=0.1, use_kd=True, beta=0.0, tau=1.0, kernel='sigmoid', t=1.0, include_last=False, s=2, m=1, lr2=0.001, sim='l2', ker_norm=False)\n",
            "cuda:0\n",
            "citeseer\n",
            "Num nodes: 3327\n",
            "torch.Size([3327, 1])\n",
            "num nodes 3327 | num classes 6 | num node feats 3703\n",
            "MODEL: GeoDist(\n",
            "  (k): Kernel(\n",
            "    (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  )\n",
            "  (teacher_gnn): ModuleList(\n",
            "    (0): Linear(in_features=3703, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (student_gnn): ModuleList(\n",
            "    (0): Linear(in_features=3703, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  (bns2d): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            ")\n",
            "Epoch: 00, Loss: 92568176.0000, Train: 15.27%, Valid: 15.52%, Test: 14.65%\n",
            "Epoch: 05, Loss: 26452406.0000, Train: 20.38%, Valid: 18.41%, Test: 19.69%\n",
            "Epoch: 10, Loss: 19788926.0000, Train: 38.91%, Valid: 34.06%, Test: 36.73%\n",
            "Epoch: 15, Loss: 16795580.0000, Train: 54.12%, Valid: 47.41%, Test: 51.26%\n",
            "Epoch: 20, Loss: 14939689.0000, Train: 65.18%, Valid: 58.48%, Test: 61.70%\n",
            "Epoch: 25, Loss: 13587813.0000, Train: 74.20%, Valid: 65.10%, Test: 67.35%\n",
            "Epoch: 30, Loss: 12537314.0000, Train: 77.33%, Valid: 67.63%, Test: 69.03%\n",
            "Epoch: 35, Loss: 11703909.0000, Train: 78.77%, Valid: 68.95%, Test: 70.23%\n",
            "Epoch: 40, Loss: 11034073.0000, Train: 79.19%, Valid: 70.76%, Test: 70.59%\n",
            "Epoch: 45, Loss: 10477247.0000, Train: 79.49%, Valid: 71.24%, Test: 70.83%\n",
            "Epoch: 50, Loss: 9996098.0000, Train: 80.10%, Valid: 71.60%, Test: 70.59%\n",
            "Epoch: 55, Loss: 9569718.0000, Train: 80.04%, Valid: 71.48%, Test: 70.71%\n",
            "Epoch: 60, Loss: 9206944.0000, Train: 80.10%, Valid: 71.72%, Test: 71.19%\n",
            "Epoch: 65, Loss: 8896930.0000, Train: 80.52%, Valid: 71.96%, Test: 71.19%\n",
            "Epoch: 70, Loss: 8615560.0000, Train: 80.70%, Valid: 72.08%, Test: 71.43%\n",
            "Epoch: 75, Loss: 8360630.5000, Train: 81.12%, Valid: 72.20%, Test: 71.55%\n",
            "Epoch: 80, Loss: 8126420.5000, Train: 81.18%, Valid: 71.72%, Test: 71.43%\n",
            "Epoch: 85, Loss: 7907773.5000, Train: 81.36%, Valid: 71.84%, Test: 71.55%\n",
            "Epoch: 90, Loss: 7703667.5000, Train: 81.66%, Valid: 71.72%, Test: 71.43%\n",
            "Epoch: 95, Loss: 7496433.5000, Train: 81.72%, Valid: 71.72%, Test: 71.31%\n",
            "Epoch: 100, Loss: 7320150.5000, Train: 81.66%, Valid: 71.60%, Test: 71.31%\n",
            "Epoch: 105, Loss: 7159331.5000, Train: 81.72%, Valid: 71.84%, Test: 71.31%\n",
            "Epoch: 110, Loss: 6995681.5000, Train: 81.72%, Valid: 71.84%, Test: 71.19%\n",
            "Epoch: 115, Loss: 6833971.0000, Train: 81.72%, Valid: 72.08%, Test: 71.19%\n",
            "Epoch: 120, Loss: 6687878.5000, Train: 81.66%, Valid: 72.08%, Test: 70.95%\n",
            "Epoch: 125, Loss: 6550399.0000, Train: 81.66%, Valid: 72.08%, Test: 71.07%\n",
            "Epoch: 130, Loss: 6419759.0000, Train: 81.72%, Valid: 71.96%, Test: 71.31%\n",
            "Epoch: 135, Loss: 6292377.5000, Train: 81.90%, Valid: 71.84%, Test: 71.07%\n",
            "Epoch: 140, Loss: 6177136.5000, Train: 81.90%, Valid: 71.96%, Test: 71.19%\n",
            "Epoch: 145, Loss: 6065747.5000, Train: 81.96%, Valid: 72.56%, Test: 70.71%\n",
            "Epoch: 150, Loss: 5952776.5000, Train: 81.96%, Valid: 72.92%, Test: 70.59%\n",
            "Epoch: 155, Loss: 5841853.5000, Train: 82.02%, Valid: 72.92%, Test: 70.71%\n",
            "Epoch: 160, Loss: 5730458.5000, Train: 81.96%, Valid: 72.92%, Test: 70.71%\n",
            "Epoch: 165, Loss: 5626381.5000, Train: 81.78%, Valid: 72.92%, Test: 70.47%\n",
            "Epoch: 170, Loss: 5532542.5000, Train: 81.72%, Valid: 72.92%, Test: 70.59%\n",
            "Epoch: 175, Loss: 5443445.5000, Train: 81.60%, Valid: 73.04%, Test: 70.71%\n",
            "Epoch: 180, Loss: 5355523.0000, Train: 81.60%, Valid: 73.04%, Test: 70.47%\n",
            "Epoch: 185, Loss: 5269941.5000, Train: 81.48%, Valid: 72.92%, Test: 70.83%\n",
            "Epoch: 190, Loss: 5174189.5000, Train: 81.42%, Valid: 72.68%, Test: 70.95%\n",
            "Epoch: 195, Loss: 5081884.5000, Train: 81.42%, Valid: 72.56%, Test: 70.59%\n",
            "Run 01:\n",
            "Highest Train: 82.02\n",
            "Highest Valid: 73.16\n",
            "Highest Test: 71.67\n",
            "Chosen epoch: 178\n",
            "Final Train: 81.54\n",
            "Final Test: 70.71\n",
            "Epoch: 00, Loss: 124309144.0000, Train: 14.91%, Valid: 16.49%, Test: 17.41%\n",
            "Epoch: 05, Loss: 34465104.0000, Train: 26.34%, Valid: 25.27%, Test: 24.61%\n",
            "Epoch: 10, Loss: 24382988.0000, Train: 37.88%, Valid: 33.94%, Test: 33.97%\n",
            "Epoch: 15, Loss: 19854290.0000, Train: 48.11%, Valid: 42.48%, Test: 43.58%\n",
            "Epoch: 20, Loss: 17041400.0000, Train: 63.50%, Valid: 56.80%, Test: 58.46%\n",
            "Epoch: 25, Loss: 15137215.0000, Train: 75.65%, Valid: 66.79%, Test: 66.51%\n",
            "Epoch: 30, Loss: 13691735.0000, Train: 79.07%, Valid: 68.71%, Test: 68.79%\n",
            "Epoch: 35, Loss: 12529688.0000, Train: 80.40%, Valid: 70.04%, Test: 70.23%\n",
            "Epoch: 40, Loss: 11590924.0000, Train: 81.06%, Valid: 70.52%, Test: 71.43%\n",
            "Epoch: 45, Loss: 10814928.0000, Train: 81.36%, Valid: 70.40%, Test: 71.67%\n",
            "Epoch: 50, Loss: 10182654.0000, Train: 81.60%, Valid: 70.28%, Test: 71.79%\n",
            "Epoch: 55, Loss: 9648699.0000, Train: 81.84%, Valid: 71.24%, Test: 71.91%\n",
            "Epoch: 60, Loss: 9201274.0000, Train: 81.78%, Valid: 71.48%, Test: 72.03%\n",
            "Epoch: 65, Loss: 8810614.0000, Train: 81.90%, Valid: 71.36%, Test: 72.03%\n",
            "Epoch: 70, Loss: 8457700.0000, Train: 81.78%, Valid: 70.88%, Test: 71.67%\n",
            "Epoch: 75, Loss: 8150051.0000, Train: 81.60%, Valid: 71.00%, Test: 71.67%\n",
            "Epoch: 80, Loss: 7876095.5000, Train: 81.54%, Valid: 71.00%, Test: 71.31%\n",
            "Epoch: 85, Loss: 7635335.5000, Train: 81.78%, Valid: 71.24%, Test: 71.31%\n",
            "Epoch: 90, Loss: 7422405.5000, Train: 81.84%, Valid: 71.12%, Test: 71.43%\n",
            "Epoch: 95, Loss: 7232026.5000, Train: 81.60%, Valid: 70.88%, Test: 71.55%\n",
            "Epoch: 100, Loss: 7055682.5000, Train: 81.72%, Valid: 71.12%, Test: 71.43%\n",
            "Epoch: 105, Loss: 6895984.0000, Train: 81.48%, Valid: 70.88%, Test: 71.43%\n",
            "Epoch: 110, Loss: 6752768.5000, Train: 81.48%, Valid: 71.00%, Test: 71.55%\n",
            "Epoch: 115, Loss: 6619687.0000, Train: 81.42%, Valid: 71.00%, Test: 71.43%\n",
            "Epoch: 120, Loss: 6493284.0000, Train: 81.42%, Valid: 71.12%, Test: 71.43%\n",
            "Epoch: 125, Loss: 6374650.5000, Train: 81.48%, Valid: 71.00%, Test: 71.31%\n",
            "Epoch: 130, Loss: 6265313.0000, Train: 81.42%, Valid: 71.00%, Test: 71.43%\n",
            "Epoch: 135, Loss: 6169388.5000, Train: 81.54%, Valid: 71.00%, Test: 71.31%\n",
            "Epoch: 140, Loss: 6082728.0000, Train: 81.60%, Valid: 71.12%, Test: 71.31%\n",
            "Epoch: 145, Loss: 6004124.5000, Train: 81.66%, Valid: 70.64%, Test: 71.31%\n",
            "Epoch: 150, Loss: 5909814.5000, Train: 81.78%, Valid: 70.76%, Test: 71.79%\n",
            "Epoch: 155, Loss: 5831884.5000, Train: 81.72%, Valid: 70.76%, Test: 71.67%\n",
            "Epoch: 160, Loss: 5766060.0000, Train: 81.78%, Valid: 70.28%, Test: 71.67%\n",
            "Epoch: 165, Loss: 5703656.5000, Train: 81.72%, Valid: 70.40%, Test: 71.31%\n",
            "Epoch: 170, Loss: 5645637.5000, Train: 81.66%, Valid: 70.40%, Test: 71.19%\n",
            "Epoch: 175, Loss: 5592602.0000, Train: 81.42%, Valid: 70.04%, Test: 71.07%\n",
            "Epoch: 180, Loss: 5546994.0000, Train: 81.48%, Valid: 70.04%, Test: 70.95%\n",
            "Epoch: 185, Loss: 5506040.5000, Train: 81.42%, Valid: 69.92%, Test: 71.31%\n",
            "Epoch: 190, Loss: 5466745.5000, Train: 81.24%, Valid: 69.92%, Test: 71.55%\n",
            "Epoch: 195, Loss: 5428682.5000, Train: 80.94%, Valid: 70.04%, Test: 71.55%\n",
            "Run 02:\n",
            "Highest Train: 81.96\n",
            "Highest Valid: 71.48\n",
            "Highest Test: 72.15\n",
            "Chosen epoch: 60\n",
            "Final Train: 81.84\n",
            "Final Test: 72.03\n",
            "Epoch: 00, Loss: 103887272.0000, Train: 23.81%, Valid: 23.95%, Test: 23.05%\n",
            "Epoch: 05, Loss: 32854652.0000, Train: 27.84%, Valid: 27.44%, Test: 25.21%\n",
            "Epoch: 10, Loss: 23181014.0000, Train: 40.65%, Valid: 38.75%, Test: 36.01%\n",
            "Epoch: 15, Loss: 18545408.0000, Train: 53.76%, Valid: 51.87%, Test: 50.42%\n",
            "Epoch: 20, Loss: 15822017.0000, Train: 65.18%, Valid: 60.41%, Test: 59.30%\n",
            "Epoch: 25, Loss: 14027086.0000, Train: 70.72%, Valid: 64.50%, Test: 65.43%\n",
            "Epoch: 30, Loss: 12747593.0000, Train: 74.32%, Valid: 67.63%, Test: 67.47%\n",
            "Epoch: 35, Loss: 11748724.0000, Train: 76.97%, Valid: 69.68%, Test: 69.39%\n",
            "Epoch: 40, Loss: 10956656.0000, Train: 78.23%, Valid: 69.92%, Test: 69.99%\n",
            "Epoch: 45, Loss: 10306484.0000, Train: 78.65%, Valid: 69.80%, Test: 69.99%\n",
            "Epoch: 50, Loss: 9746794.0000, Train: 78.83%, Valid: 69.68%, Test: 70.59%\n",
            "Epoch: 55, Loss: 9274543.0000, Train: 79.37%, Valid: 69.68%, Test: 70.35%\n",
            "Epoch: 60, Loss: 8859712.0000, Train: 79.98%, Valid: 69.55%, Test: 70.47%\n",
            "Epoch: 65, Loss: 8511106.0000, Train: 80.16%, Valid: 70.04%, Test: 70.59%\n",
            "Epoch: 70, Loss: 8216926.0000, Train: 80.28%, Valid: 70.88%, Test: 70.11%\n",
            "Epoch: 75, Loss: 7958255.5000, Train: 80.52%, Valid: 70.64%, Test: 70.11%\n",
            "Epoch: 80, Loss: 7737183.5000, Train: 80.40%, Valid: 70.52%, Test: 69.87%\n",
            "Epoch: 85, Loss: 7545195.5000, Train: 80.64%, Valid: 70.64%, Test: 70.47%\n",
            "Epoch: 90, Loss: 7369961.5000, Train: 80.70%, Valid: 71.00%, Test: 70.83%\n",
            "Epoch: 95, Loss: 7210632.5000, Train: 80.82%, Valid: 71.12%, Test: 71.07%\n",
            "Epoch: 100, Loss: 7065683.5000, Train: 80.94%, Valid: 71.12%, Test: 71.31%\n",
            "Epoch: 105, Loss: 6928832.0000, Train: 80.88%, Valid: 71.00%, Test: 71.07%\n",
            "Epoch: 110, Loss: 6797513.5000, Train: 81.24%, Valid: 71.12%, Test: 70.95%\n",
            "Epoch: 115, Loss: 6679890.5000, Train: 81.30%, Valid: 71.36%, Test: 70.71%\n",
            "Epoch: 120, Loss: 6572056.0000, Train: 81.18%, Valid: 71.24%, Test: 70.71%\n",
            "Epoch: 125, Loss: 6469943.0000, Train: 81.24%, Valid: 71.24%, Test: 70.83%\n",
            "Epoch: 130, Loss: 6374984.5000, Train: 81.24%, Valid: 71.48%, Test: 70.83%\n",
            "Epoch: 135, Loss: 6293830.5000, Train: 81.06%, Valid: 71.36%, Test: 70.83%\n",
            "Epoch: 140, Loss: 6215414.5000, Train: 80.94%, Valid: 71.24%, Test: 70.71%\n",
            "Epoch: 145, Loss: 6136896.0000, Train: 80.88%, Valid: 71.24%, Test: 70.71%\n",
            "Epoch: 150, Loss: 6063894.5000, Train: 81.00%, Valid: 71.00%, Test: 70.47%\n",
            "Epoch: 155, Loss: 5995982.5000, Train: 81.12%, Valid: 71.00%, Test: 70.59%\n",
            "Epoch: 160, Loss: 5926513.5000, Train: 81.18%, Valid: 71.12%, Test: 70.59%\n",
            "Epoch: 165, Loss: 5855293.5000, Train: 81.06%, Valid: 71.00%, Test: 70.23%\n",
            "Epoch: 170, Loss: 5787535.5000, Train: 81.00%, Valid: 70.76%, Test: 70.23%\n",
            "Epoch: 175, Loss: 5725270.5000, Train: 81.12%, Valid: 70.88%, Test: 69.99%\n",
            "Epoch: 180, Loss: 5651075.5000, Train: 81.12%, Valid: 71.00%, Test: 70.11%\n",
            "Epoch: 185, Loss: 5581000.0000, Train: 81.18%, Valid: 70.76%, Test: 70.23%\n",
            "Epoch: 190, Loss: 5523959.0000, Train: 81.36%, Valid: 71.12%, Test: 70.47%\n",
            "Epoch: 195, Loss: 5471148.5000, Train: 81.54%, Valid: 71.24%, Test: 70.83%\n",
            "Run 03:\n",
            "Highest Train: 81.66\n",
            "Highest Valid: 71.48\n",
            "Highest Test: 71.43\n",
            "Chosen epoch: 130\n",
            "Final Train: 81.24\n",
            "Final Test: 70.83\n",
            "Epoch: 00, Loss: 85334504.0000, Train: 13.17%, Valid: 15.88%, Test: 13.33%\n",
            "Epoch: 05, Loss: 28637062.0000, Train: 23.51%, Valid: 25.03%, Test: 24.13%\n",
            "Epoch: 10, Loss: 21073818.0000, Train: 32.77%, Valid: 33.69%, Test: 31.21%\n",
            "Epoch: 15, Loss: 17583412.0000, Train: 43.96%, Valid: 41.28%, Test: 41.54%\n",
            "Epoch: 20, Loss: 15453353.0000, Train: 60.01%, Valid: 56.32%, Test: 55.94%\n",
            "Epoch: 25, Loss: 13938392.0000, Train: 73.48%, Valid: 67.75%, Test: 63.99%\n",
            "Epoch: 30, Loss: 12793290.0000, Train: 77.57%, Valid: 70.52%, Test: 67.83%\n",
            "Epoch: 35, Loss: 11910167.0000, Train: 78.47%, Valid: 70.76%, Test: 69.03%\n",
            "Epoch: 40, Loss: 11200667.0000, Train: 79.13%, Valid: 71.48%, Test: 70.11%\n",
            "Epoch: 45, Loss: 10633568.0000, Train: 79.68%, Valid: 72.08%, Test: 70.23%\n",
            "Epoch: 50, Loss: 10161376.0000, Train: 79.98%, Valid: 71.96%, Test: 70.95%\n",
            "Epoch: 55, Loss: 9755360.0000, Train: 80.58%, Valid: 71.48%, Test: 70.23%\n",
            "Epoch: 60, Loss: 9388091.0000, Train: 81.06%, Valid: 70.88%, Test: 70.83%\n",
            "Epoch: 65, Loss: 9075676.0000, Train: 81.24%, Valid: 70.88%, Test: 70.95%\n",
            "Epoch: 70, Loss: 8797502.0000, Train: 81.36%, Valid: 71.24%, Test: 70.71%\n",
            "Epoch: 75, Loss: 8530514.0000, Train: 81.60%, Valid: 71.12%, Test: 70.83%\n",
            "Epoch: 80, Loss: 8290003.0000, Train: 81.84%, Valid: 71.12%, Test: 70.71%\n",
            "Epoch: 85, Loss: 8091697.5000, Train: 82.02%, Valid: 71.36%, Test: 70.83%\n",
            "Epoch: 90, Loss: 7906604.0000, Train: 82.50%, Valid: 71.12%, Test: 71.19%\n",
            "Epoch: 95, Loss: 7749590.5000, Train: 82.50%, Valid: 71.24%, Test: 71.55%\n",
            "Epoch: 100, Loss: 7634377.5000, Train: 82.32%, Valid: 71.60%, Test: 71.55%\n",
            "Epoch: 105, Loss: 7552768.5000, Train: 82.50%, Valid: 71.24%, Test: 71.55%\n",
            "Epoch: 110, Loss: 7494567.5000, Train: 82.68%, Valid: 71.24%, Test: 71.43%\n",
            "Epoch: 115, Loss: 7442992.5000, Train: 82.74%, Valid: 71.48%, Test: 71.67%\n",
            "Epoch: 120, Loss: 7393073.5000, Train: 83.04%, Valid: 71.24%, Test: 71.67%\n",
            "Epoch: 125, Loss: 7346048.5000, Train: 82.98%, Valid: 71.48%, Test: 71.55%\n",
            "Epoch: 130, Loss: 7306594.5000, Train: 83.10%, Valid: 71.72%, Test: 71.43%\n",
            "Epoch: 135, Loss: 7259145.5000, Train: 83.28%, Valid: 72.08%, Test: 71.07%\n",
            "Epoch: 140, Loss: 7193232.5000, Train: 83.40%, Valid: 72.68%, Test: 71.31%\n",
            "Epoch: 145, Loss: 7101020.0000, Train: 83.64%, Valid: 72.56%, Test: 71.43%\n",
            "Epoch: 150, Loss: 7014194.0000, Train: 83.76%, Valid: 72.44%, Test: 71.31%\n",
            "Epoch: 155, Loss: 6938392.5000, Train: 83.64%, Valid: 72.32%, Test: 71.07%\n",
            "Epoch: 160, Loss: 6870760.0000, Train: 83.94%, Valid: 72.32%, Test: 71.07%\n",
            "Epoch: 165, Loss: 6800659.5000, Train: 83.88%, Valid: 72.20%, Test: 71.31%\n",
            "Epoch: 170, Loss: 6728114.5000, Train: 83.82%, Valid: 71.96%, Test: 71.43%\n",
            "Epoch: 175, Loss: 6637218.5000, Train: 83.88%, Valid: 71.84%, Test: 71.31%\n",
            "Epoch: 180, Loss: 6512606.0000, Train: 84.13%, Valid: 72.08%, Test: 71.43%\n",
            "Epoch: 185, Loss: 6381307.5000, Train: 84.06%, Valid: 72.20%, Test: 70.95%\n",
            "Epoch: 190, Loss: 6267524.5000, Train: 84.00%, Valid: 72.32%, Test: 70.83%\n",
            "Epoch: 195, Loss: 6149559.5000, Train: 84.13%, Valid: 72.32%, Test: 70.95%\n",
            "Run 04:\n",
            "Highest Train: 84.19\n",
            "Highest Valid: 72.68\n",
            "Highest Test: 71.67\n",
            "Chosen epoch: 140\n",
            "Final Train: 83.46\n",
            "Final Test: 71.31\n",
            "Epoch: 00, Loss: 106326832.0000, Train: 21.53%, Valid: 23.10%, Test: 20.77%\n",
            "Epoch: 05, Loss: 34525640.0000, Train: 20.38%, Valid: 24.07%, Test: 21.97%\n",
            "Epoch: 10, Loss: 25939226.0000, Train: 30.19%, Valid: 29.72%, Test: 27.73%\n",
            "Epoch: 15, Loss: 21255220.0000, Train: 44.08%, Valid: 40.67%, Test: 39.38%\n",
            "Epoch: 20, Loss: 18330550.0000, Train: 58.27%, Valid: 51.87%, Test: 51.86%\n",
            "Epoch: 25, Loss: 16247629.0000, Train: 70.23%, Valid: 62.58%, Test: 61.94%\n",
            "Epoch: 30, Loss: 14699494.0000, Train: 74.92%, Valid: 66.55%, Test: 65.67%\n",
            "Epoch: 35, Loss: 13546722.0000, Train: 77.57%, Valid: 68.71%, Test: 67.95%\n",
            "Epoch: 40, Loss: 12629134.0000, Train: 79.31%, Valid: 69.80%, Test: 68.91%\n",
            "Epoch: 45, Loss: 11865373.0000, Train: 80.52%, Valid: 70.40%, Test: 69.63%\n",
            "Epoch: 50, Loss: 11220794.0000, Train: 81.72%, Valid: 72.08%, Test: 70.47%\n",
            "Epoch: 55, Loss: 10662576.0000, Train: 83.34%, Valid: 73.29%, Test: 71.43%\n",
            "Epoch: 60, Loss: 10204240.0000, Train: 83.70%, Valid: 73.29%, Test: 71.43%\n",
            "Epoch: 65, Loss: 9796039.0000, Train: 84.25%, Valid: 73.29%, Test: 71.67%\n",
            "Epoch: 70, Loss: 9413704.0000, Train: 84.55%, Valid: 73.53%, Test: 71.91%\n",
            "Epoch: 75, Loss: 9056185.0000, Train: 84.67%, Valid: 73.53%, Test: 71.79%\n",
            "Epoch: 80, Loss: 8734024.0000, Train: 84.91%, Valid: 73.53%, Test: 72.15%\n",
            "Epoch: 85, Loss: 8452810.0000, Train: 85.15%, Valid: 73.53%, Test: 72.51%\n",
            "Epoch: 90, Loss: 8188030.5000, Train: 85.15%, Valid: 73.65%, Test: 72.51%\n",
            "Epoch: 95, Loss: 7960954.0000, Train: 85.15%, Valid: 73.89%, Test: 72.63%\n",
            "Epoch: 100, Loss: 7749467.0000, Train: 85.27%, Valid: 73.65%, Test: 72.51%\n",
            "Epoch: 105, Loss: 7551771.5000, Train: 85.57%, Valid: 73.77%, Test: 72.87%\n",
            "Epoch: 110, Loss: 7369241.5000, Train: 85.75%, Valid: 74.01%, Test: 72.99%\n",
            "Epoch: 115, Loss: 7195535.5000, Train: 86.05%, Valid: 73.77%, Test: 73.11%\n",
            "Epoch: 120, Loss: 7019784.5000, Train: 86.11%, Valid: 73.89%, Test: 72.87%\n",
            "Epoch: 125, Loss: 6848785.5000, Train: 86.05%, Valid: 73.89%, Test: 72.63%\n",
            "Epoch: 130, Loss: 6688279.5000, Train: 86.11%, Valid: 73.41%, Test: 72.39%\n",
            "Epoch: 135, Loss: 6522629.5000, Train: 86.17%, Valid: 73.53%, Test: 72.27%\n",
            "Epoch: 140, Loss: 6358837.5000, Train: 86.29%, Valid: 73.53%, Test: 72.27%\n",
            "Epoch: 145, Loss: 6204949.5000, Train: 86.29%, Valid: 73.41%, Test: 72.27%\n",
            "Epoch: 150, Loss: 6064083.5000, Train: 86.29%, Valid: 73.53%, Test: 72.15%\n",
            "Epoch: 155, Loss: 5932605.5000, Train: 86.41%, Valid: 73.53%, Test: 71.91%\n",
            "Epoch: 160, Loss: 5805841.5000, Train: 86.35%, Valid: 73.41%, Test: 71.79%\n",
            "Epoch: 165, Loss: 5683447.5000, Train: 86.29%, Valid: 73.41%, Test: 71.79%\n",
            "Epoch: 170, Loss: 5567849.5000, Train: 86.17%, Valid: 73.16%, Test: 71.79%\n",
            "Epoch: 175, Loss: 5452800.5000, Train: 86.41%, Valid: 73.29%, Test: 72.15%\n",
            "Epoch: 180, Loss: 5344580.5000, Train: 86.53%, Valid: 73.16%, Test: 72.27%\n",
            "Epoch: 185, Loss: 5242583.5000, Train: 86.47%, Valid: 72.92%, Test: 72.51%\n",
            "Epoch: 190, Loss: 5147619.5000, Train: 86.53%, Valid: 72.92%, Test: 72.51%\n",
            "Epoch: 195, Loss: 5058320.5000, Train: 86.41%, Valid: 72.80%, Test: 71.91%\n",
            "Run 05:\n",
            "Highest Train: 86.65\n",
            "Highest Valid: 74.13\n",
            "Highest Test: 73.11\n",
            "Chosen epoch: 124\n",
            "Final Train: 86.11\n",
            "Final Test: 72.75\n",
            "All runs:\n",
            "Highest Train: 83.30 ± 2.13\n",
            "Highest Test: 72.00 ± 0.67\n",
            "Highest Valid: 72.59 ± 1.14\n",
            "  Final Train: 82.84 ± 2.02\n",
            "   Final Test: 71.52 ± 0.86\n",
            "Saving results to logs/citeseer_edge.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Facebook100 - Binary Dataset"
      ],
      "metadata": {
        "id": "nIYFsdCMY3NA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pre-Train Settings"
      ],
      "metadata": {
        "id": "ctJ8IplXZGu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 GKD/main.py --dataset fb100 --rand_split --use_bn --base_model gcn --mode pretrain --dist_mode no --save_model --lr 0.0001"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64K_pUtyZAjA",
        "outputId": "aa6e508c-416e-449f-b105-1611d2876eeb"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(data_dir='data', dataset='fb100', sub_dataset='', cpu=False, seed=42, train_prop=0.5, valid_prop=0.25, protocol='semi', rand_split=True, metric='acc', runs=5, epochs=200, hidden_channels=32, num_layers=3, gat_heads=8, out_heads=1, hops=1, lp_alpha=0.1, gpr_alpha=0.1, jk_type='max', directed=False, num_mlp_layers=1, display_step=5, cached=False, print_prop=False, priv_type='edge', priv_ratio=0.5, save_model=True, save_name='gcn', log_name='none', base_model='gcn', not_load_teacher=False, mode='pretrain', dist_mode='no', weight_decay=0.05, dropout=0.0, lr=0.0001, use_bn=True, use_batch=False, batch_size=2048, oracle=False, device=0, alpha=0.5, delta=0.1, use_kd=False, beta=0.0, tau=1.0, kernel='sigmoid', t=1.0, include_last=False, s=2, m=1, lr2=0.001, sim='l2', ker_norm=False)\n",
            "cuda:0\n",
            "fb100\n",
            "Invalid sub_dataname, deferring to Penn94 graph\n",
            "/content/GKD/dataset.py:204: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  edge_index = torch.tensor(A.nonzero(), dtype=torch.long)\n",
            "torch.Size([41554, 1])\n",
            "num nodes 41554 | num classes 2 | num node feats 7833\n",
            "MODEL: GeoDist(\n",
            "  (k): Kernel(\n",
            "    (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  )\n",
            "  (teacher_gnn): ModuleList(\n",
            "    (0): Linear(in_features=7833, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (student_gnn): ModuleList(\n",
            "    (0): Linear(in_features=7833, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  (bns2d): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            ")\n",
            "Epoch: 00, Loss: 0.8001, Train: 50.51%, Valid: 49.08%, Test: 49.69%\n",
            "Epoch: 05, Loss: 0.7462, Train: 54.70%, Valid: 52.75%, Test: 54.59%\n",
            "Epoch: 10, Loss: 0.7280, Train: 56.92%, Valid: 55.13%, Test: 55.85%\n",
            "Epoch: 15, Loss: 0.7117, Train: 59.27%, Valid: 57.04%, Test: 57.29%\n",
            "Epoch: 20, Loss: 0.6992, Train: 60.49%, Valid: 58.08%, Test: 58.67%\n",
            "Epoch: 25, Loss: 0.6884, Train: 61.65%, Valid: 58.97%, Test: 59.77%\n",
            "Epoch: 30, Loss: 0.6783, Train: 62.77%, Valid: 59.95%, Test: 60.54%\n",
            "Epoch: 35, Loss: 0.6692, Train: 63.72%, Valid: 60.70%, Test: 61.19%\n",
            "Epoch: 40, Loss: 0.6605, Train: 64.71%, Valid: 61.37%, Test: 61.70%\n",
            "Epoch: 45, Loss: 0.6525, Train: 65.34%, Valid: 61.96%, Test: 62.29%\n",
            "Epoch: 50, Loss: 0.6453, Train: 65.99%, Valid: 62.41%, Test: 62.72%\n",
            "Epoch: 55, Loss: 0.6385, Train: 66.65%, Valid: 62.91%, Test: 63.08%\n",
            "Epoch: 60, Loss: 0.6322, Train: 67.11%, Valid: 63.61%, Test: 63.57%\n",
            "Epoch: 65, Loss: 0.6263, Train: 67.50%, Valid: 63.87%, Test: 63.99%\n",
            "Epoch: 70, Loss: 0.6207, Train: 68.16%, Valid: 64.27%, Test: 64.39%\n",
            "Epoch: 75, Loss: 0.6154, Train: 68.50%, Valid: 64.52%, Test: 64.86%\n",
            "Epoch: 80, Loss: 0.6104, Train: 68.85%, Valid: 64.91%, Test: 65.08%\n",
            "Epoch: 85, Loss: 0.6058, Train: 69.16%, Valid: 65.10%, Test: 65.27%\n",
            "Epoch: 90, Loss: 0.6013, Train: 69.51%, Valid: 65.38%, Test: 65.42%\n",
            "Epoch: 95, Loss: 0.5971, Train: 69.95%, Valid: 65.61%, Test: 65.53%\n",
            "Epoch: 100, Loss: 0.5932, Train: 70.23%, Valid: 65.77%, Test: 65.69%\n",
            "Epoch: 105, Loss: 0.5894, Train: 70.64%, Valid: 65.92%, Test: 65.66%\n",
            "Epoch: 110, Loss: 0.5858, Train: 70.92%, Valid: 66.11%, Test: 65.79%\n",
            "Epoch: 115, Loss: 0.5823, Train: 71.24%, Valid: 66.15%, Test: 65.94%\n",
            "Epoch: 120, Loss: 0.5790, Train: 71.66%, Valid: 66.46%, Test: 66.07%\n",
            "Epoch: 125, Loss: 0.5758, Train: 72.00%, Valid: 66.63%, Test: 66.15%\n",
            "Epoch: 130, Loss: 0.5727, Train: 72.39%, Valid: 66.73%, Test: 66.26%\n",
            "Epoch: 135, Loss: 0.5697, Train: 72.75%, Valid: 66.83%, Test: 66.20%\n",
            "Epoch: 140, Loss: 0.5667, Train: 73.07%, Valid: 66.98%, Test: 66.44%\n",
            "Epoch: 145, Loss: 0.5637, Train: 73.43%, Valid: 67.07%, Test: 66.76%\n",
            "Epoch: 150, Loss: 0.5607, Train: 73.73%, Valid: 67.36%, Test: 66.86%\n",
            "Epoch: 155, Loss: 0.5578, Train: 74.24%, Valid: 67.67%, Test: 66.85%\n",
            "Epoch: 160, Loss: 0.5548, Train: 74.59%, Valid: 67.91%, Test: 66.89%\n",
            "Epoch: 165, Loss: 0.5518, Train: 74.85%, Valid: 68.01%, Test: 66.97%\n",
            "Epoch: 170, Loss: 0.5488, Train: 75.07%, Valid: 68.11%, Test: 67.11%\n",
            "Epoch: 175, Loss: 0.5459, Train: 75.41%, Valid: 68.15%, Test: 67.32%\n",
            "Epoch: 180, Loss: 0.5433, Train: 75.96%, Valid: 68.49%, Test: 67.43%\n",
            "Epoch: 185, Loss: 0.5403, Train: 76.34%, Valid: 68.77%, Test: 67.45%\n",
            "Epoch: 190, Loss: 0.5373, Train: 76.95%, Valid: 68.94%, Test: 67.69%\n",
            "Epoch: 195, Loss: 0.5362, Train: 77.43%, Valid: 69.21%, Test: 67.68%\n",
            "Run 01:\n",
            "Highest Train: 77.62\n",
            "Highest Valid: 69.40\n",
            "Highest Test: 67.87\n",
            "Chosen epoch: 199\n",
            "Final Train: 77.62\n",
            "Final Test: 67.87\n",
            "Epoch: 00, Loss: 0.7673, Train: 49.43%, Valid: 49.04%, Test: 49.05%\n",
            "Epoch: 05, Loss: 0.7288, Train: 50.53%, Valid: 50.26%, Test: 50.02%\n",
            "Epoch: 10, Loss: 0.7114, Train: 53.47%, Valid: 52.92%, Test: 52.16%\n",
            "Epoch: 15, Loss: 0.6978, Train: 55.42%, Valid: 54.99%, Test: 54.55%\n",
            "Epoch: 20, Loss: 0.6882, Train: 56.20%, Valid: 55.93%, Test: 55.39%\n",
            "Epoch: 25, Loss: 0.6804, Train: 57.11%, Valid: 56.54%, Test: 56.14%\n",
            "Epoch: 30, Loss: 0.6737, Train: 58.31%, Valid: 57.06%, Test: 56.81%\n",
            "Epoch: 35, Loss: 0.6674, Train: 59.44%, Valid: 58.32%, Test: 57.77%\n",
            "Epoch: 40, Loss: 0.6614, Train: 60.68%, Valid: 59.21%, Test: 58.65%\n",
            "Epoch: 45, Loss: 0.6554, Train: 61.82%, Valid: 59.93%, Test: 59.12%\n",
            "Epoch: 50, Loss: 0.6493, Train: 62.98%, Valid: 60.95%, Test: 60.07%\n",
            "Epoch: 55, Loss: 0.6431, Train: 63.92%, Valid: 61.59%, Test: 60.70%\n",
            "Epoch: 60, Loss: 0.6370, Train: 64.71%, Valid: 61.94%, Test: 61.22%\n",
            "Epoch: 65, Loss: 0.6310, Train: 65.68%, Valid: 62.84%, Test: 61.73%\n",
            "Epoch: 70, Loss: 0.6254, Train: 66.52%, Valid: 63.45%, Test: 62.00%\n",
            "Epoch: 75, Loss: 0.6201, Train: 67.41%, Valid: 63.97%, Test: 62.62%\n",
            "Epoch: 80, Loss: 0.6152, Train: 68.03%, Valid: 64.24%, Test: 63.08%\n",
            "Epoch: 85, Loss: 0.6107, Train: 68.67%, Valid: 64.68%, Test: 63.51%\n",
            "Epoch: 90, Loss: 0.6065, Train: 69.18%, Valid: 65.12%, Test: 63.96%\n",
            "Epoch: 95, Loss: 0.6028, Train: 69.76%, Valid: 65.34%, Test: 64.62%\n",
            "Epoch: 100, Loss: 0.5992, Train: 70.25%, Valid: 65.54%, Test: 64.87%\n",
            "Epoch: 105, Loss: 0.5959, Train: 70.71%, Valid: 65.82%, Test: 65.16%\n",
            "Epoch: 110, Loss: 0.5928, Train: 71.16%, Valid: 65.95%, Test: 65.27%\n",
            "Epoch: 115, Loss: 0.5898, Train: 71.52%, Valid: 66.40%, Test: 65.43%\n",
            "Epoch: 120, Loss: 0.5871, Train: 71.79%, Valid: 66.50%, Test: 65.85%\n",
            "Epoch: 125, Loss: 0.5843, Train: 72.17%, Valid: 66.58%, Test: 66.08%\n",
            "Epoch: 130, Loss: 0.5817, Train: 72.51%, Valid: 67.00%, Test: 66.20%\n",
            "Epoch: 135, Loss: 0.5794, Train: 72.80%, Valid: 67.15%, Test: 66.29%\n",
            "Epoch: 140, Loss: 0.5770, Train: 73.16%, Valid: 67.32%, Test: 66.45%\n",
            "Epoch: 145, Loss: 0.5746, Train: 73.49%, Valid: 67.40%, Test: 66.33%\n",
            "Epoch: 150, Loss: 0.5725, Train: 73.72%, Valid: 67.62%, Test: 66.45%\n",
            "Epoch: 155, Loss: 0.5707, Train: 74.07%, Valid: 67.74%, Test: 66.56%\n",
            "Epoch: 160, Loss: 0.5694, Train: 74.12%, Valid: 67.97%, Test: 66.54%\n",
            "Epoch: 165, Loss: 0.5677, Train: 74.06%, Valid: 67.91%, Test: 66.44%\n",
            "Epoch: 170, Loss: 0.5661, Train: 74.25%, Valid: 68.17%, Test: 66.46%\n",
            "Epoch: 175, Loss: 0.5649, Train: 74.58%, Valid: 68.25%, Test: 66.65%\n",
            "Epoch: 180, Loss: 0.5630, Train: 75.18%, Valid: 68.51%, Test: 66.88%\n",
            "Epoch: 185, Loss: 0.5612, Train: 75.28%, Valid: 68.62%, Test: 67.02%\n",
            "Epoch: 190, Loss: 0.5599, Train: 75.44%, Valid: 68.94%, Test: 67.29%\n",
            "Epoch: 195, Loss: 0.5591, Train: 75.68%, Valid: 68.77%, Test: 67.30%\n",
            "Run 02:\n",
            "Highest Train: 75.82\n",
            "Highest Valid: 68.94\n",
            "Highest Test: 67.38\n",
            "Chosen epoch: 191\n",
            "Final Train: 75.44\n",
            "Final Test: 67.29\n",
            "Epoch: 00, Loss: 0.9267, Train: 49.16%, Valid: 49.61%, Test: 48.72%\n",
            "Epoch: 05, Loss: 0.8719, Train: 49.24%, Valid: 49.71%, Test: 48.94%\n",
            "Epoch: 10, Loss: 0.8360, Train: 49.43%, Valid: 49.88%, Test: 49.17%\n",
            "Epoch: 15, Loss: 0.8102, Train: 49.78%, Valid: 50.12%, Test: 49.57%\n",
            "Epoch: 20, Loss: 0.7894, Train: 50.07%, Valid: 50.57%, Test: 49.94%\n",
            "Epoch: 25, Loss: 0.7708, Train: 50.55%, Valid: 51.22%, Test: 50.30%\n",
            "Epoch: 30, Loss: 0.7526, Train: 51.34%, Valid: 51.96%, Test: 50.85%\n",
            "Epoch: 35, Loss: 0.7355, Train: 52.33%, Valid: 52.83%, Test: 52.10%\n",
            "Epoch: 40, Loss: 0.7220, Train: 53.38%, Valid: 53.50%, Test: 52.57%\n",
            "Epoch: 45, Loss: 0.7103, Train: 54.15%, Valid: 54.25%, Test: 53.05%\n",
            "Epoch: 50, Loss: 0.7000, Train: 55.08%, Valid: 55.13%, Test: 53.88%\n",
            "Epoch: 55, Loss: 0.6906, Train: 56.09%, Valid: 55.58%, Test: 54.32%\n",
            "Epoch: 60, Loss: 0.6821, Train: 56.96%, Valid: 56.28%, Test: 54.69%\n",
            "Epoch: 65, Loss: 0.6743, Train: 58.00%, Valid: 56.86%, Test: 55.49%\n",
            "Epoch: 70, Loss: 0.6668, Train: 58.89%, Valid: 57.78%, Test: 56.22%\n",
            "Epoch: 75, Loss: 0.6597, Train: 60.03%, Valid: 58.68%, Test: 56.85%\n",
            "Epoch: 80, Loss: 0.6529, Train: 61.17%, Valid: 59.61%, Test: 57.60%\n",
            "Epoch: 85, Loss: 0.6462, Train: 62.18%, Valid: 60.74%, Test: 58.28%\n",
            "Epoch: 90, Loss: 0.6395, Train: 63.07%, Valid: 61.52%, Test: 59.25%\n",
            "Epoch: 95, Loss: 0.6329, Train: 63.85%, Valid: 62.05%, Test: 59.79%\n",
            "Epoch: 100, Loss: 0.6266, Train: 64.60%, Valid: 62.69%, Test: 60.19%\n",
            "Epoch: 105, Loss: 0.6207, Train: 65.40%, Valid: 63.11%, Test: 60.80%\n",
            "Epoch: 110, Loss: 0.6153, Train: 66.24%, Valid: 63.45%, Test: 61.05%\n",
            "Epoch: 115, Loss: 0.6105, Train: 66.92%, Valid: 63.79%, Test: 61.46%\n",
            "Epoch: 120, Loss: 0.6061, Train: 67.61%, Valid: 64.12%, Test: 61.57%\n",
            "Epoch: 125, Loss: 0.6020, Train: 68.04%, Valid: 64.33%, Test: 61.82%\n",
            "Epoch: 130, Loss: 0.5982, Train: 68.53%, Valid: 64.58%, Test: 61.94%\n",
            "Epoch: 135, Loss: 0.5947, Train: 68.93%, Valid: 64.86%, Test: 62.02%\n",
            "Epoch: 140, Loss: 0.5914, Train: 69.38%, Valid: 65.07%, Test: 62.05%\n",
            "Epoch: 145, Loss: 0.5882, Train: 69.71%, Valid: 65.31%, Test: 62.12%\n",
            "Epoch: 150, Loss: 0.5851, Train: 70.11%, Valid: 65.49%, Test: 62.34%\n",
            "Epoch: 155, Loss: 0.5820, Train: 70.52%, Valid: 65.85%, Test: 62.40%\n",
            "Epoch: 160, Loss: 0.5791, Train: 70.78%, Valid: 65.92%, Test: 62.66%\n",
            "Epoch: 165, Loss: 0.5760, Train: 71.41%, Valid: 66.49%, Test: 62.68%\n",
            "Epoch: 170, Loss: 0.5734, Train: 71.57%, Valid: 66.43%, Test: 62.70%\n",
            "Epoch: 175, Loss: 0.5709, Train: 71.89%, Valid: 66.71%, Test: 62.76%\n",
            "Epoch: 180, Loss: 0.5677, Train: 72.46%, Valid: 67.09%, Test: 62.99%\n",
            "Epoch: 185, Loss: 0.5651, Train: 72.72%, Valid: 67.42%, Test: 63.08%\n",
            "Epoch: 190, Loss: 0.5625, Train: 73.08%, Valid: 67.56%, Test: 63.07%\n",
            "Epoch: 195, Loss: 0.5606, Train: 73.20%, Valid: 67.56%, Test: 62.94%\n",
            "Run 03:\n",
            "Highest Train: 73.66\n",
            "Highest Valid: 67.87\n",
            "Highest Test: 63.10\n",
            "Chosen epoch: 200\n",
            "Final Train: 73.57\n",
            "Final Test: 63.04\n",
            "Epoch: 00, Loss: 0.7523, Train: 51.19%, Valid: 51.24%, Test: 50.75%\n",
            "Epoch: 05, Loss: 0.7210, Train: 54.23%, Valid: 53.91%, Test: 52.96%\n",
            "Epoch: 10, Loss: 0.7016, Train: 56.43%, Valid: 55.59%, Test: 55.27%\n",
            "Epoch: 15, Loss: 0.6886, Train: 58.09%, Valid: 56.72%, Test: 56.94%\n",
            "Epoch: 20, Loss: 0.6785, Train: 59.46%, Valid: 57.86%, Test: 58.33%\n",
            "Epoch: 25, Loss: 0.6697, Train: 60.92%, Valid: 58.88%, Test: 59.57%\n",
            "Epoch: 30, Loss: 0.6617, Train: 62.18%, Valid: 59.90%, Test: 60.52%\n",
            "Epoch: 35, Loss: 0.6542, Train: 63.21%, Valid: 60.44%, Test: 61.33%\n",
            "Epoch: 40, Loss: 0.6472, Train: 64.03%, Valid: 61.25%, Test: 61.66%\n",
            "Epoch: 45, Loss: 0.6406, Train: 64.76%, Valid: 61.96%, Test: 62.36%\n",
            "Epoch: 50, Loss: 0.6344, Train: 65.57%, Valid: 62.57%, Test: 63.26%\n",
            "Epoch: 55, Loss: 0.6285, Train: 66.12%, Valid: 63.02%, Test: 63.90%\n",
            "Epoch: 60, Loss: 0.6228, Train: 66.66%, Valid: 63.46%, Test: 64.36%\n",
            "Epoch: 65, Loss: 0.6174, Train: 67.19%, Valid: 63.89%, Test: 64.75%\n",
            "Epoch: 70, Loss: 0.6121, Train: 67.83%, Valid: 64.06%, Test: 64.97%\n",
            "Epoch: 75, Loss: 0.6071, Train: 68.32%, Valid: 64.27%, Test: 65.26%\n",
            "Epoch: 80, Loss: 0.6023, Train: 68.94%, Valid: 64.70%, Test: 65.45%\n",
            "Epoch: 85, Loss: 0.5976, Train: 69.37%, Valid: 65.08%, Test: 65.62%\n",
            "Epoch: 90, Loss: 0.5932, Train: 69.83%, Valid: 65.17%, Test: 65.69%\n",
            "Epoch: 95, Loss: 0.5889, Train: 70.36%, Valid: 65.35%, Test: 65.88%\n",
            "Epoch: 100, Loss: 0.5849, Train: 70.72%, Valid: 65.61%, Test: 66.22%\n",
            "Epoch: 105, Loss: 0.5810, Train: 71.18%, Valid: 65.85%, Test: 66.39%\n",
            "Epoch: 110, Loss: 0.5772, Train: 71.61%, Valid: 66.14%, Test: 66.45%\n",
            "Epoch: 115, Loss: 0.5735, Train: 71.96%, Valid: 66.37%, Test: 66.57%\n",
            "Epoch: 120, Loss: 0.5697, Train: 72.49%, Valid: 66.52%, Test: 66.78%\n",
            "Epoch: 125, Loss: 0.5659, Train: 72.94%, Valid: 66.83%, Test: 66.90%\n",
            "Epoch: 130, Loss: 0.5624, Train: 73.32%, Valid: 67.09%, Test: 67.12%\n",
            "Epoch: 135, Loss: 0.5586, Train: 73.82%, Valid: 67.29%, Test: 67.34%\n",
            "Epoch: 140, Loss: 0.5551, Train: 74.23%, Valid: 67.57%, Test: 67.30%\n",
            "Epoch: 145, Loss: 0.5517, Train: 74.81%, Valid: 67.92%, Test: 67.51%\n",
            "Epoch: 150, Loss: 0.5493, Train: 75.40%, Valid: 68.32%, Test: 67.79%\n",
            "Epoch: 155, Loss: 0.5460, Train: 75.55%, Valid: 68.44%, Test: 67.73%\n",
            "Epoch: 160, Loss: 0.5433, Train: 75.55%, Valid: 68.47%, Test: 67.50%\n",
            "Epoch: 165, Loss: 0.5407, Train: 76.09%, Valid: 69.00%, Test: 67.74%\n",
            "Epoch: 170, Loss: 0.5383, Train: 75.94%, Valid: 68.88%, Test: 67.75%\n",
            "Epoch: 175, Loss: 0.5358, Train: 76.66%, Valid: 69.18%, Test: 67.93%\n",
            "Epoch: 180, Loss: 0.5339, Train: 77.26%, Valid: 69.37%, Test: 68.03%\n",
            "Epoch: 185, Loss: 0.5316, Train: 77.42%, Valid: 69.55%, Test: 68.09%\n",
            "Epoch: 190, Loss: 0.5316, Train: 77.37%, Valid: 69.67%, Test: 68.02%\n",
            "Epoch: 195, Loss: 0.5287, Train: 77.61%, Valid: 70.06%, Test: 68.47%\n",
            "Run 04:\n",
            "Highest Train: 77.99\n",
            "Highest Valid: 70.06\n",
            "Highest Test: 68.53\n",
            "Chosen epoch: 196\n",
            "Final Train: 77.61\n",
            "Final Test: 68.47\n",
            "Epoch: 00, Loss: 0.8760, Train: 49.27%, Valid: 49.76%, Test: 48.67%\n",
            "Epoch: 05, Loss: 0.8247, Train: 49.34%, Valid: 49.81%, Test: 48.77%\n",
            "Epoch: 10, Loss: 0.7915, Train: 49.36%, Valid: 49.82%, Test: 48.85%\n",
            "Epoch: 15, Loss: 0.7671, Train: 49.60%, Valid: 50.04%, Test: 48.92%\n",
            "Epoch: 20, Loss: 0.7489, Train: 50.14%, Valid: 50.55%, Test: 49.97%\n",
            "Epoch: 25, Loss: 0.7337, Train: 51.00%, Valid: 51.41%, Test: 50.67%\n",
            "Epoch: 30, Loss: 0.7204, Train: 51.89%, Valid: 52.32%, Test: 51.29%\n",
            "Epoch: 35, Loss: 0.7088, Train: 52.43%, Valid: 52.78%, Test: 51.70%\n",
            "Epoch: 40, Loss: 0.6984, Train: 53.17%, Valid: 53.34%, Test: 52.07%\n",
            "Epoch: 45, Loss: 0.6894, Train: 54.06%, Valid: 54.22%, Test: 52.70%\n",
            "Epoch: 50, Loss: 0.6813, Train: 55.08%, Valid: 54.95%, Test: 53.03%\n",
            "Epoch: 55, Loss: 0.6741, Train: 56.07%, Valid: 55.77%, Test: 53.49%\n",
            "Epoch: 60, Loss: 0.6676, Train: 57.11%, Valid: 56.67%, Test: 54.02%\n",
            "Epoch: 65, Loss: 0.6619, Train: 58.12%, Valid: 57.51%, Test: 54.56%\n",
            "Epoch: 70, Loss: 0.6566, Train: 59.11%, Valid: 58.28%, Test: 54.98%\n",
            "Epoch: 75, Loss: 0.6518, Train: 59.92%, Valid: 58.76%, Test: 55.58%\n",
            "Epoch: 80, Loss: 0.6472, Train: 61.05%, Valid: 59.52%, Test: 56.08%\n",
            "Epoch: 85, Loss: 0.6428, Train: 61.92%, Valid: 60.32%, Test: 56.56%\n",
            "Epoch: 90, Loss: 0.6386, Train: 62.75%, Valid: 60.96%, Test: 57.31%\n",
            "Epoch: 95, Loss: 0.6347, Train: 63.50%, Valid: 61.23%, Test: 57.83%\n",
            "Epoch: 100, Loss: 0.6309, Train: 64.11%, Valid: 61.59%, Test: 58.41%\n",
            "Epoch: 105, Loss: 0.6274, Train: 64.54%, Valid: 61.92%, Test: 59.04%\n",
            "Epoch: 110, Loss: 0.6239, Train: 65.21%, Valid: 62.27%, Test: 59.53%\n",
            "Epoch: 115, Loss: 0.6206, Train: 65.60%, Valid: 62.93%, Test: 60.09%\n",
            "Epoch: 120, Loss: 0.6174, Train: 66.31%, Valid: 63.26%, Test: 60.63%\n",
            "Epoch: 125, Loss: 0.6142, Train: 66.79%, Valid: 63.46%, Test: 61.13%\n",
            "Epoch: 130, Loss: 0.6112, Train: 67.35%, Valid: 63.83%, Test: 61.44%\n",
            "Epoch: 135, Loss: 0.6082, Train: 67.87%, Valid: 64.11%, Test: 61.80%\n",
            "Epoch: 140, Loss: 0.6052, Train: 68.36%, Valid: 64.30%, Test: 62.12%\n",
            "Epoch: 145, Loss: 0.6023, Train: 68.80%, Valid: 64.46%, Test: 62.49%\n",
            "Epoch: 150, Loss: 0.5995, Train: 69.25%, Valid: 64.56%, Test: 62.86%\n",
            "Epoch: 155, Loss: 0.5968, Train: 69.74%, Valid: 64.83%, Test: 63.06%\n",
            "Epoch: 160, Loss: 0.5941, Train: 70.06%, Valid: 65.10%, Test: 63.42%\n",
            "Epoch: 165, Loss: 0.5914, Train: 70.47%, Valid: 65.23%, Test: 63.56%\n",
            "Epoch: 170, Loss: 0.5887, Train: 70.85%, Valid: 65.40%, Test: 63.85%\n",
            "Epoch: 175, Loss: 0.5861, Train: 71.13%, Valid: 65.67%, Test: 63.90%\n",
            "Epoch: 180, Loss: 0.5836, Train: 71.36%, Valid: 65.89%, Test: 64.28%\n",
            "Epoch: 185, Loss: 0.5810, Train: 71.52%, Valid: 65.85%, Test: 64.46%\n",
            "Epoch: 190, Loss: 0.5786, Train: 71.81%, Valid: 65.94%, Test: 64.35%\n",
            "Epoch: 195, Loss: 0.5764, Train: 72.10%, Valid: 66.11%, Test: 64.44%\n",
            "Run 05:\n",
            "Highest Train: 72.81\n",
            "Highest Valid: 66.72\n",
            "Highest Test: 64.80\n",
            "Chosen epoch: 200\n",
            "Final Train: 72.81\n",
            "Final Test: 64.80\n",
            "All runs:\n",
            "Highest Train: 75.58 ± 2.31\n",
            "Highest Test: 66.34 ± 2.30\n",
            "Highest Valid: 68.60 ± 1.32\n",
            "  Final Train: 75.41 ± 2.23\n",
            "   Final Test: 66.29 ± 2.29\n",
            "Saving results to logs/fb100_edge.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Edge Aware Settings"
      ],
      "metadata": {
        "id": "FAEVG0ypptzb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 GKD/main.py --dataset fb100 --rand_split --use_bn --base_model gcn --mode train --priv_type edge --dist_mode gkd --kernel sigmoid --lr 0.0001"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2NH9tbmprVT",
        "outputId": "12e7f673-e782-4ad9-b59b-092e15de7711"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(data_dir='data', dataset='fb100', sub_dataset='', cpu=False, seed=42, train_prop=0.5, valid_prop=0.25, protocol='semi', rand_split=True, metric='acc', runs=5, epochs=200, hidden_channels=32, num_layers=3, gat_heads=8, out_heads=1, hops=1, lp_alpha=0.1, gpr_alpha=0.1, jk_type='max', directed=False, num_mlp_layers=1, display_step=5, cached=False, print_prop=False, priv_type='edge', priv_ratio=0.5, save_model=False, save_name='gcn', log_name='none', base_model='gcn', not_load_teacher=False, mode='train', dist_mode='gkd', weight_decay=0.05, dropout=0.0, lr=0.0001, use_bn=True, use_batch=False, batch_size=2048, oracle=False, device=0, alpha=0.5, delta=0.1, use_kd=False, beta=0.0, tau=1.0, kernel='sigmoid', t=1.0, include_last=False, s=2, m=1, lr2=0.001, sim='l2', ker_norm=False)\n",
            "cuda:0\n",
            "fb100\n",
            "Invalid sub_dataname, deferring to Penn94 graph\n",
            "/content/GKD/dataset.py:204: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  edge_index = torch.tensor(A.nonzero(), dtype=torch.long)\n",
            "torch.Size([41554, 1])\n",
            "num nodes 41554 | num classes 2 | num node feats 7833\n",
            "MODEL: GeoDist(\n",
            "  (k): Kernel(\n",
            "    (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  )\n",
            "  (teacher_gnn): ModuleList(\n",
            "    (0): Linear(in_features=7833, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (student_gnn): ModuleList(\n",
            "    (0): Linear(in_features=7833, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  (bns2d): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            ")\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/GKD/main.py\", line 180, in <module>\n",
            "    outputs = model(dataset, dataset_mask, mode='train', dist_mode=args.dist_mode, t=args.t)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/GKD/models.py\", line 68, in forward\n",
            "    return self.forward_student(data_full, data, dist_mode, t)\n",
            "  File \"/content/GKD/models.py\", line 97, in forward_student\n",
            "    return self.gkd(xs, xt, edge_index, edge_index_full, train_idx, share_node_idx)\n",
            "  File \"/content/GKD/models.py\", line 154, in gkd\n",
            "    loss_list.append(self.k.dist_loss(mt, ms, A))\n",
            "  File \"/content/GKD/kernels.py\", line 63, in dist_loss\n",
            "    return (nn.MSELoss(reduction='none')(mt, ms) * (A + (1-A) * self.args.delta)).sum()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\", line 40, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\", line 909, in __rsub__\n",
            "    return _C._VariableFunctions.rsub(self, other)\n",
            "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 6.43 GiB. GPU 0 has a total capacty of 39.56 GiB of which 3.37 GiB is free. Process 96435 has 36.20 GiB memory in use. Of the allocated memory 28.38 GiB is allocated by PyTorch, and 6.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 GKD/main.py --dataset fb100--rand_split --use_bn --base_model gcn --mode train --priv_type edge --dist_mode gkd --use_kd --lr 0.0001"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8VoCeMwp2dB",
        "outputId": "4cc7eacf-ac7d-467a-e2fc-39cfa1d76800"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(data_dir='data', dataset='fb100--rand_split', sub_dataset='', cpu=False, seed=42, train_prop=0.5, valid_prop=0.25, protocol='semi', rand_split=False, metric='acc', runs=5, epochs=200, hidden_channels=32, num_layers=3, gat_heads=8, out_heads=1, hops=1, lp_alpha=0.1, gpr_alpha=0.1, jk_type='max', directed=False, num_mlp_layers=1, display_step=5, cached=False, print_prop=False, priv_type='edge', priv_ratio=0.5, save_model=False, save_name='gcn', log_name='none', base_model='gcn', not_load_teacher=False, mode='train', dist_mode='gkd', weight_decay=0.05, dropout=0.0, lr=0.0001, use_bn=True, use_batch=False, batch_size=2048, oracle=False, device=0, alpha=0.5, delta=0.1, use_kd=True, beta=0.0, tau=1.0, kernel='sigmoid', t=1.0, include_last=False, s=2, m=1, lr2=0.001, sim='l2', ker_norm=False)\n",
            "cuda:0\n",
            "fb100--rand_split\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/GKD/main.py\", line 47, in <module>\n",
            "    dataset = load_nc_dataset(args.dataset, args.sub_dataset, args.data_dir)\n",
            "  File \"/content/GKD/dataset.py\", line 123, in load_nc_dataset\n",
            "    raise ValueError('Invalid dataname')\n",
            "ValueError: Invalid dataname\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 GKD/main.py --dataset fb100 --rand_split --use_bn --base_model gcn --mode train --priv_type edge --dist_mode gkd --use_kd --lr 0.0001"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zejZ0TyFp5Vm",
        "outputId": "4a71c12e-3fc6-448d-8ae3-e8b6dba945fc"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(data_dir='data', dataset='fb100', sub_dataset='', cpu=False, seed=42, train_prop=0.5, valid_prop=0.25, protocol='semi', rand_split=True, metric='acc', runs=5, epochs=200, hidden_channels=32, num_layers=3, gat_heads=8, out_heads=1, hops=1, lp_alpha=0.1, gpr_alpha=0.1, jk_type='max', directed=False, num_mlp_layers=1, display_step=5, cached=False, print_prop=False, priv_type='edge', priv_ratio=0.5, save_model=False, save_name='gcn', log_name='none', base_model='gcn', not_load_teacher=False, mode='train', dist_mode='gkd', weight_decay=0.05, dropout=0.0, lr=0.0001, use_bn=True, use_batch=False, batch_size=2048, oracle=False, device=0, alpha=0.5, delta=0.1, use_kd=True, beta=0.0, tau=1.0, kernel='sigmoid', t=1.0, include_last=False, s=2, m=1, lr2=0.001, sim='l2', ker_norm=False)\n",
            "cuda:0\n",
            "fb100\n",
            "Invalid sub_dataname, deferring to Penn94 graph\n",
            "/content/GKD/dataset.py:204: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  edge_index = torch.tensor(A.nonzero(), dtype=torch.long)\n",
            "torch.Size([41554, 1])\n",
            "num nodes 41554 | num classes 2 | num node feats 7833\n",
            "MODEL: GeoDist(\n",
            "  (k): Kernel(\n",
            "    (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  )\n",
            "  (teacher_gnn): ModuleList(\n",
            "    (0): Linear(in_features=7833, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (student_gnn): ModuleList(\n",
            "    (0): Linear(in_features=7833, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  (bns2d): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            ")\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/GKD/main.py\", line 180, in <module>\n",
            "    outputs = model(dataset, dataset_mask, mode='train', dist_mode=args.dist_mode, t=args.t)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/GKD/models.py\", line 68, in forward\n",
            "    return self.forward_student(data_full, data, dist_mode, t)\n",
            "  File \"/content/GKD/models.py\", line 97, in forward_student\n",
            "    return self.gkd(xs, xt, edge_index, edge_index_full, train_idx, share_node_idx)\n",
            "  File \"/content/GKD/models.py\", line 154, in gkd\n",
            "    loss_list.append(self.k.dist_loss(mt, ms, A))\n",
            "  File \"/content/GKD/kernels.py\", line 63, in dist_loss\n",
            "    return (nn.MSELoss(reduction='none')(mt, ms) * (A + (1-A) * self.args.delta)).sum()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\", line 40, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\", line 909, in __rsub__\n",
            "    return _C._VariableFunctions.rsub(self, other)\n",
            "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 6.43 GiB. GPU 0 has a total capacty of 39.56 GiB of which 3.37 GiB is free. Process 97109 has 36.20 GiB memory in use. Of the allocated memory 28.38 GiB is allocated by PyTorch, and 6.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 GKD/main.py --dataset fb100 --rand_split --use_bn --base_model gcn --mode train --priv_type edge --dist_mode pgkd --use_kd --lr 0.0001"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWW61BDOp7Zf",
        "outputId": "7c24d453-c40b-4858-907a-9295cc2995e9"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(data_dir='data', dataset='fb100', sub_dataset='', cpu=False, seed=42, train_prop=0.5, valid_prop=0.25, protocol='semi', rand_split=True, metric='acc', runs=5, epochs=200, hidden_channels=32, num_layers=3, gat_heads=8, out_heads=1, hops=1, lp_alpha=0.1, gpr_alpha=0.1, jk_type='max', directed=False, num_mlp_layers=1, display_step=5, cached=False, print_prop=False, priv_type='edge', priv_ratio=0.5, save_model=False, save_name='gcn', log_name='none', base_model='gcn', not_load_teacher=False, mode='train', dist_mode='pgkd', weight_decay=0.05, dropout=0.0, lr=0.0001, use_bn=True, use_batch=False, batch_size=2048, oracle=False, device=0, alpha=0.5, delta=0.1, use_kd=True, beta=0.0, tau=1.0, kernel='sigmoid', t=1.0, include_last=False, s=2, m=1, lr2=0.001, sim='l2', ker_norm=False)\n",
            "cuda:0\n",
            "fb100\n",
            "Invalid sub_dataname, deferring to Penn94 graph\n",
            "/content/GKD/dataset.py:204: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  edge_index = torch.tensor(A.nonzero(), dtype=torch.long)\n",
            "torch.Size([41554, 1])\n",
            "num nodes 41554 | num classes 2 | num node feats 7833\n",
            "MODEL: GeoDist(\n",
            "  (k): Kernel(\n",
            "    (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  )\n",
            "  (teacher_gnn): ModuleList(\n",
            "    (0): Linear(in_features=7833, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (student_gnn): ModuleList(\n",
            "    (0): Linear(in_features=7833, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  (bns2d): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            ")\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/GKD/main.py\", line 199, in <module>\n",
            "    outputs = model(dataset, dataset_mask, mode='train', dist_mode=args.dist_mode, t=args.t)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/GKD/models.py\", line 68, in forward\n",
            "    return self.forward_student(data_full, data, dist_mode, t)\n",
            "  File \"/content/GKD/models.py\", line 99, in forward_student\n",
            "    return self.pgkd(xs, xt, edge_index, edge_index_full, train_idx, share_node_idx)\n",
            "  File \"/content/GKD/models.py\", line 196, in pgkd\n",
            "    gkd_dist_loss = self.k.dist_loss(mt, ms, A)\n",
            "  File \"/content/GKD/kernels.py\", line 63, in dist_loss\n",
            "    return (nn.MSELoss(reduction='none')(mt, ms) * (A + (1-A) * self.args.delta)).sum()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\", line 40, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\", line 909, in __rsub__\n",
            "    return _C._VariableFunctions.rsub(self, other)\n",
            "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 6.43 GiB. GPU 0 has a total capacty of 39.56 GiB of which 3.34 GiB is free. Process 97566 has 36.22 GiB memory in use. Of the allocated memory 28.60 GiB is allocated by PyTorch, and 6.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 GKD/main.py --dataset fb100 --rand_split --use_bn --base_model gcn --mode train --priv_type edge --dist_mode gkd --kernel gaussian --lr 0.0001"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvWMP7p-pyl9",
        "outputId": "c0790887-2c95-4295-ad03-9f66da9971d3"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(data_dir='data', dataset='fb100', sub_dataset='', cpu=False, seed=42, train_prop=0.5, valid_prop=0.25, protocol='semi', rand_split=True, metric='acc', runs=5, epochs=200, hidden_channels=32, num_layers=3, gat_heads=8, out_heads=1, hops=1, lp_alpha=0.1, gpr_alpha=0.1, jk_type='max', directed=False, num_mlp_layers=1, display_step=5, cached=False, print_prop=False, priv_type='edge', priv_ratio=0.5, save_model=False, save_name='gcn', log_name='none', base_model='gcn', not_load_teacher=False, mode='train', dist_mode='gkd', weight_decay=0.05, dropout=0.0, lr=0.0001, use_bn=True, use_batch=False, batch_size=2048, oracle=False, device=0, alpha=0.5, delta=0.1, use_kd=False, beta=0.0, tau=1.0, kernel='gaussian', t=1.0, include_last=False, s=2, m=1, lr2=0.001, sim='l2', ker_norm=False)\n",
            "cuda:0\n",
            "fb100\n",
            "Invalid sub_dataname, deferring to Penn94 graph\n",
            "/content/GKD/dataset.py:204: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  edge_index = torch.tensor(A.nonzero(), dtype=torch.long)\n",
            "torch.Size([41554, 1])\n",
            "num nodes 41554 | num classes 2 | num node feats 7833\n",
            "MODEL: GeoDist(\n",
            "  (k): Kernel(\n",
            "    (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  )\n",
            "  (teacher_gnn): ModuleList(\n",
            "    (0): Linear(in_features=7833, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (student_gnn): ModuleList(\n",
            "    (0): Linear(in_features=7833, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  (bns2d): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            ")\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/GKD/main.py\", line 180, in <module>\n",
            "    outputs = model(dataset, dataset_mask, mode='train', dist_mode=args.dist_mode, t=args.t)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/GKD/models.py\", line 68, in forward\n",
            "    return self.forward_student(data_full, data, dist_mode, t)\n",
            "  File \"/content/GKD/models.py\", line 97, in forward_student\n",
            "    return self.gkd(xs, xt, edge_index, edge_index_full, train_idx, share_node_idx)\n",
            "  File \"/content/GKD/models.py\", line 151, in gkd\n",
            "    ms = self.k(xs[share_node_idx], xs[share_node_idx])\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/GKD/kernels.py\", line 31, in forward\n",
            "    mat = (-mat/self.args.t).exp()\n",
            "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 6.43 GiB. GPU 0 has a total capacty of 39.56 GiB of which 3.37 GiB is free. Process 98066 has 36.20 GiB memory in use. Of the allocated memory 28.38 GiB is allocated by PyTorch, and 6.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Node Aware Settings"
      ],
      "metadata": {
        "id": "FPx6-YLDp-Wr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 GKD/main.py --dataset fb100 --rand_split --use_bn --base_model gcn --mode train --priv_type edge --dist_mode pgkd --use_kd --lr 0.0001"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-Ya4ShxqELe",
        "outputId": "f3908370-2587-4ad9-fdcb-f2d3e1e5ef13"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(data_dir='data', dataset='fb100', sub_dataset='', cpu=False, seed=42, train_prop=0.5, valid_prop=0.25, protocol='semi', rand_split=True, metric='acc', runs=5, epochs=200, hidden_channels=32, num_layers=3, gat_heads=8, out_heads=1, hops=1, lp_alpha=0.1, gpr_alpha=0.1, jk_type='max', directed=False, num_mlp_layers=1, display_step=5, cached=False, print_prop=False, priv_type='edge', priv_ratio=0.5, save_model=False, save_name='gcn', log_name='none', base_model='gcn', not_load_teacher=False, mode='train', dist_mode='pgkd', weight_decay=0.05, dropout=0.0, lr=0.0001, use_bn=True, use_batch=False, batch_size=2048, oracle=False, device=0, alpha=0.5, delta=0.1, use_kd=True, beta=0.0, tau=1.0, kernel='sigmoid', t=1.0, include_last=False, s=2, m=1, lr2=0.001, sim='l2', ker_norm=False)\n",
            "cuda:0\n",
            "fb100\n",
            "Invalid sub_dataname, deferring to Penn94 graph\n",
            "/content/GKD/dataset.py:204: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  edge_index = torch.tensor(A.nonzero(), dtype=torch.long)\n",
            "torch.Size([41554, 1])\n",
            "num nodes 41554 | num classes 2 | num node feats 7833\n",
            "MODEL: GeoDist(\n",
            "  (k): Kernel(\n",
            "    (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  )\n",
            "  (teacher_gnn): ModuleList(\n",
            "    (0): Linear(in_features=7833, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (student_gnn): ModuleList(\n",
            "    (0): Linear(in_features=7833, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  (bns2d): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            ")\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/GKD/main.py\", line 199, in <module>\n",
            "    outputs = model(dataset, dataset_mask, mode='train', dist_mode=args.dist_mode, t=args.t)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/GKD/models.py\", line 68, in forward\n",
            "    return self.forward_student(data_full, data, dist_mode, t)\n",
            "  File \"/content/GKD/models.py\", line 99, in forward_student\n",
            "    return self.pgkd(xs, xt, edge_index, edge_index_full, train_idx, share_node_idx)\n",
            "  File \"/content/GKD/models.py\", line 196, in pgkd\n",
            "    gkd_dist_loss = self.k.dist_loss(mt, ms, A)\n",
            "  File \"/content/GKD/kernels.py\", line 63, in dist_loss\n",
            "    return (nn.MSELoss(reduction='none')(mt, ms) * (A + (1-A) * self.args.delta)).sum()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\", line 40, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\", line 909, in __rsub__\n",
            "    return _C._VariableFunctions.rsub(self, other)\n",
            "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 6.43 GiB. GPU 0 has a total capacty of 39.56 GiB of which 3.34 GiB is free. Process 90638 has 36.22 GiB memory in use. Of the allocated memory 28.60 GiB is allocated by PyTorch, and 6.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Node Aware Settings"
      ],
      "metadata": {
        "id": "9BYhvB4jrPSO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 GKD/main.py --dataset fb100 --rand_split --use_bn --base_model gcn --mode train --dist_mode no --save_model --lr 0.0001"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acSq2JKrqBSf",
        "outputId": "1846d13a-d61e-42a8-9b31-d18a56eac7e4"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(data_dir='data', dataset='fb100', sub_dataset='', cpu=False, seed=42, train_prop=0.5, valid_prop=0.25, protocol='semi', rand_split=True, metric='acc', runs=5, epochs=200, hidden_channels=32, num_layers=3, gat_heads=8, out_heads=1, hops=1, lp_alpha=0.1, gpr_alpha=0.1, jk_type='max', directed=False, num_mlp_layers=1, display_step=5, cached=False, print_prop=False, priv_type='edge', priv_ratio=0.5, save_model=True, save_name='gcn', log_name='none', base_model='gcn', not_load_teacher=False, mode='train', dist_mode='no', weight_decay=0.05, dropout=0.0, lr=0.0001, use_bn=True, use_batch=False, batch_size=2048, oracle=False, device=0, alpha=0.5, delta=0.1, use_kd=False, beta=0.0, tau=1.0, kernel='sigmoid', t=1.0, include_last=False, s=2, m=1, lr2=0.001, sim='l2', ker_norm=False)\n",
            "cuda:0\n",
            "fb100\n",
            "Invalid sub_dataname, deferring to Penn94 graph\n",
            "/content/GKD/dataset.py:204: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  edge_index = torch.tensor(A.nonzero(), dtype=torch.long)\n",
            "torch.Size([41554, 1])\n",
            "num nodes 41554 | num classes 2 | num node feats 7833\n",
            "MODEL: GeoDist(\n",
            "  (k): Kernel(\n",
            "    (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  )\n",
            "  (teacher_gnn): ModuleList(\n",
            "    (0): Linear(in_features=7833, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (student_gnn): ModuleList(\n",
            "    (0): Linear(in_features=7833, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  (bns2d): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            ")\n",
            "Epoch: 00, Loss: 0.7987, Train: 51.64%, Valid: 52.52%, Test: 52.81%\n",
            "Epoch: 05, Loss: 0.7617, Train: 54.16%, Valid: 54.16%, Test: 54.55%\n",
            "Epoch: 10, Loss: 0.7372, Train: 55.88%, Valid: 55.32%, Test: 55.82%\n",
            "Epoch: 15, Loss: 0.7186, Train: 57.60%, Valid: 56.36%, Test: 56.86%\n",
            "Epoch: 20, Loss: 0.7033, Train: 59.64%, Valid: 57.45%, Test: 57.80%\n",
            "Epoch: 25, Loss: 0.6901, Train: 61.07%, Valid: 58.24%, Test: 58.77%\n",
            "Epoch: 30, Loss: 0.6788, Train: 62.46%, Valid: 59.59%, Test: 59.66%\n",
            "Epoch: 35, Loss: 0.6686, Train: 63.87%, Valid: 60.57%, Test: 60.84%\n",
            "Epoch: 40, Loss: 0.6596, Train: 64.75%, Valid: 61.36%, Test: 61.82%\n",
            "Epoch: 45, Loss: 0.6518, Train: 65.65%, Valid: 62.02%, Test: 62.30%\n",
            "Epoch: 50, Loss: 0.6449, Train: 66.33%, Valid: 62.66%, Test: 63.01%\n",
            "Epoch: 55, Loss: 0.6387, Train: 66.97%, Valid: 63.04%, Test: 63.44%\n",
            "Epoch: 60, Loss: 0.6330, Train: 67.45%, Valid: 63.32%, Test: 63.61%\n",
            "Epoch: 65, Loss: 0.6278, Train: 67.91%, Valid: 63.50%, Test: 63.91%\n",
            "Epoch: 70, Loss: 0.6228, Train: 68.37%, Valid: 63.81%, Test: 64.30%\n",
            "Epoch: 75, Loss: 0.6181, Train: 68.74%, Valid: 64.04%, Test: 64.61%\n",
            "Epoch: 80, Loss: 0.6135, Train: 69.09%, Valid: 64.35%, Test: 64.87%\n",
            "Epoch: 85, Loss: 0.6091, Train: 69.43%, Valid: 64.41%, Test: 65.21%\n",
            "Epoch: 90, Loss: 0.6049, Train: 69.73%, Valid: 64.61%, Test: 65.50%\n",
            "Epoch: 95, Loss: 0.6007, Train: 69.97%, Valid: 64.87%, Test: 65.70%\n",
            "Epoch: 100, Loss: 0.5967, Train: 70.29%, Valid: 65.06%, Test: 65.75%\n",
            "Epoch: 105, Loss: 0.5927, Train: 70.49%, Valid: 65.30%, Test: 66.00%\n",
            "Epoch: 110, Loss: 0.5889, Train: 70.75%, Valid: 65.34%, Test: 66.02%\n",
            "Epoch: 115, Loss: 0.5852, Train: 71.17%, Valid: 65.40%, Test: 66.06%\n",
            "Epoch: 120, Loss: 0.5815, Train: 71.57%, Valid: 65.47%, Test: 66.14%\n",
            "Epoch: 125, Loss: 0.5779, Train: 71.94%, Valid: 65.65%, Test: 66.26%\n",
            "Epoch: 130, Loss: 0.5744, Train: 72.29%, Valid: 65.82%, Test: 66.28%\n",
            "Epoch: 135, Loss: 0.5710, Train: 72.52%, Valid: 65.87%, Test: 66.36%\n",
            "Epoch: 140, Loss: 0.5676, Train: 72.88%, Valid: 65.92%, Test: 66.39%\n",
            "Epoch: 145, Loss: 0.5642, Train: 73.26%, Valid: 65.96%, Test: 66.60%\n",
            "Epoch: 150, Loss: 0.5609, Train: 73.51%, Valid: 65.99%, Test: 66.68%\n",
            "Epoch: 155, Loss: 0.5576, Train: 73.79%, Valid: 66.01%, Test: 66.80%\n",
            "Epoch: 160, Loss: 0.5543, Train: 74.04%, Valid: 66.21%, Test: 66.90%\n",
            "Epoch: 165, Loss: 0.5510, Train: 74.43%, Valid: 66.14%, Test: 66.97%\n",
            "Epoch: 170, Loss: 0.5477, Train: 74.81%, Valid: 66.19%, Test: 67.00%\n",
            "Epoch: 175, Loss: 0.5444, Train: 75.16%, Valid: 66.23%, Test: 67.05%\n",
            "Epoch: 180, Loss: 0.5411, Train: 75.55%, Valid: 66.30%, Test: 67.04%\n",
            "Epoch: 185, Loss: 0.5377, Train: 75.92%, Valid: 66.37%, Test: 67.08%\n",
            "Epoch: 190, Loss: 0.5343, Train: 76.28%, Valid: 66.37%, Test: 67.18%\n",
            "Epoch: 195, Loss: 0.5310, Train: 76.81%, Valid: 66.56%, Test: 67.24%\n",
            "Run 01:\n",
            "Highest Train: 77.07\n",
            "Highest Valid: 66.56\n",
            "Highest Test: 67.27\n",
            "Chosen epoch: 196\n",
            "Final Train: 76.81\n",
            "Final Test: 67.24\n",
            "Epoch: 00, Loss: 0.8329, Train: 50.42%, Valid: 50.40%, Test: 50.61%\n",
            "Epoch: 05, Loss: 0.7880, Train: 53.19%, Valid: 52.76%, Test: 52.80%\n",
            "Epoch: 10, Loss: 0.7556, Train: 55.50%, Valid: 54.95%, Test: 54.87%\n",
            "Epoch: 15, Loss: 0.7304, Train: 57.33%, Valid: 56.96%, Test: 56.56%\n",
            "Epoch: 20, Loss: 0.7106, Train: 59.13%, Valid: 58.72%, Test: 57.59%\n",
            "Epoch: 25, Loss: 0.6948, Train: 60.71%, Valid: 59.58%, Test: 58.85%\n",
            "Epoch: 30, Loss: 0.6821, Train: 61.94%, Valid: 60.48%, Test: 59.83%\n",
            "Epoch: 35, Loss: 0.6717, Train: 62.67%, Valid: 61.22%, Test: 60.68%\n",
            "Epoch: 40, Loss: 0.6630, Train: 63.70%, Valid: 61.68%, Test: 61.31%\n",
            "Epoch: 45, Loss: 0.6555, Train: 64.46%, Valid: 62.24%, Test: 61.94%\n",
            "Epoch: 50, Loss: 0.6488, Train: 65.31%, Valid: 62.78%, Test: 62.67%\n",
            "Epoch: 55, Loss: 0.6428, Train: 65.82%, Valid: 62.98%, Test: 63.31%\n",
            "Epoch: 60, Loss: 0.6372, Train: 66.47%, Valid: 63.41%, Test: 63.44%\n",
            "Epoch: 65, Loss: 0.6319, Train: 67.09%, Valid: 63.54%, Test: 63.63%\n",
            "Epoch: 70, Loss: 0.6270, Train: 67.41%, Valid: 63.64%, Test: 64.00%\n",
            "Epoch: 75, Loss: 0.6224, Train: 67.79%, Valid: 63.89%, Test: 64.25%\n",
            "Epoch: 80, Loss: 0.6181, Train: 68.10%, Valid: 63.99%, Test: 64.40%\n",
            "Epoch: 85, Loss: 0.6141, Train: 68.48%, Valid: 64.21%, Test: 64.61%\n",
            "Epoch: 90, Loss: 0.6103, Train: 68.92%, Valid: 64.30%, Test: 64.77%\n",
            "Epoch: 95, Loss: 0.6067, Train: 69.26%, Valid: 64.40%, Test: 64.88%\n",
            "Epoch: 100, Loss: 0.6033, Train: 69.48%, Valid: 64.49%, Test: 65.01%\n",
            "Epoch: 105, Loss: 0.6000, Train: 69.87%, Valid: 64.57%, Test: 65.13%\n",
            "Epoch: 110, Loss: 0.5967, Train: 70.15%, Valid: 64.57%, Test: 65.21%\n",
            "Epoch: 115, Loss: 0.5936, Train: 70.43%, Valid: 64.82%, Test: 65.26%\n",
            "Epoch: 120, Loss: 0.5906, Train: 70.75%, Valid: 65.06%, Test: 65.21%\n",
            "Epoch: 125, Loss: 0.5876, Train: 71.10%, Valid: 65.21%, Test: 65.25%\n",
            "Epoch: 130, Loss: 0.5847, Train: 71.40%, Valid: 65.36%, Test: 65.28%\n",
            "Epoch: 135, Loss: 0.5818, Train: 71.81%, Valid: 65.56%, Test: 65.41%\n",
            "Epoch: 140, Loss: 0.5790, Train: 72.19%, Valid: 65.64%, Test: 65.41%\n",
            "Epoch: 145, Loss: 0.5761, Train: 72.52%, Valid: 65.78%, Test: 65.55%\n",
            "Epoch: 150, Loss: 0.5732, Train: 72.80%, Valid: 65.88%, Test: 65.76%\n",
            "Epoch: 155, Loss: 0.5704, Train: 73.20%, Valid: 66.06%, Test: 65.94%\n",
            "Epoch: 160, Loss: 0.5676, Train: 73.60%, Valid: 66.12%, Test: 65.98%\n",
            "Epoch: 165, Loss: 0.5648, Train: 73.84%, Valid: 66.24%, Test: 66.03%\n",
            "Epoch: 170, Loss: 0.5620, Train: 74.16%, Valid: 66.29%, Test: 66.19%\n",
            "Epoch: 175, Loss: 0.5592, Train: 74.52%, Valid: 66.60%, Test: 66.48%\n",
            "Epoch: 180, Loss: 0.5563, Train: 74.85%, Valid: 66.62%, Test: 66.47%\n",
            "Epoch: 185, Loss: 0.5534, Train: 75.29%, Valid: 66.86%, Test: 66.76%\n",
            "Epoch: 190, Loss: 0.5506, Train: 75.53%, Valid: 66.83%, Test: 66.81%\n",
            "Epoch: 195, Loss: 0.5477, Train: 75.84%, Valid: 66.84%, Test: 67.10%\n",
            "Run 02:\n",
            "Highest Train: 76.38\n",
            "Highest Valid: 67.33\n",
            "Highest Test: 67.19\n",
            "Chosen epoch: 198\n",
            "Final Train: 76.27\n",
            "Final Test: 66.98\n",
            "Epoch: 00, Loss: 0.8512, Train: 51.77%, Valid: 50.88%, Test: 51.54%\n",
            "Epoch: 05, Loss: 0.8080, Train: 52.54%, Valid: 51.44%, Test: 52.16%\n",
            "Epoch: 10, Loss: 0.7764, Train: 53.07%, Valid: 52.15%, Test: 52.91%\n",
            "Epoch: 15, Loss: 0.7517, Train: 54.03%, Valid: 52.77%, Test: 53.53%\n",
            "Epoch: 20, Loss: 0.7320, Train: 55.08%, Valid: 53.70%, Test: 54.37%\n",
            "Epoch: 25, Loss: 0.7157, Train: 56.11%, Valid: 54.56%, Test: 55.15%\n",
            "Epoch: 30, Loss: 0.7016, Train: 57.18%, Valid: 55.46%, Test: 55.78%\n",
            "Epoch: 35, Loss: 0.6895, Train: 58.04%, Valid: 55.96%, Test: 56.44%\n",
            "Epoch: 40, Loss: 0.6792, Train: 59.06%, Valid: 56.96%, Test: 57.08%\n",
            "Epoch: 45, Loss: 0.6706, Train: 60.10%, Valid: 57.79%, Test: 58.07%\n",
            "Epoch: 50, Loss: 0.6631, Train: 61.20%, Valid: 58.74%, Test: 59.03%\n",
            "Epoch: 55, Loss: 0.6564, Train: 62.35%, Valid: 59.47%, Test: 59.77%\n",
            "Epoch: 60, Loss: 0.6504, Train: 63.22%, Valid: 60.13%, Test: 60.44%\n",
            "Epoch: 65, Loss: 0.6449, Train: 64.16%, Valid: 60.64%, Test: 60.96%\n",
            "Epoch: 70, Loss: 0.6398, Train: 64.81%, Valid: 60.98%, Test: 61.32%\n",
            "Epoch: 75, Loss: 0.6351, Train: 65.39%, Valid: 61.53%, Test: 61.71%\n",
            "Epoch: 80, Loss: 0.6306, Train: 65.93%, Valid: 61.74%, Test: 61.89%\n",
            "Epoch: 85, Loss: 0.6263, Train: 66.48%, Valid: 62.00%, Test: 62.24%\n",
            "Epoch: 90, Loss: 0.6223, Train: 66.88%, Valid: 62.03%, Test: 62.54%\n",
            "Epoch: 95, Loss: 0.6184, Train: 67.18%, Valid: 62.19%, Test: 62.79%\n",
            "Epoch: 100, Loss: 0.6147, Train: 67.61%, Valid: 62.26%, Test: 62.78%\n",
            "Epoch: 105, Loss: 0.6112, Train: 67.95%, Valid: 62.49%, Test: 62.97%\n",
            "Epoch: 110, Loss: 0.6077, Train: 68.23%, Valid: 62.72%, Test: 63.11%\n",
            "Epoch: 115, Loss: 0.6044, Train: 68.41%, Valid: 62.94%, Test: 63.37%\n",
            "Epoch: 120, Loss: 0.6010, Train: 68.79%, Valid: 63.05%, Test: 63.63%\n",
            "Epoch: 125, Loss: 0.5978, Train: 69.03%, Valid: 63.38%, Test: 63.88%\n",
            "Epoch: 130, Loss: 0.5945, Train: 69.35%, Valid: 63.59%, Test: 63.88%\n",
            "Epoch: 135, Loss: 0.5913, Train: 69.68%, Valid: 63.82%, Test: 64.08%\n",
            "Epoch: 140, Loss: 0.5881, Train: 70.01%, Valid: 64.14%, Test: 64.25%\n",
            "Epoch: 145, Loss: 0.5850, Train: 70.32%, Valid: 64.19%, Test: 64.36%\n",
            "Epoch: 150, Loss: 0.5819, Train: 70.62%, Valid: 64.30%, Test: 64.61%\n",
            "Epoch: 155, Loss: 0.5788, Train: 71.06%, Valid: 64.50%, Test: 64.84%\n",
            "Epoch: 160, Loss: 0.5757, Train: 71.33%, Valid: 64.74%, Test: 64.96%\n",
            "Epoch: 165, Loss: 0.5726, Train: 71.70%, Valid: 64.88%, Test: 65.13%\n",
            "Epoch: 170, Loss: 0.5695, Train: 72.01%, Valid: 64.90%, Test: 65.29%\n",
            "Epoch: 175, Loss: 0.5662, Train: 72.40%, Valid: 65.06%, Test: 65.55%\n",
            "Epoch: 180, Loss: 0.5630, Train: 72.67%, Valid: 65.06%, Test: 65.85%\n",
            "Epoch: 185, Loss: 0.5596, Train: 73.05%, Valid: 65.39%, Test: 66.06%\n",
            "Epoch: 190, Loss: 0.5563, Train: 73.33%, Valid: 65.39%, Test: 66.15%\n",
            "Epoch: 195, Loss: 0.5534, Train: 73.65%, Valid: 65.64%, Test: 66.05%\n",
            "Run 03:\n",
            "Highest Train: 74.10\n",
            "Highest Valid: 65.91\n",
            "Highest Test: 66.34\n",
            "Chosen epoch: 200\n",
            "Final Train: 74.00\n",
            "Final Test: 66.05\n",
            "Epoch: 00, Loss: 0.7606, Train: 51.25%, Valid: 50.95%, Test: 51.71%\n",
            "Epoch: 05, Loss: 0.7240, Train: 53.13%, Valid: 52.21%, Test: 53.00%\n",
            "Epoch: 10, Loss: 0.6986, Train: 55.66%, Valid: 54.22%, Test: 54.99%\n",
            "Epoch: 15, Loss: 0.6810, Train: 58.01%, Valid: 56.19%, Test: 56.75%\n",
            "Epoch: 20, Loss: 0.6673, Train: 60.07%, Valid: 57.50%, Test: 58.13%\n",
            "Epoch: 25, Loss: 0.6563, Train: 61.68%, Valid: 58.86%, Test: 59.73%\n",
            "Epoch: 30, Loss: 0.6471, Train: 63.21%, Valid: 60.04%, Test: 60.79%\n",
            "Epoch: 35, Loss: 0.6392, Train: 64.33%, Valid: 61.01%, Test: 61.93%\n",
            "Epoch: 40, Loss: 0.6322, Train: 65.38%, Valid: 61.50%, Test: 62.91%\n",
            "Epoch: 45, Loss: 0.6258, Train: 66.41%, Valid: 62.07%, Test: 63.44%\n",
            "Epoch: 50, Loss: 0.6199, Train: 67.45%, Valid: 62.62%, Test: 63.94%\n",
            "Epoch: 55, Loss: 0.6145, Train: 67.93%, Valid: 63.06%, Test: 64.35%\n",
            "Epoch: 60, Loss: 0.6094, Train: 68.35%, Valid: 63.33%, Test: 64.69%\n",
            "Epoch: 65, Loss: 0.6045, Train: 68.81%, Valid: 63.86%, Test: 64.82%\n",
            "Epoch: 70, Loss: 0.5998, Train: 69.23%, Valid: 64.09%, Test: 65.02%\n",
            "Epoch: 75, Loss: 0.5953, Train: 69.57%, Valid: 64.35%, Test: 65.17%\n",
            "Epoch: 80, Loss: 0.5908, Train: 70.07%, Valid: 64.75%, Test: 65.49%\n",
            "Epoch: 85, Loss: 0.5865, Train: 70.46%, Valid: 64.89%, Test: 65.51%\n",
            "Epoch: 90, Loss: 0.5823, Train: 70.90%, Valid: 65.18%, Test: 65.62%\n",
            "Epoch: 95, Loss: 0.5782, Train: 71.24%, Valid: 65.25%, Test: 65.70%\n",
            "Epoch: 100, Loss: 0.5743, Train: 71.41%, Valid: 65.33%, Test: 65.88%\n",
            "Epoch: 105, Loss: 0.5704, Train: 71.68%, Valid: 65.43%, Test: 66.08%\n",
            "Epoch: 110, Loss: 0.5666, Train: 71.95%, Valid: 65.71%, Test: 66.14%\n",
            "Epoch: 115, Loss: 0.5629, Train: 72.33%, Valid: 65.81%, Test: 66.32%\n",
            "Epoch: 120, Loss: 0.5593, Train: 72.63%, Valid: 65.88%, Test: 66.51%\n",
            "Epoch: 125, Loss: 0.5558, Train: 72.95%, Valid: 66.01%, Test: 66.60%\n",
            "Epoch: 130, Loss: 0.5523, Train: 73.37%, Valid: 66.11%, Test: 66.70%\n",
            "Epoch: 135, Loss: 0.5490, Train: 73.73%, Valid: 66.32%, Test: 66.71%\n",
            "Epoch: 140, Loss: 0.5456, Train: 74.07%, Valid: 66.51%, Test: 66.81%\n",
            "Epoch: 145, Loss: 0.5427, Train: 74.47%, Valid: 66.50%, Test: 66.97%\n",
            "Epoch: 150, Loss: 0.5393, Train: 74.50%, Valid: 66.54%, Test: 66.89%\n",
            "Epoch: 155, Loss: 0.5360, Train: 75.06%, Valid: 66.62%, Test: 67.16%\n",
            "Epoch: 160, Loss: 0.5329, Train: 75.25%, Valid: 66.78%, Test: 67.12%\n",
            "Epoch: 165, Loss: 0.5297, Train: 75.51%, Valid: 66.82%, Test: 67.06%\n",
            "Epoch: 170, Loss: 0.5266, Train: 76.08%, Valid: 66.91%, Test: 67.13%\n",
            "Epoch: 175, Loss: 0.5242, Train: 76.23%, Valid: 66.81%, Test: 67.32%\n",
            "Epoch: 180, Loss: 0.5215, Train: 76.58%, Valid: 67.09%, Test: 67.15%\n",
            "Epoch: 185, Loss: 0.5186, Train: 76.39%, Valid: 66.86%, Test: 66.89%\n",
            "Epoch: 190, Loss: 0.5153, Train: 77.21%, Valid: 67.11%, Test: 67.47%\n",
            "Epoch: 195, Loss: 0.5122, Train: 77.39%, Valid: 67.24%, Test: 67.13%\n",
            "Run 04:\n",
            "Highest Train: 77.68\n",
            "Highest Valid: 67.55\n",
            "Highest Test: 67.52\n",
            "Chosen epoch: 199\n",
            "Final Train: 77.63\n",
            "Final Test: 67.36\n",
            "Epoch: 00, Loss: 0.7950, Train: 49.00%, Valid: 49.91%, Test: 49.12%\n",
            "Epoch: 05, Loss: 0.7410, Train: 50.99%, Valid: 51.06%, Test: 50.31%\n",
            "Epoch: 10, Loss: 0.7140, Train: 53.15%, Valid: 52.82%, Test: 52.22%\n",
            "Epoch: 15, Loss: 0.6978, Train: 54.98%, Valid: 54.02%, Test: 53.57%\n",
            "Epoch: 20, Loss: 0.6850, Train: 56.51%, Valid: 55.64%, Test: 54.84%\n",
            "Epoch: 25, Loss: 0.6743, Train: 58.04%, Valid: 56.63%, Test: 55.86%\n",
            "Epoch: 30, Loss: 0.6646, Train: 59.35%, Valid: 57.51%, Test: 56.67%\n",
            "Epoch: 35, Loss: 0.6562, Train: 60.40%, Valid: 58.53%, Test: 57.43%\n",
            "Epoch: 40, Loss: 0.6486, Train: 61.65%, Valid: 59.35%, Test: 58.26%\n",
            "Epoch: 45, Loss: 0.6419, Train: 63.08%, Valid: 60.05%, Test: 59.24%\n",
            "Epoch: 50, Loss: 0.6356, Train: 64.05%, Valid: 60.88%, Test: 59.89%\n",
            "Epoch: 55, Loss: 0.6299, Train: 65.06%, Valid: 61.46%, Test: 60.48%\n",
            "Epoch: 60, Loss: 0.6246, Train: 65.89%, Valid: 61.86%, Test: 61.05%\n",
            "Epoch: 65, Loss: 0.6195, Train: 66.52%, Valid: 62.02%, Test: 61.71%\n",
            "Epoch: 70, Loss: 0.6146, Train: 67.29%, Valid: 62.33%, Test: 62.41%\n",
            "Epoch: 75, Loss: 0.6099, Train: 67.88%, Valid: 62.92%, Test: 62.97%\n",
            "Epoch: 80, Loss: 0.6053, Train: 68.25%, Valid: 63.14%, Test: 63.24%\n",
            "Epoch: 85, Loss: 0.6008, Train: 68.84%, Valid: 63.53%, Test: 63.68%\n",
            "Epoch: 90, Loss: 0.5964, Train: 69.31%, Valid: 63.76%, Test: 63.88%\n",
            "Epoch: 95, Loss: 0.5922, Train: 69.81%, Valid: 63.89%, Test: 64.00%\n",
            "Epoch: 100, Loss: 0.5881, Train: 70.28%, Valid: 64.13%, Test: 64.28%\n",
            "Epoch: 105, Loss: 0.5842, Train: 70.69%, Valid: 64.43%, Test: 64.52%\n",
            "Epoch: 110, Loss: 0.5803, Train: 70.91%, Valid: 64.52%, Test: 64.65%\n",
            "Epoch: 115, Loss: 0.5766, Train: 71.14%, Valid: 64.61%, Test: 64.81%\n",
            "Epoch: 120, Loss: 0.5730, Train: 71.44%, Valid: 64.82%, Test: 64.94%\n",
            "Epoch: 125, Loss: 0.5694, Train: 71.74%, Valid: 64.96%, Test: 65.00%\n",
            "Epoch: 130, Loss: 0.5660, Train: 72.05%, Valid: 65.06%, Test: 64.91%\n",
            "Epoch: 135, Loss: 0.5625, Train: 72.32%, Valid: 65.14%, Test: 65.01%\n",
            "Epoch: 140, Loss: 0.5590, Train: 72.59%, Valid: 65.28%, Test: 65.25%\n",
            "Epoch: 145, Loss: 0.5556, Train: 73.00%, Valid: 65.25%, Test: 65.34%\n",
            "Epoch: 150, Loss: 0.5522, Train: 73.32%, Valid: 65.38%, Test: 65.38%\n",
            "Epoch: 155, Loss: 0.5488, Train: 73.59%, Valid: 65.42%, Test: 65.45%\n",
            "Epoch: 160, Loss: 0.5455, Train: 73.82%, Valid: 65.59%, Test: 65.57%\n",
            "Epoch: 165, Loss: 0.5422, Train: 74.09%, Valid: 65.70%, Test: 65.63%\n",
            "Epoch: 170, Loss: 0.5389, Train: 74.51%, Valid: 65.91%, Test: 65.83%\n",
            "Epoch: 175, Loss: 0.5356, Train: 74.81%, Valid: 65.97%, Test: 65.98%\n",
            "Epoch: 180, Loss: 0.5323, Train: 75.29%, Valid: 66.02%, Test: 66.06%\n",
            "Epoch: 185, Loss: 0.5289, Train: 75.62%, Valid: 66.09%, Test: 66.43%\n",
            "Epoch: 190, Loss: 0.5256, Train: 76.04%, Valid: 66.27%, Test: 66.50%\n",
            "Epoch: 195, Loss: 0.5222, Train: 76.60%, Valid: 66.40%, Test: 66.57%\n",
            "Run 05:\n",
            "Highest Train: 76.84\n",
            "Highest Valid: 66.59\n",
            "Highest Test: 66.63\n",
            "Chosen epoch: 198\n",
            "Final Train: 76.70\n",
            "Final Test: 66.45\n",
            "All runs:\n",
            "Highest Train: 76.41 ± 1.38\n",
            "Highest Test: 66.99 ± 0.49\n",
            "Highest Valid: 66.79 ± 0.66\n",
            "  Final Train: 76.28 ± 1.37\n",
            "   Final Test: 66.82 ± 0.55\n",
            "Saving results to logs/fb100_edge.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!python3 GKD/main.py --dataset fb100 --rand_split --use_bn --base_model gcn --mode train  --dist_mode gkd --kernel sigmoid --lr 0.0001\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbTjC4LWqJGz",
        "outputId": "87bca5da-5ccc-4bbc-d78b-fa54410a87f4"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(data_dir='data', dataset='fb100', sub_dataset='', cpu=False, seed=42, train_prop=0.5, valid_prop=0.25, protocol='semi', rand_split=True, metric='acc', runs=5, epochs=200, hidden_channels=32, num_layers=3, gat_heads=8, out_heads=1, hops=1, lp_alpha=0.1, gpr_alpha=0.1, jk_type='max', directed=False, num_mlp_layers=1, display_step=5, cached=False, print_prop=False, priv_type='edge', priv_ratio=0.5, save_model=False, save_name='gcn', log_name='none', base_model='gcn', not_load_teacher=False, mode='train', dist_mode='gkd', weight_decay=0.05, dropout=0.0, lr=0.0001, use_bn=True, use_batch=False, batch_size=2048, oracle=False, device=0, alpha=0.5, delta=0.1, use_kd=False, beta=0.0, tau=1.0, kernel='sigmoid', t=1.0, include_last=False, s=2, m=1, lr2=0.001, sim='l2', ker_norm=False)\n",
            "cuda:0\n",
            "fb100\n",
            "Invalid sub_dataname, deferring to Penn94 graph\n",
            "/content/GKD/dataset.py:204: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  edge_index = torch.tensor(A.nonzero(), dtype=torch.long)\n",
            "torch.Size([41554, 1])\n",
            "num nodes 41554 | num classes 2 | num node feats 7833\n",
            "MODEL: GeoDist(\n",
            "  (k): Kernel(\n",
            "    (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  )\n",
            "  (teacher_gnn): ModuleList(\n",
            "    (0): Linear(in_features=7833, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (student_gnn): ModuleList(\n",
            "    (0): Linear(in_features=7833, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  (bns2d): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            ")\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/GKD/main.py\", line 180, in <module>\n",
            "    outputs = model(dataset, dataset_mask, mode='train', dist_mode=args.dist_mode, t=args.t)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/GKD/models.py\", line 68, in forward\n",
            "    return self.forward_student(data_full, data, dist_mode, t)\n",
            "  File \"/content/GKD/models.py\", line 97, in forward_student\n",
            "    return self.gkd(xs, xt, edge_index, edge_index_full, train_idx, share_node_idx)\n",
            "  File \"/content/GKD/models.py\", line 154, in gkd\n",
            "    loss_list.append(self.k.dist_loss(mt, ms, A))\n",
            "  File \"/content/GKD/kernels.py\", line 63, in dist_loss\n",
            "    return (nn.MSELoss(reduction='none')(mt, ms) * (A + (1-A) * self.args.delta)).sum()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\", line 40, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\", line 909, in __rsub__\n",
            "    return _C._VariableFunctions.rsub(self, other)\n",
            "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 6.43 GiB. GPU 0 has a total capacty of 39.56 GiB of which 3.37 GiB is free. Process 92779 has 36.20 GiB memory in use. Of the allocated memory 28.38 GiB is allocated by PyTorch, and 6.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!python3 GKD/main.py --dataset fb100 --rand_split --use_bn --base_model gcn --mode train --priv_type edge --dist_mode gkd --use_kd --lr 0.0001\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uFDWEkQqK5S",
        "outputId": "b0c5a966-6fb2-4dac-c7c6-32d007cac750"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(data_dir='data', dataset='fb100', sub_dataset='', cpu=False, seed=42, train_prop=0.5, valid_prop=0.25, protocol='semi', rand_split=True, metric='acc', runs=5, epochs=200, hidden_channels=32, num_layers=3, gat_heads=8, out_heads=1, hops=1, lp_alpha=0.1, gpr_alpha=0.1, jk_type='max', directed=False, num_mlp_layers=1, display_step=5, cached=False, print_prop=False, priv_type='edge', priv_ratio=0.5, save_model=False, save_name='gcn', log_name='none', base_model='gcn', not_load_teacher=False, mode='train', dist_mode='gkd', weight_decay=0.05, dropout=0.0, lr=0.0001, use_bn=True, use_batch=False, batch_size=2048, oracle=False, device=0, alpha=0.5, delta=0.1, use_kd=True, beta=0.0, tau=1.0, kernel='sigmoid', t=1.0, include_last=False, s=2, m=1, lr2=0.001, sim='l2', ker_norm=False)\n",
            "cuda:0\n",
            "fb100\n",
            "Invalid sub_dataname, deferring to Penn94 graph\n",
            "/content/GKD/dataset.py:204: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  edge_index = torch.tensor(A.nonzero(), dtype=torch.long)\n",
            "torch.Size([41554, 1])\n",
            "num nodes 41554 | num classes 2 | num node feats 7833\n",
            "MODEL: GeoDist(\n",
            "  (k): Kernel(\n",
            "    (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  )\n",
            "  (teacher_gnn): ModuleList(\n",
            "    (0): Linear(in_features=7833, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (student_gnn): ModuleList(\n",
            "    (0): Linear(in_features=7833, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  (bns2d): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            ")\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/GKD/main.py\", line 180, in <module>\n",
            "    outputs = model(dataset, dataset_mask, mode='train', dist_mode=args.dist_mode, t=args.t)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/GKD/models.py\", line 68, in forward\n",
            "    return self.forward_student(data_full, data, dist_mode, t)\n",
            "  File \"/content/GKD/models.py\", line 97, in forward_student\n",
            "    return self.gkd(xs, xt, edge_index, edge_index_full, train_idx, share_node_idx)\n",
            "  File \"/content/GKD/models.py\", line 154, in gkd\n",
            "    loss_list.append(self.k.dist_loss(mt, ms, A))\n",
            "  File \"/content/GKD/kernels.py\", line 63, in dist_loss\n",
            "    return (nn.MSELoss(reduction='none')(mt, ms) * (A + (1-A) * self.args.delta)).sum()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\", line 40, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\", line 909, in __rsub__\n",
            "    return _C._VariableFunctions.rsub(self, other)\n",
            "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 6.43 GiB. GPU 0 has a total capacty of 39.56 GiB of which 3.37 GiB is free. Process 93247 has 36.20 GiB memory in use. Of the allocated memory 28.38 GiB is allocated by PyTorch, and 6.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!python3 GKD/main.py --dataset fb100 --rand_split --use_bn --base_model gcn --mode train  --dist_mode gkd --use_kd --lr 0.0001\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5V2LRs3qMe6",
        "outputId": "3f9300c8-e9ff-4212-86de-f98eb7518bb6"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(data_dir='data', dataset='fb100', sub_dataset='', cpu=False, seed=42, train_prop=0.5, valid_prop=0.25, protocol='semi', rand_split=True, metric='acc', runs=5, epochs=200, hidden_channels=32, num_layers=3, gat_heads=8, out_heads=1, hops=1, lp_alpha=0.1, gpr_alpha=0.1, jk_type='max', directed=False, num_mlp_layers=1, display_step=5, cached=False, print_prop=False, priv_type='edge', priv_ratio=0.5, save_model=False, save_name='gcn', log_name='none', base_model='gcn', not_load_teacher=False, mode='train', dist_mode='gkd', weight_decay=0.05, dropout=0.0, lr=0.0001, use_bn=True, use_batch=False, batch_size=2048, oracle=False, device=0, alpha=0.5, delta=0.1, use_kd=True, beta=0.0, tau=1.0, kernel='sigmoid', t=1.0, include_last=False, s=2, m=1, lr2=0.001, sim='l2', ker_norm=False)\n",
            "cuda:0\n",
            "fb100\n",
            "Invalid sub_dataname, deferring to Penn94 graph\n",
            "/content/GKD/dataset.py:204: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  edge_index = torch.tensor(A.nonzero(), dtype=torch.long)\n",
            "torch.Size([41554, 1])\n",
            "num nodes 41554 | num classes 2 | num node feats 7833\n",
            "MODEL: GeoDist(\n",
            "  (k): Kernel(\n",
            "    (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  )\n",
            "  (teacher_gnn): ModuleList(\n",
            "    (0): Linear(in_features=7833, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (student_gnn): ModuleList(\n",
            "    (0): Linear(in_features=7833, out_features=32, bias=False)\n",
            "    (1-3): 3 x GCNLayer(\n",
            "      (specialspmm): SpecialSpmm()\n",
            "    )\n",
            "  )\n",
            "  (bns): BatchNorm1d(32, eps=1e-10, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  (bns2d): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            ")\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/GKD/main.py\", line 180, in <module>\n",
            "    outputs = model(dataset, dataset_mask, mode='train', dist_mode=args.dist_mode, t=args.t)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/GKD/models.py\", line 68, in forward\n",
            "    return self.forward_student(data_full, data, dist_mode, t)\n",
            "  File \"/content/GKD/models.py\", line 97, in forward_student\n",
            "    return self.gkd(xs, xt, edge_index, edge_index_full, train_idx, share_node_idx)\n",
            "  File \"/content/GKD/models.py\", line 154, in gkd\n",
            "    loss_list.append(self.k.dist_loss(mt, ms, A))\n",
            "  File \"/content/GKD/kernels.py\", line 63, in dist_loss\n",
            "    return (nn.MSELoss(reduction='none')(mt, ms) * (A + (1-A) * self.args.delta)).sum()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\", line 40, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\", line 909, in __rsub__\n",
            "    return _C._VariableFunctions.rsub(self, other)\n",
            "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 6.43 GiB. GPU 0 has a total capacty of 39.56 GiB of which 3.37 GiB is free. Process 93723 has 36.20 GiB memory in use. Of the allocated memory 28.38 GiB is allocated by PyTorch, and 6.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
          ]
        }
      ]
    }
  ]
}